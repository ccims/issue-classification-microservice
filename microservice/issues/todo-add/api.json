[{"labels":[null,"api",null],"text":"I need to use U-Net in Qt5. Before it, I tried to make experiment in cmake. The result was perfect.\r\nHowever, I integrated the code into a Qt5 application to load the same model,  it reported an error. \r\n\r\nThe CMakeList.txt file without Q5:\r\n```\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nproject(custom_ops)\r\nfind_package(Torch REQUIRED)\r\nset(TORCH_DIRS0 /home/SCHUSE/software/libtorch/include)\r\nset(TORCH_DIRS1 /home/SCHUSE/software/libtorch/include/csrc/api/include)\r\nfind_package( OpenCV REQUIRED )\r\ninclude_directories( ${OpenCV_INCLUDE_DIRS} )\r\ninclude_directories( ${TORCH_DIRS0} ${TORCH_DIRS1} )\r\nadd_executable(unet-app unet-app.cpp)\r\ntarget_link_libraries(unet-app ${TORCH_LIBRARIES} ${OpenCV_LIBS})\r\nset_property(TARGET unet-app PROPERTY CXX_STANDARD 11)\r\n```\r\n\r\nHere, its the code of loading model:\r\n```\r\nstd::shared_ptr<torch::jit::script::Module> module = torch::jit::load(argv[1]);\r\n```\r\nIN THIS WAY, THE MODEL WORKS PERFECTLY!!!!!!!!!!!!!!!!!!\r\n\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\nFor the Qt5 application, this application uses gstreamer, opencv and libtorch. The CMakeList.txt file with Qt5:\r\n```\r\nproject(multi_camera)\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nset(CMAKE_CXX_STANDARD 11)\r\nfind_package(PkgConfig REQUIRED)\r\nfind_package(Torch REQUIRED)\r\nfind_package(OpenCV REQUIRED )\r\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${TORCH_CXX_FLAGS}\")\r\n# Enter the directory of the tiscamera repository here:\r\nset(TISCAMERA_DIR /home/yaok/software/camera/tiscamera) \r\nset(TORCH_DIRS0 /home/SCHUSE/software/libtorch/include)\r\nset(TORCH_DIRS1 /home/SCHUSE/software/libtorch/include/csrc/api/include)\r\nset(CUDA_DIR /usr/local/cuda/include )\r\nset(CMAKE_BUILD_TYPE Debug)\r\npkg_check_modules(GSTREAMER REQUIRED gstreamer-1.0 gstreamer-app-1.0 gstreamer-video-1.0)\r\npkg_check_modules(TCAMLIB tcam)\r\n\r\nset(CMAKE_AUTOMOC ON)\r\nset(CMAKE_AUTOUIC ON)\r\nfind_package(Qt5 COMPONENTS Widgets Core Xml)\r\nif (Qt5Widgets_FOUND)\r\n    if (Qt5Widgets_VERSION VERSION_LESS 5.5)\r\n        message(FATAL_ERROR \"Minimum supported Qt5 version is 5.5\" ${Qt5_DIR} ${QT_QMAKE_EXECUTABLE})\r\n    endif()\r\nelse()\r\n    message(SEND_ERROR \"The Qt5Widgets library could not be found!\")\r\nendif(Qt5Widgets_FOUND)\r\n\r\ninclude_directories( ${CMAKE_CURRENT_BINARY_DIR} ${TISCAMERA_DIR}/examples/cpp/common  ${GSTREAMER_INCLUDE_DIRS} ${TCAM_INCLUDE_DIRS} ${OpenCV_INCLUDE_DIRS} ${CUDA_DIR})\r\ninclude_directories( ${TORCH_DIRS0} ${TORCH_DIRS1} )\r\n\r\nadd_definitions(${GSTREAMER_CFLAGS_OTHER})  \r\nadd_executable(multi_camera main.cpp mainwindow.cpp qcameraform.cpp tcamcamera.cpp cpropertiesdialog.cpp qdetthread.cpp qrevthread.cpp qsavethread.cpp segdetector.cpp  )\r\ntarget_link_libraries(multi_camera ${TCAMLIB_LIBRARIES} ${GSTREAMER_LIBRARIES} Qt5::Widgets Qt5::Core Qt5::Xml ${TORCH_LIBRARIES} ${OpenCV_LIBS})\r\nset_property(TARGET multi_camera PROPERTY CXX_STANDARD 11)\r\n```\r\nThe c++ code in QT5:\r\n```\r\nstd::shared_ptr<torch::jit::script::Module> module = torch::jit::load(model_name);\r\n```\r\n\r\nTHE ERROR INFORMATION IS :\r\n```\r\nstart load model: /home/SCHUSE/Downloads/torch_unet/aunet_model.pt\r\nterminate called after throwing an instance of 'std::runtime_error'\r\n  what():  expected ] but found 'number' here:\r\n  _195 = _193.bias\r\n  _196 = getattr(_188, \"4\")\r\n  weight32 = _196.weight\r\n  bias32 = _196.bias\r\n  running_mean32 = _196.running_mean\r\n  running_var32 = _196.running_var\r\n  _197 = self.Conv_Seg\r\n  _198 = _197.weight\r\n  _199 = _197.bias\r\n  input0 = torch._convolution(input, _3, _4, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True)\r\n                                                 ~ <--- HERE\r\n  input1 = torch.batch_norm(input0, weight, bias, running_mean, running_var, False, 0.10000000000000001, 1.0000000000000001e-05, True)\r\n  input2 = torch.relu_(input1)\r\n  input3 = torch._convolution(input2, _7, _8, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True)\r\n  x = torch.batch_norm(input3, weight0, bias0, running_mean0, running_var0, False, 0.10000000000000001, 1.0000000000000001e-05, True)\r\n  identity = torch._convolution(input, _11, _12, [1, 1], [0, 0], [1, 1], False, [0, 0], 1, False, False, True)\r\n  input4 = torch.add_(x, identity, alpha=1)\r\n  input5 = torch.relu_(input4)\r\n  input6 = torch.max_pool2d(input5, [2, 2], [2, 2], [0, 0], [1, 1], False)\r\n  input7 = torch._convolution(input6, _16, _17, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True)\r\nAborted (core dumped)\r\n```\r\nThe environment is:\r\n```\r\n-- Caffe2: CUDA detected: 10.0\r\n-- Caffe2: CUDA nvcc is: /usr/local/cuda-10.0/bin/nvcc\r\n-- Caffe2: CUDA toolkit directory: /usr/local/cuda-10.0\r\n-- Caffe2: Header version is: 10.0\r\n-- Found cuDNN: v7.4.2  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)\r\n-- Autodetected CUDA architecture(s):  6.1\r\n-- Added CUDA NVCC flags for: -gencode;arch=compute_61,code=sm_61\r\n-- Pytorch: 1.1.0\r\n-- libtorch:  libtorch-shared-with-deps-1.1.0\r\n```\r\nActually, I load the same model and I make sure that the path is correct. \r\nNow, I cannot localize the problem and do not know the reason for that error. \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n\ncc @malfet @seemethere @walterddr @yf225 @glaringlee"},{"labels":["api",null,null],"text":"## üìö Documentation\r\n\r\nFor some C++ functions (for example, torch::load), the [function documentation](https://pytorch.org/cppdocs/api/function_namespacetorch_1a4b369494adfb10b9a005aeb0bb6207cb.html?highlight=load) page shows a warning:  \r\n\r\n```\r\n\"doxygenfunction: Unable to resolve multiple matches for function ‚Äútorch::load‚Äù with arguments (std::vector<torch::Tensor>&, LoadFromArgs&&‚Ä¶) in doxygen xml output for project ‚ÄúPyTorch‚Äù from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml.\"\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/39305301/92850084-9ab57180-f41e-11ea-8e73-47015c71c87e.png)\r\n\n\ncc @yf225 @glaringlee @jlin27"},{"labels":["api",null,null],"text":"#39273 updated Python's circular padding, correcting several errors in the previous implementation. PyTorch has two circular padding implementations, however, one in Python and the other in C++:\r\n\r\nhttps://github.com/pytorch/pytorch/blob/7b547f086fbef74dd2e9c07f4392da3a2d3266b4/torch/nn/functional.py#L3831\r\n\r\nhttps://github.com/pytorch/pytorch/blob/46447045ea450069ab9a9cbbf71e86110013fb0b/torch/csrc/api/include/torch/nn/functional/padding.h#L13\r\n\r\nIt seems like we'd prefer to only have one implementation, although the author of this PR expressed that he was not familiar with C++. \n\ncc @yf225 @glaringlee @albanD @mruberry"},{"labels":["api",null,null,null],"text":"## üöÄ Feature\r\nCreate a specialized schema type that can represent None, int, or tuple of ints. Could be named `Dims`, `DimList`, `ReductionDim`, or something else.\r\n\r\n## Motivation\r\n\r\nCurrently, the only single schema type that can do this is `int[1]?`, which is an `optional<IntArrayRef>` in C++. This type seems to almost work correctly, except that if the function is called from C++ with an integer, the `optional<IntArrayRef>` is filled with a garbage value. The value must be wrapped with `IntArrayRef({<value>})` to get correct behavior:\r\n\r\n```\r\nvoid func(optional<IntArrayRef> opt_dims) {\r\n  if (opt_dims.has_value()) {\r\n    for (auto dim : opt_dims.value()) {\r\n      std::cout << dim << \" \" << std::endl;\r\n    }\r\n  }\r\n  std::cout << std::endl;\r\n}\r\n\r\nfunc(23); // This prints out a garbage value\r\nfunc({23}); // This also prints out a garbage value\r\nfunc(IntArrayRef({23})); // This correctly prints out \"23\"\r\n```\r\n\r\nAfter `int[n]?` was introduced, I tried to use it to fix #29137, but the issue with `optional<IntArrayRef>` silently breaks any C++ calls that provide an integer as the dim argument. The C++ API of `at::sum` cannot easily be changed to prevent callers from providing an int--for one, that would be a BC break, but also, there does not seem to be any way to detect whether the `optional<IntArrayRef>` argument was initialized in this faulty way.\r\n\r\nMore details starting here: https://github.com/pytorch/pytorch/pull/43982#issuecomment-689173522\r\nAnd an older discussion starting here: https://github.com/pytorch/pytorch/pull/30822#issuecomment-571818073\r\n\r\n## Pitch\r\n\r\n@zdevito wrote a good pitch here: https://github.com/pytorch/pytorch/pull/30822#issuecomment-572783469\r\n\r\nIf we had a dedicated class to represent an optional list of dimensions, we would avoid having to use `optional<IntArrayRef>`. This dimension list class would have constructors that accept the following:\r\n* An integer\r\n* A list of integers\r\n* A representation of `None` (perhaps c10::nullopt)\r\n\r\n## Alternatives\r\n\r\n\r\n\r\n## Additional context\r\n\r\nI think it's important to consider how this new dimension list class would interact with the `Dimname[n]` schema type, which accepts `None` as a valid value. Currently, if a function has one overload where an argument type is `Dimname[1]`, and another overload where that argument is `int[1]?`, this creates an ambiguous situation since both overloads would accept `None`. Some additional info: https://github.com/pytorch/pytorch/pull/43982#discussion_r481426382\r\n\r\nThis ambiguous situation compiles without error. Apparently codegen will arbitrarily choose which C++ function gets called (perhaps based on the alphabetical order of the schema overload names). To avoid the ambiguity, we could potentially have something like a `DimnameListNotNone` schema type that does everything that `Dimname[1]` does, except that it does not accept `None`. Perhaps there are other possible solutions though.\r\n\r\n@t-vi suggested trying to split `Dimname[1]` into `Dimname?[]` and `Dimname[]`, and I haven't tried that yet. Still, it would not be ideal to have to have two separate overloads for the dimname list case.\r\n\r\n\r\ncc @yf225 @glaringlee @ezyang @bhosmer @smessmer @ljk53 @mruberry @rgommers "},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\nI want to be able to determine the version of libtorch in my c++ binary in cases where I don't have access to the python library.\r\n\r\nSomething like:\r\n```\r\n#define TORCH_VERSION_MAJOR=1\r\n#define TORCH_VERSION_MINOR=6\r\n#define TORCH_VERSION_PATCH=0\r\n```\r\n\r\n## Motivation\r\n\r\nThis is useful for \r\n- Turning off torch features depending on the version of torch we are running\r\n- Debugging which version of torch is installed in production where different versions may be running.\r\n\r\n## Pitch\r\n\r\n1) I'm a developer trying to upgrade the API, but a backwards incompatible API change requires me to refactor code before upgrading.  I need to roll this out so I want to only enable the new features if I build my application for the new version of torch.\r\n2) I'm a site reliability engineer and I am rolling out a the server deploy with a new version of libtorch.  There is a bug that is claimed to be fixed in the newer version of torch and I want to verify that the new version was deployed when I validate this issue is resolved.\r\n\r\n## Alternatives\r\n\r\nCurrently I am pulling the version from the strings in libtorch_cpu.so, but this didn't get updated in v1.6.0.  This is an unreliable hack solution that I would like to remove.\r\n```\r\nstrings libtorch_cpu.so | egrep -A1 pytorch_version\r\npytorch_version\r\n1.5.0\r\n```\r\n\r\npytorch has the version number baked into the pip install and in the torch.__version__.  For my purposes I don't have access to either of these as we are not using python in our production environment and the shared libraries are built separate from the ones in the pip wheel.\r\n\r\n## Additional context\r\n\r\nI recently upgraded to libtorch version 1.6.0 to resolve a segfault on destruction of `DeviceThreadHandlePool` which seemed related to: https://github.com/pytorch/pytorch/pull/36416.  After upgrading I am still seeing some segfaults on destruction, but was worried that I might not have deployed the new version of libtorch.   By looking at other strings in that library I believe I am at v1.6.0, but I wasted some time on the red herring of the 1.5.0 version in the strings of libtorch_cpu.so and would like to avoid that in the future.\n\ncc @yf225 @glaringlee"},{"labels":[null,"api",null,null],"text":"## ‚ùì Questions and Help\r\n\r\nMy work host have all instruction sets, but service hosts are not support service host, such as 'AVX' and 'SSE4', so i want to disable the instruction set before build libtorch. How can I do it?\n\ncc @malfet @seemethere @walterddr @yf225 @glaringlee @jlin27"},{"labels":["api",null,null],"text":"There are 9 boolean flags within TensorImpl.cpp which exceeds 8bytes already.\r\nThis made the size of TensorImpl 1 word bigger than before which is not necessary. (introduced in #33033). \r\n\r\nThe purpose of this  issue is to move all the boolean flags into a 8bytes uint as bitfields, so the size of TensorImpl reduced 1 word. \r\nAnd we will also enhence the note of TensorImpl, making it more clear on the process of modifying TensorImpl.\r\n\r\ncc @yf225 @glaringlee @ezyang @bhosmer @smessmer @ljk53"},{"labels":[null,"api",null],"text":"pr #41911 adds the _fft_ namespace, which steps on the c++ _torch::fft()_ function.\r\n\r\nwhat is the intended workaround?\r\n\r\ncall _at::fft_ ?\r\n\r\nthanks\n\ncc @yf225 @glaringlee"},{"labels":["api",null],"text":"https://github.com/pytorch/pytorch/#from-source indicates indicates that a C++14 compiler is required.  However, extensive use of enable_if_t (and similar) indicates that at least C++17 is required.\n\ncc @yf225 @glaringlee"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nTrying convert a RefArray into a tensor like this  :\r\n \r\n```cpp\r\nauto tmp = torch::ones({2,3});\r\nauto shapes = torch::tensor({tmp.sizes()});\r\n```\r\nresults in this exception message : \r\n```\r\nfalse INTERNAL ASSERT FAILED at \"D:\\\\Codes\\\\cpp\\\\port\\\\LibtorchPort\\\\Dependencies\\\\libtorch-debug-latest\\\\libtorch\\\\include\\\\torch\\\\csrc\\\\api\\\\include\\\\torch\\\\detail\\\\TensorDataContainer.h\":299, please report a bug to PyTorch. TensorDataContainer is already a Tensor type, `fill_tensor` should not be called\r\n```\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nRun this : \r\n \r\n```cpp\r\nauto tmp = torch::ones({2,3});\r\nauto shapes = torch::tensor({tmp.sizes()});\r\n```\r\n## Expected behavior\r\n\r\nShouldnt happen (since it has a `vec()` member which can be automatically used in this case!) or at least should issue a better error message. \r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.6\r\n - OS (e.g., Linux): Windows 10\r\n - How you installed PyTorch (`conda`, `pip`, source): pip for python, downloaded the prebuilt libraries for libtorch\r\n - Build command you used (if compiling from source): - \r\n - Python version: 3.7\r\n - CUDA/cuDNN version: - \r\n - GPU models and configuration: - \r\n - Any other relevant information: I use cpu-mode\n\ncc @yf225 @glaringlee"},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\nCurrently the lack of such function is really felt. for example, when displaying the results on screen, it comes up a lot that you face something like : \r\n```\r\noffsets.shape: [1, 4, 46, 85]\r\nprobs.shape: [46, 85]\r\noffsets: (1,1,.,.) =\r\n 0.01 *\r\n  0.1006  1.2322\r\n  -2.9587 -2.2280\r\n\r\n(1,2,.,.) =\r\n 0.01 *\r\n  1.3772  1.3971\r\n  -1.2813 -0.8563\r\n\r\n(1,3,.,.) =\r\n 0.01 *\r\n  6.2367  9.2561\r\n   3.5719  5.4744\r\n\r\n(1,4,.,.) =\r\n  0.2901  0.2963\r\n  0.2618  0.2771\r\n[ CPUFloatType{1,4,2,2} ]\r\nprobs: 0.0001 *\r\n 1.4593  1.0351\r\n  6.6782  4.9104\r\n[ CPUFloatType{2,2} ]\r\n```\r\nwhere some tensors dims do not show  their finalized output, instead, it seems, a scaler is shown in the output instead which makes it really hard to read, specially when you are porting a Python module into C++ and you want to compare the intermediate outputs for example. \r\nApart from this, specifying the precision, threshold, edgeitems, etc can be very benificial and make life much easier! \r\n\r\n## Motivation\r\n\r\nDuring porting a Python project into C++ for production, I faced this issue, and it creeps up a lot and makes reading and comparing values between Python and C++ very hard. \r\n\r\n## Pitch\r\n\r\nPlease kindly implement set_printoptions in libtorch as well.\r\n\r\n## Alternatives\r\n\r\nThe only alternative is to alter torch code which is a very bad idea! I know no other way around this! \r\n\r\n\r\n\n\ncc @yf225 @glaringlee"},{"labels":["api",null,null,null],"text":"## üêõ Bug\r\n\r\nAs the title suggested, the `right` argument in `torch.bucketize` works opposite to the description of the documentation,\r\nas well as `numpy.digitize`.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Run the example in the docstring, get the same results as in the docstring\r\n```python\r\n>>> boundaries = torch.tensor([1, 3, 5, 7, 9])\r\n>>> v = torch.tensor([[3, 6, 9], [3, 6, 9]])\r\n>>> torch.bucketize(v, boundaries)\r\ntensor([[1, 3, 4],\r\n        [1, 3, 4]])\r\n>>> torch.bucketize(v, boundaries, right=True)\r\ntensor([[2, 3, 5],\r\n        [2, 3, 5]])\r\n```\r\n2. Run it with `numpy.digitize`\r\n```python\r\n>>> boundaries = numpy.array([1, 3, 5, 7, 9])\r\n>>> v = numpy.array([[3, 6, 9], [3, 6, 9]])\r\n>>> numpy.digitize(v, boundaries)\r\narray([[2, 3, 5],\r\n       [2, 3, 5]])\r\n>>> numpy.digitize(v, boundaries, right=True)\r\narray([[1, 3, 4],\r\n       [1, 3, 4]])\r\n```\r\n3. The two functions have consistent docstrings, but give opposite results.\r\n    To me the pytorch results **contradict the documentation**. (**Edited**)\r\n\r\n## Expected behavior\r\n\r\npytorch function behavior should agree with their documentations. (**Edited**)\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.6.0\r\nIs debug build: False\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: CentOS Linux release 7.8.2003 (Core) (x86_64)\r\nGCC version: (GCC) 7.4.0\r\nClang version: Could not collect\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.8 (64-bit runtime)\r\nIs CUDA available: False\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.5\r\n[pip3] torch==1.6.0\r\n[pip3] torchvision==0.7.0\r\n[conda] blas                      1.0                         mkl  \r\n[conda] cudatoolkit               10.2.89              hfd86e86_1  \r\n[conda] magma-cuda102             2.5.2                         1    pytorch\r\n[conda] mkl                       2020.1                      217  \r\n[conda] mkl-include               2020.1                      217  \r\n[conda] mkl-service               2.3.0            py38he904b0f_0  \r\n[conda] mkl_fft                   1.1.0            py38h23d657b_0  \r\n[conda] mkl_random                1.1.1            py38h0573a6f_0  \r\n[conda] numpy                     1.18.5           py38ha1c710e_0  \r\n[conda] numpy-base                1.18.5           py38hde5b4d6_0  \r\n[conda] pytorch                   1.6.0           py3.8_cuda10.2.89_cudnn7.6.5_0    pytorch\r\n[conda] torchvision               0.7.0                py38_cu102    pytorch\r\n\r\ncc @yf225 @glaringlee @mruberry @rgommers"},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\nCurrently the only way that seems to be working to check whether a tensor is empty or not, is to check its `has_storage` method. However, it seems, this method always returns false for SparseTensors . Therefore its not considered a proper/canonical way for checking whether a at::Tensor is empty or not.  \r\nProviding a dedicated property or a method for this purpose, thus goes a long way and will be very much appreciated. \r\n\r\n## Motivation\r\n\r\nDealing with situations, where an empy tensor is returned becasue of meeting or not! meeting some creteria and it needs to be determined whether we are dealing with an empty tensor or not!\r\n\r\n## Pitch\r\n\r\nAdd a property for checking the emptiness of a tensor! in libtorch\r\n\r\n## Alternatives\r\n\r\nCurrently `has_storage` is being used for quering whether a tensor is acually empty or not, but its not the case for SparseTensors! \r\nand wont work for them! \r\n\r\n\n\ncc @yf225 @glaringlee"},{"labels":[null,"api",null,null,null],"text":"## üêõ Bug\r\n\r\nF.mse_loss(a, b, reduction='elementwise_mean') has very different behaviors depending on if `b` require a gradient or not.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nimport torch\r\nfrom torch.nn import functional as F\r\n\r\nA = torch.ones(2)\r\nB = torch.zeros(2, requires_grad=True)\r\nprint(F.mse_loss(A, B, reduction='elementwise_mean'))\r\n\r\nC = torch.zeros(2)\r\nprint(F.mse_loss(A, C, reduction='elementwise_mean'))\r\n```\r\n\r\nreturns\r\n```\r\n# first call takes the sum\r\ntensor(2., grad_fn=<SumBackward0>)\r\n\r\n# second call takes the mean and prints a warning\r\n/home/vitchyr/anaconda2/envs/tmp/lib/python3.6/site-packages/torch/nn/_reduction.py:14: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\r\n  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\r\ntensor(1.)\r\n```\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nI think the second behavior (a deprecation warning and taking the mean) is the correct/expected behavior, but the two behaviors do not match.\r\n\r\n## Environment\r\n```\r\nPyTorch version: 1.6.0\r\nIs debug build: False\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Ubuntu 16.04.6 LTS (x86_64)\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nClang version: Could not collect\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6 (64-bit runtime)\r\nIs CUDA available: False\r\nCUDA runtime version: 10.1.105\r\nGPU models and configuration: \r\nGPU 0: GeForce GTX 1080\r\nGPU 1: GeForce GTX 1080\r\n\r\nNvidia driver version: 418.56\r\ncuDNN version: Probably one of the following:\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudnn.so.6\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudnn.so.7\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.16.3\r\n[pip] torch==1.6.0\r\n[conda] numpy                     1.16.3                   pypi_0    pypi\r\n[conda] torch                     1.6.0                    pypi_0    pypi\r\n```\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\n\r\ncc @ezyang @gchanan @zou3519 @yf225 @glaringlee @albanD @mruberry"},{"labels":["api",null,null],"text":"Currently `src->deleter` is always called, regardless if it's `nullptr` or not. It would be mildly more hassle-free if it checked `if(src->deleter)` prior to calling, just like fromDLPack accommodates not-specified strides.\r\n\r\n```cpp\r\nauto deleter = [src](void* self) {\r\n    src->deleter(const_cast<DLManagedTensor*>(src));\r\n  };\r\n``` \r\nhttps://github.com/pytorch/pytorch/blob/master/aten/src/ATen/DLConvertor.cpp#L215\n\ncc @yf225 @glaringlee"},{"labels":["api",null],"text":"I followed [https://pytorch.org/tutorials/advanced/cpp_export.html](url) to trace a model from existing weights in python as shown below\r\n\r\n`        \r\n\r\n        if self.conf.use_cuda:\r\n            torch.set_default_tensor_type('torch.cuda.FloatTensor')\r\n        else:\r\n            torch.set_default_tensor_type('torch.FloatTensor')\r\n\r\n        self.learner = face_learner(self.conf, self.device)\r\n        # load pretrained model for learner object\r\n        self.learner.model.load_state_dict(torch.load(self.conf.learner_model_path))\r\n        self.learner.model.eval()\r\n\r\n        # read the example image used for tracing\r\n        image=cv2.imread(\"videos/example.jpg\",1)\r\n\r\n        test_transform = trans.Compose([\r\n                    trans.ToTensor(),\r\n                    trans.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\r\n                ])\r\n\r\n        resized_image = cv2.resize(image, (112, 112))\r\n        # Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\r\n        traced_script_module = torch.jit.trace(self.learner.model, test_transform(resized_image).unsqueeze(0).to(self.device))\r\n        traced_script_module.save(\"traced_facelearner_model_new.pt\")\r\n`\r\n\r\nThe face learner model gives 1x512 embedding as output.\r\n\r\n`\r\n\r\n                torch::jit::script::Module model = torch::jit::load(\"traced_facelearner_model_new.pt\");\r\n\t\tmodel.to(torch::kCUDA);\r\n\t\tmodel.eval();\r\n\r\n\t\tcv::Mat visibleFrame = cv::imread(\"example.jpg\");\r\n\r\n\t\tcv::resize(visibleFrame, visibleFrame, cv::Size(112, 112));\r\n\t\tat::Tensor tensor_image = torch::from_blob(visibleFrame.data, { 1, visibleFrame.rows, visibleFrame.cols, 3 }, at::kByte);\r\n\t\ttensor_image = tensor_image.permute({ 0, 3, 1, 2 });\r\n\t\ttensor_image = tensor_image.to(at::kFloat);\r\n\r\n\t\ttensor_image[0][0] = tensor_image[0][0].sub(0.5).div(0.5);\r\n\t\ttensor_image[0][1] = tensor_image[0][1].sub(0.5).div(0.5);\r\n\t\ttensor_image[0][2] = tensor_image[0][2].sub(0.5).div(0.5);\r\n\r\n\t\ttensor_image = tensor_image.to(torch::kCUDA);\r\n\t\tstd::vector<torch::jit::IValue> input;\r\n\t\tinput.emplace_back(tensor_image);\r\n\t\t// Execute the model and turn its output into a tensor.\r\n\t\tauto output = model.forward(input).toTensor();\r\n`\r\n\r\nI'm pretty sure my preprocessing steps on the image in libtorch and pytorch are the same. But the output embedding is still different. \r\nfor eg: python output of first 3 values in the embedding\r\ntensor([[ 2.3617e-02, -1.3115e-02,  7.1695e-02,\r\n\r\nc++ output of first 3 values\r\n Columns 1 to 10 -0.0248 -0.0245 -0.0204\r\n\r\n\r\nPC Specifications:\r\nIntel i7\r\nGtX 970M \r\nWindows 10\n\ncc @suo @gmagogsfm @yf225 @glaringlee"},{"labels":[null,"api",null,null],"text":"## üöÄ Feature\r\nIt would be great for the serialization to be much broader than what it is now in libtorch. at least by providing a way for the users to be able to use existing functionality to serialize their objects. \r\n\r\n## Motivation\r\n\r\nI was trying to serialize a `std::vector<std::tuple<std::string, torch::Tensor>>` in libtorch where I found out its simply impossible. there is no way to extend the `InputArchive ` so I can add the needed logic to load from it. \r\n\r\n## Pitch\r\n\r\nAdd support for `STL` containers at least when it comes to serialization. or allow the users to be able to extend existing functionality to support their own custom types.  \r\n\r\n## Alternatives\r\n\r\nI ultimately ended up using Protobuf for serialization \r\n\n\ncc @yf225 @glaringlee"},{"labels":[null,"api",null,null],"text":"## üêõ Bug\r\n\r\nWe are building libtorch using ./scripts/build_anroid.sh.\r\n\r\nWe need the support for Aten Ops and TorchScript, so building without the BUILD_CAFFE2_MOBILE option.\r\n\r\nThe build is successful, but the library does not link ${TORCH_SRC_DIR}/csrc/api/src/optim/adam.cpp and dependencies because of NO_API being set for Mobile Builds.\r\n\r\nBecause of this I am unable to train the model and instantiate Adam Optimizer instance from the code.\r\n\r\ntorch::optim::Adam optimizer(parameters, lr); //Linker Error\r\noptimizer.zero_grad(); //Linker Error\r\noptimizer.step(); //Linker Error\r\n\r\nFollowing is the Linker error:\r\n/home/atibrewal/work/apprecommender/src/RNNRecommender.cpp:374: undefined reference to `torch::optim::AdamOptions::AdamOptions(double)'\r\n/home/atibrewal/work/apprecommender/src/RNNRecommender.cpp:375: undefined reference to `torch::optim::Optimizer::zero_grad()'\r\n/home/atibrewal/work/apprecommender/src/RNNRecommender.cpp:395: undefined reference to `torch::optim::Adam::step(std::__ndk1::function<at::Tensor ()>)'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `OptimizerParamGroup':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:68: undefined reference to `torch::optim::OptimizerParamGroup::params() const'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:68: undefined reference to `torch::optim::OptimizerParamGroup::has_options() const'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:68: undefined reference to `torch::optim::OptimizerParamGroup::options() const'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `AdamOptions':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/adam.h:21: undefined reference to `vtable for torch::optim::AdamOptions'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/adam.h:21: undefined reference to `vtable for torch::optim::AdamOptions'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `Adam':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/adam.h:52: undefined reference to `vtable for torch::optim::Adam'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/adam.h:52: undefined reference to `vtable for torch::optim::Adam'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `OptimizerOptions':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:49: undefined reference to `vtable for torch::optim::OptimizerOptions'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:49: undefined reference to `vtable for torch::optim::OptimizerOptions'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `Optimizer':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:91: undefined reference to `vtable for torch::optim::Optimizer'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:91: undefined reference to `vtable for torch::optim::Optimizer'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:93: undefined reference to `torch::optim::Optimizer::add_param_group(torch::optim::OptimizerParamGroup const&)'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `~Optimizer':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:103: undefined reference to `vtable for torch::optim::Optimizer'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:103: undefined reference to `vtable for torch::optim::Optimizer'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o:(.data.rel.ro._ZTVN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE[_ZTVN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE]+0x18): undefined reference to `torch::optim::OptimizerOptions::serialize(torch::serialize::InputArchive&)'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o:(.data.rel.ro._ZTVN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE[_ZTVN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE]+0x20): undefined reference to `torch::optim::OptimizerOptions::serialize(torch::serialize::OutputArchive&) const'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o:(.data.rel.ro._ZTIN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE[_ZTIN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE]+0x10): undefined reference to `typeinfo for torch::optim::OptimizerOptions'\r\n\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): Pytorch 1.5.1 and 1.6.0\r\n - OS (e.g., Linux): Android arm64-v8a\r\n - How you installed PyTorch (`conda`, `pip`, source): source\r\n - Build command you used (if compiling from source): /scripts/build_anroid.sh\r\n - Python version: NA\r\n - CUDA/cuDNN version: NA (using a CPU version)\r\n - GPU models and configuration: NA\r\n - Any other relevant information: Android NDK version 19c\r\n\r\n\n\ncc @yf225 @glaringlee @vincentqb"},{"labels":["api",null],"text":"## MultiheadAttention model parameters are different in python and C++.\r\nIn C++, MultiheadAttention module's parameter is no set, its Linear sub-module's parameters can be retrieved C++. \r\nIn python parameters of the module and sub module can be retrieved.\r\n\r\nThe corresponding C++ code with output is as follows\r\n```c++\r\n#include <torch/torch.h>\r\n#include <iostream>\r\nnamespace nn = torch::nn;\r\nint main() {\r\n  int64_t d_model = 4;\r\n  int64_t nhead = 2;\r\n  double dropout = 0.0;\r\n  nn::MultiheadAttention mmodel = nn::MultiheadAttention(nn::MultiheadAttentionOptions(d_model, nhead).dropout(dropout));\r\n  for (const auto& module : mmodel->modules()) {\r\n    std::cout<< \" Module name :\" << module->name() << std::endl;\r\n    for (auto& param : module->named_parameters(false)) {\r\n      std::cout<< param.key() << \":\" << param.value() << std::endl;\r\n    }\r\n  }\r\n}\r\n```\r\nC++ Output:\r\n\r\n Module name :torch::nn::MultiheadAttention\r\n Module name :torch::nn::LinearImpl\r\nweight:-0.3390  0.1080 -0.0194 -0.1426\r\n 0.0612  0.0071  0.1883  0.1399\r\n-0.2122  0.4950 -0.2251  0.0851\r\n 0.3598  0.0617 -0.3281 -0.0391\r\n[ CPUFloatType{4,4} ]\r\nbias: 0\r\n 0\r\n 0\r\n 0\r\n[ CPUFloatType{4} ]\r\n\r\nPython code with output is as follows\r\n\r\n```python\r\nimport torch.nn as nn\r\nd_model = 4\r\nnhead = 2\r\ndropout = 0.0\r\nnet = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\r\nfor m in net.modules():\r\n    print('Module name :', m)\r\n    for nm, p in m.named_parameters(recurse=False):\r\n        print(nm, \":\", p)\r\n```\r\nPython Output:\r\n\r\nModule name : MultiheadAttention(\r\n  (out_proj): _LinearWithBias(in_features=4, out_features=4, bias=True)\r\n)\r\nin_proj_weight : Parameter containing:\r\ntensor([[ 0.3215,  0.1712, -0.4258,  0.0608],\r\n        [ 0.1573, -0.3351, -0.5111,  0.1464],\r\n        [-0.2922,  0.0303,  0.5510, -0.5638],\r\n        [ 0.3144,  0.2177,  0.1631,  0.0863],\r\n        [ 0.5004, -0.2727,  0.3545, -0.1129],\r\n        [ 0.4676, -0.2856, -0.0074, -0.5064],\r\n        [-0.5378,  0.2378,  0.1775, -0.1606],\r\n        [-0.0225, -0.5279,  0.4279, -0.3752],\r\n        [ 0.4622, -0.2481, -0.3727,  0.5852],\r\n        [-0.6048, -0.4132, -0.6092, -0.5233],\r\n        [-0.3640,  0.1864, -0.3457, -0.5625],\r\n        [ 0.2493, -0.3487, -0.3142, -0.1200]], requires_grad=True)\r\nin_proj_bias : Parameter containing:\r\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\r\nModule name : _LinearWithBias(in_features=4, out_features=4, bias=True)\r\nweight : Parameter containing:\r\ntensor([[-0.3266,  0.3457,  0.2251, -0.3043],\r\n        [-0.0438,  0.4598, -0.0973,  0.3782],\r\n        [ 0.0520,  0.3891, -0.1004, -0.2929],\r\n        [ 0.0734,  0.2197, -0.2849,  0.2117]], requires_grad=True)\r\nbias : Parameter containing:\r\ntensor([0., 0., 0., 0.], requires_grad=True)\r\n\r\n\r\nAm I missing something in the C++ usage, or is there a bug. Need help to confirm C++ API usage. \r\n \r\n\n\ncc @yf225 @glaringlee"},{"labels":[null,"api",null,null],"text":"## üöÄ Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\ntorch.nn.Unflatten has been added into pytorch in #41564, it should be added into C++ Frontend as well.\r\n## Motivation\r\nThis is to add torch.nn.Unflatten support in C++ Frontend, so people who is using pure c++ (libtorch for eg) can use this module as well.\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\n\n\ncc @yf225 @glaringlee"},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\nIn the PyTorch Python API, it is possible to move a tensor to shared memory via calling the `Tensor.share_memory_()` function. I could not find similar functionality on the  C++ side using `at::Tensor`.\r\n\r\n## Motivation\r\nI have code that reads tensors from network on the C++ side (using multiple threads). These tensors are then pulled into Python land and go through Python multi-processing transforms. I want to avoid copying tensors across process boundaries, so that the multi-processing transforms can be executed efficiently. To do this, I need to move the tensor storage to shared memory. However, for efficiency purposes, I want to move the tensor memory to shared memory on the C++ side, where I have a thread pool for reading tensors from the network. \r\n\r\nAnother potential area where I am planning to use this feature is out-of process execution of PyTorch scripts in C++ land, where again, we can use shared memory to minimize the cost of transferring tensors across processes.\r\n\r\n## Pitch\r\n\r\nWhat I want is a `share_memory()` method on `at::Tensor`, mimicking the one on PyTorch tensors.\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n\n\ncc @yf225 @glaringlee"},{"labels":[null,"api",null],"text":"## üêõ Bug\r\n\r\nOn Top of Master Linux libtorch torch::cuda::is_available() returns zero even when linked against torch_cuda. I have linked against the latest wget https://download.pytorch.org/libtorch/nightly/cpu/libtorch-shared-with-deps-latest.zip\r\n\r\nIf you put the code inside pytorch's build system with cpp /tests it works ok. \r\n\r\nSnippet:\r\n\r\n    torch::Device device = torch::kCPU;\r\n    std::cout << \"CUDA DEVICE COUNT: \" << torch::cuda::device_count() << std::endl;\r\n    if (torch::cuda::is_available()) {\r\n      std::cout << \"CUDA is available! Training on GPU.\" << std::endl;\r\n      device = torch::kCUDA;\r\n    }\r\n\r\n\r\n\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Download library from https://download.pytorch.org/libtorch/nightly/cpu/libtorch-shared-with-deps-latest.zip\r\n\r\n1. link above program and run. Cuda is not detected. \r\n1.\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\nCuda should be detected. \r\n\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0):\r\n - OS (e.g., Linux):\r\n - How you installed PyTorch (`conda`, `pip`, source):\r\n - Build command you used (if compiling from source):\r\n - Python version:\r\n - CUDA/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":["api",null,null],"text":"I found that it is slow to overwrite existing tensor using tensor::save.\r\n\r\n## Code\r\n```\r\n#include <chrono>\r\n#include <filesystem>\r\n#include <torch/torch.h>\r\n\r\n uint64_t now_ms() {\r\n    return static_cast<uint64_t>(\r\n        std::chrono::time_point_cast<std::chrono::milliseconds>(\r\n            std::chrono::steady_clock::now())\r\n            .time_since_epoch()\r\n            .count());\r\n  }\r\n\r\nint main(int argc, char **argv) {\r\n\r\n  auto tensor = torch::randn({1, 200 * 1024});\r\n  auto begin_ms =now_ms();\r\n  for (int i = 0; i < 100; i++) {\r\n    torch::save(tensor, \"tmp_file\");\r\n  }\r\n  auto end_ms = now_ms();\r\n  std::cout << \"insertion used \" << end_ms - begin_ms << \" ms\" << std::endl;\r\n\r\n  begin_ms = now_ms();\r\n  for (int i = 0; i < 100; i++) {\r\n    std::filesystem::remove(\"tmp_file\");\r\n    torch::save(tensor, \"tmp_file\");\r\n  }\r\n  end_ms = now_ms();\r\n  std::cout << \"insertion used \" << end_ms - begin_ms << \" ms\" << std::endl;\r\n\r\n  return 0;\r\n}\r\n```\r\n\r\n## result\r\ninsertion used 557 ms\r\ninsertion used 82 ms\r\n\r\n## Strace results\r\n\r\n% time     seconds  usecs/call     calls    errors syscall\r\n------ ----------- ----------- --------- --------- ---------------- \r\n54.03    0.051799         517       100           writev\r\n 25.79    0.024721         103       238        92 openat \r\n16.86    0.016168         110       146           close \r\n\r\n\r\n% time     seconds  usecs/call     calls    errors syscall\r\n------ ----------- ----------- --------- --------- ----------------\r\n 61.46    0.020940         209       100           writev \r\n19.27    0.006565          65       100           unlink    \r\n  6.30    0.002147           9       238        92 openat  \r\n3.76    0.001281           9       137           mmap             \r\n  2.01    0.000684           4       146           close \r\n\r\nThe only significant difference between these two blocks is that writev syscall is twice slower in the first case.\r\n\r\n## Expectation\r\nOverwrite should be as fast as removing the old tensor manually\r\n\r\n## Environment\r\nUbuntu 20.04\r\npytorch version is github master\r\n\r\n\n\ncc @yf225 @glaringlee @VitalyFedyunin @ngimel"},{"labels":["api",null,null],"text":"nn::Sequential(nn::Linear(dim_states, h_neurons),\r\n\t\t\t\t\t\t\tnn::Functional(torch::tanh),\r\n\t\t\t\t\t\t\tnn::Linear(h_neurons, h_neurons),\r\n\t                        nn::Functional(torch::tanh),\r\n\t\t\t\t\t\t\tnn::Linear(h_neurons, dim_acts),\r\n\t\t\t\t\t\t\tnn::Functional(torch::softmax(-1)));\r\n\r\ncompile error\r\n../src/actorcritic.cpp:13:40: error: no matching function for call to ‚Äòsoftmax(int)‚Äô\r\n\r\nnn::Functional(torch::softmax((int64_t)-1)  \r\nerror: no matching function for call to ‚Äòsoftmax(int64_t)‚Äô\n\ncc @yf225 @glaringlee @albanD @mruberry"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nMultiheadAttention c++ API did not register parameters under some conditions. The most important ones are 'in_proj_weight' and 'in_proj_bias'.\r\n\r\nHere is the parameter registration phase in c++ impl:\r\nhttps://github.com/pytorch/pytorch/blob/47766e648ff16d4b1175d04710caed566de14ab4/torch/csrc/api/src/nn/modules/activation.cpp#L450\r\n\r\nHere is the parameter registration phase in python impl:\r\nhttps://github.com/pytorch/pytorch/blob/75a4862f639de666c66a0db240c993918b80707f/torch/nn/modules/activation.py#L842\r\n\r\nThe problem here is that in python, the following code will register parameter automatically, but c++ version doesn't.\r\n```\r\nself.in_proj_bias = Parameter(torch.empty(3 * embed_dim))\r\n```\r\nThe reason is that `Module` has a customized __setattr__ which handles the parameter/module registration automatically:\r\nhttps://github.com/pytorch/pytorch/blob/eace0533985641d9c2f36e43e3de694aca886bd9/torch/nn/modules/module.py#L657\r\n\r\nThis will cause problem when people want to update parameters' value by iterating parameter that returned by calling parameters(), since some of the parameters won't be returned by c++ version. Here is an example:\r\nhttps://github.com/pytorch/pytorch/blob/f71cccc457421ad220cf58914c8bc3801b072300/test/test_nn.py#L4678\r\n\r\nThe possible equivalent c++ impl will be something like this:\r\n```\r\ntorch::MultiheadAttention model(torch::MultiheadAttentionOptions(4, 2).dropout(0.0));\r\n{\r\n    torch::NoGradGuard guard;\r\n    for (auto& p : model->parameters()) {\r\n      auto sz = p.view(-1).size(0);\r\n      p.copy_(torch::cos(torch::arange(0, sz, tensor_options).view(p.sizes())));\r\n    }\r\n}\r\n```\r\nCurrently, c++ code will return two less parameters from module->parameters() than python version due to not registering the parameter correctly.\r\n\r\n## To Reproduce\r\n\r\nAbove c++ code piece is an example.\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nPython and c++ api should return same number of parameters when calling parameters().\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\n ```\r\nPyTorch version: 1.7.0a0+fced54a\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2\r\n\r\nOS: CentOS Linux 7 (Core)\r\nGCC version: (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.8\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.2.88\r\nGPU models and configuration: \r\nGPU 0: Tesla M40\r\nGPU 1: Tesla M40\r\n\r\nNvidia driver version: 418.126.02\r\ncuDNN version: Probably one of the following:\r\n/usr/lib64/libcudnn.so.7.6.5\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so.7.1.4\r\n```\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\n\r\ncc @yf225 @glaringlee"},{"labels":["api",null,null],"text":"## üöÄ Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\nWhen I try to load a plugin library built with 2 cpp file,\r\n```python\r\ntorch.ops.load_library(\"libtorch_plugins.so\")\r\n```\r\n\r\nI got the following error:\r\n```\r\nOnly a single TORCH_LIBRARY can be used to register the namespace decode; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  Previous registration of TORCH_LIBRARY was registered at /home/cloudhan/workspaces/torch_plugins/src/readjpeg_cpu.cpp:146; latest registration was registered at /home/cloudhan/workspaces/torch_plugins/src/readpng_cpu.cpp:87\r\n```\r\n\r\n## Motivation\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\nCurrently, the only valid way to build a plugin library is to collect all op registration into one translation unit. \r\nThat is\r\n```cpp\r\n// file foo.cpp\r\n\r\n// define op foo\r\n```\r\n\r\n```cpp\r\n// file bar.cpp\r\n\r\n// define op bar\r\n```\r\n\r\n```cpp\r\n// registration.cpp\r\n\r\n#include \"foo.h\"\r\n#include \"bar.h\"\r\n\r\n// register ops foo and bar \r\n```\r\nIn this way, it is hard to maintain flexible extension op set. Since to add a new op,  you need to directly modify `registration.cpp`\r\nTo remove unneeded ops, you also need to modify `registration.cpp`\r\n\r\nIf distributed registration is supported, all I need is\r\n```cpp\r\n// file foo.cpp\r\n\r\n// define op foo\r\n// register op foo\r\n```\r\n\r\n```cpp\r\n// file bar.cpp\r\n\r\n// define op bar\r\n// register op bar \r\n```\r\n\r\nSimply control which cpp file to be compiled and linked, I can now control the registration easier.\r\n\r\n\n\ncc @yf225 @glaringlee @ezyang @bhosmer @smessmer @ljk53"},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\nFor a torch::PackedTensorAccessor object, when we access the elements of its, check, or cast the indexing number type.\r\n## Motivation\r\n```\r\ntorch::PackedTensorAccessor<scalar_t,1,torch::RestrictPtrTraits,size_t> some_values;\r\n\r\nconst float idx_float = some_index;\r\nconst int idx_int = some_index;\r\n\r\nsome_values[idx_float ] // may get weird results while no warning or error at all\r\nsome_values[idx_int]    // correct way\r\n```\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\n\r\n## Pitch\r\nplease consider adding type checking or type casting to the indexing number.\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\n\ncc @yf225 @glaringlee"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\ni am working on translating pytorch code to c++ environment.\r\nat the pytorch code there is support to take and provide tensors of indexes along different dimensions, which change the output tensor shape,\r\nthis feature is not supported at the c++ framework  \r\n\r\nSteps to reproduce the behavior:\r\nat pytorch:\r\n\r\n1. tensor = torch.arange(25*4*96*170).reshape(25,4,96,170)\r\n2. a = torch.arange(25)\r\n3. x=a\r\n4. y=a\r\n5. output = tensor[a, :, y, x]\r\n\r\noutput shape is: [25,4]\r\n\r\nthought maybe to use the torch::index function, but it fails when number of dimensions is larger than 3.\r\n\r\nhow do i produce the same behavior at the c++ framework?\r\n\r\n - PyTorch Version (e.g., 1.0): torch==1.3.0\r\n - OS (e.g., Linux): Linux\r\n - Python version: Python 3.6.8\r\n\r\n\n\ncc @yf225 @glaringlee"},{"labels":[null,"api"],"text":"I have a code that successfully compiles on some machines but not on the others. \r\n\r\nproject structure:\r\nforeach_cuda\r\n--[libtorch]\r\n--CMakeLists.txt\r\n--main.cu\r\n--[build] \r\n\r\n**How am i running it**\r\n-> module list \r\n 1) cuda/10.2   2) cudnn/v7.6.5.32-cuda.10.2\r\n\r\n-> cd build \r\n-> cmake -DCMAKE_PREFIX_PATH=/private/home/iuriiz/fun/cuda-tutorial/libtorch ..\r\n-> cmake --build . --config Release\r\nFAIL\r\n\r\nBuild error: \r\n_make[2]: *** No rule to make target '/usr/local/cuda/lib64/libnvToolsExt.so', needed by 'foreach_cuda'.  Stop.\r\nCMakeFiles/Makefile2:72: recipe for target 'CMakeFiles/foreach_cuda.dir/all' failed\r\nmake[1]: *** [CMakeFiles/foreach_cuda.dir/all] Error 2\r\nMakefile:83: recipe for target 'all' failed\r\nmake: *** [all] Error 2_\r\n\r\n**Setup**\r\nMachine: internal devfair\r\nCUDA version: 10.2\r\nLibtorch: https://download.pytorch.org/libtorch/cu102/libtorch-shared-with-deps-1.5.1.zip\r\n\r\n**Code**\r\nCMakeLists.txt\r\n```\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nproject(foreach_cuda)\r\n\r\nfind_package(Torch REQUIRED)\r\nfind_package(CUDA REQUIRED)\r\n\r\ncuda_add_executable(foreach_cuda main.cu)\r\n\r\ntarget_link_libraries(foreach_cuda \"${TORCH_LIBRARIES}\")\r\nset_property(TARGET foreach_cuda PROPERTY CXX_STANDARD 14)\r\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${TORCH_CXX_FLAGS}\")\r\n```\r\n\r\nmain.cu\r\n\r\n```\r\n#include <iostream>\r\n#include <math.h>\r\n#include <torch/torch.h>\r\n#include <torch/cuda.h>\r\n#include <cuda.h>\r\n#include <cuda_runtime.h>\r\n#include <ATen/ATen.h>\r\n#include <ATen/AccumulateType.h>\r\n#include <ATen/cuda/CUDAContext.h>\r\n#include <ATen/cuda/Exceptions.h>\r\n#include <chrono>\r\n\r\n\r\nint main(void)\r\n{\r\n  std::cout << \"CUDA available: \" << torch::cuda::is_available() << std::endl;\r\n  \r\n  return 0;\r\n}\r\n```\r\n\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":[null,null,"api",null,null],"text":"We now fully support undefined Tensors in the backward pass to represent a Tensor full of zeroes.\r\nWe should leverage this and stop creating full size Tensors for custom Function (both on python and cpp side)\n\ncc @ezyang @SsnL @albanD @zou3519 @gqchen @yf225 @glaringlee @VitalyFedyunin @ngimel"},{"labels":["api",null,null],"text":"I want build some preprocess tensor in my c++ codeÔºå example as\r\n\r\n    # include \"common/libtorch/include/torch/script.h\"\r\n    # include \"common/libtorch/include/torch/csrc/api/include/torch/torch.h\"\r\n    # include <iostream>\r\n    # include <vector>\r\n    using namespace std;\r\n    int main(int argc, char *argv[]) {\r\n        // ÊûÑÂª∫Á§∫‰æãËæìÂÖ•\r\n        // std::vector<torch::jit::IValue> inputs;\r\n        std::vector<int64_t> res_data;\r\n        res_data.resize(1 * 3* 16 * 16);\r\n        cout << res_data.size() << endl;\r\n        torch::Tensor res_tensor = torch::from_blob(res_data.data(),{1, 3, 16, 16}, torch::kInt64);\r\n        cout << \"OK\" << endl;\r\n    }\r\n\r\nbut i got the error:\r\n\r\n    terminate called after throwing an instance of 'std::system_error'\r\n    what():  Unknown error -1\r\n    Aborted (core dumped)\r\n\r\nmy g++ version=5.5Ôºåusing std=c++14 optionÔºåmy libtorch version=1.5. Is someone know about this error ? thank you very much !!\r\n\r\n    \n\ncc @yf225 @glaringlee"},{"labels":["api",null,null],"text":"## üìö Documentation\r\n\r\nhttps://pytorch.org/cppdocs/api/classat_1_1_tensor.html#_CPPv4NK2at6Tensor4itemEv\r\nand\r\nhttps://pytorch.org/cppdocs/api/classat_1_1_tensor.html#_CPPv4I0ENK2at6Tensor4itemE1Tv\r\n\r\nare both missing descriptions.\r\n\r\n--------\r\n\r\nI am trying to get a `float` out of a `Tensor` (that is a single element, kFloat32) on the GPU.\r\n\r\ne.g.\r\n`float x = x_tensor.item()`\r\nHowever, this gives a compile-time error:\r\n`error: cannot convert ‚Äòc10::Scalar‚Äô to ‚Äòdouble‚Äô in assignment`\r\n\r\nUsing `float x = x_tensor<float>.item()` compiles just fine, doesn't work either (program spins forever, probably waiting for CUDA kernel to end after a bad memory access or something).\r\n\r\nWhat is the proper way to get the float out of the tensor (and back into main memory)? It prints just fine, so it must be doable.\r\nI'd prefer to do it without printing and parsing or moving the entire tensor back to the CPU.\n\ncc @yf225 @glaringlee @jlin27"},{"labels":[null,"api",null,null],"text":"My previous program based on  libtorch  1.0.0 Slow down 100ms after the upgrade. And then I find that the same code ran libtorch1.0.0 would be faster than 1.3.0-1.5.1. That's why?  1.1.0-1.2.0 I have not test.\r\n\n\ncc @suo @gmagogsfm @yf225 @glaringlee @VitalyFedyunin @ngimel"},{"labels":["api",null,null],"text":"I'm trying to deploy a yolov5s model in my C++ program.\r\nI followed the instructions in [https://gist.github.com/jakepoz/eb36163814a8f1b6ceb31e8addbba270](url) to get a torchscript converted model.\r\nThese are my C++ code, I put these code in a thread in ORBSLAM (a SLAM system), meanwhile there are other SLAM threads running.\r\n```cpp\r\n  modelpath = \"yolov5s.torchscript\";\r\n  cout << \"before loading\" << endl;\r\n  long start = time_in_ms();\r\n  model = torch::jit::load(modelpath);\r\n  long end = time_in_ms();\r\n  cout << \"it took \" << end - start << \" ms to load the model\" << endl;\r\n  torch::jit::getProfilingMode() = false;\r\n  torch::jit::getExecutorMode() = false;\r\n  torch::jit::setGraphExecutorOptimize(false);\r\n\r\n  tensor_image = torch::zeros((1, 3, 640,640));\r\n  long start = time_in_ms();\r\n  std::vector<torch::jit::IValue> inputs;\r\n  inputs.push_back(torch::ones({1, 3, 640, 640}));\r\n  //inputs.emplace_back(tensor_image);\r\n  torch::jit::IValue output = model.forward(inputs);\r\n  long end = time_in_ms();\r\n  cout << \"it took \" << end - start << \" ms to run the model once\" << endl;\r\n```\r\n\r\nIt took 720ms to load the model and 1300ms to run the model once.\r\nBut when I run this model in python environment, it only takes 200ms.\r\nI would like to know if it's reasonable or what should I do to accelerate this.\r\n\r\n\r\n\r\n\r\n\r\n\n\ncc @yf225 @glaringlee @VitalyFedyunin @ngimel"},{"labels":[null,"api",null,null],"text":"When I work on torchvision I would like to see color from my compiler, but I don't have it.\n\ncc @yf225 @glaringlee"},{"labels":["api",null,null],"text":"## üêõ Bug\r\n\r\nI followed the example for [bind_module](https://pytorch.org/cppdocs/api/function_namespacetorch_1_1python_1a977cbbe6d9378ef36203873c87858095.html?highlight=pybind11_module) to test a simple python wrapper for a `torch::nn::Module subclass`. It compiles just fine, but when I try to import the compiled module, I get the error `ImportError: generic_type: type \"Net\" referenced unknown base type \"torch::nn::Module\"`.\r\n\r\n## To Reproduce\r\nSteps to reproduce the behavior:\r\n1. Create the following file structure\r\n```\r\n‚îú‚îÄ‚îÄ setup.py\r\n‚îú‚îÄ‚îÄ src\r\n     ‚îú‚îÄ‚îÄ pybind\r\n             ‚îî‚îÄ‚îÄ test_pybindings.cpp\r\n```\r\n2. `test_pybindings.cpp`:\r\n```\r\n#include <torch/torch.h>\r\n#include <torch/python.h>\r\n\r\nstruct Net : torch::nn::Module {\r\n    Net(int in, int out) { }\r\n    torch::Tensor forward(torch::Tensor x) { return x; }\r\n};\r\n\r\nPYBIND11_MODULE(test_module, m) {\r\n    torch::python::bind_module<Net>(m, \"Net\")\r\n        .def(py::init<int, int>())\r\n        .def(\"forward\", &Net::forward);\r\n}\r\n```\r\n\r\n3. `setup.py` (based on the example from [here](https://pytorch.org/docs/stable/cpp_extension.html#torch.utils.cpp_extension.CppExtension):\r\n```\r\nimport sys\r\nimport torch.cuda\r\nfrom setuptools import setup\r\nfrom torch.utils.cpp_extension import BuildExtension, CppExtension, CUDAExtension\r\nfrom torch.utils.cpp_extension import CUDA_HOME\r\n\r\next_modules = [\r\n    CppExtension(\r\n        'test_module',\r\n        ['src/pybind/test_pybindings.cpp'],\r\n        extra_compile_args=['-O3', '-g', '-Werror', '-fopenmp'])\r\n]\r\nsetup(name='test_module', ext_modules=ext_modules,\r\n        cmdclass={'build_ext': BuildExtension})\r\n```\r\n\r\n4. Alternatively, `CMakeLists.txt` (gives the same error):\r\n```    \r\ncmake_minimum_required(VERSION 2.8.8)\r\nproject(test_module)\r\n\r\n# Set this to something else on the command line if the path is different\r\nif (NOT CUDA_TOOLKIT_ROOT_DIR)\r\n    set(CUDA_TOOLKIT_ROOT_DIR /usr/local/cuda)\r\nendif()\r\n\r\nfind_package(Torch REQUIRED)\r\n\r\n# Try to compile with c++14\r\n# http://stackoverflow.com/a/25836953\r\ninclude(CheckCXXCompilerFlag)\r\nCHECK_CXX_COMPILER_FLAG(\"-std=c++14\" COMPILER_SUPPORTS_CXX14)\r\nif(COMPILER_SUPPORTS_CXX14)\r\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++14\")\r\n    message(STATUS \"The compiler ${CMAKE_CXX_COMPILER} supports C++14.\")\r\nelse()\r\n    message(STATUS \"The compiler ${CMAKE_CXX_COMPILER} has no C++14 support. Please use a different C++ compiler.\")\r\nendif()\r\n\r\n# Enable compile optimizations and necessary flags\r\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -O3 -fopenmp -fPIC\")\r\n\r\n# Enable debug flags (use if you want to debug in gdb)\r\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g3 -Wall\")\r\n\r\n# Include our header files\r\ninclude_directories(${TORCH_INCLUDE_DIRS})\r\n\r\n\r\n# TORCH_LIBRARIES doesn't include torch_python, so just get the path ourselves\r\nlink_directories(${TORCH_INSTALL_PREFIX}/lib/)\r\nadd_subdirectory(pybind11)\r\n\r\npybind11_add_module(test_module src/pybind/test_pybindings.cpp)\r\ntarget_link_libraries(test_module\r\n        PRIVATE c10 torch torch_cpu torch_python)\r\n```\r\n\r\n## Expected behavior\r\n\r\nWithin the proper build directory (or by adding it to the `PYTHONPATH`) I would expect `python3 -c \"import test_module\"` to run without error, but it gives:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nImportError: generic_type: type \"Net\" referenced unknown base type \"torch::nn::Module\"\r\n```\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.6.0a0+dfbf016\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Ubuntu 16.04.6 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.2.89\r\nGPU models and configuration: GPU 0: GeForce RTX 2070 SUPER\r\nNvidia driver version: 450.36.06\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.19.0\r\n[pip3] torch==1.6.0a0+dfbf016\r\n[conda] Could not collect\r\n\r\n\r\n## Additional context\r\n\r\nNote that I installed pytorch from source with `python3 setup.py install --user`, and set `Torch_DIR` in my `.bashrc` to `~/.local/lib/python3.6/site-packages/torch/share/cmake/Torch` to allow the cmake build (which is preferred but not required for me), and to have the C++ torch and python version be the same build. \r\nI am on the master branch commit dfbf0164c9d47e89ec019668f3cc92ac345cfc8f.\r\n\n\ncc @yf225 @glaringlee"},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\n\r\nThe ability to turn off scientific notation (standard form) using the C++ API.\r\n\r\n## Motivation\r\n\r\nIt would be useful to turn off the scientific notation used to display tensors. Sometimes I will often get numbers like: 9.9999e-01 which - in the common tongue - is more frequently known as 0.9999 or 1.0. This notation can be really helpful for very small numbers close to zero but in certain situations it is just confusing.\r\n\r\n## Pitch\r\n\r\nIt would be nice to have an option when creating tensors to turn off scientific notation.\r\n\n\ncc @yf225 @glaringlee"},{"labels":["api",null,null,null],"text":"## üêõ Bug\r\n\r\nUsing the data_parallel C++ interface results in code that is much slower on multiple GPUs than on a single GPU.  In addition, the GPU utilization is less than 10% with muliple GPUs compared to over 96% with a single GPU.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n Implement a non-trivial model (e.g. ResNet50 or SlowFast) using the libtorch c++ interface (I used libtorch-win-shared-with-deps-1.5.0.zip + cuda 10.1)\r\n\r\nAdd mulitiple GPU support via torch::nn::parallel::data_parallel\r\n\r\nTime training runs with a single GPU and with multiple GPUs \r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nRuns with multiple GPUs should be faster than runs on a single GPU.  Definitely not *much* slower.\r\n\r\n## Environment\r\n\r\n\r\n - PyTorch Version (e.g., 1.0): LibTorch 1.5.0 pre-built library\r\n - OS (e.g., Linux): Windows 7\r\n - How you installed PyTorch (`conda`, `pip`, source): N/A\r\n - Build command you used (if compiling from source): \r\n - Python version: N/A\r\n - CUDA/cuDNN version: 10.1\r\n - GPU models and configuration: 2x GTX 1080\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\nThis is in line with what @dmagee reported in #18837. Looking though the code, it appears as if replicas of the modules are cloned and deleted on every iteration of training. Is there a way to use data_parallel and avoid this overhead?\n\ncc @VitalyFedyunin @ngimel @yf225 @glaringlee @albanD @mruberry"},{"labels":[null,"api",null,null],"text":"I want to perform on the GPU non-maximum-suppression on the output of a darknet/yolo CNN. \r\nThe following testing code works fine : \r\n\r\n//Credits: adapted from https://github.com/pprp to test nms parallel algo with at::Tensor as input\r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include \"string\"\r\n//#include <windows.h>//needed for LoadLibrary\r\n#include <cuda_runtime.h>\r\n#include <iostream>\r\n#include <opencv2/core/core.hpp>\r\n#include <opencv2/highgui/highgui.hpp>\r\n#include \"opencv2/imgproc/imgproc.hpp\"\r\n#include \"device_launch_parameters.h\"\r\n\r\n#include \"device_functions.h\"\r\n\r\n#include <ATen/ATen.h>\r\n#include <ATen/cuda/CUDAContext.h>\r\n#include <THC/THC.h>\r\n#include <THC/THCDeviceUtils.cuh>\r\n\r\n\r\n#include \"torch/torch.h\"//->including torch gives problems!!!???\r\n\r\n\r\nusing namespace std;\r\n\r\n#define HANDLE_ERROR(ans) { gpuAssert((ans), __FILE__, __LINE__); }\r\n\r\ninline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\r\n{\r\n\tif (code != cudaSuccess)\r\n\t{\r\n\t\tfprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\r\n\t\tif (abort) exit(code);\r\n\t}\r\n}\r\n\r\n\r\ntypedef struct\r\n{\r\n\tdouble x,y,w,h;\r\n\tchar s[100];\r\n\tchar cls[100];\r\n\tdouble cmps;\r\n}box;\r\n\r\n__device__ inline float devIoU(float const* const   b1, float const* const  b2) {\r\n\tfloat ai = (float)(b1[2] + 1) * (b1[3] + 1);\r\n\tfloat aj = (float)(b2[2] + 1) * (b2[3] + 1);\r\n\tfloat x_inter, x2_inter, y_inter, y2_inter;\r\n\r\n\tx_inter = max(b1[0], b2[0]);\r\n\ty_inter = max(b1[1], b2[1]);\r\n\r\n\tx2_inter = min((b1[0] + b1[2]), (b2[0] + b2[2]));\r\n\ty2_inter = min((b1[1] + b1[3]), (b2[1] + b2[3]));\r\n\r\n\tfloat w = (float)max((float)0, x2_inter - x_inter);\r\n\tfloat h = (float)max((float)0, y2_inter - y_inter);\r\n\r\n\tfloat inter = ((w * h) / (ai + aj - w * h));\r\n\treturn inter;\r\n}\r\n\r\n\r\n__global__ void NMS_GPU(const int n_boxes, const float nms_overlap_thresh,\r\n\tconst float* dev_boxes, bool* d_res) {\r\n\tunsigned int xIndex = blockIdx.x * blockDim.x + threadIdx.x;\r\n\t//unsigned int xIndex = threadIdx.x;//only 1 block with index 0!\r\n\tfloat cur_box[5];\r\n\tfloat a_box[5];\r\n\tcur_box[0] = dev_boxes[xIndex * 5 + 0];\r\n\tcur_box[1] = dev_boxes[xIndex * 5 + 1];\r\n\tcur_box[2] = dev_boxes[xIndex * 5 + 2];\r\n\tcur_box[3] = dev_boxes[xIndex * 5 + 3];\r\n\tcur_box[4] = dev_boxes[xIndex * 5 + 4];\r\n\t//__syncthreads();//not necessary as cur_box is not a shared resource\r\n\tfor (int i = 0; i < 19; i++)\r\n\t{\r\n\t\tif (i != xIndex)\r\n\t\t{\r\n\t\t\ta_box[0] = dev_boxes[i * 5 + 0];\r\n\t\t\ta_box[1] = dev_boxes[i * 5 + 1];\r\n\t\t\ta_box[2] = dev_boxes[i * 5 + 2];\r\n\t\t\ta_box[3] = dev_boxes[i * 5 + 3];\r\n\t\t\ta_box[4] = dev_boxes[i * 5 + 4];\r\n\t\t\tif (a_box[4] < cur_box[4] )\r\n\t\t\t{\r\n\t\t\t\tif (devIoU(a_box, cur_box) > nms_overlap_thresh)\r\n\t\t\t\t{\r\n\t\t\t\t\td_res[i] = false;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n\r\n\r\n\r\nint main()\r\n{\r\n\tint const threadsPerBlock = sizeof(unsigned long long) * 8;//Bufo : =64(float size)\r\n\t//LoadLibrary(TEXT(\"D:\\\\dev\\\\Cpp\\\\dependencies\\\\torchnew\\\\lib\\\\torch_cuda.dll\"));\r\n\tat::DeviceType device_type;\r\n\r\n\tif (at::cuda::is_available()) {\r\n\t\tdevice_type = at::kCUDA;\r\n\t}\r\n\telse {\r\n\t\tdevice_type = at::kCPU;\r\n\t\tstd::cout << \"No GPU avalaible, sorry ...\" << std::endl;\r\n\t\treturn 0;\r\n\t}\r\n\tat::Device device(device_type);\r\n\tstd::cout << \"Device : \" << device_type << std::endl;\r\n\r\n\tconst int count = 19;\r\n\tcv::Mat temp = cv::imread(\"Cow_45.jpg\",1);\r\n\r\n\tbool *h_res =(bool*)malloc(sizeof(bool)*count);//contains the result of the nms algo (cpu context)\r\n\tfor(int i=0; i<count; i++)\r\n\t{\r\n\t\th_res[i] = true;\r\n\t}\r\n\r\n\tbox b[count];\r\n\tb[0].x = 996.000000;b[0].y = 2566.420000;b[0].w = 170.793000;b[0].h=172.580000;\r\n\tstrcpy(b[0].cls,\"nose\");strcpy(b[0].s,\"0.983194\");b[0].cmps=0.983194;\r\n\tb[1].x = 4238.937000;b[1].y = 1594.513000;b[1].w = 160.063000;b[1].h=148.487000;\r\n\tstrcpy(b[1].cls,\"eye\");strcpy(b[1].s,\"0.992166\");b[1].cmps=0.992166;\r\n\tb[2].x = 4656.389000;b[2].y = 2175.186000;b[2].w = 316.180000;b[2].h=221.552000;\r\n\tstrcpy(b[2].cls,\"nose\");strcpy(b[2].s,\"0.994816\");b[2].cmps=0.994816;\r\n\tb[3].x = 4316.000000;b[3].y = 1660.000000;b[3].w = 127.474000;b[3].h=113.452000;\r\n\tstrcpy(b[3].cls,\"eye\");strcpy(b[3].s,\"0.990833\");b[3].cmps=0.990833;\r\n\tb[4].x = 997.013000;b[4].y = 2664.408000;b[4].w = 222.214000;b[4].h=229.068000;\r\n\tstrcpy(b[4].cls,\"nose\");strcpy(b[4].s,\"0.985067\");b[4].cmps=0.985067;\r\n\tb[5].x = 666.069000;b[5].y = 2029.219000;b[5].w = 135.689000;b[5].h=160.833000;\r\n\tstrcpy(b[5].cls,\"eye\");strcpy(b[5].s,\"0.993240\");b[5].cmps=0.993240;\r\n\tb[6].x = 4653.547000;b[6].y = 2324.000000;b[6].w = 338.125000;b[6].h=133.902000;\r\n\tstrcpy(b[6].cls,\"nose\");strcpy(b[6].s,\"0.982858\");b[6].cmps=0.982858;\r\n\tb[7].x = 4476.556000;b[7].y = 2131.557000;b[7].w = 253.402000;b[7].h=273.601000;\r\n\tstrcpy(b[7].cls,\"nose\");strcpy(b[7].s,\"0.959098\");b[7].cmps=0.959098;\r\n\tb[8].x = 754.326000;b[8].y = 2571.066000;b[8].w = 324.674000;b[8].h=161.605000;\r\n\tstrcpy(b[8].cls,\"nose\");strcpy(b[8].s,\"0.993699\");b[8].cmps=0.993699;\r\n\tb[9].x = 729.962000;b[9].y = 2658.741000;b[9].w = 349.038000;b[9].h=192.046000;\r\n\tstrcpy(b[9].cls,\"nose\");strcpy(b[9].s,\"0.986209\");b[9].cmps=0.986209;\r\n\tb[10].x = 1271.863000;b[10].y = 2058.679000;b[10].w = 138.781000;b[10].h=137.553000;\r\n\tstrcpy(b[10].cls,\"eye\");strcpy(b[10].s,\"0.989965\");b[10].cmps=0.989965;\r\n\tb[11].x = 4316.000000;b[11].y = 1601.751000;b[11].w = 134.204000;b[11].h=141.249000;\r\n\tstrcpy(b[11].cls,\"eye\");strcpy(b[11].s,\"0.988307\");b[11].cmps=0.988307;\r\n\tb[12].x = 650.901000;b[12].y = 2032.621000;b[12].w = 91.484000;b[12].h=42.112000;\r\n\tstrcpy(b[12].cls,\"eye\");strcpy(b[12].s,\"0.969982\");b[12].cmps=0.969982;\r\n\tb[13].x = 1328.000000;b[13].y = 2058.692000;b[13].w = 103.849000;b[13].h=136.518000;\r\n\tstrcpy(b[13].cls,\"eye\");strcpy(b[13].s,\"0.987316\");b[13].cmps=0.987316;\r\n\tb[14].x = 214.809000;b[14].y = 1599.809000;b[14].w = 1553.705000;b[14].h=1319.679000;\r\n\tstrcpy(b[14].cls,\"head\");strcpy(b[14].s,\"0.997623\");b[14].cmps=0.997623;\r\n\tb[15].x = 3826.177000;b[15].y = 1072.206000;b[15].w = 1254.063000;b[15].h=1412.903000;\r\n\tstrcpy(b[15].cls,\"head\");strcpy(b[15].s,\"0.997487\");b[15].cmps=0.997487;\r\n\tb[16].x = 729.632000;b[16].y = 2578.523000;b[16].w = 442.495000;b[16].h=302.378000;\r\n\tstrcpy(b[16].cls,\"nose\");strcpy(b[16].s,\"0.960093\");b[16].cmps=0.960093;\r\n\tb[17].x = 655.430000;b[17].y = 2031.151000;b[17].w = 91.570000;b[17].h=148.691000;\r\n\tstrcpy(b[17].cls,\"eye\");strcpy(b[17].s,\"0.993275\");b[17].cmps=0.993275;\r\n\tb[18].x = 4251.712000;b[18].y = 1660.000000;b[18].w = 147.288000;b[18].h=105.309000;\r\n\tstrcpy(b[18].cls,\"eye\");strcpy(b[18].s,\"0.992576\");b[18].cmps=0.992576;\r\n\r\n\t//***************************************************************************************************************************************\r\n\t//copy boxes to a  at::tensor\r\n\tat::Tensor boxes = at::zeros({ count,5 });\r\n\r\n\tfor (int i = 0; i < count; i++) {\r\n\t\tboxes[i][0] = b[i].x;\r\n\t\tboxes[i][1] = b[i].y;\r\n\t\tboxes[i][2] = b[i].w;\r\n\t\tboxes[i][3] = b[i].h;\r\n\t\tboxes[i][4] = b[i].cmps;\r\n\t}\r\n\r\n\tboxes  = boxes.to(device);\r\n\tfloat* boxes_as_array = boxes.data<float>();//convert at::tensor to a flat array\r\n\r\n\tfloat nms_overlap_thresh = 0.1;\r\n\r\n\t//Comment: this piece of code is apparently necessary to assign the Torch cuda context to the global cuda context\r\n\tTHCState* state = at::globalContext().lazyInitCUDA(); // TODO replace with getTHCState\r\n\tconst int col_blocks = THCCeilDiv(count, threadsPerBlock);\r\n\tunsigned long long* mask_dev = NULL;\r\n\tmask_dev = (unsigned long long*) THCudaMalloc(state,count * col_blocks * sizeof(unsigned long long));\r\n\t//-------------------------------------------------------------------------------------------------------------\r\n\r\n\tbool *d_res;\r\n    //port h_res to GPU\r\n\tHANDLE_ERROR(cudaMalloc((void**)&d_res, count*sizeof(bool)));\r\n\tHANDLE_ERROR(cudaMemcpy(d_res, h_res,sizeof(bool)*count, cudaMemcpyHostToDevice));\r\n\r\n\tNMS_GPU<<<dim3(1,count,1),count>>>(count,nms_overlap_thresh, boxes_as_array,d_res);\r\n\t\r\n\t//port d_res to CPU\r\n\tHANDLE_ERROR(cudaMemcpy(h_res, d_res, sizeof(bool)*count, cudaMemcpyDeviceToHost));\r\n\r\n\t//display result\r\n\tfor(int i =0; i<count ; i++)\r\n\t{\r\n\t\tif(*(h_res+i) == true)\r\n\t\t{\r\n\t\t\t//printf(\"GPU Draw: %d--%d\\n\",i,*(h_res+i));\r\n\t\t\tcv::putText(temp,b[i].cls,cv::Point((int)b[i].x,(int)b[i].y-5),cv::FONT_HERSHEY_SIMPLEX,1.7,cv::Scalar(255,255,255),5,8,0);\r\n\t\t\tcv::putText(temp,b[i].s,cv::Point((int)b[i].x+120,(int)b[i].y-5),cv::FONT_HERSHEY_SIMPLEX,1.7,cv::Scalar(255,255,255),5,8,0);\r\n\t\t\tcv::rectangle(temp,cv::Point((int)b[i].x,(int)b[i].y),cv::Point((int)b[i].x + (int)b[i].w,(int)b[i].y + (int)b[i].h),cv::Scalar(92.185,194),8,8,0);\r\n\t\t}\r\n\t}\r\n\tcv::namedWindow(\"Window\",0);\r\n\tcv::resizeWindow(\"Window\",1064,800);\r\n\tcv::imshow(\"Window\",temp);\r\n\tcv::waitKey(0);\r\n\treturn 0;\r\n}\r\n\r\nProblem : When I include \"torch/torch.h\"  (uncomment line 23) - something I need for rest of the project -  I get the following error (Visual Studio 2019):\r\n\r\n\"Error\t\tmember \"torch::jit::detail::ParameterPolicy::all_slots\" may not be initialized\tacudaNMSTEST\tD:\\dev\\Cpp\\dependencies\\torchnew\\include\\torch\\csrc\\jit\\api\\module.h\t490\t\"\r\n\r\nI struggled a couple of days to find a solution, but in vain. Any idea what is going on/what I did wrong?\r\n\r\n\n\ncc @malfet @yf225 @glaringlee @peterjc123 @nbcsm @guyang3532"},{"labels":[null,"api",null],"text":"## ‚ùì Questions and Help\r\nif in pytorch\r\n    `torch.manual_seed(0)`\r\nthen in libtorch\r\n    `torch::manual_seed(0);`\r\n\r\nso, in pytorch\r\n```\r\n    torch.cuda.manual_seed(0)\r\n    torch.cuda.manual_seed_all(0)\r\n```\r\nin libtorch\r\n`??`\r\n\r\n### Please note that this issue tracker is not a help form and this issue will be closed.\r\n\r\nWe have a set of [listed resources available on the website](https://pytorch.org/resources). Our primary means of support is our discussion forum:\r\n\r\n- [Discussion Forum](https://discuss.pytorch.org/)\r\n\n\ncc @yf225 @glaringlee"},{"labels":[null,null,"api",null,null,null,null],"text":"## üêõ Bug\r\n\r\nTensor.std(0) returns a scalar instead of a vector.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nfloat data[] = { 1, 2, 3, 4, 5, 6 };\r\ntorch::Tensor f = torch::from_blob(data, {2, 3});\r\nstd::cout << f.mean(0) << std::endl;\r\n// yields a 1-d tensor as expected.\r\n// 2.5000\r\n// 3.5000\r\n// 4.5000\r\n// [ CPUFloatType{3} ]\r\nstd::cout << f.std(0) << std::endl;\r\n// yields a scalar, unexpected.\r\n// 1.70783\r\n// [ CPUFloatType{} ]\r\n```\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nTensor.std(0) should return a vector to be consistent with other methods. As @ptrblck pointed out in this thread https://discuss.pytorch.org/t/tensor-std-0-returns-a-scalar-instead-of-a-vector/85974, the reason this is happening is because 0 is being interpreted as the `unbiased` argument here, and suggests `f.std(true, 0)` as a workaround. However, even `f.std(true, 0)` actually collapses dimension 1, which is also unintuitive.\r\n\r\nIdeally, these behaviors should be fixed or listed in the documentation.\r\n\r\n## Environment\r\n\r\n`Libtorch 1.4.0` on XCode 11.4 \r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225 @glaringlee @bhosmer @smessmer @ljk53 @SsnL"},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\n\r\nAdd C++ API for [`torch.autograd.functional.jacobian`](https://pytorch.org/docs/stable/_modules/torch/autograd/functional.html#jacobian)\r\n\r\n## Motivation\r\n\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\n\r\nI would like to calculate the jacobian of my model output wrt to the input and the feature is available in the python api but was dismayed to find out that it was not in the C++ API.\r\n\r\n## Pitch\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\nInclude `torch::autograd::functional::jacobian` functionality in C++ API\r\n\r\n## Alternatives\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered, if any. -->\r\n\r\nN/A\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n\r\nJust some links for easy browsing:\r\nhttps://github.com/pytorch/pytorch/tree/master/torch/csrc/autograd\r\nhttps://pytorch.org/cppdocs/api/namespace_torch__autograd.html\r\nhttps://pytorch.org/docs/stable/_modules/torch/autograd/functional.html#jacobian\r\n\r\n\r\ncc @ezyang @SsnL @albanD @zou3519 @gqchen @yf225 @glaringlee"},{"labels":["api",null,null],"text":"\r\nThis is my first question ever on Github, so please accept my apologies if I have not posted this in the right place. With the release of the 1.5 stable version of the C++ API for PyTorch, there are some changes in some of the object interfaces. For instance, now\r\n\r\n`optimizer.options.learning_rate();`\r\n\r\nwon't work (here the optimiser being used is Adam) since `learning_rate` has changed to `lr` (see https://github.com/pytorch/pytorch/releases) but moreover the optimiser no longer has options (`no member named 'options' in 'torch::optim::Adam'`). So my question is: how would one run\r\n\r\n`optimizer.options.learning_rate();`\r\n\r\nor update the learning rate\r\n\r\n`optimizer.options.learning_rate(updatedlearningrate);`\r\n\r\nwith the new release? Any help will be appreciated! Thank you\n\ncc @yf225 @glaringlee @vincentqb"},{"labels":[null,null,"api",null],"text":"## üêõ Bug\r\n\r\n`libtorch/include/c10/util/logging_is_not_google_glog.h` exposes `ERROR`, `FATAL`, etc in the global namespace.\r\nThis is included by `torch/script.h`.\r\n\r\nThis causes the conflict with a user code.\r\n\r\n## Expected behavior\r\n\r\nPut them in some namespace.\r\n\r\n## Environment\r\n\r\nbuild-hash: 4ff3872a2099993bf7e...\r\nbuild-version: 1.5.0+cpu\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":[null,"api",null,null],"text":"## üêõ Bug\r\n\r\nOn some macs, loading libtorch 1.5 crash the program right at initialization.\r\nThis does not happen on every mac.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Link your app to the official build of libtorch 1.5 macos https://download.pytorch.org/libtorch/cpu/libtorch-macos-1.5.0.zip\r\n2. Run your app\r\n\r\n**Here's the call stack from the crash report, look in particular from step 12 to 9:**\r\n\r\n7 libc++abi.dylib 0x00007fff6e660f86 __cxxabiv1::failed_throw(__cxxabiv1::__cxa_exception) + 27\r\n8 libc++abi.dylib 0x00007fff6e653f99 __cxa_throw + 113\r\n9 libtorch_cpu.dylib 0x0000000125ae3a5e Xbyak::CodeArray::CodeArray(unsigned long, void*, Xbyak::Allocator*) + 462\r\n10 libtorch_cpu.dylib 0x0000000125ae2f01 Xbyak::CodeGenerator::CodeGenerator(unsigned long, void*, Xbyak::Allocator*) + 33\r\n11 libtorch_cpu.dylib 0x0000000125a8bdbc mkldnn::impl::cpu::jit_avx512_core_cvt_ps_to_bf16_t::jit_avx512_core_cvt_ps_to_bf16_t(unsigned long) + 44\r\n12 libtorch_cpu.dylib 0x0000000125a90bd5 _GLOBAL__sub_I_bfloat16_utils.cpp + 2389\r\n13  dyld                          \t0x0000000110735592 ImageLoaderMachO::doModInitFunctions(ImageLoader::LinkContext const&) + 506\r\n\r\n**Step 9. of this stack points to lines 990-1003 from here:**\r\nhttps://github.com/oneapi-src/oneDNN/blob/rls-v1.2/src/cpu/xbyak/xbyak.h\r\n\r\nHere's the full Apple crash report I get:\r\n\r\nProcess:               SpectraLayers [30150]\r\nPath:                  /Applications/SpectraLayers 7.app/Contents/MacOS/SpectraLayers\r\nIdentifier:            com.Steinberg.SpectraLayers7\r\nVersion:               7.0.0.209 (7.0.0.209)\r\nCode Type:             X86-64 (Native)\r\nParent Process:        ??? [1]\r\nResponsible:           SpectraLayers [30150]\r\nUser ID:               501\r\n\r\nDate/Time:             2020-06-13 10:23:25.225 +0200\r\nOS Version:            Mac OS X 10.14.6 (18G5033)\r\nReport Version:        12\r\nBridge OS Version:     4.5 (17P5300)\r\nAnonymous UUID:        2B222A5C-DC20-4A64-D70C-25B43525FBE8\r\n\r\nSleep/Wake UUID:       68B4EFCE-FE40-4D40-A3A3-55D804AD0000\r\n\r\nTime Awake Since Boot: 220000 seconds\r\nTime Since Wake:       550 seconds\r\n\r\nSystem Integrity Protection: enabled\r\n\r\nCrashed Thread:        0  Dispatch queue: com.apple.main-thread\r\n\r\nException Type:        EXC_CRASH (SIGABRT)\r\nException Codes:       0x0000000000000000, 0x0000000000000000\r\nException Note:        EXC_CORPSE_NOTIFY\r\n\r\nApplication Specific Information:\r\n/Applications/SpectraLayers 7.app/Contents/MacOS/../Frameworks/libtorch_cpu.dylib\r\nterminating with uncaught exception of type Xbyak::Error: can't protect\r\nabort() called\r\n\r\nThread 0 Crashed:: Dispatch queue: com.apple.main-thread\r\n0   libsystem_kernel.dylib        \t0x00007fff715102c2 __pthread_kill + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff715cbbf1 pthread_kill + 284\r\n2   libsystem_c.dylib             \t0x00007fff7147a6a6 abort + 127\r\n3   libc++abi.dylib               \t0x00007fff6e655641 abort_message + 231\r\n4   libc++abi.dylib               \t0x00007fff6e6557c7 default_terminate_handler() + 243\r\n5   libobjc.A.dylib               \t0x00007fff6fc08eeb _objc_terminate() + 105\r\n6   libc++abi.dylib               \t0x00007fff6e66119e std::__terminate(void (*)()) + 8\r\n7   libc++abi.dylib               \t0x00007fff6e660f86 __cxxabiv1::failed_throw(__cxxabiv1::__cxa_exception*) + 27\r\n8   libc++abi.dylib               \t0x00007fff6e653f99 __cxa_throw + 113\r\n9   libtorch_cpu.dylib            \t0x0000000125ae3a5e Xbyak::CodeArray::CodeArray(unsigned long, void*, Xbyak::Allocator*) + 462\r\n10  libtorch_cpu.dylib            \t0x0000000125ae2f01 Xbyak::CodeGenerator::CodeGenerator(unsigned long, void*, Xbyak::Allocator*) + 33\r\n11  libtorch_cpu.dylib            \t0x0000000125a8bdbc mkldnn::impl::cpu::jit_avx512_core_cvt_ps_to_bf16_t::jit_avx512_core_cvt_ps_to_bf16_t(unsigned long) + 44\r\n12  libtorch_cpu.dylib            \t0x0000000125a90bd5 _GLOBAL__sub_I_bfloat16_utils.cpp + 2389\r\n13  dyld                          \t0x0000000110735592 ImageLoaderMachO::doModInitFunctions(ImageLoader::LinkContext const&) + 506\r\n14  dyld                          \t0x0000000110735798 ImageLoaderMachO::doInitialization(ImageLoader::LinkContext const&) + 40\r\n15  dyld                          \t0x0000000110730bea ImageLoader::recursiveInitialization(ImageLoader::LinkContext const&, unsigned int, char const*, ImageLoader::InitializerTimingList&, ImageLoader::UninitedUpwards&) + 362\r\n16  dyld                          \t0x0000000110730b80 ImageLoader::recursiveInitialization(ImageLoader::LinkContext const&, unsigned int, char const*, ImageLoader::InitializerTimingList&, ImageLoader::UninitedUpwards&) + 256\r\n17  dyld                          \t0x0000000110730b80 ImageLoader::recursiveInitialization(ImageLoader::LinkContext const&, unsigned int, char const*, ImageLoader::InitializerTimingList&, ImageLoader::UninitedUpwards&) + 256\r\n18  dyld                          \t0x000000011072fd73 ImageLoader::processInitializers(ImageLoader::LinkContext const&, unsigned int, ImageLoader::InitializerTimingList&, ImageLoader::UninitedUpwards&) + 133\r\n19  dyld                          \t0x000000011072fe05 ImageLoader::runInitializers(ImageLoader::LinkContext const&, ImageLoader::InitializerTimingList&) + 73\r\n20  dyld                          \t0x000000011071f765 dyld::initializeMainExecutable() + 199\r\n21  dyld                          \t0x0000000110724709 dyld::_main(macho_header const*, unsigned long, int, char const**, char const**, char const**, unsigned long*) + 6213\r\n22  dyld                          \t0x000000011071e503 dyldbootstrap::start(macho_header const*, int, char const**, long, macho_header const*, unsigned long*) + 1167\r\n23  dyld                          \t0x000000011071e036 _dyld_start + 54\r\n\r\nThread 0 crashed with X86 Thread State (64-bit):\r\n  rax: 0x0000000000000000  rbx: 0x00000001107bf5c0  rcx: 0x00007ffeec4851c8  rdx: 0x0000000000000000\r\n  rdi: 0x0000000000000307  rsi: 0x0000000000000006  rbp: 0x00007ffeec485200  rsp: 0x00007ffeec4851c8\r\n   r8: 0x00007ffeec485090   r9: 0x00007ffeec485260  r10: 0x0000000000000000  r11: 0x0000000000000206\r\n  r12: 0x0000000000000307  r13: 0x0000003000000008  r14: 0x0000000000000006  r15: 0x000000000000002d\r\n  rip: 0x00007fff715102c2  rfl: 0x0000000000000206  cr2: 0x00007fffa7b65188\r\n  \r\nLogical CPU:     0\r\nError Code:      0x02000148\r\nTrap Number:     133\r\n\r\n\r\nBinary Images:\r\n       0x103777000 -        0x10545dfff +com.Steinberg.SpectraLayers7 (7.0.0.209 - 7.0.0.209) <B039FAC5-7A29-38D2-900A-ED51613ED7DA> /Applications/SpectraLayers 7.app/Contents/MacOS/SpectraLayers\r\n       0x105504000 -        0x105505fff +libtorch.dylib (0) <45C1863F-6DFD-3F6D-8980-792B90E37513> /Applications/SpectraLayers 7.app/Contents/Frameworks/libtorch.dylib\r\n       0x10550b000 -        0x105534ff3 +libc10.dylib (0) <835FB93F-21EC-3E19-A899-E44F1917693C> /Applications/SpectraLayers 7.app/Contents/Frameworks/libc10.dylib\r\n       0x105557000 -        0x10599efff +org.qt-project.QtWidgets (5.15 - 5.15.0) <FB5EEB60-BD0B-3818-A2E9-CF69E0B1D74A> /Applications/SpectraLayers 7.app/Contents/Frameworks/QtWidgets.framework/Versions/5/QtWidgets\r\n       0x105b54000 -        0x106049fe3 +org.qt-project.QtGui (5.15 - 5.15.0) <FF68F42D-ECAB-3C23-AF28-A25D3930B7B2> /Applications/SpectraLayers 7.app/Contents/Frameworks/QtGui.framework/Versions/5/QtGui\r\n       0x1061a6000 -        0x1062b6ff3 +org.qt-project.QtNetwork (5.15 - 5.15.0) <FE520B4B-F1E2-3AC0-9D0E-FB64D77897CB> /Applications/SpectraLayers 7.app/Contents/Frameworks/QtNetwork.framework/Versions/5/QtNetwork\r\n       0x106316000 -        0x10631affb +org.qt-project.QtConcurrent (5.15 - 5.15.0) <82AD3E1D-C55A-356C-9AEF-D1B8A463985C> /Applications/SpectraLayers 7.app/Contents/Frameworks/QtConcurrent.framework/Versions/5/QtConcurrent\r\n       0x106323000 -        0x10686d657 +org.qt-project.QtCore (5.15 - 5.15.0) <EACC2818-F08D-3861-A8EF-EA2F17800B66> /Applications/SpectraLayers 7.app/Contents/Frameworks/QtCore.framework/Versions/5/QtCore\r\n       0x106965000 -        0x107a19c17 +libtensorflow_framework.1.dylib (0) <93EA5990-E075-3827-B1F8-3FE1797F3F7F> /Applications/SpectraLayers 7.app/Contents/Frameworks/libtensorflow_framework.1.dylib\r\n       0x108465000 -        0x108598fc7 +libiomp5.dylib (0) <52F67CC7-A4B0-3F4D-A80D-7DC28D4A776A> /Applications/SpectraLayers 7.app/Contents/Frameworks/libiomp5.dylib\r\n       0x11071d000 -        0x11078770f  dyld (655.1.1) <DF71FC3D-E58F-3D48-9165-3B96FF8BFA22> /usr/lib/dyld\r\n       0x1107e8000 -        0x116a28feb +libtensorflow.1.dylib (0) <F2A0BBE5-BBE7-3D75-8755-9A865602E0CD> /Applications/SpectraLayers 7.app/Contents/Frameworks/libtensorflow.1.dylib\r\n       0x11cb55000 -        0x1284fcf4f +libtorch_cpu.dylib (0) <17C36C10-9231-3506-8008-B4D7185D1ECE> /Applications/SpectraLayers 7.app/Contents/Frameworks/libtorch_cpu.dylib\r\n    0x7fff41465000 -     0x7fff41469fff  com.apple.agl (3.3.2 - AGL-3.3.2) <A5954DED-265B-395D-B907-3CEC000B10B6> /System/Library/Frameworks/AGL.framework/Versions/A/AGL\r\n    0x7fff41814000 -     0x7fff41814fff  com.apple.Accelerate (1.11 - Accelerate 1.11) <762942CB-CFC9-3A0C-9645-A56523A06426> /System/Library/Frameworks/Accelerate.framework/Versions/A/Accelerate\r\n    0x7fff4182c000 -     0x7fff41ec5fef  com.apple.vImage (8.1 - ???) <53FA3611-894E-3158-A654-FBD2F70998FE> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vImage.framework/Versions/A/vImage\r\n    0x7fff41ec6000 -     0x7fff4213fff3  libBLAS.dylib (1243.200.4) <417CA0FC-B6CB-3FB3-ACBC-8914E3F62D20> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\r\n    0x7fff42140000 -     0x7fff421b2ffb  libBNNS.dylib (38.250.1) <538D12A2-9B9D-3E22-9896-F90F6E69C06E> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBNNS.dylib\r\n    0x7fff421b3000 -     0x7fff4255cff3  libLAPACK.dylib (1243.200.4) <92175DF4-863A-3780-909A-A3E5C410F2E9> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib\r\n    0x7fff4255d000 -     0x7fff42572feb  libLinearAlgebra.dylib (1243.200.4) <CB671EE6-DEA1-391C-9B2B-AA09A46B4D7A> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLinearAlgebra.dylib\r\n    0x7fff42573000 -     0x7fff42578ff3  libQuadrature.dylib (3.200.2) <1BAE7E22-2862-379F-B334-A3756067730F> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libQuadrature.dylib\r\n    0x7fff42579000 -     0x7fff425f5ff3  libSparse.dylib (79.200.5) <E78B33D3-672A-3C53-B512-D3DDB2E9AC8D> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparse.dylib\r\n    0x7fff425f6000 -     0x7fff42609fe3  libSparseBLAS.dylib (1243.200.4) <E9243341-DB77-37C1-97C5-3DFA00DD70FA> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparseBLAS.dylib\r\n    0x7fff4260a000 -     0x7fff427f1ff7  libvDSP.dylib (671.250.4) <7B110627-A9C1-3FB7-A077-0C7741BA25D8> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvDSP.dylib\r\n    0x7fff427f2000 -     0x7fff428a5ff7  libvMisc.dylib (671.250.4) <D5BA4812-BFFC-3CD0-B382-905CD8555DA6> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvMisc.dylib\r\n    0x7fff428a6000 -     0x7fff428a6fff  com.apple.Accelerate.vecLib (3.11 - vecLib 3.11) <74288115-EF61-30B6-843F-0593B31D4929> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/vecLib\r\n    0x7fff42a48000 -     0x7fff437fdffb  com.apple.AppKit (6.9 - 1671.60.109) <78DB9AAE-C127-3BAA-8BAE-145AAFBFFBA2> /System/Library/Frameworks/AppKit.framework/Versions/C/AppKit\r\n    0x7fff4384f000 -     0x7fff4384ffff  com.apple.ApplicationServices (50.1 - 50.1) <DD5FDF45-E7C1-335C-8757-3D714CBA9367> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ApplicationServices\r\n    0x7fff43850000 -     0x7fff438bbfff  com.apple.ApplicationServices.ATS (377 - 453.11.2.2) <A258DA73-114B-3102-A056-4AAAD3CEB9DD> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/ATS\r\n    0x7fff43954000 -     0x7fff43a6bff7  libFontParser.dylib (228.6.2.5) <CEDF1D5A-8897-3621-A1DC-558301F8BE05> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontParser.dylib\r\n    0x7fff43a6c000 -     0x7fff43aaefff  libFontRegistry.dylib (228.12.2.4) <6DDE44EC-FF6B-3893-9209-45E0955ABDD5> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontRegistry.dylib\r\n    0x7fff43b9f000 -     0x7fff43ba3ff3  com.apple.ColorSyncLegacy (4.13.0 - 1) <E8E9342C-47EB-359D-A373-554AC19B174A> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ColorSyncLegacy.framework/Versions/A/ColorSyncLegacy\r\n    0x7fff43c3e000 -     0x7fff43c90ff7  com.apple.HIServices (1.22 - 628) <2BE461FF-80B9-30D3-A574-AED5724B1C1B> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/HIServices.framework/Versions/A/HIServices\r\n    0x7fff43c91000 -     0x7fff43ca0fff  com.apple.LangAnalysis (1.7.0 - 1.7.0) <F5617A2A-FEA6-3832-B5BA-C2111B98786F> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/LangAnalysis.framework/Versions/A/LangAnalysis\r\n    0x7fff43ca1000 -     0x7fff43ceaff7  com.apple.print.framework.PrintCore (14.7 - 503.8) <E1D0FCBC-155E-372E-A90F-4A20B94FC114> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore\r\n    0x7fff43ceb000 -     0x7fff43d24ff7  com.apple.QD (3.12 - 407.2) <28C7D39F-59C9-3314-BECC-67045487229C> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/QD.framework/Versions/A/QD\r\n    0x7fff43d25000 -     0x7fff43d31fff  com.apple.speech.synthesis.framework (8.1.3 - 8.1.3) <5E7B9BD4-122B-3012-A044-3259C97E7509> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis\r\n    0x7fff43d32000 -     0x7fff43fa9fff  com.apple.audio.toolbox.AudioToolbox (1.14 - 1.14) <32487CB2-246B-3B80-8F60-D65DFC367DDC> /System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox\r\n    0x7fff43fab000 -     0x7fff43fabfff  com.apple.audio.units.AudioUnit (1.14 - 1.14) <B489CFDA-DEF3-38F5-A815-23EC30B8DA03> /System/Library/Frameworks/AudioUnit.framework/Versions/A/AudioUnit\r\n    0x7fff44304000 -     0x7fff446a6fff  com.apple.CFNetwork (978.3 - 978.3) <6A5459BD-77A4-386C-872D-9BB297D83588> /System/Library/Frameworks/CFNetwork.framework/Versions/A/CFNetwork\r\n    0x7fff446bb000 -     0x7fff446bbfff  com.apple.Carbon (158 - 158) <38182BEA-597C-39AC-B4BA-4849E24EE84E> /System/Library/Frameworks/Carbon.framework/Versions/A/Carbon\r\n    0x7fff446bc000 -     0x7fff446bfffb  com.apple.CommonPanels (1.2.6 - 98) <1CD6D56D-8EC7-3528-8CBC-FC69533519B5> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/CommonPanels.framework/Versions/A/CommonPanels\r\n    0x7fff446c0000 -     0x7fff449b7fff  com.apple.HIToolbox (2.1.1 - 918.7) <88D7F19C-8C9D-384B-BAB5-8205CA282F2C> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/HIToolbox.framework/Versions/A/HIToolbox\r\n    0x7fff449b8000 -     0x7fff449bbff3  com.apple.help (1.3.8 - 66) <A08517EB-8958-36C9-AEE0-1A8FEEACBE3F> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Help.framework/Versions/A/Help\r\n    0x7fff449bc000 -     0x7fff449c1ff7  com.apple.ImageCapture (9.0 - 1534.2) <DB063E87-ED8F-3E4E-A7E2-A6B45FA73EF7> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ImageCapture.framework/Versions/A/ImageCapture\r\n    0x7fff449c2000 -     0x7fff44a57ff3  com.apple.ink.framework (10.9 - 225) <7C7E9483-2E91-3DD3-B1E0-C238F42CA0DD> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Ink.framework/Versions/A/Ink\r\n    0x7fff44a58000 -     0x7fff44a70ff7  com.apple.openscripting (1.7 - 179.1) <9B8C1ECC-5864-3E21-9149-863E884EA25C> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/OpenScripting.framework/Versions/A/OpenScripting\r\n    0x7fff44a90000 -     0x7fff44a91ff7  com.apple.print.framework.Print (14.2 - 267.4) <A7A9D2A0-D4E0-35EF-A0F7-50521F707C33> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Print.framework/Versions/A/Print\r\n    0x7fff44a92000 -     0x7fff44a94ff7  com.apple.securityhi (9.0 - 55006) <05717F77-7A7B-37E6-AB3E-03F063E9095B> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SecurityHI.framework/Versions/A/SecurityHI\r\n    0x7fff44a95000 -     0x7fff44a9bff7  com.apple.speech.recognition.framework (6.0.3 - 6.0.3) <3CC050FB-EBCB-3087-8EA5-F378C8F99217> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SpeechRecognition.framework/Versions/A/SpeechRecognition\r\n    0x7fff44bbd000 -     0x7fff44bbdfff  com.apple.Cocoa (6.11 - 23) <BB61D501-2D32-3DA2-9573-0C884189B211> /System/Library/Frameworks/Cocoa.framework/Versions/A/Cocoa\r\n    0x7fff44bcb000 -     0x7fff44d1aff7  com.apple.ColorSync (4.13.0 - 3345.6) <356BA478-76DE-3087-86BE-5E884276AB83> /System/Library/Frameworks/ColorSync.framework/Versions/A/ColorSync\r\n    0x7fff44ea6000 -     0x7fff44f2cfff  com.apple.audio.CoreAudio (4.3.0 - 4.3.0) <1E8E64E6-0E58-375A-97F7-07CB4EE181AC> /System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio\r\n    0x7fff44f90000 -     0x7fff44fbaffb  com.apple.CoreBluetooth (1.0 - 1) <4F2DDEF0-1F92-384B-8CDA-4958725D0A8E> /System/Library/Frameworks/CoreBluetooth.framework/Versions/A/CoreBluetooth\r\n    0x7fff44fbb000 -     0x7fff45340fef  com.apple.CoreData (120 - 866.6) <132CB39B-8D58-30FA-B8AD-49BFFF34B293> /System/Library/Frameworks/CoreData.framework/Versions/A/CoreData\r\n    0x7fff45341000 -     0x7fff45431ff7  com.apple.CoreDisplay (101.3 - 110.18) <6DD41271-E145-3E99-9D49-7CC8AC1C65B6> /System/Library/Frameworks/CoreDisplay.framework/Versions/A/CoreDisplay\r\n    0x7fff45432000 -     0x7fff45877ff7  com.apple.CoreFoundation (6.9 - 1575.235) <BECD568A-70AE-32BC-A6F1-A69BD61C1D37> /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation\r\n    0x7fff45879000 -     0x7fff45f09fe7  com.apple.CoreGraphics (2.0 - 1265.10) <92E5B053-A926-3788-B3BB-E563B2B96836> /System/Library/Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics\r\n    0x7fff45f0b000 -     0x7fff4622bfff  com.apple.CoreImage (14.4.0 - 750.0.140) <11026E39-D2FF-3CF6-8ACE-7BA293F9853E> /System/Library/Frameworks/CoreImage.framework/Versions/A/CoreImage\r\n    0x7fff46689000 -     0x7fff46689fff  com.apple.CoreServices (946 - 946) <BC6F47BD-5947-32C3-BDC9-4C63AF659F4E> /System/Library/Frameworks/CoreServices.framework/Versions/A/CoreServices\r\n    0x7fff4668a000 -     0x7fff46706ff7  com.apple.AE (773 - 773) <55AE7C9E-27C3-30E9-A047-3B92A6FD53B4> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/AE.framework/Versions/A/AE\r\n    0x7fff46707000 -     0x7fff469defff  com.apple.CoreServices.CarbonCore (1178.33 - 1178.33) <CB87F0C7-2CD6-3983-8E32-B6A2EC925352> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CarbonCore.framework/Versions/A/CarbonCore\r\n    0x7fff469df000 -     0x7fff46a27ff7  com.apple.DictionaryServices (1.2 - 284.16.4) <746EB200-DC51-30AE-9CBC-608A7B4CC8DA> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/DictionaryServices.framework/Versions/A/DictionaryServices\r\n    0x7fff46a28000 -     0x7fff46a30ffb  com.apple.CoreServices.FSEvents (1239.200.13 - 1239.200.13) <5913F08D-4AA2-3200-B998-012E6A19A66D> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/FSEvents.framework/Versions/A/FSEvents\r\n    0x7fff46a31000 -     0x7fff46be2ff7  com.apple.LaunchServices (946 - 946) <A0C91634-9410-38E8-BC11-7A5A369E6BA5> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/LaunchServices\r\n    0x7fff46be3000 -     0x7fff46c81ff7  com.apple.Metadata (10.7.0 - 1191.58) <89DA10B4-5695-3FD9-A920-C34C33957868> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/Metadata.framework/Versions/A/Metadata\r\n    0x7fff46c82000 -     0x7fff46cccff7  com.apple.CoreServices.OSServices (946 - 946) <20C4EEF8-D5AC-39A0-9B4A-78F88E3EFBCC> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/OSServices.framework/Versions/A/OSServices\r\n    0x7fff46ccd000 -     0x7fff46d34ff7  com.apple.SearchKit (1.4.0 - 1.4.0) <DA08AA6F-A6F1-36C0-87F4-E26294E51A3A> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SearchKit.framework/Versions/A/SearchKit\r\n    0x7fff46d35000 -     0x7fff46d56ff3  com.apple.coreservices.SharedFileList (71.28 - 71.28) <487A8464-729E-305A-B5D1-E3FE8EB9CFC5> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SharedFileList.framework/Versions/A/SharedFileList\r\n    0x7fff47061000 -     0x7fff471c3ff3  com.apple.CoreText (352.0 - 584.26.3.4) <7247EA49-9F90-3258-AABF-932C6343BD6A> /System/Library/Frameworks/CoreText.framework/Versions/A/CoreText\r\n    0x7fff471c4000 -     0x7fff47204ff3  com.apple.CoreVideo (1.8 - 281.4) <10CF8E52-07E3-382B-8091-2CEEEFFA69B4> /System/Library/Frameworks/CoreVideo.framework/Versions/A/CoreVideo\r\n    0x7fff47205000 -     0x7fff47294fff  com.apple.framework.CoreWLAN (13.0 - 1375.2) <EC43DDAD-D838-3469-88F1-667EF5963AD1> /System/Library/Frameworks/CoreWLAN.framework/Versions/A/CoreWLAN\r\n    0x7fff474eb000 -     0x7fff474f0ffb  com.apple.DiskArbitration (2.7 - 2.7) <0D7444BE-7F82-3480-8873-08E8EBC6DE47> /System/Library/Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration\r\n    0x7fff476b7000 -     0x7fff47a64ffb  com.apple.Foundation (6.9 - 1575.235) <60DBA0A0-F514-3755-9E19-A62216D7C856> /System/Library/Frameworks/Foundation.framework/Versions/C/Foundation\r\n    0x7fff47ad3000 -     0x7fff47b02ffb  com.apple.GSS (4.0 - 2.0) <E2B90D08-3857-3155-9FCC-07D778988EC9> /System/Library/Frameworks/GSS.framework/Versions/A/GSS\r\n    0x7fff47c02000 -     0x7fff47d0cfff  com.apple.Bluetooth (6.0.14 - 6.0.14d8) <526047AA-211F-3E6E-9418-B0379AE193F5> /System/Library/Frameworks/IOBluetooth.framework/Versions/A/IOBluetooth\r\n    0x7fff47d6f000 -     0x7fff47dfefff  com.apple.framework.IOKit (2.0.2 - 1483.260.4) <8A90F547-86EF-3DFB-92FE-0E2C0376DD84> /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit\r\n    0x7fff47e00000 -     0x7fff47e0fffb  com.apple.IOSurface (255.6.1 - 255.6.1) <85F85EBB-EA59-3A8B-B3EB-7C20F3CC77AE> /System/Library/Frameworks/IOSurface.framework/Versions/A/IOSurface\r\n    0x7fff47e63000 -     0x7fff47feffef  com.apple.ImageIO.framework (3.3.0 - 1850.2.6) <CA362EE8-5EFD-33C3-AAB8-241846C486F1> /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO\r\n    0x7fff47ff0000 -     0x7fff47ff4ffb  libGIF.dylib (1850.2.6) <22A37594-65B6-38D3-BE4E-FB4ECFA1D93C> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libGIF.dylib\r\n    0x7fff47ff5000 -     0x7fff480d1fe7  libJP2.dylib (1850.2.6) <5CC65160-9FF8-3E92-858D-17FB9E80B43D> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJP2.dylib\r\n    0x7fff480d2000 -     0x7fff480f7feb  libJPEG.dylib (1850.2.6) <E484FD1B-0033-3177-A1C5-2E2795E9CBD8> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJPEG.dylib\r\n    0x7fff483ba000 -     0x7fff483e0feb  libPng.dylib (1850.2.6) <05430FA2-EF4E-3765-AF93-463F01E6EBA7> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libPng.dylib\r\n    0x7fff483e1000 -     0x7fff483e3ffb  libRadiance.dylib (1850.2.6) <AD9283A9-9CA9-3ECE-9236-1D142B94645B> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libRadiance.dylib\r\n    0x7fff483e4000 -     0x7fff48431feb  libTIFF.dylib (1850.2.6) <BB39423E-2C3A-3C65-A497-2F951354E0A1> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libTIFF.dylib\r\n    0x7fff495a4000 -     0x7fff495bdfff  com.apple.Kerberos (3.0 - 1) <DB1E0679-37E1-3B93-9789-32F63D660C3B> /System/Library/Frameworks/Kerberos.framework/Versions/A/Kerberos\r\n    0x7fff49fd9000 -     0x7fff4a081ff7  com.apple.Metal (162.2 - 162.2) <B65C71BF-D40E-3BB3-940C-117DDD203551> /System/Library/Frameworks/Metal.framework/Versions/A/Metal\r\n    0x7fff4a09d000 -     0x7fff4a0bcff7  com.apple.MetalPerformanceShaders.MPSCore (1.0 - 1) <44CE8362-E972-3697-AD6F-15BC863BAEB8> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSCore.framework/Versions/A/MPSCore\r\n    0x7fff4a0bd000 -     0x7fff4a139fe7  com.apple.MetalPerformanceShaders.MPSImage (1.0 - 1) <EE8440DA-66DF-3923-ABBC-E0543211C069> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSImage.framework/Versions/A/MPSImage\r\n    0x7fff4a13a000 -     0x7fff4a161fff  com.apple.MetalPerformanceShaders.MPSMatrix (1.0 - 1) <E64450DF-2B96-331E-B7F4-666E00571C70> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSMatrix.framework/Versions/A/MPSMatrix\r\n    0x7fff4a162000 -     0x7fff4a28dff7  com.apple.MetalPerformanceShaders.MPSNeuralNetwork (1.0 - 1) <F2CF26B6-73F1-3644-8FE9-CDB9B2C4501F> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSNeuralNetwork.framework/Versions/A/MPSNeuralNetwork\r\n    0x7fff4a28e000 -     0x7fff4a2a8fff  com.apple.MetalPerformanceShaders.MPSRayIntersector (1.0 - 1) <B33A35C3-0393-366B-ACFB-F4BB6A5F7B4A> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSRayIntersector.framework/Versions/A/MPSRayIntersector\r\n    0x7fff4a2a9000 -     0x7fff4a2aaff7  com.apple.MetalPerformanceShaders.MetalPerformanceShaders (1.0 - 1) <69F14BCF-C5C5-3BF8-9C31-8F87D2D6130A> /System/Library/Frameworks/MetalPerformanceShaders.framework/Versions/A/MetalPerformanceShaders\r\n    0x7fff4b0a1000 -     0x7fff4b0adff7  com.apple.NetFS (6.0 - 4.0) <E917806F-0607-3292-B2D6-A15404D61B99> /System/Library/Frameworks/NetFS.framework/Versions/A/NetFS\r\n    0x7fff4db4b000 -     0x7fff4dba2ff7  com.apple.opencl (2.15.3 - 2.15.3) <3F72F3B0-F607-39E5-BDF6-5C37C9B67430> /System/Library/Frameworks/OpenCL.framework/Versions/A/OpenCL\r\n    0x7fff4dba3000 -     0x7fff4dbbeff7  com.apple.CFOpenDirectory (10.14 - 207.200.4) <F03D84EB-49B2-3A00-9127-B9A269824026> /System/Library/Frameworks/OpenDirectory.framework/Versions/A/Frameworks/CFOpenDirectory.framework/Versions/A/CFOpenDirectory\r\n    0x7fff4dbbf000 -     0x7fff4dbcaffb  com.apple.OpenDirectory (10.14 - 207.200.4) <A8020CEE-5B78-3581-A735-EA2833683F31> /System/Library/Frameworks/OpenDirectory.framework/Versions/A/OpenDirectory\r\n    0x7fff4e51a000 -     0x7fff4e51cfff  libCVMSPluginSupport.dylib (17.7.3) <83C36A70-5F35-37D1-A124-A2CD497F1915> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCVMSPluginSupport.dylib\r\n    0x7fff4e51d000 -     0x7fff4e522ff3  libCoreFSCache.dylib (166.5) <5BC99EE7-7FFD-3F30-9AEE-EEDC25067AC4> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreFSCache.dylib\r\n    0x7fff4e523000 -     0x7fff4e527fff  libCoreVMClient.dylib (166.5) <B8FA5858-8185-3992-AD3B-A81AF08C3CDD> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreVMClient.dylib\r\n    0x7fff4e528000 -     0x7fff4e530ff7  libGFXShared.dylib (17.7.3) <09F50639-F0CB-3312-8BAC-5AA8083350F6> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGFXShared.dylib\r\n    0x7fff4e531000 -     0x7fff4e53cfff  libGL.dylib (17.7.3) <4EEC82D4-A3C6-336D-9F90-67F1D24ED35B> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib\r\n    0x7fff4e53d000 -     0x7fff4e577fef  libGLImage.dylib (17.7.3) <B175F261-69D1-3366-A009-DF75CB32E2F9> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLImage.dylib\r\n    0x7fff4e6eb000 -     0x7fff4e729fff  libGLU.dylib (17.7.3) <5BB2F84A-4D96-35A1-8A5B-99AE39CD9E59> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLU.dylib\r\n    0x7fff4f0c6000 -     0x7fff4f0d5ffb  com.apple.opengl (17.7.3 - 17.7.3) <9C1FCE6E-FED6-3A09-9FDC-4C81F8CDB2A6> /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL\r\n    0x7fff4fedf000 -     0x7fff50136ff7  com.apple.QuartzCore (1.11 - 701.14) <1E82D0E6-EB06-3CC6-AEB5-06E3365887D0> /System/Library/Frameworks/QuartzCore.framework/Versions/A/QuartzCore\r\n    0x7fff5096c000 -     0x7fff50c6cff7  com.apple.security (7.0 - 58286.270.6) <0FA49A7B-26C3-3DEF-B369-046E6D0CDF12> /System/Library/Frameworks/Security.framework/Versions/A/Security\r\n    0x7fff50c6d000 -     0x7fff50cf9fff  com.apple.securityfoundation (6.0 - 55185.260.1) <C5C23F73-34A8-3676-9FFB-B18ABB42DA1A> /System/Library/Frameworks/SecurityFoundation.framework/Versions/A/SecurityFoundation\r\n    0x7fff50d2b000 -     0x7fff50d2ffff  com.apple.xpc.ServiceManagement (1.0 - 1) <7F9EC269-38C8-334B-976A-3951021B28B7> /System/Library/Frameworks/ServiceManagement.framework/Versions/A/ServiceManagement\r\n    0x7fff510c8000 -     0x7fff51135fff  com.apple.SystemConfiguration (1.17 - 1.17) <30C8327F-3EFF-3520-9C50-016F8B6B954F> /System/Library/Frameworks/SystemConfiguration.framework/Versions/A/SystemConfiguration\r\n    0x7fff54371000 -     0x7fff54416fff  com.apple.APFS (1.0 - 1) <06284DE8-5883-39F8-B04D-0D5EA74D12ED> /System/Library/PrivateFrameworks/APFS.framework/Versions/A/APFS\r\n    0x7fff54e2b000 -     0x7fff54e2cff7  com.apple.AggregateDictionary (1.0 - 1) <A6AF8AC4-1F25-37C4-9157-A02E9C200926> /System/Library/PrivateFrameworks/AggregateDictionary.framework/Versions/A/AggregateDictionary\r\n    0x7fff5542d000 -     0x7fff55459ff7  com.apple.framework.Apple80211 (13.0 - 1380.2) <E02D473E-2CE6-34EA-833C-758E479E066A> /System/Library/PrivateFrameworks/Apple80211.framework/Versions/A/Apple80211\r\n    0x7fff55581000 -     0x7fff55590fc7  com.apple.AppleFSCompression (96.200.3 - 1.0) <3CF60CE8-976E-3CB8-959D-DD0948C1C2DE> /System/Library/PrivateFrameworks/AppleFSCompression.framework/Versions/A/AppleFSCompression\r\n    0x7fff5568c000 -     0x7fff55697fff  com.apple.AppleIDAuthSupport (1.0 - 1) <2E9D1398-DBE6-328B-ADDA-20FA5FAD7405> /System/Library/PrivateFrameworks/AppleIDAuthSupport.framework/Versions/A/AppleIDAuthSupport\r\n    0x7fff556d8000 -     0x7fff55721ff3  com.apple.AppleJPEG (1.0 - 1) <4C1F426B-7D77-3980-9633-7DBD8C666B9A> /System/Library/PrivateFrameworks/AppleJPEG.framework/Versions/A/AppleJPEG\r\n    0x7fff55975000 -     0x7fff55997fff  com.apple.applesauce (1.0 - ???) <F49107C7-3C51-3024-8EF1-C57643BE4F3B> /System/Library/PrivateFrameworks/AppleSauce.framework/Versions/A/AppleSauce\r\n    0x7fff55af6000 -     0x7fff55b0affb  com.apple.AssertionServices (1.0 - 1) <456E507A-4561-3628-9FBE-173ACE7429D8> /System/Library/PrivateFrameworks/AssertionServices.framework/Versions/A/AssertionServices\r\n    0x7fff55ed9000 -     0x7fff55fc5ff7  com.apple.AuthKit (1.0 - 1) <2765ABE9-54F2-3E45-8A93-1261E251B90D> /System/Library/PrivateFrameworks/AuthKit.framework/Versions/A/AuthKit\r\n    0x7fff56187000 -     0x7fff5618ffff  com.apple.coreservices.BackgroundTaskManagement (1.0 - 57.1) <2A396FC0-7B79-3088-9A82-FB93C1181A57> /System/Library/PrivateFrameworks/BackgroundTaskManagement.framework/Versions/A/BackgroundTaskManagement\r\n    0x7fff56190000 -     0x7fff56225fff  com.apple.backup.framework (1.10.5 - ???) <4EEC51E2-AE4C-340A-B686-901810152C12> /System/Library/PrivateFrameworks/Backup.framework/Versions/A/Backup\r\n    0x7fff56226000 -     0x7fff56293ff3  com.apple.BaseBoard (360.28 - 360.28) <68FA8044-F3CD-3BC6-9DAB-27DACF52BFC0> /System/Library/PrivateFrameworks/BaseBoard.framework/Versions/A/BaseBoard\r\n    0x7fff57f00000 -     0x7fff57f09ffb  com.apple.CommonAuth (4.0 - 2.0) <93335CB6-ABEB-3EC7-A040-8A667F40D5F3> /System/Library/PrivateFrameworks/CommonAuth.framework/Versions/A/CommonAuth\r\n    0x7fff58be2000 -     0x7fff58bf3ff7  com.apple.CoreEmoji (1.0 - 69.19.9) <228457B3-E191-356E-9A5B-3C0438D05FBA> /System/Library/PrivateFrameworks/CoreEmoji.framework/Versions/A/CoreEmoji\r\n    0x7fff5919d000 -     0x7fff59203ff7  com.apple.CoreNLP (1.0 - 130.15.22) <27877820-17D0-3B02-8557-4014E876CCC7> /System/Library/PrivateFrameworks/CoreNLP.framework/Versions/A/CoreNLP\r\n    0x7fff594b0000 -     0x7fff594b8ff7  com.apple.CorePhoneNumbers (1.0 - 1) <11F97C7E-C183-305F-8E6C-9B374F50E26B> /System/Library/PrivateFrameworks/CorePhoneNumbers.framework/Versions/A/CorePhoneNumbers\r\n    0x7fff59a2c000 -     0x7fff59ab0fff  com.apple.CoreSymbolication (10.2 - 64490.25.1) <28B2FF2D-3FDE-3A20-B343-341E5BD4E22F> /System/Library/PrivateFrameworks/CoreSymbolication.framework/Versions/A/CoreSymbolication\r\n    0x7fff59b40000 -     0x7fff59c6bff7  com.apple.coreui (2.1 - 499.10) <A80F4B09-F940-346F-A9DF-4EFADD9220A8> /System/Library/PrivateFrameworks/CoreUI.framework/Versions/A/CoreUI\r\n    0x7fff59c6c000 -     0x7fff59e0cfff  com.apple.CoreUtils (5.9 - 590.16) <9D7E165D-EB34-3E01-A02B-FF6BFBD81DD5> /System/Library/PrivateFrameworks/CoreUtils.framework/Versions/A/CoreUtils\r\n    0x7fff59e60000 -     0x7fff59ec3ff7  com.apple.framework.CoreWiFi (13.0 - 1375.2) <343139CE-6BCC-3B6B-91B4-24A503AEE607> /System/Library/PrivateFrameworks/CoreWiFi.framework/Versions/A/CoreWiFi\r\n    0x7fff59ec4000 -     0x7fff59ed5ff3  com.apple.CrashReporterSupport (10.13 - 938.28) <74CC266D-FEF3-32DB-A16F-0ECB8D79C993> /System/Library/PrivateFrameworks/CrashReporterSupport.framework/Versions/A/CrashReporterSupport\r\n    0x7fff59f65000 -     0x7fff59f74fff  com.apple.framework.DFRFoundation (1.0 - 211.1) <E3F02F2A-2059-39CC-85DA-969676EB88EB> /System/Library/PrivateFrameworks/DFRFoundation.framework/Versions/A/DFRFoundation\r\n    0x7fff59f75000 -     0x7fff59f79ff7  com.apple.DSExternalDisplay (3.1 - 380) <787B9748-B120-3453-B8FE-61D9E363A9E0> /System/Library/PrivateFrameworks/DSExternalDisplay.framework/Versions/A/DSExternalDisplay\r\n    0x7fff59ffa000 -     0x7fff5a06fffb  com.apple.datadetectorscore (7.0 - 590.27) <06FB1A07-7AE6-3ADD-8E7E-41955FAB38E8> /System/Library/PrivateFrameworks/DataDetectorsCore.framework/Versions/A/DataDetectorsCore\r\n    0x7fff5a0bb000 -     0x7fff5a0f8ff7  com.apple.DebugSymbols (190 - 190) <6F4FAACA-E06B-38AD-A0C2-14EA5408A231> /System/Library/PrivateFrameworks/DebugSymbols.framework/Versions/A/DebugSymbols\r\n    0x7fff5a0f9000 -     0x7fff5a234ff7  com.apple.desktopservices (1.13.5 - ???) <ED60E493-4E56-3622-A55C-2CABF5D02316> /System/Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/DesktopServicesPriv\r\n    0x7fff5b17b000 -     0x7fff5b596fff  com.apple.vision.FaceCore (3.3.4 - 3.3.4) <A576E2DA-BF6F-3B18-8FEB-324E5C5FA9BD> /System/Library/PrivateFrameworks/FaceCore.framework/Versions/A/FaceCore\r\n    0x7fff604eb000 -     0x7fff604f0fff  com.apple.GPUWrangler (3.50.15 - 3.50.15) <B42426AC-C5E9-3ECD-9798-22811555C9F6> /System/Library/PrivateFrameworks/GPUWrangler.framework/Versions/A/GPUWrangler\r\n    0x7fff612fc000 -     0x7fff6130bfff  com.apple.GraphVisualizer (1.0 - 5) <48D020B7-5938-3FAE-B468-E291AEE2C06F> /System/Library/PrivateFrameworks/GraphVisualizer.framework/Versions/A/GraphVisualizer\r\n    0x7fff61471000 -     0x7fff614e5ffb  com.apple.Heimdal (4.0 - 2.0) <D97FCF19-EAD6-3E2F-BE88-F817E45CAE96> /System/Library/PrivateFrameworks/Heimdal.framework/Versions/A/Heimdal\r\n    0x7fff627ea000 -     0x7fff627f1ffb  com.apple.IOAccelerator (404.14 - 404.14) <8E1BB4BA-15A7-3711-8502-AD2770EE368F> /System/Library/PrivateFrameworks/IOAccelerator.framework/Versions/A/IOAccelerator\r\n    0x7fff627f5000 -     0x7fff6280dfff  com.apple.IOPresentment (1.0 - 42.6) <890C4723-37AB-344B-9BF8-BFD436C06EE8> /System/Library/PrivateFrameworks/IOPresentment.framework/Versions/A/IOPresentment\r\n    0x7fff62bb5000 -     0x7fff62be2ff7  com.apple.IconServices (379 - 379) <7BAD562D-4FA3-3E11-863C-1EEBE2406D2C> /System/Library/PrivateFrameworks/IconServices.framework/Versions/A/IconServices\r\n    0x7fff62e75000 -     0x7fff62e87ff3  com.apple.security.KeychainCircle.KeychainCircle (1.0 - 1) <70CE5230-195D-3443-94EE-EFA57039724F> /System/Library/PrivateFrameworks/KeychainCircle.framework/Versions/A/KeychainCircle\r\n    0x7fff62ea2000 -     0x7fff62f7dff7  com.apple.LanguageModeling (1.0 - 159.15.15) <3DE3CE61-542B-37B7-883E-4B9717CAC65F> /System/Library/PrivateFrameworks/LanguageModeling.framework/Versions/A/LanguageModeling\r\n    0x7fff62f7e000 -     0x7fff62fbaff7  com.apple.Lexicon-framework (1.0 - 33.15.10) <4B5E843E-2809-3E70-9560-9254E2656419> /System/Library/PrivateFrameworks/Lexicon.framework/Versions/A/Lexicon\r\n    0x7fff62fc1000 -     0x7fff62fc6fff  com.apple.LinguisticData (1.0 - 238.25) <F529B961-098C-3E4C-A3E9-9DA9BFA1B3F0> /System/Library/PrivateFrameworks/LinguisticData.framework/Versions/A/LinguisticData\r\n    0x7fff63cbc000 -     0x7fff63ce4ff7  com.apple.spotlight.metadata.utilities (1.0 - 1191.58) <23E8580B-19C0-3E4F-A9FE-368DA80EAA6F> /System/Library/PrivateFrameworks/MetadataUtilities.framework/Versions/A/MetadataUtilities\r\n    0x7fff63ce5000 -     0x7fff63d72ff7  com.apple.gpusw.MetalTools (1.0 - 1) <9B542958-6363-3041-A265-EC7AC7BD7A43> /System/Library/PrivateFrameworks/MetalTools.framework/Versions/A/MetalTools\r\n    0x7fff63f1d000 -     0x7fff63f38ffb  com.apple.MobileKeyBag (2.0 - 1.0) <39337CBB-1D39-3DDC-A998-591194C76523> /System/Library/PrivateFrameworks/MobileKeyBag.framework/Versions/A/MobileKeyBag\r\n    0x7fff63fc1000 -     0x7fff63febffb  com.apple.MultitouchSupport.framework (2450.1 - 2450.1) <42A23EC9-64A7-31C7-BF33-DF4412ED8A3F> /System/Library/PrivateFrameworks/MultitouchSupport.framework/Versions/A/MultitouchSupport\r\n    0x7fff64227000 -     0x7fff64231fff  com.apple.NetAuth (6.2 - 6.2) <0D01BBE5-0269-310D-B148-D19DAE143DEB> /System/Library/PrivateFrameworks/NetAuth.framework/Versions/A/NetAuth\r\n    0x7fff64a92000 -     0x7fff64ae3ff3  com.apple.OTSVG (1.0 - ???) <B7620B5E-CDE2-3BDD-B6EC-8AB143FC5C4E> /System/Library/PrivateFrameworks/OTSVG.framework/Versions/A/OTSVG\r\n    0x7fff65c7c000 -     0x7fff65c8bff7  com.apple.PerformanceAnalysis (1.218.2 - 218.2) <65F3DB3E-6D4E-33A0-B510-EF768D323DAB> /System/Library/PrivateFrameworks/PerformanceAnalysis.framework/Versions/A/PerformanceAnalysis\r\n    0x7fff67b1d000 -     0x7fff67b3bff7  com.apple.ProtocolBuffer (1 - 263.2) <907D6C95-D050-31DE-99CA-16A5135BC6F9> /System/Library/PrivateFrameworks/ProtocolBuffer.framework/Versions/A/ProtocolBuffer\r\n    0x7fff67cd3000 -     0x7fff67d23fff  com.apple.ROCKit (27.6 - 27.6) <756C2253-E8B1-3C48-9945-DE8D6AD24DE2> /System/Library/PrivateFrameworks/ROCKit.framework/Versions/A/ROCKit\r\n    0x7fff67e7d000 -     0x7fff67e9ffff  com.apple.RemoteViewServices (2.0 - 128) <8FB0E4EB-DCBB-32E6-94C6-AA9BA9EE4CAC> /System/Library/PrivateFrameworks/RemoteViewServices.framework/Versions/A/RemoteViewServices\r\n    0x7fff696a9000 -     0x7fff697c7fff  com.apple.Sharing (1288.62.5 - 1288.62.5) <BB647030-839A-3271-B205-D4325346DD3B> /System/Library/PrivateFrameworks/Sharing.framework/Versions/A/Sharing\r\n    0x7fff6a5db000 -     0x7fff6a88afff  com.apple.SkyLight (1.600.0 - 340.55) <1F737945-E242-3F03-A7D6-1A5955AB1298> /System/Library/PrivateFrameworks/SkyLight.framework/Versions/A/SkyLight\r\n    0x7fff6b02e000 -     0x7fff6b03afff  com.apple.SpeechRecognitionCore (5.0.21 - 5.0.21) <7A6A67DB-C813-328E-AAFB-D267A5B50B3D> /System/Library/PrivateFrameworks/SpeechRecognitionCore.framework/Versions/A/SpeechRecognitionCore\r\n    0x7fff6b78b000 -     0x7fff6b816fc7  com.apple.Symbolication (10.2 - 64490.38.1) <9FDCC98D-5B32-35AD-A9BF-94DF2B78507F> /System/Library/PrivateFrameworks/Symbolication.framework/Versions/A/Symbolication\r\n    0x7fff6bcfe000 -     0x7fff6bd0affb  com.apple.TCC (1.0 - 1) <73CF6FA9-44CE-30C9-887F-235940976585> /System/Library/PrivateFrameworks/TCC.framework/Versions/A/TCC\r\n    0x7fff6bf70000 -     0x7fff6c038ff3  com.apple.TextureIO (3.8.4 - 3.8.1) <7CEAC05A-D283-3D5A-B1E3-C849285FA0BF> /System/Library/PrivateFrameworks/TextureIO.framework/Versions/A/TextureIO\r\n    0x7fff6c0f5000 -     0x7fff6c2adffb  com.apple.UIFoundation (1.0 - 551.5) <A0FDC3A4-45C6-3C87-B77F-7DC394374C08> /System/Library/PrivateFrameworks/UIFoundation.framework/Versions/A/UIFoundation\r\n    0x7fff6d7da000 -     0x7fff6d7ddfff  com.apple.dt.XCTTargetBootstrap (1.0 - 14490.66) <7AE3457F-AF40-3508-93FB-1D9E31EB1C9D> /System/Library/PrivateFrameworks/XCTTargetBootstrap.framework/Versions/A/XCTTargetBootstrap\r\n    0x7fff6dbde000 -     0x7fff6dbe0ffb  com.apple.loginsupport (1.0 - 1) <3F8D6334-BCD6-36C1-BA20-CC8503A84375> /System/Library/PrivateFrameworks/login.framework/Versions/A/Frameworks/loginsupport.framework/Versions/A/loginsupport\r\n    0x7fff6deaa000 -     0x7fff6dedefff  libCRFSuite.dylib (41.15.4) <406DAC06-0C77-3F90-878B-4D38F11F0256> /usr/lib/libCRFSuite.dylib\r\n    0x7fff6dee1000 -     0x7fff6deebff7  libChineseTokenizer.dylib (28.15.3) <9B7F6109-3A5D-3641-9A7E-31D2239D73EE> /usr/lib/libChineseTokenizer.dylib\r\n    0x7fff6df79000 -     0x7fff6df7affb  libDiagnosticMessagesClient.dylib (107) <A14D0819-0970-34CD-8680-80E4D7FE8C2C> /usr/lib/libDiagnosticMessagesClient.dylib\r\n    0x7fff6dfb1000 -     0x7fff6e208ff3  libFosl_dynamic.dylib (18.3.4) <1B5DD4E2-8AE0-315E-829E-D5BFCD264EA8> /usr/lib/libFosl_dynamic.dylib\r\n    0x7fff6e259000 -     0x7fff6e278fff  libMobileGestalt.dylib (645.270.1) <99A06C8A-97D6-383D-862C-F453BABB48A4> /usr/lib/libMobileGestalt.dylib\r\n    0x7fff6e279000 -     0x7fff6e279fff  libOpenScriptingUtil.dylib (179.1) <4D603146-EDA5-3A74-9FF8-4F75D8BB9BC6> /usr/lib/libOpenScriptingUtil.dylib\r\n    0x7fff6e3b9000 -     0x7fff6e3baffb  libSystem.B.dylib (1252.250.1) <82F463D9-8E43-30B7-8CB2-A65E6EBDDB34> /usr/lib/libSystem.B.dylib\r\n    0x7fff6e436000 -     0x7fff6e437fff  libThaiTokenizer.dylib (2.15.1) <ADB37DC3-7D9B-3E73-A72A-BCC3433C937A> /usr/lib/libThaiTokenizer.dylib\r\n    0x7fff6e449000 -     0x7fff6e45fffb  libapple_nghttp2.dylib (1.24.1) <6F04250A-6686-3FDC-9A8D-290C64B06502> /usr/lib/libapple_nghttp2.dylib\r\n    0x7fff6e460000 -     0x7fff6e489ffb  libarchive.2.dylib (54.250.1) <47289946-8504-3966-9127-6CE39993DC2C> /usr/lib/libarchive.2.dylib\r\n    0x7fff6e48a000 -     0x7fff6e509fff  libate.dylib (1.13.8) <92B44EDB-369D-3EE8-AEC5-61F8B9313DBF> /usr/lib/libate.dylib\r\n    0x7fff6e50d000 -     0x7fff6e50dff3  libauto.dylib (187) <3E3780E1-96F3-3A22-91C5-92F9A5805518> /usr/lib/libauto.dylib\r\n    0x7fff6e5df000 -     0x7fff6e5efffb  libbsm.0.dylib (39.200.18) <CF381E0B-025B-364F-A83D-2527E03F1AA3> /usr/lib/libbsm.0.dylib\r\n    0x7fff6e5f0000 -     0x7fff6e5fdfff  libbz2.1.0.dylib (38.200.3) <272953A1-8D36-329B-BDDB-E887B347710F> /usr/lib/libbz2.1.0.dylib\r\n    0x7fff6e5fe000 -     0x7fff6e651ff7  libc++.1.dylib (400.9.4) <9A60A190-6C34-339F-BB3D-AACE942009A4> /usr/lib/libc++.1.dylib\r\n    0x7fff6e652000 -     0x7fff6e667ff7  libc++abi.dylib (400.17) <38C09CED-9090-3719-90F3-04A2749F5428> /usr/lib/libc++abi.dylib\r\n    0x7fff6e668000 -     0x7fff6e668ff3  libcharset.1.dylib (51.200.6) <2A27E064-314C-359C-93FC-8A9B06206174> /usr/lib/libcharset.1.dylib\r\n    0x7fff6e669000 -     0x7fff6e679ffb  libcmph.dylib (6.15.1) <9C52B2FE-179F-32AC-B87E-2AFC49ABF817> /usr/lib/libcmph.dylib\r\n    0x7fff6e67a000 -     0x7fff6e692ffb  libcompression.dylib (52.250.2) <7F4BB18C-1FB4-3825-8D8B-6E6B168774C6> /usr/lib/libcompression.dylib\r\n    0x7fff6e907000 -     0x7fff6e91dfff  libcoretls.dylib (155.220.1) <4C64BE3E-41E3-3020-8BB7-07E90C0C861C> /usr/lib/libcoretls.dylib\r\n    0x7fff6e91e000 -     0x7fff6e91fff3  libcoretls_cfhelpers.dylib (155.220.1) <0959B3E9-6643-3589-8BB3-21D52CDF0EF1> /usr/lib/libcoretls_cfhelpers.dylib\r\n    0x7fff6edcb000 -     0x7fff6ee21ff3  libcups.2.dylib (462.15) <9A487009-8412-3D77-8F55-DE4BBCFBE58C> /usr/lib/libcups.2.dylib\r\n    0x7fff6ef55000 -     0x7fff6ef55fff  libenergytrace.dylib (17.200.1) <80BB567A-FD18-3497-BF97-353F57D98CDD> /usr/lib/libenergytrace.dylib\r\n    0x7fff6ef87000 -     0x7fff6ef8cff7  libgermantok.dylib (17.15.2) <E5F0F794-FF27-3D64-AE52-C78C6A84DD67> /usr/lib/libgermantok.dylib\r\n    0x7fff6ef8d000 -     0x7fff6ef92ff7  libheimdal-asn1.dylib (520.270.1) <73F60D6F-76F8-35EF-9C86-9A81225EE4BE> /usr/lib/libheimdal-asn1.dylib\r\n    0x7fff6efbd000 -     0x7fff6f0adfff  libiconv.2.dylib (51.200.6) <2047C9B7-3F74-3A95-810D-2ED8F0475A99> /usr/lib/libiconv.2.dylib\r\n    0x7fff6f0ae000 -     0x7fff6f30fffb  libicucore.A.dylib (62141.0.1) <A0D63918-76E9-3C1B-B255-46F4C1DA7FE8> /usr/lib/libicucore.A.dylib\r\n    0x7fff6f35c000 -     0x7fff6f35dfff  liblangid.dylib (128.15.1) <22D05C4F-769B-3075-ABCF-44A0EBACE028> /usr/lib/liblangid.dylib\r\n    0x7fff6f35e000 -     0x7fff6f376ff3  liblzma.5.dylib (10.200.3) <E1F4FD60-1CE4-37B9-AD95-29D348AF1AC0> /usr/lib/liblzma.5.dylib\r\n    0x7fff6f38e000 -     0x7fff6f432ff7  libmecab.1.0.0.dylib (779.24.1) <A8D0379B-85FA-3B3D-89ED-5CF2C3826AB2> /usr/lib/libmecab.1.0.0.dylib\r\n    0x7fff6f433000 -     0x7fff6f637fff  libmecabra.dylib (779.24.1) <D71F71E0-30E2-3DB3-B636-7DE13D51FB4B> /usr/lib/libmecabra.dylib\r\n    0x7fff6f80f000 -     0x7fff6fb60ff7  libnetwork.dylib (1229.250.15) <72C7E9E3-B2BE-3300-BE1B-64606222022C> /usr/lib/libnetwork.dylib\r\n    0x7fff6fbf2000 -     0x7fff70377fdf  libobjc.A.dylib (756.2) <7C312627-43CB-3234-9324-4DEA92D59F50> /usr/lib/libobjc.A.dylib\r\n    0x7fff70389000 -     0x7fff7038dffb  libpam.2.dylib (22.200.1) <586CF87F-349C-393D-AEEB-FB75F94A5EB7> /usr/lib/libpam.2.dylib\r\n    0x7fff70390000 -     0x7fff703c5fff  libpcap.A.dylib (79.250.3) <97B8CE1B-3EF6-3443-95EF-5659733139C9> /usr/lib/libpcap.A.dylib\r\n    0x7fff704de000 -     0x7fff704f6ffb  libresolv.9.dylib (65.200.3) <1FB0982D-84D9-36E0-B3D8-C808891EFF50> /usr/lib/libresolv.9.dylib\r\n    0x7fff70549000 -     0x7fff70726fff  libsqlite3.dylib (274.26) <6404BA3B-BCA4-301F-B2FE-8776105A2AA3> /usr/lib/libsqlite3.dylib\r\n    0x7fff7093f000 -     0x7fff70942ff7  libutil.dylib (51.200.4) <CE9B18C9-66ED-32D4-9D29-01F8FCB467B0> /usr/lib/libutil.dylib\r\n    0x7fff70943000 -     0x7fff70950fff  libxar.1.dylib (417.1) <39CCF46B-C81A-34B1-92A1-58C4E5DA846E> /usr/lib/libxar.1.dylib\r\n    0x7fff70955000 -     0x7fff70a38ff3  libxml2.2.dylib (32.15) <2748446B-C53C-3B6C-BB5D-B9153D7243E1> /usr/lib/libxml2.2.dylib\r\n    0x7fff70a39000 -     0x7fff70a61ff3  libxslt.1.dylib (16.7) <EC50E503-AEEE-3F50-956F-55E4AF4584D9> /usr/lib/libxslt.1.dylib\r\n    0x7fff70a62000 -     0x7fff70a74ff7  libz.1.dylib (70.200.4) <B048FC1F-058F-3A08-A1FE-81D5308CB3E6> /usr/lib/libz.1.dylib\r\n    0x7fff71258000 -     0x7fff7125cff3  libcache.dylib (81) <1987D1E1-DB11-3291-B12A-EBD55848E02D> /usr/lib/system/libcache.dylib\r\n    0x7fff7125d000 -     0x7fff71267ff3  libcommonCrypto.dylib (60118.250.2) <1765BB6E-6784-3653-B16B-CB839721DC9A> /usr/lib/system/libcommonCrypto.dylib\r\n    0x7fff71268000 -     0x7fff7126fff7  libcompiler_rt.dylib (63.4) <5212BA7B-B7EA-37B4-AF6E-AC4F507EDFB8> /usr/lib/system/libcompiler_rt.dylib\r\n    0x7fff71270000 -     0x7fff71279ff7  libcopyfile.dylib (146.250.1) <98CD00CD-9B91-3B5C-A9DB-842638050FA8> /usr/lib/system/libcopyfile.dylib\r\n    0x7fff7127a000 -     0x7fff712fefc3  libcorecrypto.dylib (602.260.2) <01464D24-570C-3B83-9D18-467769E0FCDD> /usr/lib/system/libcorecrypto.dylib\r\n    0x7fff71385000 -     0x7fff713beff7  libdispatch.dylib (1008.270.1) <97273678-E94C-3C8C-89F6-2E2020F4B43B> /usr/lib/system/libdispatch.dylib\r\n    0x7fff713bf000 -     0x7fff713ebff7  libdyld.dylib (655.1.1) <002418CC-AD11-3D10-865B-015591D24E6C> /usr/lib/system/libdyld.dylib\r\n    0x7fff713ec000 -     0x7fff713ecffb  libkeymgr.dylib (30) <0D0F9CA2-8D5A-3273-8723-59987B5827F2> /usr/lib/system/libkeymgr.dylib\r\n    0x7fff713ed000 -     0x7fff713f9ff3  libkxld.dylib (4903.278.35) <AF9234BD-D3A5-323A-B170-1525C841DD7E> /usr/lib/system/libkxld.dylib\r\n    0x7fff713fa000 -     0x7fff713faff7  liblaunch.dylib (1336.261.4) <AEBAE502-D691-3D26-BFD9-CB41090C0360> /usr/lib/system/liblaunch.dylib\r\n    0x7fff713fb000 -     0x7fff71400fff  libmacho.dylib (927.0.3) <A377D608-77AB-3F6E-90F0-B4F251A5C12F> /usr/lib/system/libmacho.dylib\r\n    0x7fff71401000 -     0x7fff71403ff7  libquarantine.dylib (86.270.1) <3F36A3D6-9606-3D90-B520-809BAEF981C3> /usr/lib/system/libquarantine.dylib\r\n    0x7fff71404000 -     0x7fff71405ff7  libremovefile.dylib (45.200.2) <9FBEB2FF-EEBE-31BC-BCFC-C71F8D0E99B6> /usr/lib/system/libremovefile.dylib\r\n    0x7fff71406000 -     0x7fff7141dff3  libsystem_asl.dylib (356.200.4) <A62A7249-38B8-33FA-9875-F1852590796C> /usr/lib/system/libsystem_asl.dylib\r\n    0x7fff7141e000 -     0x7fff7141eff7  libsystem_blocks.dylib (73) <A453E8EE-860D-3CED-B5DC-BE54E9DB4348> /usr/lib/system/libsystem_blocks.dylib\r\n    0x7fff7141f000 -     0x7fff714a6fff  libsystem_c.dylib (1272.250.1) <7EDACF78-2FA3-35B8-B051-D70475A35117> /usr/lib/system/libsystem_c.dylib\r\n    0x7fff714a7000 -     0x7fff714aaffb  libsystem_configuration.dylib (963.270.3) <2B4A836D-68A4-33E6-8D48-CD4486B03387> /usr/lib/system/libsystem_configuration.dylib\r\n    0x7fff714ab000 -     0x7fff714aeff7  libsystem_coreservices.dylib (66) <719F75A4-74C5-3BA6-A09E-0C5A3E5889D7> /usr/lib/system/libsystem_coreservices.dylib\r\n    0x7fff714af000 -     0x7fff714b5fff  libsystem_darwin.dylib (1272.250.1) <EC9B39A5-9592-3577-8997-7DC721D20D8C> /usr/lib/system/libsystem_darwin.dylib\r\n    0x7fff714b6000 -     0x7fff714bcffb  libsystem_dnssd.dylib (878.270.3) <D5352ABD-0311-3327-8E64-93F29EB19BF1> /usr/lib/system/libsystem_dnssd.dylib\r\n    0x7fff714bd000 -     0x7fff71508ffb  libsystem_info.dylib (517.200.9) <D09D5AE0-2FDC-3A6D-93EC-729F931B1457> /usr/lib/system/libsystem_info.dylib\r\n    0x7fff71509000 -     0x7fff71531ff7  libsystem_kernel.dylib (4903.278.35) <253AF05A-457D-37A6-890B-C3CD9CE8A3FD> /usr/lib/system/libsystem_kernel.dylib\r\n    0x7fff71532000 -     0x7fff7157dff7  libsystem_m.dylib (3158.200.7) <F19B6DB7-014F-3820-831F-389CCDA06EF6> /usr/lib/system/libsystem_m.dylib\r\n    0x7fff7157e000 -     0x7fff715a8fff  libsystem_malloc.dylib (166.270.1) <011F3AD0-8E6A-3A89-AE64-6E5F6840F30A> /usr/lib/system/libsystem_malloc.dylib\r\n    0x7fff715a9000 -     0x7fff715b3ff7  libsystem_networkextension.dylib (767.250.2) <FF06F13A-AEFE-3A27-A073-910EF78AEA36> /usr/lib/system/libsystem_networkextension.dylib\r\n    0x7fff715b4000 -     0x7fff715bbfff  libsystem_notify.dylib (172.200.21) <145B5CFC-CF73-33CE-BD3D-E8DDE268FFDE> /usr/lib/system/libsystem_notify.dylib\r\n    0x7fff715bc000 -     0x7fff715c5fef  libsystem_platform.dylib (177.270.1) <9D1FE5E4-EB7D-3B3F-A8D1-A96D9CF1348C> /usr/lib/system/libsystem_platform.dylib\r\n    0x7fff715c6000 -     0x7fff715d0ff7  libsystem_pthread.dylib (330.250.2) <2D5C08FF-484F-3D59-9132-CE1DCB3F76D7> /usr/lib/system/libsystem_pthread.dylib\r\n    0x7fff715d1000 -     0x7fff715d4ff7  libsystem_sandbox.dylib (851.270.3) <0F89B133-8D87-3B2E-BA5A-C7138738C581> /usr/lib/system/libsystem_sandbox.dylib\r\n    0x7fff715d5000 -     0x7fff715d7ff3  libsystem_secinit.dylib (30.260.2) <EF1EA47B-7B22-35E8-BD9B-F7003DCB96AE> /usr/lib/system/libsystem_secinit.dylib\r\n    0x7fff715d8000 -     0x7fff715dfff3  libsystem_symptoms.dylib (820.267.1) <03F1C2DD-0F5A-3D9D-88F6-B26C0F94EB52> /usr/lib/system/libsystem_symptoms.dylib\r\n    0x7fff715e0000 -     0x7fff715f5ff7  libsystem_trace.dylib (906.260.2) <12C1B9A2-39D6-3428-AE60-2303BD201A57> /usr/lib/system/libsystem_trace.dylib\r\n    0x7fff715f7000 -     0x7fff715fcffb  libunwind.dylib (35.4) <24A97A67-F017-3CFC-B0D0-6BD0224B1336> /usr/lib/system/libunwind.dylib\r\n    0x7fff715fd000 -     0x7fff7162cfff  libxpc.dylib (1336.261.4) <7A9D1BF7-F17F-3B87-9373-B0079544E8C5> /usr/lib/system/libxpc.dylib\r\n\r\nExternal Modification Summary:\r\n  Calls made by other processes targeting this process:\r\n    task_for_pid: 0\r\n    thread_create: 0\r\n    thread_set_state: 0\r\n  Calls made by this process:\r\n    task_for_pid: 0\r\n    thread_create: 0\r\n    thread_set_state: 0\r\n  Calls made by all processes on this machine:\r\n    task_for_pid: 177097\r\n    thread_create: 0\r\n    thread_set_state: 0\r\n\r\nVM Region Summary:\r\nReadOnly portion of Libraries: Total=848.5M resident=0K(0%) swapped_out_or_unallocated=848.5M(100%)\r\nWritable regions: Total=596.0M written=0K(0%) resident=0K(0%) swapped_out=0K(0%) unallocated=596.0M(100%)\r\n \r\n                                VIRTUAL   REGION \r\nREGION TYPE                        SIZE    COUNT (non-coalesced) \r\n===========                     =======  ======= \r\nKernel Alloc Once                    8K        1 \r\nMALLOC                           203.0M       15 \r\nMALLOC guard page                   16K        4 \r\nMALLOC_NANO (reserved)           384.0M        1         reserved VM address space (unallocated)\r\nSTACK GUARD                       56.0M        1 \r\nStack                             8192K        1 \r\n__DATA                            29.5M      248 \r\n__FONT_DATA                          4K        1 \r\n__LINKEDIT                       357.0M       14 \r\n__TEXT                           491.5M      242 \r\n__UNICODE                          564K        1 \r\nshared memory                        8K        2 \r\n===========                     =======  ======= \r\nTOTAL                              1.5G      531 \r\nTOTAL, minus reserved VM space     1.1G      531 \n\ncc @malfet @yf225 @glaringlee @gujinghui @PenghuiCheng @XiaobingSuper @jianyuh @VitalyFedyunin"},{"labels":["api",null,null],"text":"I find that nonzero function in C++ API much slower than python.\r\nHere comes my test code:\r\n\r\n```\r\nauto test = torch::ones({1,368,1224});\r\n    for(int i = 0;i < 368;++i){\r\n        for(int j = 0;j<1224;++j){\r\n            float f;\r\n            fin>>f;\r\n            test.index_put_({0,i,j},f);\r\n        }\r\n    }    //just read the a tensor from file \r\n    test = test.cuda();\r\n    clock_t total = 0;\r\n    for(int i = 0;i<100;++i){\r\n        clock_t startTime = clock();\r\n        auto t = at::nonzero(test);\r\n        clock_t endTime = clock();\r\n        total += endTime-startTime;\r\n    }\r\n\r\n    cout<<(double)(total)/CLOCKS_PER_SEC * 1000 / 100<<endl;\r\n```\r\n\r\nand python code:\r\n```\r\ntest = torch.Tensor(test).cuda()\r\ntotal = 0.0\r\nfor i in range(100):\r\n    torch.cuda.synchronize()\r\n    start = time.time()\r\n    t = torch.nonzero(test)\r\n    torch.cuda.synchronize()\r\n    end = time.time()\r\n    total += end-start\r\n\r\nprint((end-start)*10,\"ms\")\r\n```\r\n\r\nC++ result is: 0.32987 ms\r\npython result is : 0.0018024444580078125 ms\r\n\r\nThe env of my computer:\r\n```\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 16.04.6 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.5\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration: GPU 0: GeForce GTX 1660 Ti\r\nNvidia driver version: Could not collect\r\ncuDNN version: Could not collect\r\n```\r\nthe libtorch bulid-version is 1.6.0.dev20200603+cu101\r\n\r\ncc @yf225 @glaringlee @VitalyFedyunin @ngimel"},{"labels":["api",null,null],"text":"## üêõ Bug\r\nIs was following the example for saving a `torch::tensor` in `c++` and loading it in python kindly provided by @xiangpan-osu at the bottom of #20356. In particular, I wrote \r\n```c++\r\n#include <torch/script.h>\r\n\r\n#include <iostream>\r\n#include <memory>\r\n\r\nint main() {\r\n  auto x = torch::ones({3, 3});\r\n  auto bytes = torch::jit::pickle_save(x);\r\n  std::ofstream fout(\"x.zip\", std::ios::out | std::ios::binary);\r\n  fout.write(bytes.data(), bytes.size());\r\n  fout.close();\r\n  return 0;\r\n}\r\n```\r\nand compiled the program with \r\n```c++\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nfind_package(Torch REQUIRED)\r\n\r\nadd_executable(example-app test.cpp)\r\ntarget_link_libraries(example-app  PUBLIC \"${TORCH_LIBRARIES}\")\r\nset_property(TARGET example-app PROPERTY CXX_STANDARD 17)\r\n```\r\nWhen loading the saved file `x.zip` in python, I receive the following error: \r\n```python\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-2-f3cc1cba2382> in <module>\r\n----> 1 torch.load('x.zip')\r\n\r\n~/.local/lib/python3.7/site-packages/torch/serialization.py in load(f, map_location, pickle_module, **pickle_load_args)\r\n    526         if _is_zipfile(opened_file):\r\n    527             with _open_zipfile_reader(f) as opened_zipfile:\r\n--> 528                 return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\r\n    529         return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\r\n    530 \r\n\r\n~/.local/lib/python3.7/site-packages/torch/serialization.py in _load(zip_file, map_location, pickle_module, **pickle_load_args)\r\n    780     unpickler = pickle_module.Unpickler(data_file, **pickle_load_args)\r\n    781     unpickler.persistent_load = persistent_load\r\n--> 782     result = unpickler.load()\r\n    783 \r\n    784     return result\r\n\r\n~/.local/lib/python3.7/site-packages/torch/serialization.py in persistent_load(saved_id)\r\n    772         data_type, key, location, size = data\r\n    773         if key not in loaded_storages:\r\n--> 774             load_tensor(data_type(size), size, key, _maybe_decode_ascii(location))\r\n    775         storage = loaded_storages[key]\r\n    776         return storage\r\n\r\n~/.local/lib/python3.7/site-packages/torch/serialization.py in load_tensor(obj, size, key, location)\r\n    757         name = 'tensors/{}'.format(key)\r\n    758         size_long = struct.pack(\"<Q\", size)\r\n--> 759         tensor_file = io.BytesIO(size_long + zip_file.get_record(name))\r\n    760         offset = None\r\n    761         is_real_file = False\r\n\r\nRuntimeError: [enforce fail at inline_container.cc:197] . file not found: archive/tensors/0\r\nframe #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x7f7db9c0fd37 in /home/fabian/.local/lib/python3.7/site-packages/torch/lib/libc10.so)\r\nframe #1: caffe2::serialize::PyTorchStreamReader::getRecordID(std::string const&) + 0xe0 (0x7f7dbcd92e30 in /home/fabian/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\nframe #2: caffe2::serialize::PyTorchStreamReader::getRecord(std::string const&) + 0x25 (0x7f7dbcd959f5 in /home/fabian/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\nframe #3: <unknown function> + 0x6a6488 (0x7f7e04ec6488 in /home/fabian/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\r\nframe #4: <unknown function> + 0x295a74 (0x7f7e04ab5a74 in /home/fabian/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\r\nframe #5: _PyMethodDef_RawFastCallKeywords + 0x13b (0x5c85bb in /usr/bin/python)\r\nframe #6: _PyObject_FastCallKeywords + 0x6c9 (0x5ca149 in /usr/bin/python)\r\nframe #7: /usr/bin/python() [0x535a11]\r\nframe #8: _PyEval_EvalFrameDefault + 0x4511 (0x53c5a1 in /usr/bin/python)\r\nframe #9: _PyEval_EvalCodeWithName + 0xb87 (0x536f27 in /usr/bin/python)\r\nframe #10: _PyFunction_FastCallKeywords + 0x488 (0x5c9468 in /usr/bin/python)\r\nframe #11: /usr/bin/python() [0x535880]\r\nframe #12: _PyEval_EvalFrameDefault + 0x552 (0x5385e2 in /usr/bin/python)\r\nframe #13: _PyEval_EvalCodeWithName + 0xb87 (0x536f27 in /usr/bin/python)\r\nframe #14: _PyFunction_FastCallDict + 0x34e (0x5ca63e in /usr/bin/python)\r\nframe #15: /usr/bin/python() [0x5cbcf4]\r\nframe #16: PyObject_CallFunctionObjArgs + 0x89 (0x5cc109 in /usr/bin/python)\r\nframe #17: /usr/bin/python() [0x46f5c3]\r\nframe #18: _PyMethodDescr_FastCallKeywords + 0x1c3 (0x4daca3 in /usr/bin/python)\r\nframe #19: /usr/bin/python() [0x535956]\r\nframe #20: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #21: _PyEval_EvalCodeWithName + 0xb87 (0x536f27 in /usr/bin/python)\r\nframe #22: _PyFunction_FastCallDict + 0x34e (0x5ca63e in /usr/bin/python)\r\nframe #23: _PyEval_EvalFrameDefault + 0x19a2 (0x539a32 in /usr/bin/python)\r\nframe #24: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\nframe #25: _PyFunction_FastCallKeywords + 0x488 (0x5c9468 in /usr/bin/python)\r\nframe #26: /usr/bin/python() [0x535880]\r\nframe #27: _PyEval_EvalFrameDefault + 0x4511 (0x53c5a1 in /usr/bin/python)\r\nframe #28: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\nframe #29: PyEval_EvalCode + 0x23 (0x64cbb3 in /usr/bin/python)\r\nframe #30: /usr/bin/python() [0x64e321]\r\nframe #31: _PyMethodDef_RawFastCallKeywords + 0x70 (0x5c84f0 in /usr/bin/python)\r\nframe #32: /usr/bin/python() [0x535990]\r\nframe #33: _PyEval_EvalFrameDefault + 0x552 (0x5385e2 in /usr/bin/python)\r\nframe #34: /usr/bin/python() [0x4d90d4]\r\nframe #35: _PyEval_EvalFrameDefault + 0x1a7f (0x539b0f in /usr/bin/python)\r\nframe #36: /usr/bin/python() [0x4d90d4]\r\nframe #37: _PyEval_EvalFrameDefault + 0x1a7f (0x539b0f in /usr/bin/python)\r\nframe #38: /usr/bin/python() [0x4d90d4]\r\nframe #39: _PyMethodDescr_FastCallKeywords + 0x34d (0x4dae2d in /usr/bin/python)\r\nframe #40: /usr/bin/python() [0x535956]\r\nframe #41: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #42: _PyFunction_FastCallKeywords + 0x18b (0x5c916b in /usr/bin/python)\r\nframe #43: /usr/bin/python() [0x535880]\r\nframe #44: _PyEval_EvalFrameDefault + 0x552 (0x5385e2 in /usr/bin/python)\r\nframe #45: _PyFunction_FastCallKeywords + 0x18b (0x5c916b in /usr/bin/python)\r\nframe #46: /usr/bin/python() [0x535880]\r\nframe #47: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #48: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\nframe #49: _PyFunction_FastCallKeywords + 0x488 (0x5c9468 in /usr/bin/python)\r\nframe #50: /usr/bin/python() [0x535880]\r\nframe #51: _PyEval_EvalFrameDefault + 0x1451 (0x5394e1 in /usr/bin/python)\r\nframe #52: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\nframe #53: _PyFunction_FastCallKeywords + 0x488 (0x5c9468 in /usr/bin/python)\r\nframe #54: /usr/bin/python() [0x535880]\r\nframe #55: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #56: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\nframe #57: _PyFunction_FastCallKeywords + 0x488 (0x5c9468 in /usr/bin/python)\r\nframe #58: /usr/bin/python() [0x535880]\r\nframe #59: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #60: _PyFunction_FastCallKeywords + 0x18b (0x5c916b in /usr/bin/python)\r\nframe #61: /usr/bin/python() [0x535880]\r\nframe #62: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #63: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\n``` \r\nDoes somebody have any ideas I cannot load the tensor in python? I find it difficult to make sense of the error message above and would appreciate any hints and suggestions! \r\n## Environment\r\nCollecting environment information...\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 19.10\r\nGCC version: (Ubuntu 9.2.1-9ubuntu2) 9.2.1 20191008\r\nCMake version: version 3.13.4\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.1.168\r\nGPU models and configuration: GPU 0: Quadro T1000\r\nNvidia driver version: 435.21\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.17.0\r\n[pip3] torch==1.4.0\r\n[pip3] torchvision==0.5.0\r\n[conda] Could not collect\n\ncc @yf225 @glaringlee"},{"labels":["api",null],"text":"Valgrind is my go-to for wrangling possible memory leaks. It is a beautiful piece of software, but is unfortunately (and necessarily) imperfect. I just ran a libtorch-based application through a relatively brief optimization of a CNN model, and it generated a fair number of loss records. Fortunately, all of them appear to be of the ‚Äúpossibly lost‚Äù variety (as opposed to ‚Äúdefinitely lost‚Äù); I was using all of the available leak-check-heuristics available to valgrind. Many of these records reflect pytorch-based allocations embedded in pthread-related activities, which may just suggest that threads are not being thoroughly cleaned up on exit.\r\nHowever, there are a number of records which, at least going by the traceback, don‚Äôt reflect an allocation embedded in thread creation. For brevity, I won't quote any of them here, because I just want to ask a larger question: Is libtorch (v. 1.5, specifically) being subjected to any kind of careful memory-leak vetting, whether by valgrind or some other checker? I know valgrind is not necessarily the ultimate authority; something as simple as a -fsanitize=address compilation could do as well or better.\n\ncc @yf225 @glaringlee"},{"labels":["api",null],"text":"If C++ extension uses `ATen/Parallel.h` it requires [`AT_PARALLEL_OPENMP`/`AT_PARALLEL_NATIVE`/`AT_PARALLEL_NATIVE_TBB`](https://github.com/pytorch/pytorch/blob/46447045ea450069ab9a9cbbf71e86110013fb0b/aten/src/ATen/Parallel.h#L147-L153) which were used to build installed PyTorch. Currently they are unavailable after build, so these values should be included into `ATen/Config.h.in`\n\ncc @yf225 @glaringlee"},{"labels":["api",null,null],"text":"## üìö Documentation\r\n\r\nThe document enclosing the details of how one installs the C++ distribution of Pytorch, found [here](https://pytorch.org/cppdocs/installing.html), is missing one paragraph of code between the sentences _In that case CMake configuration step would look something like follows:_ and _If all goes well, it will look something like this:_\r\n\r\nApologies if this is not the place to report this, this was the best fit according to the template text.\r\n\n\ncc @yf225 @glaringlee"},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\nAdd cpack support for creating prepackaged builds of libtorch\r\n\r\n## Motivation\r\nDue to https://github.com/pytorch/pytorch/issues/14573 I need to compile libtorch from source and link against system protobuf.  libtorch is installed as part of a CI pipeline and rather than build it from source each time, I would like to be able to point to a prebuilt `.deb` package to install.\r\n\r\n## Pitch\r\nAdd [the few lines](https://gitlab.kitware.com/cmake/community/-/wikis/doc/cpack/Packaging-With-CPack) it would it take to support cpack\r\n\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":[null,"api",null,null],"text":"Please complete torchvision for libtorch c++.\r\nlike torchvision.ops ,torchvision.models.detection\r\nIt is best to provide a compiled torchvision.lib for libtorch.\r\n\n\ncc @yf225 @glaringlee @fmassa"},{"labels":[null,null,"api",null,null],"text":"## üêõ Bug\r\n`IntegrationTest.CartPole` from `test/cpp/api/integration.cpp` sometimes times out on `pytorch_bazel_build` CI jobs, see for example:\r\nSee failure: https://circleci.com/api/v1.1/project/github/pytorch/pytorch/5577465/output/104/0?file=true&allocation-id=5ecd716dc9b52d5635d36866-0-build%2F5B5F7F46\r\n\n\ncc @ezyang @gchanan @zou3519 @malfet @yf225 @glaringlee"},{"labels":[null,"api",null],"text":"## üêõ Bug\r\n\r\nLibTorch 1.5.0 seemed built on top of GLIBC 2.23 where PyTorch 1.5.0 pip wheel built on lower version. Do we have a plan to support LibTorch on version below 2.23? Or any instruction for user on GLIBC 2.23 and below to use it?\r\n\r\n## To Reproduce\r\n\r\nIf you try to use it on Cent OS 7, you can easily fall into the following issue:\r\n\r\n```\r\ndownload\r\nhttps://download.pytorch.org/libtorch/cu102/libtorch-cxx11-abi-shared-with-deps-1.5.0.zip\r\n```\r\n\r\nError message\r\n```\r\n/lib64/libm.so.6: version `GLIBC_2.23' not found (required by /home/centos/libtorch_cpu.so)\r\n```\r\n\r\n## Expected behavior\r\n\r\nIt should be fine to use the libtorch for lower GLIBC version as claimed here: https://pytorch.org/get-started/locally/#supported-linux-distributions\r\n\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.5.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: CentOS Linux 7 (Core)\r\nGCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)\r\nCMake version: version 3.6.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.4\r\n[pip3] torch==1.5.0\r\n[conda] Could not collect\r\n\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":[null,"api",null,null],"text":"## üêõ Bug\r\n\r\nI tried to build with my custom C++ application with Cent OS 7 and it failed. Then I tried to build from source with pytorch 1.5.0 and it crashed in a different place.\r\n\r\nSince the website claim Cent OS 7 is supported with GLIbc version > 2.17, how I can use it on Cent OS 7?\r\n\r\n## To Reproduce\r\n\r\n```\r\n# download https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-1.5.0%2Bcpu.zip\r\n# My custom cmake follow the guideline\r\n```\r\n\r\nerror messaage\r\n```\r\n-- The C compiler identification is GNU 4.8.5\r\n-- The CXX compiler identification is GNU 4.8.5\r\n-- Check for working C compiler: /usr/bin/cc\r\n-- Check for working C compiler: /usr/bin/cc -- works\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\n-- Check for working CXX compiler: /usr/bin/c++\r\n-- Check for working CXX compiler: /usr/bin/c++ -- works\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\nBuilding torch with the host...\r\n-- Looking for pthread.h\r\n-- Looking for pthread.h - found\r\n-- Looking for pthread_create\r\n-- Looking for pthread_create - not found\r\n-- Looking for pthread_create in pthreads\r\n-- Looking for pthread_create in pthreads - not found\r\n-- Looking for pthread_create in pthread\r\n-- Looking for pthread_create in pthread - found\r\n-- Found Threads: TRUE\r\n-- Found torch: /home/centos/pytorch/pytorch-native/libtorch/lib/libtorch.so\r\n-- Found JNI: /usr/lib/jvm/jre/lib/amd64/libjawt.so\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/centos/pytorch/build\r\n\r\nIn file included from /home/centos/pytorch/pytorch-native/libtorch/include/c10/util/typeid.h:22:0,\r\n                 from /home/centos/pytorch/pytorch-native/src/pytorch_jni_utils.h:16,\r\n                 from /home/centos/pytorch/pytorch-native/src/ai_pytorch_jni_PyTorchLibrary_nn_functional.cc:15:\r\n/home/centos/pytorch/pytorch-native/libtorch/include/c10/util/C++17.h:16:2: error: #error \"You're trying to build PyTorch with a too old version of GCC. We need GCC 5 or later.\"\r\n #error \"You're trying to build PyTorch with a too old version of GCC. We need GCC 5 or later.\"\r\n  ^\r\n/home/centos/pytorch/pytorch-native/libtorch/include/c10/util/C++17.h:24:2: error: #error You need C++14 to compile PyTorch\r\n #error You need C++14 to compile PyTorch\r\n  ^\r\nIn file included from /home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/util/ArrayRef.h:19:0,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/core/MemoryFormat.h:5,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/ATen/core/TensorBody.h:5,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/ATen/Tensor.h:11,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/ATen/Context.h:4,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/ATen/ATen.h:5,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/torch/csrc/api/include/torch/types.h:3,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/torch/script.h:3,\r\n                 from /home/centos/djl/pytorch/pytorch-native/src/ai_djl_pytorch_jni_PyTorchLibrary_inference.cc:13:\r\n/home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/util/C++17.h:16:2: error: #error \"You're trying to build PyTorch with a too old version of GCC. We need GCC 5 or later.\"\r\n #error \"You're trying to build PyTorch with a too old version of GCC. We need GCC 5 or later.\"\r\n  ^\r\n/home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/util/C++17.h:24:2: error: #error You need C++14 to compile PyTorch\r\n #error You need C++14 to compile PyTorch\r\n  ^\r\nIn file included from /home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/util/typeid.h:22:0,\r\n                 from /home/centos/djl/pytorch/pytorch-native/src/djl_pytorch_jni_utils.h:16,\r\n                 from /home/centos/djl/pytorch/pytorch-native/src/ai_djl_pytorch_jni_PyTorchLibrary_torch_isjm.cc:15:\r\n/home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/util/C++17.h:16:2: error: #error \"You're trying to build PyTorch with a too old version of GCC. We need GCC 5 or later.\"\r\n```\r\n\r\n\r\nAfter this, build from source\r\n\r\n```\r\n# checkout tags/v1.5.0\r\nmkdir build && cd build\r\npython3 ../tools/build_libtorch.py\r\n```\r\n\r\nError message\r\n```\r\ncmake -DBUILD_PYTHON=False -DBUILD_TEST=True -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_COMPILER=/usr/bin/cmake -DCMAKE_INSTALL_PREFIX=/home/centos/pytorch/torch -DCMAKE_PREFIX_PATH=/usr/lib/python3.6/site-packages -DNUMPY_INCLUDE_DIR=/home/centos/.local/lib/python3.6/site-packages/numpy/core/include -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DUSE_NUMPY=True /home/centos/pytorch\r\n-- The CXX compiler identification is unknown\r\n-- The C compiler identification is GNU 4.8.5\r\n-- Check for working CXX compiler: /usr/bin/cmake\r\n-- Check for working CXX compiler: /usr/bin/cmake -- broken\r\nCMake Error at /usr/local/share/cmake-3.6/Modules/CMakeTestCXXCompiler.cmake:54 (message):\r\n  The C++ compiler \"/usr/bin/cmake\" is not able to compile a simple test\r\n  program.\r\n\r\n  It fails with the following output:\r\n\r\n   Change Dir: /home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeTmp\r\n\r\n\r\n\r\n  Run Build Command:\"/usr/bin/gmake\" \"cmTC_53171/fast\"\r\n\r\n  /usr/bin/gmake -f CMakeFiles/cmTC_53171.dir/build.make\r\n  CMakeFiles/cmTC_53171.dir/build\r\n\r\n  gmake[1]: Entering directory\r\n  `/home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeTmp'\r\n\r\n  Building CXX object CMakeFiles/cmTC_53171.dir/testCXXCompiler.cxx.o\r\n\r\n  /usr/bin/cmake -o CMakeFiles/cmTC_53171.dir/testCXXCompiler.cxx.o -c\r\n  /home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeTmp/testCXXCompiler.cxx\r\n\r\n\r\n  CMake Error: The source directory\r\n  \"/home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeTmp/testCXXCompiler.cxx\"\r\n  is a file, not a directory.\r\n\r\n  Specify --help for usage, or press the help button on the CMake GUI.\r\n\r\n  gmake[1]: *** [CMakeFiles/cmTC_53171.dir/testCXXCompiler.cxx.o] Error 1\r\n\r\n  gmake[1]: Leaving directory\r\n  `/home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeTmp'\r\n\r\n  gmake: *** [cmTC_53171/fast] Error 2\r\n\r\n\r\n\r\n\r\n\r\n  CMake will not be able to correctly generate this project.\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:23 (project)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeOutput.log\".\r\nSee also \"/home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeError.log\".\r\nTraceback (most recent call last):\r\n  File \"../tools/build_libtorch.py\", line 23, in <module>\r\n    rerun_cmake=True, cmake_only=False, cmake=CMake())\r\n  File \"/home/centos/pytorch/tools/build_pytorch_libs.py\", line 59, in build_caffe2\r\n    rerun_cmake)\r\n  File \"/home/centos/pytorch/tools/setup_helpers/cmake.py\", line 323, in generate\r\n    self.run(args, env=my_env)\r\n  File \"/home/centos/pytorch/tools/setup_helpers/cmake.py\", line 141, in run\r\n    check_call(command, cwd=self.build_dir, env=env)\r\n  File \"/usr/lib64/python3.6/subprocess.py\", line 311, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['cmake', '-DBUILD_PYTHON=False', '-DBUILD_TEST=True', '-DCMAKE_BUILD_TYPE=Release', '-DCMAKE_CXX_COMPILER=/usr/bin/cmake', '-DCMAKE_INSTALL_PREFIX=/home/centos/pytorch/torch', '-DCMAKE_PREFIX_PATH=/usr/lib/python3.6/site-packages', '-DNUMPY_INCLUDE_DIR=/home/centos/.local/lib/python3.6/site-packages/numpy/core/include', '-DPYTHON_EXECUTABLE=/usr/bin/python3', '-DPYTHON_INCLUDE_DIR=/usr/include/python3.6m', '-DUSE_NUMPY=True', '/home/centos/pytorch']' returned non-zero exit status 1.\r\n```\r\n\r\n\r\n\r\n## Environment\r\n\r\nCollecting environment information...\r\nIs debug build: No\r\n\r\nOS: CentOS Linux 7 (Core)\r\nGCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)\r\nCMake version: version 3.6.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":["api",null],"text":"Now the libtorch header file is too slow to debug and compile.Will the next version of libtorch provide modules instead of header files in the c++20 standard?\r\n\r\nlike this:\r\nimport torch\r\ntorch::Tensor a=torch::tensor({1,2});\n\ncc @yf225 @glaringlee"},{"labels":[null,"api",null],"text":"Can you add an overloaded operator &,|,^ to a libtorch tensor\r\nexample:\r\npython: \r\na=torch.tensor((1))  \r\nb=torch.tensor((1))  \r\nc=a&b\r\nlibtorch:\r\nauto a=torch::tensor({1});\r\nauto b=torch::tensor({1});\r\nauto c=a&b;////no support\r\n\n\ncc @yf225 @glaringlee @ezyang"},{"labels":[null,"api",null,null,null],"text":"## üêõ Bug\r\n\r\nSegment Fault After model inference all images usnig C++ API\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. c++ code load my model\r\n2. do inference \r\n3. input all images\r\n4. before return, error occur\r\n\r\nMy dbg error message:\r\n\r\n```\r\n== Switch to GPU mode\r\n[New Thread 0x7fff215ea700 (LWP 30485)]\r\n[New Thread 0x7fff20de9700 (LWP 30486)]\r\n== ResNet50 loaded!\r\n== Label loaded! Let's try it\r\n== Input image path: [enter Q to exit]\r\n/home/yyh/test/PyTorch-CPP/pic/dog.jpg\r\n[New Thread 0x7fff2d664700 (LWP 30487)]\r\n[New Thread 0x7fff2ce63700 (LWP 30488)]\r\n[New Thread 0x7fff29fff700 (LWP 30489)]\r\n[New Thread 0x7fff297fe700 (LWP 30490)]\r\n[New Thread 0x7fff28ffd700 (LWP 30491)]\r\n[New Thread 0x7fff287fc700 (LWP 30492)]\r\n[New Thread 0x7fff27ffb700 (LWP 30493)]\r\n[New Thread 0x7fff03fff700 (LWP 30494)]\r\n[New Thread 0x7fff0233d700 (LWP 30495)]\r\n[New Thread 0x7fff01b3c700 (LWP 30496)]\r\n[New Thread 0x7ffeeffff700 (LWP 30497)]\r\n[New Thread 0x7ffeef7fe700 (LWP 30498)]\r\n[New Thread 0x7ffeeeffd700 (LWP 30499)]\r\n[New Thread 0x7ffeddfff700 (LWP 30500)]\r\n[New Thread 0x7ffedd7fe700 (LWP 30501)]\r\n[New Thread 0x7ffedcffd700 (LWP 30502)]\r\n[New Thread 0x7ffedc7fc700 (LWP 30503)]\r\n[New Thread 0x7ffedbffb700 (LWP 30504)]\r\n[New Thread 0x7ffedb7fa700 (LWP 30505)]\r\n[New Thread 0x7ffed54e9700 (LWP 30506)]\r\n[New Thread 0x7ffed4ce8700 (LWP 30507)]\r\n[New Thread 0x7ffebbfff700 (LWP 30508)]\r\n[New Thread 0x7ffebb7fe700 (LWP 30509)]\r\n[New Thread 0x7ffebaffd700 (LWP 30510)]\r\n[New Thread 0x7ffeba7fc700 (LWP 30511)]\r\n[New Thread 0x7ffeb9ffb700 (LWP 30512)]\r\n[New Thread 0x7ffeb97fa700 (LWP 30513)]\r\n[New Thread 0x7ffeb8ff9700 (LWP 30514)]\r\n[New Thread 0x7ffeb87f8700 (LWP 30515)]\r\n[New Thread 0x7ffeb7ff7700 (LWP 30516)]\r\n[New Thread 0x7ffeb77f6700 (LWP 30517)]\r\n[New Thread 0x7ffeb6ff5700 (LWP 30518)]\r\n[New Thread 0x7ffeb67f4700 (LWP 30519)]\r\n[New Thread 0x7ffeb5ff3700 (LWP 30520)]\r\n[New Thread 0x7ffeb57f2700 (LWP 30521)]\r\n[New Thread 0x7ffeb4ff1700 (LWP 30522)]\r\n[New Thread 0x7ffeb47f0700 (LWP 30523)]\r\n[New Thread 0x7ffeb3fef700 (LWP 30524)]\r\n[New Thread 0x7ffeb37ee700 (LWP 30525)]\r\n[New Thread 0x7ffeb2fed700 (LWP 30526)]\r\n[New Thread 0x7ffeb27ec700 (LWP 30527)]\r\n[New Thread 0x7ffeb1feb700 (LWP 30528)]\r\n[New Thread 0x7ffeb17ea700 (LWP 30529)]\r\n[New Thread 0x7ffeb0fe9700 (LWP 30530)]\r\n[New Thread 0x7ffeb07e8700 (LWP 30531)]\r\n[New Thread 0x7ffeaffe7700 (LWP 30532)]\r\n== image size: [976 x 549] ==\r\n== simply resize: [224 x 224] ==\r\n============= Top-1 =============\r\nLabel: beagle\r\nWith Probability: 99.1227%\r\n============= Top-2 =============\r\nLabel: Walker hound, Walker foxhound\r\nWith Probability: 0.469355%\r\n============= Top-3 =============\r\nLabel: English foxhound\r\nWith Probability: 0.110916%\r\n== Input image path: [enter Q to exit]\r\nQ\r\n\r\nThread 1 \"classifier\" received signal SIGSEGV, Segmentation fault.\r\n0x00007fffec81723e in ?? () from /usr/local/cuda-10.2/lib64/libcudart.so.10.2\r\nMissing separate debuginfos, use: yum debuginfo-install libgcc-8.3.1-4.5.el8.x86_64 libgomp-8.3.1-4.5.el8.x86_64 libstdc++-8.3.1-4.5.el8.x86_64 zlib-1.2.11-10.el8.x86_64\r\n(gdb) bt\r\n#0 0x00007fffec81723e in ?? () from /usr/local/cuda-10.2/lib64/libcudart.so.10.2\r\n#1 0x00007fffec81c70b in ?? () from /usr/local/cuda-10.2/lib64/libcudart.so.10.2\r\n#2 0x00007fffec8492d0 in cudaStreamDestroy () from /usr/local/cuda-10.2/lib64/libcudart.so.10.2\r\n#3 0x00007fff68f0551d in cudnnDestroy () from /usr/local/lib/libtorch_cuda.so\r\n#4 0x00007fff68207a05 in at::cuda::(anonymous namespace)::DeviceThreadHandlePool<cudnnContext*, &at::native::(anonymous namespace)::createCuDNNHandle, &at::native::(anonymous namespace)::destroyCuDNNHandle>::~DeviceThreadHandlePool() () from /usr/local/lib/libtorch_cuda.so\r\n#5 0x00007fff63e66677 in __cxa_finalize () from /lib64/libc.so.6\r\n#6 0x00007fff65a68a83 in __do_global_dtors_aux () from /usr/local/lib/libtorch_cuda.so\r\n#7 0x00007fffffffe0b0 in ?? ()\r\n#8 0x00007ffff7de4106 in _dl_fini () from /lib64/ld-linux-x86-64.so.2\r\nBacktrace stopped: frame did not save the PC\r\n(gdb)\r\n```\r\n\r\nMy code:\r\n\r\n```\r\n// One-stop header.\r\n#include <torch/script.h>\r\n\r\n// headers for opencv\r\n#include <opencv2/highgui/highgui.hpp>\r\n#include <opencv2/imgproc/imgproc.hpp>\r\n#include <opencv2/opencv.hpp>\r\n\r\n#include <cmath>\r\n#include <iostream>\r\n#include <memory>\r\n#include <string>\r\n#include <vector>\r\n\r\n#define kIMAGE_SIZE 224\r\n#define kCHANNELS 3\r\n#define kTOP_K 3\r\n\r\nbool LoadImage(std::string file_name, cv::Mat &image) {\r\n    image = cv::imread(file_name);  // CV_8UC3\r\n    if (image.empty() || !image.data) {\r\n        return false;\r\n    }\r\n    cv::cvtColor(image, image, cv::COLOR_BGR2RGB);\r\n    std::cout << \"== image size: \" << image.size() << \" ==\" << std::endl;\r\n\r\n    // scale image to fit\r\n    cv::Size scale(kIMAGE_SIZE, kIMAGE_SIZE);\r\n    cv::resize(image, image, scale);\r\n    std::cout << \"== simply resize: \" << image.size() << \" ==\" << std::endl;\r\n\r\n    // convert [unsigned int] to [float]\r\n    image.convertTo(image, CV_32FC3, 1.0f / 255.0f);\r\n\r\n    return true;\r\n}\r\n\r\nbool LoadImageNetLabel(std::string file_name,\r\n                       std::vector<std::string> &labels) {\r\n    std::ifstream ifs(file_name);\r\n    if (!ifs) {\r\n        return false;\r\n    }\r\n    std::string line;\r\n    while (std::getline(ifs, line)) {\r\n        labels.push_back(line);\r\n    }\r\n    return true;\r\n}\r\n\r\nint main(int argc, const char *argv[]) {\r\n    if (argc != 3) {\r\n        std::cerr << \"Usage: classifier <path-to-exported-script-module> \"\r\n                     \"<path-to-lable-file>\"\r\n                  << std::endl;\r\n        return -1;\r\n    }\r\n\r\n    torch::jit::script::Module module = torch::jit::load(argv[1]);\r\n    std::cout << \"== Switch to GPU mode\" << std::endl;\r\n    // to GPU\r\n    module.to(at::kCUDA);\r\n\r\n    std::cout << \"== ResNet50 loaded!\\n\";\r\n    std::vector<std::string> labels;\r\n    if (LoadImageNetLabel(argv[2], labels)) {\r\n        std::cout << \"== Label loaded! Let's try it\\n\";\r\n    } else {\r\n        std::cerr << \"Please check your label file path.\" << std::endl;\r\n        return -1;\r\n    }\r\n\r\n    std::string file_name = \"\";\r\n    cv::Mat image;\r\n    while (true) {\r\n        std::cout << \"== Input image path: [enter Q to exit]\" << std::endl;\r\n        std::cin >> file_name;\r\n        if (file_name == \"Q\") {\r\n            break;\r\n        }\r\n        if (LoadImage(file_name, image)) {\r\n            auto input_tensor = torch::from_blob(\r\n                    image.data, {1, kIMAGE_SIZE, kIMAGE_SIZE, kCHANNELS});\r\n            input_tensor = input_tensor.permute({0, 3, 1, 2});\r\n            input_tensor[0][0] = input_tensor[0][0].sub_(0.485).div_(0.229);\r\n            input_tensor[0][1] = input_tensor[0][1].sub_(0.456).div_(0.224);\r\n            input_tensor[0][2] = input_tensor[0][2].sub_(0.406).div_(0.225);\r\n\r\n            // to GPU\r\n            input_tensor = input_tensor.to(at::kCUDA);\r\n\r\n            torch::Tensor out_tensor = module.forward({input_tensor}).toTensor();\r\n\r\n            auto results = out_tensor.sort(-1, true);\r\n            auto softmaxs = std::get<0>(results)[0].softmax(0);\r\n            auto indexs = std::get<1>(results)[0];\r\n\r\n            for (int i = 0; i < kTOP_K; ++i) {\r\n                auto idx = indexs[i].item<int>();\r\n                std::cout << \"    ============= Top-\" << i + 1\r\n                          << \" =============\" << std::endl;\r\n                std::cout << \"    Label:  \" << labels[idx] << std::endl;\r\n                std::cout << \"    With Probability:  \"\r\n                          << softmaxs[i].item<float>() * 100.0f << \"%\" << std::endl;\r\n            }\r\n\r\n        } else {\r\n            std::cout << \"Can't load the image, please check your path.\" << std::endl;\r\n        }\r\n    }\r\n    std::cout << \"Before return, I'm OK!\" << std::endl; **//This can print out**\r\n    return 0;\r\n}\r\n```\r\n\r\n## Expected behavior\r\n\r\nNo error occur.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): Libtorch-1.5.0\r\n - OS (e.g., Linux): CentOS-8.1-1911\r\n - How you installed PyTorch (`conda`, `pip`, source): \r\n - Build command you used (if compiling from source):\r\n - Python version: 3.7\r\n - CUDA/cuDNN version: 10.2/7.6.5\r\n - GPU models and configuration: Tesla T4\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225 @glaringlee @ngimel"},{"labels":[null,"api",null],"text":"I am currently trying to implement the Pytorch C++ API into production. RTOS are indispensable in production environments so I'm trying to cross-compile with cmake for QNX Neutrino 7.0.0 (x86_64). \r\nHowever, when compiling a simple test program (empty main() function just including \"#include <torch/torch.h>\") \r\nI get the following compiler errors:\r\n\r\nhttps://github.com/shyney7/libtorch-cross-RTOS-test/blob/master/Compilerlogs/comperr-without-stdlib-flag.md\r\n\r\nI had to set the following command so that cmake finds the torch library in the host path.\r\n\r\n` SET(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY BOTH)`\r\n\r\nThis is how my **cmake Toolchain File** looks like:\r\n\r\nhttps://github.com/shyney7/libtorch-cross-RTOS-test/blob/master/cmake/qnx_7.0.0_linux_x86_64.cmake\r\n\r\nThis is my **CMakeLists.txt** file:\r\n\r\nhttps://github.com/shyney7/libtorch-cross-RTOS-test/blob/master/CMakeLists.txt\r\n\r\nUnfortunately I am not a computer scientist but a mechanical engineer working at a research lab of a german university trying to implement libtorch into production. So I am not sure what the compiler errors mean. Thats why I searched the web for similar errors and found an issue of another repo here: \r\nhttps://github.com/eProsima/Fast-RTPS/issues/300\r\nThere it is mentioned that it is also needed to prevent the qcc compiler from using the LLVM Compiler Infrastructure from v1/memory by using the `-stdlib=libstdc++` flag.\r\nI also tried this by changing my CMakeLists.txt file to use the following flags:\r\n`set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=gnu++14 -stdlib=libstdc++ ${TORCH_CXX_FLAGS}\")` \r\n\r\nBut then I'm getting the following **compiler errors**:\r\n\r\nhttps://github.com/shyney7/libtorch-cross-RTOS-test/blob/master/Compilerlogs/comperr_with-stdlib%3Dlibstdc%2B%2B_flag.md\r\n\r\nIn the announcement videos where Libtorch and the C++ API were introduced, it was always said that the C++ API is specifically for production environments. The fact is that in production environments you mostly work with real-time operating systems like QNX or FreeRTOS, so I'm sure that there is somehow a way to get libtorch working on QNX.\r\n\r\nHere is the repo with all the files:\r\nhttps://github.com/shyney7/libtorch-cross-RTOS-test\r\n\r\nHere is also a link to my first post on the discussion forums where I faced some issues with setting up the cmake toolchain file correctly:\r\nhttps://discuss.pytorch.org/t/cross-compiling-with-cmake-for-embedded-systems-qnx/79681\r\n\r\n## Environment\r\n\r\n - Libtorch Version : 1.5 Release\r\n - OS : cross-compiling on Ubuntu 18.04 (VM) for **QNX 7.0.0 (x84_64)**\r\n - How you installed PyTorch : libtorch 1.5 zip from pytorch.org (for linux tried with both Pre & cxx11 ABI)\r\n - Build command you used : \r\n\r\n`cmake -DCMAKE_TOOLCHAIN_FILE=../cmake/qnx_7.0.0_linux_x86_64.cmake ..`\r\n`make`\r\n - GNU version: 5.4.0\r\n - CUDA/cuDNN version: none\r\n - GPU models and configuration: none\r\n - cmake version: 3.10.2 \r\n\r\n\r\ncc @malfet @yf225 @glaringlee"},{"labels":[null,"api",null],"text":"## üêõ Bug\r\n\r\nWhen I compile a simple package (**a** for instance) using cmake, the exported ${TORCH_LIBRARIES}$ is as follows,\r\n```\r\ntorch;torch_library;/usr/lib/libc10.so;/opt/cuda/lib/stubs/libcuda.so;/opt/cuda/lib/libnvrtc.so;/opt/cuda/lib/libnvToolsExt.so;/opt/cuda/lib64/libcudart.so;/usr/lib/libc10_cuda.so\r\n```\r\nPackage **a** compiles successfully even if the linker fails to link **torch_library**. \r\n\r\nThe actual problem arises when I have another package (**b**), dependent on the already created package **a**. When I build, it fails with error\r\n\r\n```\r\nCMake Error at /home/vsury/dev/ros/pytorch-example/devel_isolated/a/share/a/cmake/aConfig.cmake:150 (message):\r\n  Project 'b' tried to find library '-Wl,--no-as-needed,$<TARGET_FILE:torch>\r\n  -Wl,--as-needed'.  The library is neither a target nor built/installed\r\n  properly.  Did you compile project 'a'? Did you find_package() it before\r\n  the subdirectory containing its code is included?\r\n```\r\n\r\nThe reason has to do with **torch_library** because there is no library such as **libtorch_library.so**.\r\n\r\nLooking further, it seems like that ${TORCH_LIBRARIES} is linked to ${Caffe2_MAIN_LIBS},\r\n\r\nhttps://github.com/pytorch/pytorch/blob/master/cmake/TorchConfig.cmake.in#L41\r\n\r\nand  ${Caffe2_MAIN_LIBS} is linked to **torch_library**,\r\n\r\nhttps://github.com/pytorch/pytorch/blob/master/cmake/Caffe2Config.cmake.in#L121\r\n\r\nI do not understand the need for **torch_library** and removing it from $TORCH_LIBRARIES$ fixes the entire problem.\r\n\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Create a package **a** with any script with torch functionalities (basically CMakeLists should contain find_package(Torch REQUIRED) and build target with torch libraries.\r\n2. Create another package **b** and make it depend on **a**.\r\n3. Compile package b to get the error.\r\n\r\n## Expected behavior\r\n\r\nSuccessful build\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n\r\n - PyTorch Version (e.g., 1.0): 1.5.0\r\n - OS (e.g., Linux): Archlinux\r\n - How you installed PyTorch (`conda`, `pip`, source): pacman -S\r\n - Build command you used (if compiling from source): cmake and make\r\n - Python version:\r\n - CUDA/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":[null,null,"api",null,null,null],"text":"## üêõ Bug\r\n\r\nDear community,\r\n\r\nI am a dev from [KeOps project](https://github.com/getkeops/keops/) building optimized operations written in C++/Cuda that are compatible with pytorch (among others scientific languages). \r\n\r\nWe successfully build python modules compatible with pyTorch since the pyTorch v0.2... But the last v1.5 broke our modules with a runtime error complaining about [missing symbols](https://github.com/getkeops/keops/issues/59).\r\n\r\n\r\nTo simplify the analysis you may find below a minimal working example that builds a module through pybind11n the spirit of [pytorch doc](https://pytorch.org/tutorials/advanced/cpp_frontend.html#writing-a-basic-application). \r\n\r\nIt should output a file `test_module.cpython-38-x86_64-linux-gnu.so` that can be imported from python. This module works well when building with pytorch 1.4 but raised a runtime error when building with pytorch v1.5. \r\n\r\n\r\n## To Reproduce\r\n\r\nAssuming pyTorch and pybind11 installed (e.g. through conda).  There are 2 files\r\n\r\n`module_test.cpp` contains\r\n\r\n```cpp\r\n#include <torch/extension.h>\r\n#include <pybind11/pybind11.h>\r\n// Main function\r\nat::Tensor foo(int s) {\r\n     return torch::eye(s);\r\n}    \r\n\r\n// PyBind11 entry point \r\nPYBIND11_MODULE(test_module, m) {\r\nm.def(\"foo\", &foo, \"Entry point to test module\");\r\n}\r\n```   \r\nand `CMakeList.txt` contains\r\n```\r\nproject(test_module LANGUAGES CXX)\r\n\r\nfind_package(Torch REQUIRED)\r\nfind_package(pybind11  REQUIRED)\r\n\r\npybind11_add_module(test_module ${CMAKE_CURRENT_SOURCE_DIR}/test_module.cpp)\r\ntarget_link_libraries(test_module PUBLIC \"${TORCH_LIBRARIES}\")\r\n```\r\nit can be compile with\r\n\r\n ```bash\r\n$ mkdir build\r\n$ cd build\r\n$ cmake -DCMAKE_PREFIX_PATH=\"/home/bcharlier/.conda/envs/keops/lib/python3.8/site-packages/torch/\" .. && make\r\n```\r\nand run with (note that `torch` is imported first)\r\n```\r\n$ python -c \"import torch; print(torch.__version__); import test_module; print(test_module.foo(3))\"\r\n\r\n1.5.0\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nImportError: /home/bcharlier/src/test_module/build/test_module.cpython-38-x86_64-linux-gnu.so: undefined symbol: _Z16THPVariable_WrapN2at6TensorE\r\n```\r\nThe missing symbol is not exactly the same when [building a module with the keops library](https://github.com/getkeops/keops/issues/59)... But I guess this is irrelevant.\r\n\r\n## Expected behavior\r\n\r\nIt works fine when compiling with pytorch v1.4\r\n\r\n```bash\r\n$ cmake -DCMAKE_PREFIX_PATH=\"/home/bcharlier/.conda/envs/keops_torch14/lib/python3.8/site-packages/torch/\" .. && make\r\n$ python -c \"import torch; print(torch.__version__); import test_module; print(test_module.foo(3))\"\r\n1.4.0\r\ntensor([[1., 0., 0.],\r\n        [0., 1., 0.],\r\n        [0., 0., 1.]])\r\n```\r\n\r\n## Environment\r\n\r\nThe bug was reported by various users running on linux. Here is my config:\r\n\r\n```\r\nCollecting environment information...\r\nPyTorch version: 1.5.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Arch Linux\r\nGCC version: (Arch Linux 9.3.0-1) 9.3.0\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.8\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.2.89\r\nGPU models and configuration: GPU 0: Quadro T2000\r\nNvidia driver version: 440.82\r\ncuDNN version: /usr/lib/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.4\r\n[conda] blas                      1.0                         mkl  \r\n[conda] cudatoolkit               10.2.89              hfd86e86_1  \r\n[conda] mkl                       2020.0                      166  \r\n[conda] mkl-service               2.3.0            py38he904b0f_0  \r\n[conda] mkl_fft                   1.0.15           py38ha843d7b_0  \r\n[conda] mkl_random                1.1.0            py38h962f231_0  \r\n[conda] numpy                     1.18.1           py38h4f9e942_0  \r\n[conda] numpy-base                1.18.1           py38hde5b4d6_1  \r\n[conda] pytorch                   1.5.0           py3.8_cuda10.2.89_cudnn7.6.5_0    pytorch\r\n\r\n```\n\ncc @ezyang @gchanan @zou3519 @malfet @yf225 @glaringlee"},{"labels":["api",null,null],"text":"In the latest 1.5 release, I am unable to find Transformer model api in C++ (equivalent to the torch.nn.Transformer in its python counterpart). Any timeline for its implementation in C++?\n\ncc @yf225 @glaringlee"},{"labels":["api",null],"text":"i use libtorch to do inference, and i got a two-dimensional tensor, but how can i obatian the value, or how can i transform the tensor in C++ to  a array?\r\n\n\ncc @yf225 @glaringlee"},{"labels":["api",null],"text":"how to create tensor from tensorRT fp16 half type pointer in libtorch?\r\nI am working on a detection model. I change the backbone of it to tensorRT to do FP16 inference, and the detection code such as decode boxes and nms is done in libtorch and torchvisoin, so how to create fp16 tensor from tensorRT half type pointers?\r\nThe important code is to illustrate the issue:\r\n```\r\n// tensorRT code to get half type outpus\r\nhalf_float::half* outputs[18];\r\ndoInference(*engine, data, outputs, 1);\r\n// to get the final outputs with libtorch\r\nvector<torch::Tensor> output;\r\n//???? how to feed the date in outpus to output????\r\n// get the result with libtorch method detect_trt->forward\r\n auto res = detect_trt->forward(output); \r\n```\r\nThanks in advance.\n\ncc @yf225 @glaringlee"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nHi\r\n\r\nI've encountered a problem with the code in \"c10/utils/variant.h\" while trying to build a C++ application.\r\nI've created a simple test program to explain the problem. \r\nThe code I‚Äôm trying to build is the following one\r\n\r\n```cpp\r\n//Include standard libraries\r\n#include <iostream>\r\n\r\n//Define namespace data\r\n//This can be included for example by another header file\r\nnamespace data\r\n{\r\n}\r\n\r\n//Include torch library\r\n#include <torch/torch.h>\r\n\r\nint main(int argc, char* argv[])\r\n{\r\n  std::cout << torch::randn({3, 3}) << std::endl;\r\n  return 0;\r\n}\r\n```\r\n\r\nThe CMakeLists.txt is\r\n\r\n```\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nproject(test_variant)\r\n\r\nfind_package(Torch REQUIRED)\r\n\r\nadd_executable(test_variant main.cpp)\r\ntarget_link_libraries(test_variant \"${TORCH_LIBRARIES}\")\r\nset_property(TARGET test_variant PROPERTY CXX_STANDARD 14)\r\n```\r\n\r\nI‚Äôve added an empty ‚Äúdata‚Äù namespace to better explain the problem.\r\nWhen I build the example I get a lot of errors like\r\n\r\n```\r\n~/test_variant/libtorch/include/c10/util/variant.h:2519:7: error: invalid use of ‚Äòvoid‚Äô\r\n       AUTO_RETURN(v && holds_alternative<I>(*v)\r\n```\r\n\r\nI‚Äôve looked inside the file and it seems that the problem is the statement (line 1165 c10/utils/variant.h)\r\n\r\n```\r\nAUTO_REFREF_RETURN(recursive_union::get_alt(\r\n              data(lib::forward<V>(v)), in_place_index_t<I>{}))\r\n```\r\n\r\nWhere ‚Äúdata‚Äù is incorrectly detected as the namespace I‚Äôve added before the <torch/torch.h> inclusion.\r\nI think it should refer to the ‚Äúdata‚Äù function which can be found in the same file at line 1743 (I tried to change its name and indeed the error is solved).\r\nCould this be an issue or it‚Äôs something I‚Äôm doing wrong in my code?\r\n\r\nThank you very much for your help\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): LibTorch 1.4.0\r\n - OS (e.g., Linux): Ubuntu 16.04 (default compiler)\r\n - How you installed PyTorch (`conda`, `pip`, source): pre-built libraries\r\n - Build command you used (if compiling from source): N/A\r\n - Python version: N/A\r\n - CUDA/cuDNN version: N/A\r\n - GPU models and configuration: N/A\r\n - Any other relevant information: cpu mode only \n\ncc @yf225"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nThe output from a traced model using (1) python and (2) c++ are different.  \r\n\r\nxpost: https://discuss.pytorch.org/t/c-and-pytorch-inference-discrepancy/77388?u=jonrbates\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n**1. Create model in python**\r\n```\r\nimport torch\r\nfrom transformers import GPT2LMHeadModel\r\nmodel = GPT2LMHeadModel.from_pretrained(\"distilgpt2\", \r\n           pad_token_id=50256,\r\n           torchscript=True)\r\ntraced_model = torch.jit.trace(model, [torch.tensor([[464, 6842, 1816,  625,  262, 8598,  284,  766]])])\r\ntorch.jit.save(traced_model, \"traced_distilgpt2.pt\")\r\n```\r\n\r\n**2. Inference in pytorch**\r\n```\r\nloaded_model = torch.jit.load(\"traced_distilgpt2.pt\")\r\noutputs = loaded_model(torch.tensor([[464, 6842, 1816,  625,  262, 8598,  284,  766]]))\r\n\r\ntorch.max(outputs[0],2)\r\n>> torch.return_types.max(values=tensor([[-26.7050, -53.3268, -66.3666, -50.1084, -54.8050, -72.4056, -55.2586,-63.5215]], grad_fn=<MaxBackward0>),\r\nindices=tensor([[ 383,  373,  319,  262, 1353,  290,  262,  262]]))\r\n\r\ntorch.min(outputs[0][:, :, :],2)\r\n>>torch.return_types.min(\r\nvalues=tensor([[ -47.3794,  -77.6341,  -95.8365,  -75.3026,  -81.6899, -103.6701, -83.0335,  -93.0259]], grad_fn=<MinBackward0>),\r\nindices=tensor([[  154,  7134, 31204, 22997, 10298, 31204, 22997, 31573]]))\r\n```\r\n\r\n**3. Inference in c**\r\n```\r\nint main(int argc, const char* argv[]) {\r\n\r\n  torch::jit::script::Module module;\r\n  module = torch::jit::load(argv[1]);\r\n  std::cout << \"Model loaded.\\n\";\r\n  module.eval(); // just in case?\r\n\r\n  torch::Tensor x = torch::tensor({464, 6842, 1816,  625,  262, 8598,  284,  766},\r\n    torch::dtype(torch::kInt64)).reshape({8, 1});\r\n  std::vector<torch::jit::IValue> inputs;\r\n  inputs.push_back(x);\r\n\r\n  // Execute the model and turn its output into a tensor (all_encoder_layers).\r\n  torch::Tensor out = module.forward(inputs).toTuple()->elements()[0].toTensor();\r\n\r\n  auto z = torch::max(out, /*dim=*/2);\r\n  std::cout << std::get<0>(z) << '\\n';\r\n  std::cout << std::get<1>(z) << '\\n';\r\n\r\n  z = torch::min(out, /*dim=*/2);\r\n  std::cout << std::get<0>(z) << '\\n';\r\n  std::cout << std::get<1>(z) << '\\n';\r\n\r\n  return 0;\r\n}\r\n```\r\n\r\nOutput from running c exe (with argv[1] = \"traced_distilgpt2.pt\") :\r\n```\r\n-26.7050\r\n-28.0251\r\n-29.0539\r\n-28.2608\r\n-26.3226\r\n-28.0652\r\n-26.8328\r\n-28.5087\r\n[ Variable[CPUFloatType]{8,1} ]\r\n 383\r\n 383\r\n 383\r\n 383\r\n 383\r\n 383\r\n 383\r\n 383\r\n[ Variable[CPULongType]{8,1} ]\r\n-47.3794\r\n-48.2470\r\n-49.5565\r\n-49.0826\r\n-46.3104\r\n-48.5934\r\n-47.3013\r\n-49.1308\r\n[ Variable[CPUFloatType]{8,1} ]\r\n 154\r\n 154\r\n 154\r\n 154\r\n 154\r\n 154\r\n 154\r\n 154\r\n[ Variable[CPULongType]{8,1} ]\r\n```\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\nThe models agree for the first token (position=0) but for positions 1-7 the encoder outputs disagree.  All outputs should be equal. \r\n<!-- -->\r\n\r\n## Environment (Pytorch)\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Microsoft Windows 10 Pro\r\nGCC version: (x86_64-posix-seh-rev0, Built by MinGW-W64 project) 5.4.0\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration: GPU 0: Quadro M500M\r\nNvidia driver version: 442.23\r\ncuDNN version: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin\\cudnn64_7.dll\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] _tflow_select             2.3.0                       mkl\r\n[conda] blas                      1.0                         mkl\r\n[conda] cudatoolkit               10.1.243             h74a9793_0\r\n[conda] libmklml                  2019.0.5                      0\r\n[conda] mkl                       2019.4                      245\r\n[conda] mkl-include               2020.0                      166\r\n[conda] mkl-service               2.3.0            py37hb782905_0\r\n[conda] mkl_fft                   1.0.14           py37h14836fe_0\r\n[conda] mkl_random                1.1.0            py37h675688f_0\r\n[conda] numpy                     1.16.5           py37h19fb1c0_0\r\n[conda] numpy-base                1.16.5           py37hc3f5095_0\r\n[conda] numpydoc                  0.9.1                      py_0\r\n[conda] pytorch                   1.4.0           py3.7_cuda101_cudnn7_0    pytorch\r\n[conda] tensorflow                2.1.0           mkl_py37ha977152_0\r\n[conda] tensorflow-base           2.1.0           mkl_py37h230818c_0\r\n[conda] torchvision               0.5.0                py37_cu101    pytorch\r\n\r\n## Environment (C++)\r\n\r\nPyTorch version: N/A\r\nIs debug build: N/A\r\nCUDA used to build PyTorch: N/A\r\n\r\nOS: Ubuntu 18.04.4 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: version 3.10.2\r\n\r\nPython version: 2.7\r\nIs CUDA available: N/A\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: Could not collect\r\nNvidia driver version: Could not collect\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] Could not collect\r\n\n\ncc @yf225"},{"labels":[null,"api",null,null],"text":"similar to issue #33192\r\n\r\nif we start with AnyModule a, there is no good way to add a name, \r\nto create a NamedAnyModule\r\ni.e. in  _nn/modules/container/named_any.h_\r\n\r\n```\r\nprivate:\r\n  /// Creates a `NamedAnyModule` from a type-erased `AnyModule`.\r\n  NamedAnyModule(std::string name, AnyModule any_module)\r\n    : name_(std::move(name)), module_(std::move(any_module)) {}\r\n```\r\nI can create the pr to move this method to public if it makes sense.\r\n(similar to pr #34208)\n\ncc @yf225"},{"labels":["api",null],"text":"## üöÄ Feature\r\nI would be able to clone a model into another model. Such as being done in the [Reinforcement Learning (DQN) Tutorial](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) at **Training**.\r\n\r\nThe requested functions that do exist in python but not C++ are:\r\n```\r\nload_state_dict()\r\nstate_dict()\r\ntarget_net.load_state_dict(policy_net.state_dict())\r\n```\r\n\r\n## Motivation\r\nIt would be neat to be able to follow the pytorch example listed above. However the C++ library are missing the necessary functions for doing this.\r\n\n\ncc @yf225"},{"labels":[null,"api",null],"text":"## üêõ Bug\r\n\r\nLoad pytorch tensor created by torch.save(tensor_name, tensor_path) in c++ libtorch failed.\r\nHow can I save some tensor in python, but load it in libtorch?\r\n## To Reproduce\r\n\r\nusing the following code:\r\n\r\nI save tensor named piror using python, using the code:\r\n```\r\nprior = torch.ones(32145, 4)\r\ntorch.save(prior,  'prior.pth')\r\n```\r\nAnd I load the tensor in libtorch using C++, by the following code:\r\n```\r\ntorch::Tensor priors = torch::ones({32145, 4});\r\ntorch::load(priors , \"/app/model/prior.pth\");\r\n```\r\n\r\n## Expected behavior\r\nload the tensor successfully.\r\nAnd get exact same value as in pytorch python-api.\r\n\r\n## Environment\r\nCollecting environment information...\r\nPyTorch version: N/A\r\nIs debug build: N/A\r\nCUDA used to build PyTorch: N/A\r\n\r\nOS: Ubuntu 16.04.5 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCMake version: version 3.13.2\r\n\r\nPython version: 3.5\r\nIs CUDA available: N/A\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration:\r\nGPU 0: TITAN X (Pascal)\r\nGPU 1: TITAN X (Pascal)\r\n\r\nNvidia driver version: 430.26\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.4.2\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] Could not collect\r\n\r\n## Additional context\r\nBut I got the error:\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  `torch::jit::load()` received a file from `torch.save()`, but `torch::jit::load()` can only load files produced by `torch.jit.save()` (load at ../torch/csrc/jit/serialization/import.cpp:285)\r\n\r\nWhy is that? I do not use torch::jit::load but torch::load, so how to load tensor saved in pytorch?\r\n\r\nThanks in advance.\n\ncc @suo @yf225"},{"labels":[null,"api",null],"text":"How can I save some tensor in python, but load it in libtorch:\r\n\r\nI save tensor named piror using python, using the code:\r\n```\r\ntorch.save(prior,  'prior.pth')\r\n```\r\nAnd I load the tensor in libtorch using C++, by the following code:\r\n```\r\nstd::vector<torch::Tensor> tensorVec;\r\ntorch::load(tensorVec, \"/app/model/prior.pth\");\r\ntorch::Tensor priors = tensorVec[0];\r\n```\r\nBut I got the error:\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  `torch::jit::load()` received a file from `torch.save()`, but `torch::jit::load()` can only load files produced by `torch.jit.save()` (load at ../torch/csrc/jit/serialization/import.cpp:285)\r\n\r\nWhy is that? And what should I do to solve the issue? Thanks in advance.\n\ncc @suo @yf225"},{"labels":[null,null,"api",null,null,null,null,null],"text":"Hi, I want to use my pretrained model(which is trained on pytorch) in my C++ project. I have saved my network in Python and loaded in C++ using jit.\r\n\r\n```\r\n//Python\r\ntraced_script_module = torch.jit.trace(model, input)\r\ntraced_script_module.save(\"model.pt\")\r\n//C++\r\ntorch::jit::script::Module model =torch::jit::load(file_name);\r\n```\r\n\r\nI am passing CUDAFloatTensor as an input. I am supposed to have three outputs from my model.\r\n\r\n```\r\nauto outputs = model.forward({ input });\r\nauto heatmap= outputs.toTuple()->elements()[0].toTensor(); \r\nauto bbox = outputs.toTuple()->elements()[1].toTensor();\r\nauto scan_rec= outputs.toTuple()->elements()[2].toTensor();\r\n```\r\nI realized forward pass doesn‚Äôt always give correct results. Sometimes it gives answer below.(which is the right answer I checked on pytorch and outputs on there are always consistent)\r\n`first three elements of bbox : 0.4311, 0.4620, 0.3915`\r\n\r\nBut most of the times I get values like this in each three output and I am having exception when I am trying to use my outputs.\r\n`first three elements of bbox : = 9.3593e-36, 3.9978e+07,-5.3179e+37`\r\n\r\nWhich is really weird. I am assuming there is some kind of overflow going on. I don‚Äôt want to train any network in C++. I just want to use my pretrained model as a deterministic function. I also set these in any case before calling forward pass but it didn‚Äôt help. I have no idea what is going on.\r\n\r\n```\r\ntorch::manual_seed(0);\r\ntorch::NoGradGuard no_grad;\r\n\r\n```\r\nEnvironment:\r\nWindows 10\r\nCUDA 10.1\r\nVisual Studio 2019\r\nLibtorch Nightly Release latest\r\n\n\ncc @ezyang @gchanan @zou3519 @suo @yf225 @peterjc123"},{"labels":[null,"api",null],"text":"## üêõ Bug\r\n\r\n(not sure how much of a bug this is, maybe it's expected)\r\nI'm currently working on adapting some [rust bindings](https://github.com/LaurentMazare/tch-rs) for PyTorch and in the process came across the following issue for which I don't have a good solution. The issue can be show on C++ code.\r\n- When linking the final binary with `-ltorch -ltorch_cpu -lc10`, `torch::cuda::is_available()` returns false.\r\n- When linking the final binary with `-Wl,--no-as-needed -ltorch -ltorch_cpu -lc10`, `torch::cuda::is_available()` returns true.\r\n- When linking without `-ltorch_cpu`, I get a missing symbol error for: `c10::Dispatcher::singleton`.\r\n\r\nI tried compiling some C++ pytorch code with cmake and it seems to use --no-as-needed to get this to work.\r\n\r\nIs there a way to get some external code to compile without libtorch_cpu?\r\nOne difficulty is that the rust build system does not let you specify arbitrary linker flags so I cannot easily set `-Wl,--no-as-needed`.\r\n\r\n## To Reproduce\r\n\r\nThe issue can be reproduced using the C++ code below.\r\n\r\n```c++\r\n#include <torch/torch.h>\r\n#include <iostream>\r\n\r\nint main() {\r\n  std::cout << torch::cuda::is_available() << std::endl;\r\n}\r\n```\r\nThen:\r\n- `g++ test.cpp -std=gnu++14 -ltorch -ltorch_cpu -lc10 && ./a.out` prints 0.\r\n- `g++ test.cpp -std=gnu++14 -Wl,--no-as-needed -ltorch -ltorch_cpu -lc10 && ./a.out` prints 1.\r\n\r\n## Expected behavior\r\n\r\nI would have hoped for cuda to be reported as available without the `-Wl,--no-as-needed` flag.\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): release/1.5 branch as of 2020-04-11.\r\n - OS (e.g., Linux): Linux (ubuntu 18.04)\r\n - How you installed PyTorch (`conda`, `pip`, source): source, compiled with cuda support\r\n - Build command you used (if compiling from source): `python setup.py build`\r\n - Python version: 3.7.1.\r\n - CUDA/cuDNN version: 10.0/none.\r\n - GPU models and configuration: 1x GeForce RTX 2080.\r\n - Any other relevant information: gcc/g++ 7.5.0, ld 2.3.0\r\n\r\n## Additional context\n\ncc @yf225"},{"labels":["api",null],"text":"I previous using this get cuda stream:\r\n\r\n```\r\nmodulated_deformable_col2im_coord_cuda(THCState_getCurrentStream(state),\r\n```\r\n\r\nI found this API gone `THCState_getCurrentStream` without even a deprecation warning, what's the altinate of this API?\r\nin torch 1.5?\n\ncc @yf225"},{"labels":["api",null],"text":"This is to better match the Python API `ctx.saved_tensors`.\r\n\r\nI believe we originally named it `get_saved_variables()` because there was still a Tensor vs. Variable distinction at that time. Now that Tensor and Variable are the same, we can deprecate `get_saved_variables()` and replace it with `get_saved_tensors()`.\r\n\r\ncc @yf225"},{"labels":["api",null,null,null],"text":"## üêõ Bug\r\n\r\nThere are some minor labelling errors in the default options check in  _optim/adah.h_: \r\n```\r\n     auto betas = defaults.betas();\r\n     TORCH_CHECK(std::get<0>(betas) >= 0, \"Invalid learning rate: \", std::get<0>(betas));\r\n     TORCH_CHECK(std::get<1>(betas) >= 0, \"Invalid learning rate: \", std::get<1>(betas));\r\n     TORCH_CHECK(defaults.weight_decay() >= 0, \"Invalid learning rate: \", defaults.weight_decay());\r\n```\r\nI am also seeing worse convergance on some simple GAN's with MNIST,\r\ne.g. the tutorial example, using the newer adam vs the 1.4 version,\r\nbut I don't have a good way to reproduce this yet.\r\nthe GAN's produce noticeably less convincing digits than using the 1.4 version for the same settings and number of iterations.\r\n\n\ncc @yf225 @vincentqb"},{"labels":["api",null],"text":"## üöÄ Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\nCan we remove \"using namespace ...\" from the public headers of libtorch?\r\n\r\n## Motivation\r\nE.g., `torch/csrc/api/include/torch/nn/modules/_functions.h` has this line `using namespace torch::autograd;`. This pollutes the namespace of some applications.\r\n\r\n\n\ncc @yf225"},{"labels":["api",null,null],"text":"In Python, we have the following tensor print behavior:\r\n```python\r\n>>> x=torch.ones(2, 2, requires_grad=True)\r\n>>> x\r\ntensor([[1., 1.],\r\n        [1., 1.]], requires_grad=True)\r\n>>> y=x*2\r\n>>> y\r\ntensor([[2., 2.],\r\n        [2., 2.]], grad_fn=<MulBackward0>)\r\n```\r\nHowever in C++, we have the following behavior:\r\n```cpp\r\nauto x = torch::ones({2, 2}, torch::requires_grad());\r\nstd::cout << x << std::endl;\r\nauto y = x * 2;\r\nstd::cout << y << std::endl;\r\n```\r\n```cpp\r\n 1  1\r\n 1  1\r\n[ CPUFloatType{2,2} ]\r\n 2  2\r\n 2  2\r\n[ CPUFloatType{2,2} ]\r\n```\r\nIt would be nice to show `requires_grad` and `grad_fn` in C++ tensor print as well.\n\ncc @yf225"},{"labels":["api",null,null],"text":"I build 32bit libtorch myself.And I use torch.jit.trace to convert my python module into c++ module. When I try to load module in vs2017 project , an error occur.There is an unhandled exception at 0x00007ffb0ee5db8e (ucrtbase. DLL) (in libtorch1.3.1. Exe): a serious program exit was requested. \r\n\r\n# Python code\r\n```python\r\ndef package():\r\n    model = BiSINet(p=2, q=8)\r\n    model.load_state_dict(\r\n        weight_convert(torch.load(\"weights/temp/SINetDIS_decoder_360_3c.pth\", \"cpu\")))\r\n    model.cpu()\r\n    model.eval()\r\n    with torch.no_grad():\r\n        model_input = torch.rand(1, 3, 224, 224)\r\n        trace_model_script = torch.jit.trace(model, model_input)\r\n        trace_model_script.save('weights/convert/SINet_decoder_3c_x86.pt')\r\n```\r\n\r\n# C++ code\r\n```c++\r\n#include <torch/script.h>\r\n#include <iostream>\r\n\r\nint main() {\r\n\ttorch::jit::script::Module module;\r\n\ttry {\r\n\t\tmodule = torch::jit::load(\"A:\\\\projects\\\\libtorchs\\\\sinet_50.pt\");\r\n\t}\r\n\tcatch (const c10::Error &e) {\r\n\t\tstd::cerr << \"error loading the model\\n\";\r\n\t\treturn -1;\r\n\t}\r\n\tstd::cout << \"ok\\n\";\r\n\treturn 0;\r\n}\r\n```\r\n\r\n# Error Message\r\n0x00007FFB0EE5DB8E (ucrtbase.dll) (libtorch1.3.1.exe ‰∏≠)Â§ÑÊúâÊú™ÁªèÂ§ÑÁêÜÁöÑÂºÇÂ∏∏: ËØ∑Ê±Ç‰∫Ü‰∏•ÈáçÁöÑÁ®ãÂ∫èÈÄÄÂá∫„ÄÇ Âá∫Áé∞‰∫Ü \r\n\r\ncc @yf225 @peterjc123"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nI got the following error when calling `optimizer.backward()`.\r\n`one of the variables needed for gradient computation has been modified by an inplace operation: [CPUFloatType [50, 40]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True). after train`\r\n\r\n## To Reproduce\r\nNot sure, since I can't see which operation that makes my code crash.\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nI expected the function that was listed in the error to exist.\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): Libtorch 1.4\r\n - OS (e.g., Linux): Windows 7 64 bit\r\n - How you installed PyTorch (`conda`, `pip`, source): source\r\n - Build command you used (if compiling from source): none\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: none\r\n - GPU models and configuration: none\r\n - Any other relevant information: none\r\n\r\n\n\ncc @yf225"},{"labels":[null,"api",null],"text":"# üêõ Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Compile & Run code below.\r\n\r\n```C++\r\n#include <torch/torch.h>\r\n\r\n// Define a new Module.\r\nstruct Net : torch::nn::Module {\r\n  Net() {\r\n    // Construct and register two Linear submodules.\r\n    fc1 = register_module(\"fc1\", torch::nn::Linear(784, 64));\r\n    fc2 = register_module(\"fc2\", torch::nn::Linear(64, 32));\r\n    fc3 = register_module(\"fc3\", torch::nn::Linear(32, 10));\r\n  }\r\n\r\n  // Implement the Net's algorithm.\r\n  torch::Tensor forward(torch::Tensor x) {\r\n    // Use one of many tensor manipulation functions.\r\n    x = torch::relu(fc1->forward(x.reshape({x.size(0), 784})));\r\n    x = torch::dropout(x, /*p=*/0.5, /*train=*/is_training());\r\n    x = torch::relu(fc2->forward(x));\r\n    x = torch::log_softmax(fc3->forward(x), /*dim=*/1);\r\n    return x;\r\n  }\r\n\r\n  // Use one of many \"standard library\" modules.\r\n  torch::nn::Linear fc1{nullptr}, fc2{nullptr}, fc3{nullptr};\r\n};\r\n\r\nint main() {\r\n  // Create a new Net.\r\n  auto net = std::make_shared<Net>();\r\n\r\n  // Create a multi-threaded data loader for the MNIST dataset.\r\n  auto data_loader = torch::data::make_data_loader(\r\n      torch::data::datasets::MNIST(\"./data\").map(\r\n          torch::data::transforms::Stack<>()),\r\n      /*batch_size=*/64);\r\n\r\n  // Instantiate an SGD optimization algorithm to update our Net's parameters.\r\n  torch::optim::SGD optimizer(net->parameters(), /*lr=*/0.01);\r\n\r\n  for (size_t epoch = 1; epoch <= 10; ++epoch) {\r\n    size_t batch_index = 0;\r\n    // Iterate the data loader to yield batches from the dataset.\r\n    torch::Device device = epoch % 2 == 1 ? torch::kCUDA : torch::kCPU;\r\n    net->to(device);\r\n    std::cout << \"Device of network is \" << device << std::endl;\r\n    for (auto& batch : *data_loader) {\r\n      // Reset gradients.\r\n      optimizer.zero_grad();\r\n      // Execute the model on the input data.\r\n      torch::Tensor prediction = net->forward(batch.data.to(device));\r\n      // Compute a loss value to judge the prediction of our model.\r\n      torch::Tensor loss = torch::nll_loss(prediction, batch.target.to(device));\r\n      // Compute gradients of the loss w.r.t. the parameters of our model.\r\n      if(batch_index == 0) std::cout << \"Device of loss is \" << loss.device() << \"\\n\";\r\n      loss.backward();\r\n      if(batch_index == 0) std::cout << \"loss.backward() success\" << \"\\n\";\r\n\t \t\r\n      // Update the parameters based on the calculated gradients.\r\n      optimizer.step();\r\n      // Output the loss and checkpoint every 100 batches.\r\n      if (++batch_index % 100 == 0) {\r\n        std::cout << \"Epoch: \" << epoch << \" | Batch: \" << batch_index\r\n                  << \" | Loss: \" << loss.item<float>() << std::endl;\r\n        // Serialize your model periodically as a checkpoint.\r\n        torch::save(net, \"net.pt\");\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nand output is\r\n\r\n```\r\nDevice of network is cuda\r\nDevice of loss is cuda:0\r\nloss.backward() success\r\nEpoch: 1 | Batch: 100 | Loss: 2.2953\r\nEpoch: 1 | Batch: 200 | Loss: 2.252\r\nEpoch: 1 | Batch: 300 | Loss: 2.22181\r\nEpoch: 1 | Batch: 400 | Loss: 2.13327\r\nEpoch: 1 | Batch: 500 | Loss: 2.04376\r\nEpoch: 1 | Batch: 600 | Loss: 1.80017\r\nEpoch: 1 | Batch: 700 | Loss: 1.65806\r\nEpoch: 1 | Batch: 800 | Loss: 1.47708\r\nEpoch: 1 | Batch: 900 | Loss: 1.40919\r\nDevice of network is cpu\r\nDevice of loss is cpu\r\nterminate called after throwing an instance of 'torch::utils::FutureError'\r\n  what():  expected device cuda:0 but got device cpu (compute_types at /pytorch/aten/src/ATen/native/TensorIterator.cpp:246)\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f0850510576 in /home/sonic/Downloaded_Library/libtorch/lib/libc10.so)\r\nframe #1: at::TensorIterator::compute_types() + 0x17d4 (0x7f08426fe214 in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cpu.so)\r\nframe #2: at::TensorIterator::build() + 0x44 (0x7f0842700104 in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cpu.so)\r\nframe #3: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x146 (0x7f08427007b6 in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cpu.so)\r\nframe #4: at::native::add_out(at::Tensor&, at::Tensor const&, at::Tensor const&, c10::Scalar) + 0x3c (0x7f084242155c in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cpu.so)\r\nframe #5: <unknown function> + 0x101717d (0x7f0805af717d in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cuda.so)\r\nframe #6: <unknown function> + 0x2b517ea (0x7f084443e7ea in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cpu.so)\r\nframe #7: <unknown function> + 0x2cf9c5c (0x7f08445e6c5c in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cpu.so)\r\nframe #8: torch::autograd::AccumulateGrad::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0xdc (0x7f08445e81bc in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cpu.so)\r\nframe #9: <unknown function> + 0x2cf5745 (0x7f08445e2745 in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cpu.so)\r\nframe #10: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f08445dfa43 in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cpu.so)\r\nframe #11: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f08445e0822 in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cpu.so)\r\nframe #12: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f08445d8e99 in /home/sonic/Downloaded_Library/libtorch/lib/libtorch_cpu.so)\r\nframe #13: <unknown function> + 0xc70f (0x7f085074970f in /home/sonic/Downloaded_Library/libtorch/lib/libtorch.so)\r\nframe #14: <unknown function> + 0x76db (0x7f08416d56db in /lib/x86_64-linux-gnu/libpthread.so.0)\r\nframe #15: clone + 0x3f (0x7f0803dec88f in /lib/x86_64-linux-gnu/libc.so.6)\r\n\r\nAborted (core dumped)\r\n```\r\n\r\n## Expected behavior\r\n\r\nRun w/o any segmentation faults.\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.2.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.0.130\r\n\r\nOS: Ubuntu 18.04.4 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: version 3.10.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration: GPU 0: GeForce RTX 2070 SUPER\r\nNvidia driver version: 430.50\r\ncuDNN version: /usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudnn.so.7.5.0\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.17.1\r\n[pip3] torch==1.2.0\r\n[pip3] torchvision==0.4.0\r\n[conda] Could not collect\r\n\r\ncc @ezyang @SsnL @albanD @zou3519 @gqchen @yf225"},{"labels":["api",null,null],"text":"Repro:\r\n```\r\nauto options = F::BatchNormFuncOptions().weight(w).bias(b).momentum(m).eps(e).training(t);\r\nstd::cout << options << std::endl;\r\n```\r\n\r\nExpected result: \r\nPrint value for each property.\r\n\r\nActual Result:\r\n```\r\n‚Äòtorch::nn::functional::BatchNormFuncOptions‚Äô is not derived from ‚Äòconst torch::ExpandingArray<D, T>‚Äô\r\n         std::cout << options << std::endl;\r\n                      ^~~~~~~\r\n```\n\ncc @yf225"},{"labels":[null,"api",null],"text":"## üêõ Bug\r\n\r\nRunning the following code in cuda-enabled libtorch throws error \"CUDA error: driver shutting down\", even though the code doesn't use CUDA. Running the same code in cpu-only libtorch doesn't throw any error.\r\n\r\n```cpp\r\n#include <iostream>\r\n#include <torch/torch.h>\r\n\r\nusing namespace torch::autograd;\r\n\r\nclass MulConstant : public Function<MulConstant> {\r\n public:\r\n  static Variable forward(AutogradContext *ctx, Variable variable, double constant) {\r\n    ctx->saved_data[\"constant\"] = constant;\r\n    return variable * constant;\r\n  }\r\n\r\n  static variable_list backward(AutogradContext *ctx, variable_list grad_outputs) {\r\n    return {grad_outputs[0] * ctx->saved_data[\"constant\"].toDouble(), Variable()};\r\n  }\r\n};\r\n\r\nint main(int argc, char* argv[])\r\n{\r\n  auto x = torch::randn({2}).requires_grad_();\r\n  auto y = MulConstant::apply(x, 5.5);\r\n  y.sum().backward();\r\n  std::cout << x.grad() << std::endl;\r\n}\r\n```\r\nError:\r\n```\r\nterminate called after throwing an instance of 'c10::Error'\r\nterminate called recursively\r\n  what():  CUDA error: driver shutting down (setDevice at /pytorch/c10/cuda/impl/CUDAGuardImpl.h:42)\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7fedc6342656 in /data/libtorch/libtorch_nightly_cu92/libtorch/lib/libc10.so)\r\nframe #1: <unknown function> + 0xc6c2 (0x7fed7bad26c2 in /data/libtorch/libtorch_nightly_cu92/libtorch/lib/libc10_cuda.so)\r\nframe #2: torch::autograd::Engine::set_device(int) + 0x159 (0x7fedb9c36b39 in /data/libtorch/libtorch_nightly_cu92/libtorch/lib/libtorch_cpu.so)\r\nframe #3: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x34 (0x7fedb9c39064 in /data/libtorch/libtorch_nightly_cu92/libtorch/lib/libtorch_cpu.so)\r\nframe #4: <unknown function> + 0xc70f (0x7fedc657b70f in /data/libtorch/libtorch_nightly_cu92/libtorch/lib/libtorch.so)\r\nframe #5: <unknown function> + 0x76ba (0x7fed7c3756ba in /lib/x86_64-linux-gnu/libpthread.so.0)\r\nframe #6: clone + 0x6d (0x7fed7c8bc41d in /lib/x86_64-linux-gnu/libc.so.6)\r\nAborted (core dumped)\r\n```\r\nBetter backtrace:\r\n```\r\nThread 4 \"example-app\" hit Catchpoint 1 (exception thrown), 0x00007fffccab38bd in __cxa_throw () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n(gdb) bt\r\n#0  0x00007fffccab38bd in __cxa_throw () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#1  0x00007fffc4d14ab9 in c10::cuda::impl::CUDAGuardImpl::getDevice (this=0x997920) at ../c10/cuda/impl/CUDAGuardImpl.h:37\r\n#2  0x00007fffc4d14ed6 in c10::cuda::impl::CUDAGuardImpl::setDevice (this=0x997920, d=...) at ../c10/cuda/impl/CUDAGuardImpl.h:51\r\n#3  0x00007ffff0f101db in torch::autograd::Engine::set_device (this=0x7ffff7b16bc0 <torch::autograd::Engine::get_base_engine()::engine>, device=1) at ../torch/csrc/autograd/engine.cpp:264\r\n#4  0x00007ffff0f1034d in torch::autograd::Engine::thread_init (this=0x7ffff7b16bc0 <torch::autograd::Engine::get_base_engine()::engine>, device=1, ready_queue=std::shared_ptr (count 2, weak 0) 0x1b33aa0)\r\n    at ../torch/csrc/autograd/engine.cpp:293\r\n#5  0x00007ffff0f3613e in std::_Mem_fn_base<void (torch::autograd::Engine::*)(int, std::shared_ptr<torch::autograd::ReadyQueue> const&), true>::operator()<int, std::shared_ptr<torch::autograd::ReadyQueue>, void>(torch::autograd::Engine*, int&&, std::shared_ptr<torch::autograd::ReadyQueue>&&) const (this=0x1b340d8, __object=0x7ffff7b16bc0 <torch::autograd::Engine::get_base_engine()::engine>) at /usr/include/c++/5/functional:600\r\n#6  0x00007ffff0f360a1 in std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(int, std::shared_ptr<torch::autograd::ReadyQueue> const&)> (torch::autograd::Engine*, int, std::shared_ptr<torch::autograd::ReadyQueue>)>::_M_invoke<0ul, 1ul, 2ul>(std::_Index_tuple<0ul, 1ul, 2ul>) (this=0x1b340b8) at /usr/include/c++/5/functional:1531\r\n#7  0x00007ffff0f35cb8 in std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(int, std::shared_ptr<torch::autograd::ReadyQueue> const&)> (torch::autograd::Engine*, int, std::shared_ptr<torch::autograd::ReadyQueue>)>::operator()() (this=0x1b340b8) at /usr/include/c++/5/functional:1520\r\n#8  0x00007ffff0f35ac8 in std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(int, std::shared_ptr<torch::autograd::ReadyQueue> const&)> (torch::autograd::Engine*, int, std::shared_ptr<torch::autograd::ReadyQueue>)> >::_M_run() (this=0x1b340a0) at /usr/include/c++/5/thread:115\r\n#9  0x00007fffccadec80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#10 0x00007fffcbafa6ba in start_thread (arg=0x7fff9cd8d700) at pthread_create.c:333\r\n#11 0x00007fffcc24441d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\r\n```\r\nUpdate: I noticed that if we initialize a cuda tensor (e.g. `auto cuda_tensor = torch::randn({3, 4}, torch::kCUDA); std::cout << cuda_tensor << std::endl;`) before running the C++ custom autograd function, the whole thing would pass and there is no error.\r\n\r\n## Expected behavior\r\n\r\nIt should just work without throwing any error.\r\n\r\n## Environment\r\n\r\nLatest libtorch nightly\r\n\r\ncc @ezyang @SsnL @albanD @zou3519 @gqchen @yf225"},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\nHello, this may already be available and undocumented, but is there any way to access the full C++ frontend API on the mobile build? \r\n\r\nCurrently the mobile build only exposes the TorchScript portion of libtorch, so, e.g. I can't use `torch::nn` operations on mobile. \r\n\n\ncc @yf225"},{"labels":["api",null],"text":"I've tried to run mnist train example (https://github.com/pytorch/examples/tree/master/cpp/mnist)\r\nCode crushes on train_dataset creation whith message \"Unhandled exception at 0x00007FFE7B879179 in MNIST.exe: Microsoft C++ exception: c10::Error at memory location 0x00000068D2EFF4B0. occurred\".\r\n[auto train_dataset = torch::data::datasets::MNIST(kDataRoot)\r\n        .map(torch::data::transforms::Normalize<>(0.1307, 0.3081))\r\n        .map(torch::data::transforms::Stack<>());]\r\nEnvironment:\r\nWin10, VS 2019, Release, CPU.\r\n\r\nI'm not sure if mnist-data prpared correctly. Just put them to ./data catalog\r\n26.03.2020  12:10         1¬†648¬†877 t10k-images-idx3-ubyte.gz\r\n26.01.1998  18:07         7¬†840¬†016 t10k-images.idx3-ubyte\r\n26.03.2020  12:10             4¬†542 t10k-labels-idx1-ubyte.gz\r\n26.01.1998  18:07            10¬†008 t10k-labels.idx1-ubyte\r\n26.03.2020  12:09         9¬†912¬†422 train-images-idx3-ubyte.gz\r\n18.11.1996  18:36        47¬†040¬†016 train-images.idx3-ubyte\r\n26.03.2020  12:09            28¬†881 train-labels-idx1-ubyte.gz\r\n18.11.1996  18:36            60¬†008 train-labels.idx1-ubyte\r\n\r\nWhat is wrong?\n\ncc @yf225"},{"labels":["api",null,null],"text":"## üìö Documentation\r\n\r\ntorch::cat is missing documentation? Following this link, where I searched for the documentation only returned other functions where torch::cat are begin used in the body?\r\n\r\nhttps://pytorch.org/cppdocs/search.html?q=torch%3A%3Acat&check_keywords=yes&area=default\r\n"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nSince this commit : https://github.com/pytorch/pytorch/commit/76035f050b215d0606fe786901dcd07b5c9544fe#diff-b8c53e7a2010d3dae3200c9911950551\r\nIt's no longer possible to directly access the options variable of Adam in libtorch, making it impossible to change the learning rate on the fly with libtorch.\r\nHow can I change the learning rate ?\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Install the latest nightly of libtorch\r\n2. Create an Adam optimizer\r\n3. Try to access its .options variable to change the learning rate : options does not exist anymore\r\n\n\ncc @yf225"},{"labels":["api",null],"text":"I use ConvTranspose2d in a Sequential, and forward called with one parameter, it invoke above issue. I think it is a bug of libtorch,  ConvTranspose2d need another forward overload function with one parameter.\r\n\n\ncc @yf225"},{"labels":["api",null],"text":"`torch::normal` only supports (double, double) as input, but `at::normal` supports (double, double) / (double, Tensor) / (Tensor, double) / (Tensor, Tensor) as input.\r\n\r\nPython `torch.normal` also supports all four types of inputs (https://pytorch.org/docs/stable/torch.html#torch.normal), and we should do the same for `torch::normal`.\r\n\r\nSome notes:\r\n- `torch::normal` is currently defined in`torch/csrc/autograd/generated/variable_factories.h`\r\n- Per conversation with Ed, we should put the tracing logic in VariableType and just dispatch `torch::normal` to VariableType\r\n\r\n(This issue was originally reported by @ailzhang)\r\n\r\ncc @yf225 \r\n\r\ncc @ailzhang @ezyang "},{"labels":[null,"api",null],"text":"## To Reproduce\r\n\r\nIn python, accessing the .grad attribute of a non-leaf tensor is a common pitfall users run into. For example:\r\n```\r\nx = torch.randn(3, requires_grad=True).cuda()\r\ny = x ** 2\r\ny.sum().backward()\r\nx.grad\r\n```\r\nLuckily, this raises a nice warning in Python:\r\n```\r\n/scratch/rzou/pt/cudnn_double_Bwd/torch/tensor.py:746: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\r\n  warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\r\n```\r\n\r\nIn the C++ API, no warning happens: https://discuss.pytorch.org/t/very-confused-with-changes-in-autograd/74355 . It would be great for usability to add that warning.\r\n\r\n\n\ncc @ezyang @SsnL @albanD @zou3519 @gqchen @yf225"},{"labels":["api",null,null,null],"text":"## üìö Documentation\r\nWhen I use function `torch::randint()` it takes arguments `int64_t high, at::IntArrayRef size, at::TensorOptions &options = {}` however, at the documentation it says there should also be a `at::Generator generator`\r\n\r\nhttps://pytorch.org/cppdocs/api/function_namespacetorch_1ad86f0f5e4b92098660b54e584342a188.html?highlight=randint\r\n\r\nI am using libtorch 1.4\n\ncc @yf225"},{"labels":["api",null,null],"text":"When compiling custom-dataset example receive errors:\r\n1) no instance of constructor \"torch::nn::Functional::Functional\" matches the argument list\tCustomDataSet\t...\\CustomDataSet\\CTorch.cpp\t125\t\r\n2) cannot determine which instance of overloaded function \"torch::log_softmax\" is intended\tCustomDataSet\t...\\CustomDataSet\\CTorch.cpp\t125\t\r\n line 125 is: push_back(Functional(torch::log_softmax, 1, torch::nullopt));\r\n\r\nCould anybody help with this?\n\ncc @yf225 @peterjc123"},{"labels":["api",null,null],"text":"I tried to do it in #34968 but that PR added c-tor Generator(Device device) to C++ API to match Python API, to avoid code duplication the logic was moved from THPGenerator_pynew to corresponding at::Generator c-tor. Unfortunately it made Generator.h dependent on CPUGenerator.h and CUDAGenerator.h, but this is how our Python API works :(\n\ncc @yf225"},{"labels":["api",null,null],"text":"## üêõ Bug\r\nresult in memory leak when use libtorch. but i think that it is very strange. because i only define `torch::DeiviceType`  , then got **bug1**\r\n### bug1\r\n```\r\nstill reachable: 884,654 bytes in 13,927 blocks of which reachable via heuristic: stdstring :436062 bytes in 5832 blocks\r\n```\r\n\r\n### bug2\r\n```\r\npossibly lost: 3104 bytes in 22 blocks\r\nstill reachable: 1231592 bytes in 14005 blocks of which reachable via heuristic: stdstring :436062 bytes in 5832 blocks\r\n```\r\n## To Reproduce\r\n### bug1\r\n```c++\r\nint main()\r\n{\r\n torch::DeviceType device_type;\r\n}\r\n```\r\n### bug2\r\n```c++\r\nint main()\r\n{\r\n torch::DeviceType device_type;\r\nif(torch::cuda::is_available())\r\n{\r\ndevice_type = torch::kCUDA;\r\n}\r\nelse\r\n{\r\ndevice_type = torch::kCPU;\r\n}\r\ntorch::Device device(device_type)\r\n}\r\n```\r\n\r\n\r\n## Environment\r\n\r\n - PyTorch Version : 1.4\r\n- libtorch Version: 1.4\r\n - OS (e.g., Linux): Ubuntu 16.04\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Python version: 3.5\r\n - CUDA/cuDNN version: 10\r\n\r\n\r\n## update\r\n- the memory leak caused by the `valgrind` tool, not bug for libtorch.\r\n- `cuda-memcheck` is need for detect memory leak instead of `valgrind`\r\n\r\nBut `cuda-memcheck` report this error below:\r\n```shell\r\nProgram hit cudaErrorCudartUnloading (error 4) due to \"driver shutting down\" on CUDA API call to cudaEventDestroy.\r\n=========     Saved host backtrace up to driver entry point at error\r\n=========     Host Frame:/usr/local/nvidia/lib64/libcuda.so.1 [0x377f93]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libcudart-1b201d85.so.10.1 (cudaEventDestroy + 0x18e) [0x49c8e]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so (_ZN19cublasFixedSizePool8tearDownEv + 0xe4) [0x10a4ac34]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so (_ZN36cublasFixedSizePoolWithGraphSuppport8tearDownEv + 0x16) [0x1083f666]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so (cublasDestroy_v2 + 0xd0) [0xebccfd0]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so (cudnnDestroy + 0x219) [0xf473e99]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so [0x46cc655]\r\n=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__cxa_finalize + 0x9a) [0x3a36a]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so [0x18ab893]\r\n```\r\n\r\n\r\ncc @yf225"},{"labels":[null,"api",null,null],"text":"## üöÄ Feature\r\nC++ API should support Famous Open Datasets CIFAR10 and CIFAR100.\r\n**Dataset Reference**: [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)\r\n\r\n## Motivation\r\nWhile creating PyTorch C++ tutorials [https://github.com/prabhuomkar/pytorch-cpp](https://github.com/prabhuomkar/pytorch-cpp), I came to know that PyTorch has support for these datasets via [vision](https://github.com/pytorch/vision/tree/master/torchvision/datasets). As of now, [C++ API for Datasets](https://github.com/pytorch/pytorch/tree/master/torch/csrc/api/src/data/datasets) only has MNIST.\r\nSupport for standard datasets like CIFAR, COCO, ImageNet, etc out of the box will help developers play with C++ API easily.\r\n\r\n## Pitch\r\n- Add [cifar.h](https://github.com/pytorch/pytorch/tree/master/torch/csrc/api/include/torch/data/datasets) header with _`TORCH_API`_ `CIFAR` class.\r\n- Add [cifar.cpp](https://github.com/pytorch/pytorch/tree/master/torch/csrc/api/src/data/datasets) with both `CIFAR10` and `CIFAR100` support similar to vision for reading images, targets and getting train/test data. \r\n\r\n## Alternatives\r\nN/A\r\n\r\n## Additional context\r\nReference C++ Implementation: [cifar10.h](https://github.com/prabhuomkar/pytorch-cpp/blob/master/tutorials/intermediate/deep_residual_network/include/cifar10.h) and [cifar10.cpp](https://github.com/prabhuomkar/pytorch-cpp/blob/master/tutorials/intermediate/deep_residual_network/src/cifar10.cpp)\r\nReference Python Implementation: [cifar.py](https://github.com/pytorch/vision/blob/master/torchvision/datasets/cifar.py)\r\n\n\ncc @yf225 @fmassa"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nI intend to use libtorch in a plugin project for the VFX compositing software Nuke (https://www.foundry.com/products/nuke). When I include torch using the standard line:\r\n#include <torch/torch.h>\r\nI'm getting a class name ambiguity with the class \"Node\" in Nuke's API. This shouldn't really happen since everything is properly namespaces. I've traced the problem down to these sources in torch: \r\ntorch/csrc/autograd/VariableTypeUtils.h\r\ntorch/csrc/api/include/torch/nn/modules/_functions.h\r\n\r\nThis makes torch::autograd::Node to appear in the root namespace and clashes with a Node from Nuke that is also declared in the root namespace.\r\n\r\nSince Nuke is a commercial product it's hard to make any changes there, so I hope that somebody can correct these sources so they internally just specify the whole namespace to the functions internally so that the \"using namespace\" lines can be removed.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behaviour:\r\n\r\n1. Start a clean C++ project and write this code snippet:\r\n```\r\n#include <torch/torch.h>\r\nstruct Node{};\r\nvoid bogus(Node *node){}\r\n```\r\n2. struct Node{}; in this case is coming from a third party library that you haven't got control over.\r\n3. Compile, and you will get an ambiguity error\r\n\r\nAlternatively, if you got Nuke available on your system:\r\n\r\n1. Copy one of the example plugins from Nuke\r\n2. Include torch using the standard line \"#include <torch/torch.h>\"\r\n3. Compile, and you will get the following error output:\r\n\r\nScanning dependencies of target ilp_MLTest\r\n[ 72%] Built target py\r\n[ 81%] Built target extension_files\r\n[ 90%] Building CXX object plugins/ilp_MLTest/CMakeFiles/ilp_MLTest.dir/ilp_MLTest.cpp.o\r\n/users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:35:17: error: expected ‚Äò)‚Äô before ‚Äò*‚Äô token\r\n  ilp_MLTest(Node* node) : DD::Image::Iop(node)\r\n                 ^\r\n/users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:63:26: error: reference to ‚ÄòNode‚Äô is ambiguous\r\n static Iop* ilp_MLTest_c(Node* node) { return new ilp_MLTest(node); }\r\n                          ^~~~\r\nIn file included from /ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:13:0,\r\n                 from /users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:8:\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Description.h:15:7: note: candidates are: class Node\r\n class Node;\r\n       ^~~~\r\nIn file included from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/autograd/custom_function.h:3:0,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/nn/modules/_functions.h:3,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/nn/modules/normalization.h:4,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/nn/modules.h:26,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/nn.h:7,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/all.h:7,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/torch.h:3,\r\n                 from /users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:19:\r\n/ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/autograd/function.h:88:18: note:                 struct torch::autograd::Node\r\n struct TORCH_API Node : std::enable_shared_from_this<Node> {\r\n                  ^~~~\r\n/users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:63:32: error: ‚Äònode‚Äô was not declared in this scope\r\n static Iop* ilp_MLTest_c(Node* node) { return new ilp_MLTest(node); }\r\n                                ^~~~\r\n/users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:63:32: note: suggested alternative: ‚ÄòNode‚Äô\r\n static Iop* ilp_MLTest_c(Node* node) { return new ilp_MLTest(node); }\r\n                                ^~~~\r\n                                Node\r\n/users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:68:78: error: no matching function for call to ‚ÄòDD::Image::Op::Description::Description(const char* const&, const char [18], DD::Image::Iop*&)‚Äô\r\n const Iop::Description ilp_MLTest::d(CLASS, \"Filter/ilp_MLTest\", ilp_MLTest_c);\r\n                                                                              ^\r\nIn file included from /users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:8:0:\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1952:9: note: candidate: DD::Image::Op::Description::Description(const char*, const char*, DD::Image::Op::Description::IopConstructor)\r\n         Description(const char* n, const char* /*menu*/, IopConstructor c) :\r\n         ^~~~~~~~~~~\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1952:9: note:   no known conversion for argument 3 from ‚ÄòDD::Image::Iop*‚Äô to ‚ÄòDD::Image::Op::Description::IopConstructor {aka DD::Image::Iop* (*)(Node*)}‚Äô\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1942:9: note: candidate: DD::Image::Op::Description::Description(const char*, const char*, DD::Image::Op::Description::OpConstructor)\r\n         Description(const char* n, const char* /*menu*/, OpConstructor c) :\r\n         ^~~~~~~~~~~\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1942:9: note:   no known conversion for argument 3 from ‚ÄòDD::Image::Iop*‚Äô to ‚ÄòDD::Image::Op::Description::OpConstructor {aka DD::Image::Op* (*)(Node*)}‚Äô\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1932:9: note: candidate: DD::Image::Op::Description::Description(const char*, DD::Image::Op::Description::OpConstructor, DD::Image::Description::NodeBuilder)\r\n         Description(const char* n, OpConstructor c, NodeBuilder nodeBuilder) :\r\n         ^~~~~~~~~~~\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1932:9: note:   no known conversion for argument 2 from ‚Äòconst char [18]‚Äô to ‚ÄòDD::Image::Op::Description::OpConstructor {aka DD::Image::Op* (*)(Node*)}‚Äô\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1925:9: note: candidate: DD::Image::Op::Description::Description(const char*, DD::Image::Op::Description::OpConstructor, DD::Image::License*)\r\n         Description(const char* n, OpConstructor c, License * l = 0) :\r\n         ^~~~~~~~~~~\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1925:9: note:   no known conversion for argument 2 from ‚Äòconst char [18]‚Äô to ‚ÄòDD::Image::Op::Description::OpConstructor {aka DD::Image::Op* (*)(Node*)}‚Äô\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1897:25: note: candidate: constexpr DD::Image::Op::Description::Description(const DD::Image::Op::Description&)\r\n       class DDImage_API Description : public DD::Image::Description\r\n                         ^~~~~~~~~~~\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1897:25: note:   candidate expects 1 argument, 3 provided\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1897:25: note: candidate: constexpr DD::Image::Op::Description::Description(DD::Image::Op::Description&&)\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1897:25: note:   candidate expects 1 argument, 3 provided\r\nmake[2]: *** [plugins/ilp_MLTest/CMakeFiles/ilp_MLTest.dir/build.make:63: plugins/ilp_MLTest/CMakeFiles/ilp_MLTest.dir/ilp_MLTest.cpp.o] Error 1\r\nmake[1]: *** [CMakeFiles/Makefile2:170: plugins/ilp_MLTest/CMakeFiles/ilp_MLTest.dir/all] Error 2\r\nmake: *** [Makefile:130: all] Error 2\r\n11:59:52 ERROR    BuildError: The cmake build system failed.\r\n\r\n\r\n## Expected behavior\r\n\r\nThat the plugin compiles just as normal, with no build errors from including the torch headers.\r\n\r\n## Environment\r\n\r\nPyTorch 1.4.0\r\nOS: CentOS Linux release 7.6.1810 (Core) \r\nGCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)\r\nCMake version: version 2.8.12.2\r\n\n\ncc @yf225"},{"labels":["api"],"text":"## üêõ Bug\r\n\r\nI want to make my `current_state`, which is made of `std::vector<double>` to a `torch::Tensor`.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1: Have a dobule vector, i.e `0.0642382 0.0395936 0 0.219108 0.372894 0.422909 0.554452 0.302765 1`\r\n2: `torch::Tensor current_state = torch::from_blob(current_state.data(), { 9}).to(*device);`\r\n3: std::cout << \"next state is: \\n\" << next_state << std::endl;\r\n\r\nobserve the output: \r\n```\r\nnext state is: \r\n-1.7024e+35\r\n1.3785e+00\r\n-6.2066e+14\r\n1.2834e+00\r\n0.0000e+00\r\n0.0000e+00\r\n-1.0163e+17\r\n1.5941e+00\r\nnan\r\n```\r\n\r\n## Expected behavior\r\n\r\nTo get a tensor with the same values as my vector...\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): Libtorch 1.4\r\n - OS (e.g., Linux): Windows 7 64 bit\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source): `cmake --build . --config Release --target INSTALL`\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: NA\r\n - GPU models and configuration: NA\r\n - Any other relevant information: NA\r\n\r\n## Additional context\r\nThe following line gives me a tensor that looks like I want, however it crashes when I try to feed it through the network...\r\n\r\n`torch::Tensor test_next_state = torch::tensor(current_state);`\r\n\n\ncc @yf225"},{"labels":["api",null,null],"text":"## üêõ Bug\r\n`torch::nn::Linear` without bias throws an error when `to` is called. \r\n\r\n## To Reproduce\r\n```c++\r\n#include<torch/torch.h>\r\nint main(int argc, char* argv[])\r\n{\r\n  torch::Tensor x = torch::ones({100, 4});\r\n  auto lopt       = torch::nn::LinearOptions(4, 4).bias(false);\r\n  auto lin        = torch::nn::Linear(lopt);\r\n  // works\r\n  auto y          = lin->forward(x);\r\n  // error\r\n  lin->to(torch::kFloat64);\r\n  x = torch::ones({100, 4}, torch::kFloat64);\r\n  y = lin->forward(x);\r\n}\r\n```\r\nThis is the output, but this MWE is only executed as a test in a larger project\r\nso the output might differ.\r\n```\r\n terminate called after throwing an instance of 'c10::Error'\r\n  what():  tensor does not have a device (device at /home/nls/gasnew/pytorch/torch/include/c10/core/TensorImpl.h:461)\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x6a (0x7ffff220035a in /home/nls/gasnew/pytorch/torch/lib/libc10.so)\r\nframe #1: c10::TensorImpl::device() const + 0xf8 (0x7ffff7f0e288 in /home/nls/gasnew/gasPyTorch/build/gt/src/libgt.so)\r\nframe #2: at::Tensor::device() const + 0x20 (0x7ffff7f117d4 in /home/nls/gasnew/gasPyTorch/build/gt/src/libgt.so)\r\nframe #3: at::Tensor::options() const + 0x71 (0x7ffff7f5fb41 in /home/nls/gasnew/gasPyTorch/build/gt/src/libgt.so)\r\nframe #4: at::native::to(at::Tensor const&, c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat>) + 0x6c (0x7ffff368fabc in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\nframe #5: <unknown function> + 0x1714a6b (0x7ffff392aa6b in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\nframe #6: <unknown function> + 0x32572d0 (0x7ffff546d2d0 in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\nframe #7: <unknown function> + 0x173c003 (0x7ffff3952003 in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\nframe #8: at::Tensor c10::KernelFunction::callUnboxedOnly<at::Tensor, at::Tensor const&, c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat> >(at::Tensor const&, c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat>) const + 0x141 (0x55555559bfd3 in /home/nls/gasnew/gasPyTorch/build/test/testgt)\r\nframe #9: at::Tensor c10::Dispatcher::callUnboxedOnly<at::Tensor, at::Tensor const&, c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat> >(c10::OperatorHandle const&, at::Tensor const&, c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat>) const + 0x16f (0x5555555968c9 in /home/nls/gasnew/gasPyTorch/build/test/testgt)\r\nframe #10: at::Tensor::to(c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat>) const + 0x1de (0x55555558f6dc in /home/nls/gasnew/gasPyTorch/build/test/testgt)\r\nframe #11: void torch::nn::Module::to_impl<c10::ScalarType&, bool&>(c10::ScalarType&, bool&) + 0x149 (0x7ffff59d5f19 in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\nframe #12: torch::nn::Module::to(c10::ScalarType, bool) + 0x1c (0x7ffff59d2bac in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\n```\r\n## Environment\r\n\r\n - PyTorch Version: 1.4 from source\r\n - OS: Linux\n\ncc @yf225"},{"labels":["api",null,null,null],"text":"https://pytorch.org/cppdocs/api/function_namespacetorch_1a99dc9f736064b2179cc58e6436f7a021.html#exhale-function-namespacetorch-1a99dc9f736064b2179cc58e6436f7a021\r\n\r\nhttps://pytorch.org/cppdocs/api/function_namespacetorch_1a4b369494adfb10b9a005aeb0bb6207cb.html#exhale-function-namespacetorch-1a4b369494adfb10b9a005aeb0bb6207cb\r\n\r\nsee issue: https://github.com/pytorch/pytorch/issues/33862#issuecomment-593518890\n\ncc @yf225 @vincentqb"},{"labels":[null,null,null,"api",null],"text":"## üêõ Bug\r\n\r\nThe library size of torch is very large (~267MB without CUDA, 1.2 GB with CUDA).\r\nThis can be caused by using a library like Intel IPP similar to this opencv bug.\r\nhttps://github.com/opencv/opencv/issues/15177\r\nThis limits the use of pytorch models in small environments (without CUDA).\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n1. Download the libtorch C++ library\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nLibrary size without CUDA should be a lot less than that. or at least providing libtorch_tiny or ways to create it.\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n - PyTorch Version: 1.4\r\n - OS: Linux\r\n\n\ncc @ezyang @gchanan @zou3519 @seemethere @yf225"},{"labels":["api",null,null],"text":"WARNING: ThreadSanitizer: data race (pid=17) Read of size 8 at 0x7fd6718c2ea0 by thread T2:\r\n\r\n```#0 std::__1::shared_ptr<at::CPUGenerator>::get() const external/clang/include/c++/v1/memory:3800:49 (libexternal_Spytorch_Slibaten.so+0x37dba2)\r\n#1 at::detail::getDefaultCPUGenerator() external/pytorch/aten/src/ATen/CPUGenerator.cpp:27:26 (libexternal_Spytorch_Slibaten.so+0x37dba2)\r\n#2 THFloatTensor_uniform external/pytorch/aten/src/TH/generic/THTensorRandom.cpp:81:73 (libexternal_Spytorch_Slibaten.so+0x1801ace)\r\n#3 at::native::legacy::cpu::_th_uniform_(at::Tensor&, double, double, at::Generator*) bazel-out/k8-dbg-tsan/bin/external/pytorch/ATen/LegacyTHFunctionsCPU.cpp:9339:13 (libexternal_Spytorch_Slibaten.so+0x1a165cf)\r\n#4 at::CPUType::(anonymous namespace)::uniform_(at::Tensor&, double, double, at::Generator*) bazel-out/k8-dbg-tsan/bin/external/pytorch/ATen/CPUType.cpp:2079:12 (libexternal_Spytorch_Slibaten.so+0x192487f)\r\n#5 c10::detail::WrapRuntimeKernelFunctor_<at::Tensor& (*)(at::Tensor&, double, double, at::Generator*), at::Tensor&, c10::guts::typelist::typelist<at::Tensor&, double, double, at::Generator*> >::operator()(at::Tensor&, double, double, at::Generator*) external/pytorch/aten/src/ATen/core/boxing/kernel_lambda.h:23:14 (libexternal_Spytorch_Slibpytorch.so+0x1321734)\r\n#6 c10::detail::wrap_kernel_functor_unboxed_<c10::detail::WrapRuntimeKernelFunctor_<at::Tensor& (*)(at::Tensor&, double, double, at::Generator*), at::Tensor&, c10::guts::typelist::typelist<at::Tensor&, double, double, at::Generator*> >, at::Tensor& (at::Tensor&, double, double, at::Generator*)>::call(c10::OperatorKernel*, at::Tensor&, double, double, at::Generator*) external/pytorch/aten/src/ATen/core/boxing/kernel_functor.h:262:14 (libexternal_Spytorch_Slibpytorch.so+0x1321734)\r\n#7 at::Tensor& c10::KernelFunction::callUnboxed<at::Tensor&, at::Tensor&, double, double, at::Generator*>(c10::OperatorHandle const&, at::Tensor&, double, double, at::Generator*) const external/pytorch/aten/src/ATen/core/boxing/KernelFunction_impl.h:62:16 (libexternal_Spytorch_Slibpytorch.so+0x8d4c21)\r\n#8 at::Tensor& c10::Dispatcher::callUnboxed<at::Tensor&, at::Tensor&, double, double, at::Generator*>(c10::OperatorHandle const&, at::Tensor&, double, double, at::Generator*) const external/pytorch/aten/src/ATen/core/dispatch/Dispatcher.h:179:26 (libexternal_Spytorch_Slibpytorch.so+0x954957)\r\n#9 at::Tensor& c10::OperatorHandle::callUnboxed<at::Tensor&, at::Tensor&, double, double, at::Generator*>(at::Tensor&, double, double, at::Generator*) const external/pytorch/aten/src/ATen/core/dispatch/Dispatcher.h:154:41 (libexternal_Spytorch_Slibpytorch.so+0x954957)\r\n#10 at::Tensor::uniform_(double, double, at::Generator*) const bazel-out/k8-dbg-tsan/bin/external/pytorch/ATen/core/TensorMethods.h:4653:15 (libexternal_Spytorch_Slibpytorch.so+0x954957)\r\n#11 at::native::rand(c10::ArrayRef<long>, at::Generator*, c10::TensorOptions const&) external/pytorch/aten/src/ATen/native/TensorFactories.cpp:441:17 (libexternal_Spytorch_Slibaten.so+0x9155fb)\r\n#12 at::native::rand(c10::ArrayRef<long>, c10::TensorOptions const&) external/pytorch/aten/src/ATen/native/TensorFactories.cpp:436:10 (libexternal_Spytorch_Slibaten.so+0x915572)\r\n#13 at::TypeDefault::rand(c10::ArrayRef<long>, c10::TensorOptions const&) bazel-out/k8-dbg-tsan/bin/external/pytorch/ATen/TypeDefault.cpp:3284:12 (libexternal_Spytorch_Slibaten.so+0x1a80570)\r\n#14 c10::detail::WrapRuntimeKernelFunctor_<at::Tensor (*)(c10::ArrayRef<long>, c10::TensorOptions const&), at::Tensor, c10::guts::typelist::typelist<c10::ArrayRef<long>, c10::TensorOptions const&> >::operator()(c10::ArrayRef<long>, c10::TensorOptions const&) external/pytorch/aten/src/ATen/core/boxing/kernel_lambda.h:23:14 (libexternal_Spytorch_Slibpytorch.so+0x132b8bd)\r\n#15 c10::detail::wrap_kernel_functor_unboxed_<c10::detail::WrapRuntimeKernelFunctor_<at::Tensor (*)(c10::ArrayRef<long>, c10::TensorOptions const&), at::Tensor, c10::guts::typelist::typelist<c10::ArrayRef<long>, c10::TensorOptions const&> >, at::Tensor (c10::ArrayRef<long>, c10::TensorOptions const&)>::call(c10::OperatorKernel*, c10::ArrayRef<long>, c10::TensorOptions const&) external/pytorch/aten/src/ATen/core/boxing/kernel_functor.h:262:14 (libexternal_Spytorch_Slibpytorch.so+0x132b8bd)\r\n#16 at::Tensor c10::KernelFunction::callUnboxed<at::Tensor, c10::ArrayRef<long>, c10::TensorOptions const&>(c10::OperatorHandle const&, c10::ArrayRef<long>, c10::TensorOptions const&) const external/pytorch/aten/src/ATen/core/boxing/KernelFunction_impl.h:62:16 (test_pytorch+0xd1fcb)\r\n#17 at::Tensor c10::Dispatcher::callUnboxed<at::Tensor, c10::ArrayRef<long>, c10::TensorOptions const&>(c10::OperatorHandle const&, c10::ArrayRef<long>, c10::TensorOptions const&) const external/pytorch/aten/src/ATen/core/dispatch/Dispatcher.h:179:26 (test_pytorch+0xcf638)\r\n#18 at::Tensor c10::OperatorHandle::callUnboxed<at::Tensor, c10::ArrayRef<long>, c10::TensorOptions const&>(c10::ArrayRef<long>, c10::TensorOptions const&) const external/pytorch/aten/src/ATen/core/dispatch/Dispatcher.h:154:41 (test_pytorch+0xcf638)\r\n#19 at::rand(c10::ArrayRef<long>, c10::TensorOptions const&) bazel-out/k8-dbg-tsan/bin/external/pytorch/ATen/Functions.h:6638:15 (libros_Ssrc_Sa_Ulibtorch_Uuser_Sliba_Ulibtorch_Uuser.so+0x16794)\r\n#20 torch::rand(c10::ArrayRef<long>, c10::TensorOptions const&)::'lambda'()::operator()() const bazel-out/k8-dbg-tsan/bin/external/pytorch/torch/csrc/autograd/generated/variable_factories.h:534:12 (libros_Ssrc_Sa_Ulibtorch_Uuser_Sliba_Ulibtorch_Uuser.so+0x16794)\r\n#21 torch::rand(c10::ArrayRef<long>, c10::TensorOptions const&) bazel-out/k8-dbg-tsan/bin/external/pytorch/torch/csrc/autograd/generated/variable_factories.h:532:23 (libros_Ssrc_Sa_Ulibtorch_Uuser_Sliba_Ulibtorch_Uuser.so+0x12194)\r\n#22 a_libtorch_user::ALibtorchUser::call_inference(int) ros/src/a_libtorch_user/src/ALibtorchUser.cpp:32:26 (libros_Ssrc_Sa_Ulibtorch_Uuser_Sliba_Ulibtorch_Uuser.so+0x10bf7)\r\n#23 decltype(*(std::__1::forward<a_libtorch_user::ALibtorchUser*>(fp0)).*fp(std::__1::forward<int>(fp1))) std::__1::__invoke<void (a_libtorch_user::ALibtorchUser::*)(int), a_libtorch_user::ALibtorchUser*, int, void>(void (a_libtorch_user::ALibtorchUser::*&&)(int), a_libtorch_user::ALibtorchUser*&&, int&&) external/clang/include/c++/v1/type_traits:3471:1 (libros_Ssrc_Sa_Ulibtorch_Uuser_Sliba_Ulibtorch_Uuser.so+0x267ed)\r\n#24 void std::__1::__thread_execute<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void (a_libtorch_user::ALibtorchUser::*)(int), a_libtorch_user::ALibtorchUser*, int, 2ul, 3ul>(std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void (a_libtorch_user::ALibtorchUser::*)(int), a_libtorch_user::ALibtorchUser*, int>&, std::__1::__tuple_indices<2ul, 3ul>) external/clang/include/c++/v1/thread:277:5 (libros_Ssrc_Sa_Ulibtorch_Uuser_Sliba_Ulibtorch_Uuser.so+0x267ed)\r\n#25 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void (a_libtorch_user::ALibtorchUser::*)(int), a_libtorch_user::ALibtorchUser*, int> >(void*) external/clang/include/c++/v1/thread:287:5 (libros_Ssrc_Sa_Ulibtorch_Uuser_Sliba_Ulibtorch_Uuser.so+0x267ed)```\r\n\r\ntest.cpp\r\n--------\r\nvoid call_inference() {\r\n    int batch_size = 100;\r\n    torch::Tensor data = torch::rand({batch_size, 100, 30}).to(device);\r\n    torch::Tensor h0 = torch::rand({1, batch_size, 256}).to(device);\r\n    torch::Tensor c0 = torch::rand({1, batch_size, 256}).to(device);\r\n    module.run_method(\"forward\", data, h0, c0);\r\n}\r\n...\r\nfor (int32_t i = 0; i < n; i++) {\r\n    std::thread t(&all_inference, i);\r\n}\r\n```\n\ncc @yf225"},{"labels":["api",null,null],"text":"## üêõ Can't save to ostream\r\n\r\nI want to save my model as a `istream` for later processing.\r\nI found the following on the api:\r\n\r\nhttps://pytorch.org/cppdocs/api/function_namespacetorch_1a99dc9f736064b2179cc58e6436f7a021.html#exhale-function-namespacetorch-1a99dc9f736064b2179cc58e6436f7a021\r\n\r\nhttps://pytorch.org/cppdocs/api/function_namespacetorch_1a4b369494adfb10b9a005aeb0bb6207cb.html#exhale-function-namespacetorch-1a4b369494adfb10b9a005aeb0bb6207cb\r\n\r\n## To Reproduce\r\n`torch::optim::SGD sgd(0.9);` give me error: \r\n\r\n>Error (active)\tE0289\tno instance of constructor \"torch::optim::SGD::SGD\" matches the argument list\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): LibTorch 1.4\r\n - OS (e.g., Linux): Windows 7 64 bit\r\n - How you installed PyTorch (`conda`, `pip`, source): source: https://download.pytorch.org/libtorch/cpu/libtorch-win-shared-with-deps-1.4.0.zip\r\n - Build command you used (if compiling from source): cmake --build . --config Release --target INSTALL\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: NA\r\n - GPU models and configuration: NA\r\n - Any other relevant information: NA\r\n\r\n\n\ncc @yf225"},{"labels":["api",null,null],"text":"## üêõ Bug\r\n\r\nModels saved in C++ LibTorch with torch::save, cannot be loaded in python using torch.load. When I save a custom model (a class which inherits from torch::nn::Module) using torch::save(model, filepath), the result is a zip archive (.pt). The archive has the same structure as [it should](https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/docs/serialization.md) but python comes up with the error \r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Save a class which inherits from the torch::nn::Module class in C++ using torch::save\r\n2. Try to load that saved archive in python using torch.load\r\n3. Find this error below: \r\n\r\n`Traceback (most recent call last):\r\n  File \"torch_plotting.py\", line 59, in <module>\r\n    policy_model, value_model = load_models(containing_path, model_number)\r\n  File \"torch_plotting.py\", line 37, in load_models\r\n    policy_model = torch.load(policy_file)\r\n  File \"/home/jamie/anaconda3/envs/tensorflow/lib/python3.7/site-packages/torch/serialization.py\", line 528, in load\r\n    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\r\n  File \"/home/jamie/anaconda3/envs/tensorflow/lib/python3.7/site-packages/torch/serialization.py\", line 782, in _load\r\n    result = unpickler.load()\r\nModuleNotFoundError: No module named '__torch__'`\r\n\r\n## Expected behavior\r\n\r\nExpect to have a fully loaded model that behaves the same way as the c++ one which I can use to perform inference.\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 19.10\r\nGCC version: (Ubuntu 9.2.1-9ubuntu2) 9.2.1 20191008\r\nCMake version: version 3.16.4\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce GTX 1050 Ti\r\nNvidia driver version: 440.33.01\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.17.2\r\n[pip3] numpydoc==0.9.1\r\n[pip3] torch==1.4.0\r\n[pip3] torchvision==0.5.0\r\n[conda] blas                      1.0                         mkl  \r\n[conda] mkl                       2019.4                      243  \r\n[conda] mkl-service               2.3.0            py37he904b0f_0  \r\n[conda] mkl_fft                   1.0.14           py37ha843d7b_0  \r\n[conda] mkl_random                1.1.0            py37hd6b4f25_0  \r\n[conda] torch                     1.4.0                    pypi_0    pypi\r\n[conda] torchvision               0.5.0                    pypi_0    pypi\r\n\r\n## Additional context\r\n\r\nI am using the libtorch provided by [this link](https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-1.4.0%2Bcpu.zip) and using cmake to build my project. The file to open is \r\n[policy_9999.zip](https://github.com/pytorch/pytorch/files/4255490/policy_9999.zip) (renamed to policy_9999.zip instead of the original policy_9999.pt so it could be uploaded.)\r\n\r\n\r\n\n\ncc @yf225 @glaringlee @SsnL"},{"labels":["api",null,null],"text":"## üêõ Bug\r\n\r\nWith PR #33027, the fix to allow Sequential to call forward with default args skipped,\r\nthe options element in RNNImpl is protected (was public before)\r\n\r\n```\r\n protected:\r\n  FORWARD_HAS_DEFAULT_ARGS({1, AnyValue(Tensor())})\r\n\r\n  RNNOptions options;\r\n```\n\ncc @yf225"},{"labels":["api",null],"text":"Instead of\r\n\r\n```\r\nclass TensorOptions {\r\n  TensorOptions device(optional<Device>) { ... } // setter\r\n}\r\n```\r\n\r\nwe should have\r\n\r\n```\r\nclass TensorOptions {\r\n  TensorOptions device(Device) { ... } // setter\r\n  TensorOptions device_opt(optional<Device>) { ... } // setter\r\n}\r\n```\r\n\r\nThis makes the class more user friendly as now `x.device({kCUDA, 1})` works; it also makes it symmetric with `at::device({kCUDA, 1})`.\n\ncc @yf225"},{"labels":["api",null,null],"text":"struct Net : torch::nn::Module {\r\n\tNet()\r\n\t\t: conv1(torch::nn::Conv2dOptions(1, 20, /*kernel_size=*/5).stride(1)),\r\n\t\tconv2(torch::nn::Conv2dOptions(20, 40, /*kernel_size=*/5)),\r\n\t\tfc1(640, 120),\r\n\t\tfc2(120, 10) {\r\n\t\tregister_module(\"conv1\", conv1);\r\n\t\tregister_module(\"conv2\", conv2);\r\n\t\tregister_module(\"conv2_drop\", conv2_drop);\r\n\t\tregister_module(\"fc1\", fc1);\r\n\t\tregister_module(\"fc2\", fc2);\r\n\t}\r\n\ttorch::Tensor forward(torch::Tensor x) {\r\n\t\tx = torch::relu(torch::max_pool2d(conv1->forward(x), 2));//(28-5)+1=24,12 x 12 x 10\r\n\t\tx = torch::relu(torch::max_pool2d(conv2_drop->forward(conv2->forward(x)), 2));//(12-5)+1=8,4 x 4 x 20\r\n\t\t//x = torch::relu(torch::avg_pool2d(conv2_drop->forward(conv2->forward(x)), 2));//(12-5)+1=8,4 x 4 x 20\r\n\r\n\t\tx = x.view({ -1, 640 });\r\n\t\tx = torch::relu(fc1->forward(x));\r\n\t\tx = torch::dropout(x, /*p=*/0.5, /*training=*/is_training());\r\n\t\tx = fc2->forward(x);\r\n\t\treturn torch::log_softmax(x, /*dim=*/1);\r\n\t}\r\n\ttorch::nn::Conv2d conv1;\r\n\ttorch::nn::Conv2d conv2;\r\n\ttorch::nn::Dropout2d conv2_drop;\r\n\ttorch::nn::Linear fc1;\r\n\ttorch::nn::Linear fc2;\r\n};\n\ncc @yf225 @houseroad @spandantiwari @lara-hdr @BowenBao @neginraoof"},{"labels":["api",null,null],"text":"## üêõ Bug\r\n\r\nUsing `torch::var_out` in the C++ API with dimnames instead of the index of the dimension seems to return the standard deviation instead of the variance.\r\n\r\n## To Reproduce\r\n\r\nRunning the following program:\r\n\r\n```\r\n#include <torch/torch.h>\r\n#include <iostream>\r\n\r\nint main() {\r\n    auto d = torch::Dimname::fromSymbol(torch::Symbol::dimname(\"a\"));\r\n    std::vector<torch::Dimname> ds;\r\n    ds.push_back(d);\r\n    \r\n    auto x = torch::rand(100, ds);\r\n    \r\n    auto y = torch::zeros(1);\r\n    torch::var_out(y, x, {0});\r\n    std::cout << y << std::endl;\r\n    \r\n    auto z = torch::zeros(1);\r\n    torch::var_out(z, x, ds);\r\n    std::cout << z << std::endl;\r\n}\r\n```\r\n\r\nReturns: \r\n\r\n```\r\n(base) dfalbel@Daniels-MacBook-Pro build % ./example-app\r\nWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (operator() at ../c10/core/TensorImpl.h:845)\r\n0.073097\r\n[ CPUFloatType{} ]\r\n0.270365\r\n[ CPUFloatType{} ]\r\n```\r\n\r\nSince:\r\n\r\n```\r\nsqrt(0.073097)\r\n[1] 0.2703646\r\n```\r\n\r\nIt seems that when using dimnames `torch_var_out` is returning the standard deviation.\r\n\r\n## Expected behavior\r\n\r\nExpected both values to be identical.\r\n\r\n## Environment\r\n\r\nI am using Pytorch C++ 1.4 - downloaded from here: https://download.pytorch.org/libtorch/cpu/libtorch-macos-1.4.0.zip on MacOS\r\n\n\ncc @yf225 @zou3519"},{"labels":["api",null],"text":"The class was explicitly designed to be two words large, we should pass it by value.\n\ncc @yf225"},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\n`torch.round` to take an optimal argument which specifies the decimal place to which rounding should occur\r\n\r\n## Pitch\r\n`torch.round` should have the same functionality as `numpy.around`. Specifying a decimal place will round _up to_ that decimal place, using the same rounding strategy as `torch.round` currently uses. The default value of the decimal parameter should be 0 to keep current behaviour.\r\nE.g.\r\n```\r\n>>> tensor = torch.tensor([0.1234, 0.1237])\r\n>>>torch.round(tensor, decimals=3)\r\ntensor([0.123, 0.124])\r\n```\r\n\r\n## Alternatives\r\nYou can use `numpy.around` on the tensor, but I assume this has some performance hit?\r\n\n\ncc @yf225"},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\n\r\nAdd the same strong wolfe line search option to the LibTorch interface as the Python counterpart.\r\n\r\nhttps://pytorch.org/docs/master/optim.html\r\n\r\n## Motivation\r\n\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\n\r\nUnify the interface between Python and C++\r\n\r\n## Pitch\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\nImplement the strong wolfe line search algorithm and add a flag to the `LBFGSOptions` struct\r\n\r\n## Alternatives\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered, if any. -->\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n\n\ncc @yf225"},{"labels":["api",null,null],"text":"in https://github.com/pytorch/pytorch/pull/33189 we switch RREf to be managed by intrusive_ptr, and we made the UserRRef/OwnerRRef public to make `c10::make_intrusive<OwnerRRef>(getWorkerId(), rrefId, type)` work since it does not support private constructor, and `intrusive_ptr<OwnerRRef>(new OwnerRRef())` does not work because of intrusive_ptr limitation. \r\n\r\nWe should figure out a way to make it private again before we announce C++ API for rpc.\n\ncc @yf225 @pietern @mrshenli @pritamdamania87 @zhaojuanmao @satgera @gqchen @aazzolini @rohan-varma @xush6528 @jjlilley @osalpekar"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nThe fractional max pooling options for output ratio need to be an expanding array of doubles.\r\ncurrently:\r\n\r\n```\r\ntemplate <size_t D>\r\nstruct FractionalMaxPoolOptions {\r\n  FractionalMaxPoolOptions(ExpandingArray<D> kernel_size)\r\n      : kernel_size_(kernel_size) {}\r\n\r\n  /// the size of the window to take a max over\r\n  TORCH_ARG(ExpandingArray<D>, kernel_size);\r\n\r\n  /// the target output size of the image\r\n  TORCH_ARG(c10::optional<ExpandingArray<D>>, output_size) = c10::nullopt;\r\n\r\n  /// If one wants to have an output size as a ratio of the input size, this option can be given.\r\n  /// This has to be a number or tuple in the range (0, 1)\r\n  TORCH_ARG(c10::optional<ExpandingArray<D>>, output_ratio) = c10::nullopt;\r\n```\r\n\r\nlater, in nn/functional/pooling.h, if no output sizes, output ratios are used:\r\n```\r\n  if (output_size_ == c10::nullopt) {\r\n    TORCH_INTERNAL_ASSERT(output_ratio != c10::nullopt);\r\n    output_size_ = {(int64_t)(input.sizes()[2] * (*output_ratio.value())[0]),\r\n                    (int64_t)(input.sizes()[3] * (*output_ratio.value())[1]),\r\n                    (int64_t)(input.sizes()[4] * (*output_ratio.value())[2])};\r\n  }\r\n```\r\n\r\nthe code compiles with integers, but won't allow for output ratios of 0.5, for example\r\n\r\n\r\n\n\ncc @yf225"},{"labels":["api",null],"text":"Achieving API parity between our Python and C++ frontend is crucial for broadening the number of language communities PyTorch can address. By the PyTorch 1.5 release, we will provide the following improvements to the PyTorch C++ frontend:\r\n\r\n**Python/C++ API Parity:**\r\n- [x] torch.nn modules and functional (tracking issue: https://github.com/pytorch/pytorch/issues/25883)\r\n  - [x] RNN (https://github.com/pytorch/pytorch/pull/34322)\r\n  - [x] LSTM (https://github.com/pytorch/pytorch/pull/34322)\r\n  - [x] GRU (https://github.com/pytorch/pytorch/pull/34322)\r\n  - [x] RNNCell (https://github.com/pytorch/pytorch/pull/34400)\r\n  - [x] LSTMCell (https://github.com/pytorch/pytorch/pull/34400)\r\n  - [x] GRUCell (https://github.com/pytorch/pytorch/pull/34400)\r\n  - [x] AdaptiveLogSoftmaxWithLoss (https://github.com/pytorch/pytorch/pull/29076)\r\n  - [x] PackedSequence (https://github.com/pytorch/pytorch/pull/33652)\r\n  - [x] pack_padded_sequence (https://github.com/pytorch/pytorch/pull/33652)\r\n  - [x] pad_packed_sequence (https://github.com/pytorch/pytorch/pull/33652)\r\n  - [x] pad_sequence (https://github.com/pytorch/pytorch/pull/33652)\r\n  - [x] pack_sequence (https://github.com/pytorch/pytorch/pull/33652)\r\n- [ ] Python/C++ API parity test for torch.nn modules and functional\r\n  - [x] Fix AdaptiveAvgPool{2,3}d and AdaptiveMaxPool{2,3}d implementation (https://github.com/pytorch/pytorch/pull/35022)\r\n  - [x] Fix Conv and ConvTranspose implementation (https://github.com/pytorch/pytorch/pull/35023)\r\n  - [x] Fix fractional_max_pool3d_with_indices implementation (https://github.com/pytorch/pytorch/pull/35024)\r\n  - [x] Fix F::interpolate and torch::nn::Upsample implementation (https://github.com/pytorch/pytorch/pull/35025)\r\n  - [x] Add inplace tests for several torch::nn modules / functionals (#35147)\r\n  - [x] Renaming: MultiLabelMarginLossFuncOptions -> MultilabelMarginLossFuncOptions, MultiLabelSoftMarginLossFuncOptions -> MultilabelSoftMarginLossFuncOptions (#35163)\r\n  - [ ] Turn on parity test (https://github.com/pytorch/pytorch/pull/35189, https://github.com/pytorch/pytorch/pull/35190)\r\n- [ ] torch.optim optimizers (tracking issue: https://github.com/pytorch/pytorch/issues/28440, make sure to test that the new design doesn't break serialization BC)\r\n- [x] tensor multi-dim indexing API\r\n  - [x] https://github.com/pytorch/pytorch/pull/32841\r\n  - [x] https://github.com/pytorch/pytorch/pull/30426\r\n  - [x] https://github.com/pytorch/pytorch/pull/30427\r\n- [x] C++ tensor autograd API (tracking issue: https://github.com/pytorch/pytorch/issues/25874). Remaining items:\r\n  - [x] grad_fn (https://github.com/pytorch/pytorch/pull/28287)\r\n  - [x] register_hook (https://github.com/pytorch/pytorch/pull/28287)\r\n  - [x] retain_grad (https://github.com/pytorch/pytorch/pull/33349)\r\n  - [x] _base (https://github.com/pytorch/pytorch/pull/33316)\r\n\r\n**Deprecation**\r\n- [x] Remove deprecated torch::nn::BatchNorm / FeatureDropout / modules_ordered_dict and torch::nn::init::Nonlinearity / FanMode (https://github.com/pytorch/pytorch/pull/34508)\r\n\r\n**Bug fixes:**\r\n- [x] Allow skipping default arguments in module's forward method when module is used in Sequential (PR: https://github.com/pytorch/pytorch/pull/33027)\r\n- [x] ModuleList compile error: error: 'begin' was not declared in this scope (Issue: https://github.com/pytorch/pytorch/issues/32414, PR: https://github.com/pytorch/pytorch/pull/34463)\r\n- [x] C++ nn::FractionalMaxPool2d/3d output_ratio option is integer, should be double (Issue: https://github.com/pytorch/pytorch/issues/33240, PR: https://github.com/pytorch/pytorch/pull/33304)\r\n- [x] Remove `using namespace torch::autograd` from header files (Issue: https://github.com/pytorch/pytorch/issues/34371. PR: https://github.com/pytorch/pytorch/pull/34423)\r\n\r\n**Docs:**\r\n- [x] For each `torch::nn` layer, document how to use `*Options` to specify options (ideally right above `torch::nn` layer doc) (https://github.com/pytorch/pytorch/pull/34522)\r\n- [x] For each `torch::nn` functional, document how to use `*Options` to specify options (ideally right above `torch::nn` functional doc) (https://github.com/pytorch/pytorch/pull/34688) (https://github.com/pytorch/pytorch/pull/34752) (ETA: 3/13)\r\n- [x] Fix torch::Tensor doc generation (Issue: https://github.com/pytorch/pytorch/issues/25845. PR: https://github.com/pytorch/pytorch/pull/34467)\r\n- [ ] How to use C++ tensor multi-dim indexing (ETA: 4/3)\r\n  - [ ] Maybe a table to show the translation between two languages\r\n\r\n**Tutorials:**\r\n- [ ] Autograd in C++ (ETA: 4/3)\r\n  - [ ] Basic autograd operations (https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html, https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_autograd.html?highlight=autograd)\r\n  - [ ] How to use C++ custom autograd function (https://pytorch.org/docs/stable/notes/extending.html#extending-torch-autograd)\r\n  - [ ] How to use `at::Tensor::register_hook`\r\n  - [ ] How to compute higher-order gradients in C++ (e.g. issue: https://github.com/pytorch/pytorch/issues/18173)\r\n\r\n**Blog post:**\r\n- [ ] C++ frontend revamp (ETA: 4/3)\r\n\r\n\r\n\r\ncc @yf225 @gchanan "},{"labels":["api",null],"text":"## üöÄ Feature\r\ncan these private _push_back_ functions be made public?\r\n\r\n```\r\n/// Adds a type-erased `AnyModule` to the `Sequential`.\r\n  void push_back(AnyModule any_module) {\r\n    push_back(c10::to_string(modules_.size()), std::move(any_module));\r\n  }\r\n\r\n  void push_back(std::string name, AnyModule any_module) {\r\n    modules_.push_back(std::move(any_module));\r\n    const auto index = modules_.size() - 1;\r\n    register_module(std::move(name), modules_[index].ptr());\r\n  }\r\n```\r\n\r\n## Motivation\r\n\r\nIf i already have an `AnyModule a`,\r\nI can't figure out how to add it to a _Sequential_ without something like\r\n`if(auto* m=a.as<torch::nn::Conv2d>()) seq->push_back<torch::nn::Conv2d>(*m)`\r\nwhich will then turn it back into an AnyModule and add it.\r\n\r\nOr making the single AnyModule into a vector:\r\n`seq->extend(std::vector<AnyModule>{a})`\r\n\r\nThanks\n\ncc @yf225"},{"labels":[null,"api",null,null],"text":"## Issue description\r\n\r\nI have downloaded the LibTorch zip from [here](https://pytorch.org/get-started/locally/). I used the 1.4 stable build for windows with CUDA 10.1 support. However the torch folder within the include directory does not contain the \"torch.h\" header file used in many [examples](https://pytorch.org/cppdocs/installing.html#minimal-example). This error comes up when I use the line:\r\n`\r\n#include <Torch/torch.h>\r\n`\r\nThe error simply says \"cannot open torch.h\".\r\n\r\nI am using Microsoft Visual Studio 2019 and I have already added the additional include and library directories. The only \"torch.h\" file I can find is at \"....\\include\\torch\\csrc\\api\\include\\torch\\torch.h\" but this does not include all of the other header files I need such as for the torch::nn::Module class etc.\r\n\r\n## System Info\r\n\r\nCollecting environment information...\r\nPyTorch version: N/A\r\nIs debug build: N/A\r\nCUDA used to build PyTorch: N/A\r\n\r\nOS: Microsoft Windows 10 Pro\r\nGCC version: (MinGW.org GCC-6.3.0-1) 6.3.0\r\nCMake version: version 3.15.0-rc2\r\n\r\nPython version: 3.6\r\nIs CUDA available: N/A\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration: GPU 0: GeForce GTX 1050 Ti\r\nNvidia driver version: 431.36\r\ncuDNN version: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin\\cudnn64_7.dll\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.14.3\r\n[pip3] numpydoc==0.8.0\r\n[conda] blas                      1.0                         mkl\r\n[conda] mkl                       2018.0.2                      1\r\n[conda] mkl-service               1.1.2            py36h57e144c_4\r\n[conda] mkl_fft                   1.0.1            py36h452e1ab_0\r\n[conda] mkl_random                1.0.1            py36h9258bd6_0\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225 @peterjc123"},{"labels":[null,"api",null,null],"text":"Currently torch::allclose() fails with\r\n`C++ exception with description \"Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead. (sub_check at ../aten/src/ATen/native/BinaryOps.h:24)`\r\non bool tensors\n\ncc @yf225 @izdeby"},{"labels":["api",null,null],"text":"```\r\n  const auto a = torch::tensor({std::numeric_limits<int64_t>::lowest() + 1}, torch::kInt64);\r\n  ASSERT_TRUE(torch::allclose(a, a)); // works\r\n\r\n  const auto b = torch::tensor({std::numeric_limits<int64_t>::lowest()}, torch::kInt64);\r\n  ASSERT_TRUE(torch::allclose(b, b)); // does not\r\n```\n\ncc @yf225"},{"labels":[null,"api",null,null],"text":"## üöÄ Feature\r\n\r\nThe `at::Tensor` datatype does not have `&` overloaded the way it is in the python API, thus not allowing for boolean element-wise operations between tensors.\r\n\r\n## Motivation\r\n\r\nI want to call the `at::where()` function with a boolean tensor that is the outcome of the AND of two conditions.\r\n\r\n## Pitch\r\n\r\nSomething like this should be possible:\r\n``` c++\r\n  auto output = at::where((target > -EPSILON) & (target < EPSILON), all_zeros, whatever_values);\r\n```\r\n## Alternatives\r\n\r\nThis is ugly and tedious IMO:\r\n\r\n``` c++\r\n  auto output = at::where(target > -EPSILON, output_pos, zeros);\r\n  output = at::where(output < EPSILON, zeros, output_pos);\r\n```\r\n\n\ncc @yf225"},{"labels":["api",null,null,null,null],"text":"## üêõ Bug\r\n\r\nThe `MagmaInitializesCorrectly_CUDA` test case in `test/cpp/api/tensor_cuda.cpp` fails with the following error:\r\n\r\n```\r\n[0;32m[ RUN      ] #[mTensorTest.MagmaInitializesCorrectly_CUDA\r\nunknown file: Failure\r\nC++ exception with description \"inverse_cuda: U(4,4) is zero, singular U. (singleCheckErrors at /home/jenkins/pytorch/aten/src/ATen/native/LinearAlgebraUtils.h:138)\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xc0 (0x1000135086a0 in /home/jenkins/pytorch/build/lib/libc10.so)\r\nframe #1: <unknown function> + 0x1550eb0 (0x1000058e0eb0 in /home/jenkins/pytorch/build/lib/libtorch_cuda.so)\r\nframe #2: at::native::_inverse_helper_cuda(at::Tensor const&) + 0x9bc (0x1000058e8c1c in /home/jenkins/pytorch/build/lib/libtorch_cuda.so)\r\nframe #3: <unknown function> + 0x3072224 (0x100007402224 in /home/jenkins/pytorch/build/lib/libtorch_cuda.so)\r\nframe #4: <unknown function> + 0xec6f20 (0x100000f46f20 in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #5: at::native::inverse(at::Tensor const&) + 0x14c (0x1000009f53fc in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #6: <unknown function> + 0xf9b674 (0x10000101b674 in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #7: <unknown function> + 0xec6f20 (0x100000f46f20 in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #8: at::Tensor c10::Dispatcher::callUnboxed<at::Tensor, at::Tensor const&>(c10::OperatorHandle const&, at::Tensor const&) const + 0xd4 (0x10f009ef4 in build/bin/test_api)\r\nframe #9: <unknown function> + 0x2aabffc (0x100002b2bffc in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #10: <unknown function> + 0xec6f20 (0x100000f46f20 in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #11: TensorTest_MagmaInitializesCorrectly_CUDA_Test::TestBody() + 0x804 (0x10f398de4 in build/bin/test_api)\r\nframe #12: void testing::internal::HandleExceptionsInMethodIfSupported<testing::Test, void>(testing::Test*, void (testing::Test::*)(), char const*) + 0x78 (0x10f45de48 in build/bin/test_api)\r\nframe #13: <unknown function> + 0x880774 (0x10f450774 in build/bin/test_api)\r\nframe #14: <unknown function> + 0x880cb4 (0x10f450cb4 in build/bin/test_api)\r\nframe #15: <unknown function> + 0x881174 (0x10f451174 in build/bin/test_api)\r\nframe #16: testing::internal::UnitTestImpl::RunAllTests() + 0xeac (0x10f45252c in build/bin/test_api)\r\nframe #17: testing::UnitTest::Run() + 0xb8 (0x10f452938 in build/bin/test_api)\r\nframe #18: main + 0x108 (0x10edc25e8 in build/bin/test_api)\r\nframe #19: <unknown function> + 0x2441c (0x1000139f441c in /lib/powerpc64le-linux-gnu/libc.so.6)\r\nframe #20: __libc_start_main + 0xb8 (0x1000139f4618 in /lib/powerpc64le-linux-gnu/libc.so.6)\r\n\" thrown in the test body.\r\n#[0;31m[  FAILED  ] #[mTensorTest.MagmaInitializesCorrectly_CUDA (288 ms)\r\n```\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Build PyTorch from source, and make sure to build the cpp API tests along with it\r\n2. Run the `tensor_cuda.cpp` tests (probably with `test_api` in the `build/bin` directory)\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nThe test should pass\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): master\r\n - OS (e.g., Linux): RHEL\r\n - How you installed PyTorch (`conda`, `pip`, source): source\r\n - Build command you used (if compiling from source): `python setup.py install`\r\n - Python version: `3.6`\r\n - CUDA/cuDNN version: 10.2\r\n - GPU models and configuration: 4x Tesla V100\r\n - Any other relevant information: Ran on Power architecture\r\n\r\n## Aditional Information\r\n\r\nI've submitted a PR to fix this here: https://github.com/pytorch/pytorch/pull/32547\r\n\n\ncc @yf225 @ngimel"},{"labels":[null,null,null,"api",null],"text":"## üêõ Bug\r\nUse PyTorch model in C++, compilation breaks when using the default route.\r\nCMake `find_package(Torch REQUIRED)` \r\n\r\nreturns corrupted `TORCH_LIBRARIES` list\r\n\r\n```\r\ntorch\r\ntorch_library\r\n/usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so\r\n/usr/local/cuda/lib64/stubs/libcuda.so\r\n/usr/local/cuda/lib64/libnvrtc.so\r\n/usr/local/cuda/lib64/libnvToolsExt.so\r\n/usr/local/cuda/lib64/libcudart.so\r\n/usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so\r\n```\r\n\r\nIt should not contain absolute paths to the other libraries but rather the lib names.\r\nThe library paths should be added to the environment if necessary\r\n\r\n## Solution\r\n\r\nInstead of \r\n\r\n`target_link_libraries(MyTARGET PUBLIC ${TORCH_LIBRARIES})`\r\n\r\ndo\r\n\r\n```\r\nlink_directories(/usr/local/lib/python3.6/dist-packages/torch/lib/)\r\nlink_directories(/usr/local/cuda/lib64/)\r\nlink_directories(/usr/local/cuda/lib64/stubs)\r\n\r\ntarget_link_libraries(MyTARGET PUBLIC torch torch_library libc10.so libcuda.so libnvrtc.so libnvToolsExt.so libcudart.so libc10_cuda.so)\r\n```\r\n\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Create `CMakeLists.txt`\r\n2.`find_package(Torch REQUIRED)`\r\n3. `message(\"TORCH LIBS ${TORCH_LIBRARIES}\")`\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nReturns linker errors as `c10` can not be found\r\n\r\n```\r\n/usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Backend.h:107: undefined reference to `c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\r\nSunlightNoiseClassifier/libSunlightNoiseClassifier.a(SunlightNoiseClassifier.cpp.o): In function `c10::backendToDeviceType(c10::Backend)':\r\n```\r\n\r\n## Environment\r\n\r\n```\r\ncmake version 3.5.1\r\n\r\npython collect_env.py \r\nCollecting environment information...\r\nPyTorch version: N/A\r\nIs debug build: N/A\r\nCUDA used to build PyTorch: N/A\r\n\r\nOS: Ubuntu 16.04.3 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 2.7\r\nIs CUDA available: N/A\r\nCUDA runtime version: 9.2.148\r\nGPU models and configuration: Could not collect\r\nNvidia driver version: Could not collect\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] msgpack-numpy==0.4.4.2\r\n[pip] numpy==1.16.4\r\n[pip] torch==1.2.0\r\n[pip] torchvision==0.4.0\r\n[conda] Could not collect\r\n```\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nCode crashes in C++ API when torch tensor is read from specific buffer\r\n\r\n## To Reproduce\r\n\r\nbuild and run this code in release build\r\n\r\n```c++\r\n#include <iostream>\r\n#include <torch/extension.h>\r\n\r\nint main() {\r\n    std::string buffer;\r\n    buffer.resize((1 << 19) + 128);\r\n    std::memset(buffer.data(), 0, buffer.size());\r\n    size_t start_offset;\r\n    // This would work fine\r\n    start_offset = 1 << 10;\r\n    // This crashes\r\n    start_offset = (1 << 10) - 1;\r\n    size_t element_count = 319;\r\n    std::cerr << buffer.size() << \" vs \" << torch::elementSize(torch::kInt32) * element_count + start_offset;\r\n    auto tensor = torch::from_blob(buffer.data() + start_offset, {element_count}, torch::CPU(torch::kInt32));\r\n    tensor.clone();\r\n}\r\n```\r\n\r\n```cmake\r\ncmake_minimum_required(VERSION 3.12)\r\nproject(from_blob_sigsegv)\r\n\r\n\r\nset(CMAKE_CXX_STANDARD 17)\r\nset(CMAKE_PREFIX_PATH /home/alxmopo3ov/libtorch)\r\n\r\nfind_package(Torch REQUIRED)\r\ninclude_directories(${TORCH_INCLUDE_DIRS})\r\nfind_package(Python3 COMPONENTS Interpreter Development)\r\ninclude_directories(${Python3_INCLUDE_DIRS})\r\n\r\nadd_executable(from_blob_sigsegv main.cpp)\r\ntarget_link_libraries(from_blob_sigsegv ${Python3_LIBRARIES} ${TORCH_LIBRARIES})\r\n```\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nDon't crash\r\n\r\n## Environment\r\n\r\nCollecting environment information...\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 14.04.6 LTS\r\nGCC version: (Ubuntu 7.4.0-1ubuntu1~14.04~ppa1) 7.4.0\r\nCMake version: version 3.12.2\r\n\r\nPython version: 3.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.15.1\r\n[pip3] numpydoc==0.8.0\r\n[pip3] torch==1.4.0\r\n[pip3] torchvision==0.2.1\r\n[conda] blas                      1.0                         mkl  \r\n[conda] mkl                       2019.0                      118  \r\n[conda] mkl-service               1.1.2            py37h90e4bf4_5  \r\n[conda] mkl_fft                   1.0.4            py37h4414c95_1  \r\n[conda] mkl_random                1.0.1            py37h4414c95_1  \r\n[conda] torch                     1.4.0                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\n\ncc @yf225"},{"labels":["api",null,null],"text":"## üöÄ Feature\r\n\r\nDistributedStreamSampler: support stream sampler in distributed setting\r\n\r\n## Motivation\r\n\r\nA new class `torch::data::samplers::DistributedStreamSampler` both works in distributed setting like `torch::data::samplers::DistributedSequentialSampler` and works with `torch::data::datasets::StreamDataset` like `torch::data::samplers::StreamSampler`.\r\n\r\n## Pitch\r\n\r\nworks with StreamDataset in distributed setting.\r\n\r\n## Alternatives\r\n\r\nimplement this by user\r\n\r\n## Additional context\r\n\r\nnone\r\n\n\ncc @yf225 @pietern @mrshenli @pritamdamania87 @zhaojuanmao @satgera @rohan-varma @gqchen @aazzolini @xush6528 @osalpekar"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nThe example for ModuleList found in the documentation [here](https://pytorch.org/cppdocs/api/classtorch_1_1nn_1_1_module_list_impl.html#_CPPv4N5torch2nn14ModuleListImplE) does not seem to compile.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nAttempt to compile the following source on GCC 7.4, taken from the documentation:\r\n\r\n```cpp\r\n#include <torch/torch.h>\r\n\r\nint main() {\r\n\r\n  torch::nn::ModuleList mlist(\r\n    torch::nn::Linear(3, 4),\r\n    torch::nn::BatchNorm(4),\r\n    torch::nn::Dropout(0.5)\r\n  );\r\n\r\n  for (const auto &module : mlist) {\r\n    module.pretty_print();\r\n}\r\n```\r\n\r\nCompile error:\r\n```\r\nC++ compilation of rule '//src/learning:pytorch' failed (Exit 1) gcc failed: error executing command /usr\r\n/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 38 argument(s) skipped)\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\nsrc/learning/pytorch_test.cpp: In function 'int main()':\r\nsrc/learning/pytorch_test.cpp:12:29: error: 'begin' was not declared in this scope\r\n   for (const auto &module : mlist) {\r\n                             ^~~~~\r\nsrc/learning/pytorch_test.cpp:12:29: note: suggested alternative:\r\nIn file included from /usr/include/c++/7/string:51:0,\r\n                 from /usr/include/c++/7/stdexcept:39,\r\n                 from /usr/include/c++/7/array:39,\r\n                 from /usr/include/c++/7/tuple:39,\r\n                 from /usr/include/c++/7/bits/unique_ptr.h:37,\r\n                 from /usr/include/c++/7/memory:80,\r\n                 from external/pytorch/libtorch/include/c10/core/Allocator.h:4,\r\n                 from external/pytorch/libtorch/include/ATen/ATen.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/types.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/all.h:4,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/torch.h:3,\r\n                 from src/learning/pytorch_test.cpp:1:\r\n/usr/include/c++/7/bits/range_access.h:105:37: note:   'std::begin'\r\n   template<typename _Tp> const _Tp* begin(const valarray<_Tp>&);\r\n                                     ^~~~~\r\nsrc/learning/pytorch_test.cpp:12:29: error: 'end' was not declared in this scope\r\n   for (const auto &module : mlist) {\r\n                             ^~~~~\r\nsrc/learning/pytorch_test.cpp:12:29: note: suggested alternatives:\r\nIn file included from /usr/include/c++/7/string:51:0,\r\n                 from /usr/include/c++/7/stdexcept:39,\r\n                 from /usr/include/c++/7/array:39,\r\n                 from /usr/include/c++/7/tuple:39,\r\n                 from /usr/include/c++/7/bits/unique_ptr.h:37,\r\n                 from /usr/include/c++/7/memory:80,\r\n                 from external/pytorch/libtorch/include/c10/core/Allocator.h:4,\r\n                 from external/pytorch/libtorch/include/ATen/ATen.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/types.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/all.h:4,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/torch.h:3,\r\n                 from src/learning/pytorch_test.cpp:1:\r\n/usr/include/c++/7/bits/range_access.h:107:37: note:   'std::end'\r\n   template<typename _Tp> const _Tp* end(const valarray<_Tp>&);\r\n                                     ^~~\r\nIn file included from external/pytorch/libtorch/include/ATen/core/Dimname.h:5:0,\r\n                 from external/pytorch/libtorch/include/ATen/core/NamedTensor.h:4,\r\n                 from external/pytorch/libtorch/include/ATen/core/TensorBody.h:20,\r\n                 from external/pytorch/libtorch/include/ATen/Tensor.h:11,\r\n                 from external/pytorch/libtorch/include/ATen/Context.h:4,\r\n                 from external/pytorch/libtorch/include/ATen/ATen.h:5,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/types.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/data.h:3,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/all.h:4,\r\n                 from external/pytorch/libtorch/include/torch/csrc/api/include/torch/torch.h:3,\r\n                 from src/learning/pytorch_test.cpp:1:\r\nexternal/pytorch/libtorch/include/ATen/core/interned_strings.h:374:1: note:   'c10::attr::end'\r\n FORALL_NS_SYMBOLS(DEFINE_SYMBOL)\r\n ^\r\nexternal/pytorch/libtorch/include/ATen/core/interned_strings.h:374:1: note:   'c10::attr::end'\r\nsrc/learning/pytorch_test.cpp:14:1: error: expected '}' at end of input\r\n }\r\n```\r\n\r\n \r\n## Expected behavior\r\n\r\nI believe this should pretty print the submodules...\r\n\r\n## Environment\r\n\r\n - GCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n - PyTorch Version (e.g., 1.0): 1.4\r\n - OS (e.g., Linux): Ubuntu 18.04.1 LTS\r\n - How you installed PyTorch (`conda`, `pip`, source): Linux CPU-only binary\r\n - Build command you used (if compiling from source): n/a\r\n - Python version: n/a\r\n - CUDA/cuDNN version: n/a\r\n - GPU models and configuration: n/a\r\n - Any other relevant information: Using GCC 7 via Bazel (see trace above for full compile flags)\r\n\r\n## Additional context\r\n\r\nAlso, is there way to initialize an empty ModuleList an do operations on it? If I try to push_back on an empty ModuleList I get ```  what():  Accessing empty ModuleHolder (get at external/pytorch/libtorch/include/torch/csrc/api/include/torch/nn/pimpl.h:107)``` which makes it not so useful for my use-case of creating variable sized networks at runtime. \n\ncc @yf225"},{"labels":["api",null,null],"text":"## üìö Documentation\r\n\r\nCurrently, PyTorch C++ API docs (https://pytorch.org/cppdocs/) only tracks the master branch. Ideally we should add PyTorch version selector into it, similar to the Python API docs (https://pytorch.org/docs/stable/index.html).\r\n\n\ncc @yf225 @ezyang @zou3519"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nIn Python, we have the following behavior:\r\n```python\r\n>>> torch.set_default_dtype(torch.double)\r\n>>> a = 1.1\r\n>>> t = torch.tensor([a, a])\r\n>>> t.dtype\r\ntorch.float64\r\n```\r\n\r\nHowever, currently in C++, we have the following behavior:\r\n```cpp\r\ntorch::set_default_dtype(torch::scalarTypeToTypeMeta(torch::kDouble));\r\nfloat a = 1.1;\r\ntorch::tensor({a, a}).dtype()  // prints: float\r\n```\r\n\r\nWe should fix the C++ API behavior (by returning a double tensor instead of a float tensor in the above case), to match the Python API.\r\n\r\ncc @yf225"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nThis has come up before, issue #14079 and pr #11040\r\n\r\nIt looks like the python side was fixed to return longs (but documentation still has: \"_dtype (torch.dtype, optional) ‚Äì the desired data type of returned tensor. Default: if None, uses a global default_\")\r\n\r\n## To Reproduce\r\n\r\n```\r\n>>> import torch\r\n>>> torch.randint(10,(3,)).dtype\r\ntorch.int64\r\n```\r\n```\r\nstd::cerr << torch::randint(10,{3}) << \"\\n\";\r\n 5\r\n 0\r\n 9\r\n[ CPUFloatType{3} ]\r\n```\r\n\r\n## Expected behavior\r\n\r\nBoth behaviours are reasonable, but I guess I would expect the c++ implementation to match python.\n\ncc @yf225"},{"labels":["api",null],"text":"Please improve the error prompt for libtorch.\r\n0x00007FFF9026A839 Â§Ñ(‰Ωç‰∫é ConsoleApplication1.exe ‰∏≠)ÂºïÂèëÁöÑÂºÇÂ∏∏: Microsoft C++ ÂºÇÂ∏∏: c10::ErrorÔºå‰Ωç‰∫éÂÜÖÂ≠ò‰ΩçÁΩÆ 0x0000002C2A9AF7F0 Â§Ñ„ÄÇ\r\n0x00007FFF9026A839 Â§Ñ(‰Ωç‰∫é ConsoleApplication1.exe ‰∏≠)ÊúâÊú™ÁªèÂ§ÑÁêÜÁöÑÂºÇÂ∏∏: Microsoft C++ ÂºÇÂ∏∏: c10::ErrorÔºå‰Ωç‰∫éÂÜÖÂ≠ò‰ΩçÁΩÆ 0x0000002C2A9AF7F0 Â§Ñ„ÄÇ\r\n-----------------------------------------------------------\r\nwin10 x64,libtorch 1.3.1 version release no gpu, 2020.01.13\r\n----------------------------------------------------------\r\n#include \"torch/torch.h\"\r\n#include <iostream>\r\n\r\nstruct Net : torch::nn::Module {\r\n\tNet() {\r\n\t\t// Construct and register two Linear submodules.\r\n\t\tfc1 = register_module(\"fc1\", torch::nn::Linear(784, 64));\r\n\t\tfc2 = register_module(\"fc2\", torch::nn::Linear(64, 32));\r\n\t\tfc3 = register_module(\"fc3\", torch::nn::Linear(32, 10));\r\n\t}\r\n\r\n\t// Implement the Net's algorithm.\r\n\ttorch::Tensor forward(torch::Tensor x) {\r\n\t\t// Use one of many tensor manipulation functions.\r\n\t\tx = torch::relu(fc1->forward(x.reshape({ x.size(0), 784 })));\r\n\t\tx = torch::dropout(x, /*p=*/0.5, /*train=*/is_training());\r\n\t\tx = torch::relu(fc2->forward(x));\r\n\t\tx = torch::log_softmax(fc3->forward(x), /*dim=*/1);\r\n\t\treturn x;\r\n\t}\r\n\r\n\t// Use one of many \"standard library\" modules.\r\n\ttorch::nn::Linear fc1{ nullptr }, fc2{ nullptr }, fc3{ nullptr };\r\n\r\n};\r\n\r\nint main() {\r\n\t// Create a new Net.\r\n\tauto net = std::make_shared<Net>();\r\n\r\n\t// Create a multi-threaded data loader for the MNIST dataset.\r\n\tauto data_loader = torch::data::make_data_loader(\r\n\t\ttorch::data::datasets::MNIST(\"./data\").map(\r\n\t\t\ttorch::data::transforms::Stack<>()),\r\n\t\t/*batch_size=*/64);\r\n\r\n\t// Instantiate an SGD optimization algorithm to update our Net's parameters.\r\n\ttorch::optim::SGD optimizer(net->parameters(), /*lr=*/0.01);\r\n\r\n\tfor (size_t epoch = 1; epoch <= 10; ++epoch) {\r\n\t\tsize_t batch_index = 0;\r\n\t\t// Iterate the data loader to yield batches from the dataset.\r\n\t\tfor (auto& batch : *data_loader) {\r\n\t\t\t// Reset gradients.\r\n\t\t\toptimizer.zero_grad();\r\n\t\t\t// Execute the model on the input data.\r\n\t\t\ttorch::Tensor prediction = net->forward(batch.data);\r\n\t\t\t// Compute a loss value to judge the prediction of our model.\r\n\t\t\ttorch::Tensor loss = torch::nll_loss(prediction, batch.target);\r\n\t\t\t// Compute gradients of the loss w.r.t. the parameters of our model.\r\n\t\t\tloss.backward();\r\n\t\t\t// Update the parameters based on the calculated gradients.\r\n\t\t\toptimizer.step();\r\n\t\t\t// Output the loss and checkpoint every 100 batches.\r\n\t\t\tif (++batch_index % 100 == 0) {\r\n\t\t\t\tstd::cout << \"Epoch: \" << epoch << \" | Batch: \" << batch_index\r\n\t\t\t\t\t<< \" | Loss: \" << loss.item<float>() << std::endl;\r\n\t\t\t\t// Serialize your model periodically as a checkpoint.\r\n\t\t\t\ttorch::save(net, \"net.pt\");\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n\n\ncc @yf225"},{"labels":["api",null,null],"text":"## üêõ Bug\r\n\r\nnightly Pytorch cannot compile cpp extension\r\n\r\n## To Reproduce\r\n\r\nExtension [here](https://pytorch.org/tutorials/advanced/cpp_extension.html#writing-a-mixed-c-cuda-extension) defines:\r\n\r\n```c++\r\n#define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n```\r\n\r\nresults in deprecation:\r\n\r\n```text\r\n\r\nwarning: ‚Äòat::DeprecatedTypeProperties& at::Tensor::type() const‚Äô is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement\r\n\r\n```\r\n\r\nbut there is no `is_cuda` in `options` struct.\r\nThe fix was to call `x.is_cuda()` directly, which is nicer.\r\n\r\n```c++\r\n#define CHECK_CUDA(x) TORCH_CHECK(x.is_cuda(), #x \" must be a CUDA tensor\")\r\n```\r\n\r\n## Expected behavior\r\n\r\nExamples to be tested\r\n\r\n## Environment\r\n\r\nCollecting environment information...\r\nPyTorch version: 1.5.0.dev20200113\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.0\r\n\r\nOS: Ubuntu 16.04.6 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce GTX 1070\r\nNvidia driver version: 418.87.01\r\ncuDNN version: /usr/local/lib/libcudnn.so.5.1.10\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.17.4\r\n[pip] torch==1.5.0.dev20200113\r\n[pip] torchvision==0.5.0a0+e50d746\r\n[conda] blas                      1.0                         mkl\r\n[conda] mkl                       2019.4                      243\r\n[conda] mkl-service               2.3.0            py36he904b0f_0\r\n[conda] mkl_fft                   1.0.15           py36ha843d7b_0\r\n[conda] mkl_random                1.1.0            py36hd6b4f25_0\r\n[conda] pytorch                   1.5.0.dev20200113 py3.6_cuda10.0.130_cudnn7.6.3_0    pytorch-nightly\r\n[conda] torchvision               0.5.0.dev20200113      py36_cu100    pytorch-nightly\r\n\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @yf225"},{"labels":[null,"api",null,null],"text":"A C++ extension calling backward() on a tensor hangs when called from python.\r\n\r\nI've posted this same issue with some back tracing [in the forum](https://discuss.pytorch.org/t/tensor-backward-called-within-c-extension-hangs/65473).\r\n\r\n## To Reproduce\r\nHere is the basic extension, following the tutorial on C++/CUDA extensions. I get the same issue if I install the extension via `load_inline`.\r\n\r\n1. Source `diff.cpp`\r\n```cpp\r\n#include <torch/extension.h>\r\n\r\nvoid backw(torch::Tensor tens) {\r\n    tens.backward({}, true, true);\r\n}\r\n\r\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\r\n    m.def(\"backw\", &backw, \"DIFF backw\");\r\n}\r\n```\r\n\r\n2. `setup.py` file\r\n```python\r\nfrom setuptools import setup, Extension\r\nfrom torch.utils import cpp_extension\r\n\r\nsetup(name='diff_cpp',\r\n      ext_modules=[cpp_extension.CppExtension('diff_cpp', ['diff.cpp'])],\r\n      cmdclass={'build_ext': cpp_extension.BuildExtension})\r\n```\r\n\r\n3. Install via `python setup.py install`\r\nThe installation proceeds without error, and the extension can subsequently be installed as `diff_cpp`. The following test script hangs at the last line:\r\n```python\r\nimport torch\r\nimport diff_cpp    # fine\r\nx = torch.tensor([1.0, 2.0], requires_grad=True)\r\ny = torch.sum(x)\r\ndiff_cpp.backw(y)  # hangs\r\n```\r\n\r\n## Environment\r\nI have so far tried this on two machines in multiple configurations, each time inside a fresh `python -m venv env` virtual environment and installing pytorch using pip.\r\n- python 3.7, torch 1.3.1, CPU\r\n- python 3.6, torch 1.3.1, CUDA 10.1\r\n- python 3.6, nightly, CUDA 10.1\r\n\r\nHere are the details of one of the environments I've tried this on:\r\n```\r\nPyTorch version: 1.3.1+cpu\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Arch Linux\r\nGCC version: (GCC) 9.2.0\r\nCMake version: version 3.16.2\r\n\r\nPython version: 3.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.0\r\n[pip3] torch==1.3.1+cpu\r\n[pip3] torchvision==0.4.2+cpu\r\n[conda] Could not collect\r\n```\r\n\n\ncc @ezyang @SsnL @albanD @zou3519 @gqchen @yf225"},{"labels":[null,"api",null],"text":"Hi,guys, i am a newer for pytorch and libtorch, and i want to compile the libtorch by source official code,but there are some problem happened.I compile the source official code by  this(https://github.com/pytorch/pytorch/blob/master/docs/libtorch.rst) guide directly(i don't compile the pytorch),but the problem happened like this:\r\n[2066/2066] Install the project...\r\n-- Install configuration: \"Release\"\r\nCMake Error at third_party/protobuf/cmake/cmake_install.cmake:48 (file):\r\n  file INSTALL cannot find\r\n  \"/home/cyj/Documents/pytorch-test/build_libtorch/build/third_party/protobuf/cmake/CMakeFiles/CMakeRelink.dir/protoc\".\r\nCall Stack (most recent call first):\r\n  cmake_install.cmake:80 (include)\r\n  \r\nFAILED: cd /home/cyj/Documents/pytorch-test/build_libtorch/build && /usr/bin/cmake -P cmake_install.cmake\r\nninja: build stopped: subcommand failed.\r\nTraceback (most recent call last):\r\n  File \"../tools/build_libtorch.py\", line 23, in <module>\r\n    rerun_cmake=True, cmake_only=False, cmake=CMake())\r\n  File \"/home/cyj/Documents/pytorch-test/tools/build_pytorch_libs.py\", line 62, in build_caffe2\r\n    cmake.build(my_env)\r\n  File \"/home/cyj/Documents/pytorch-test/tools/setup_helpers/cmake.py\", line 339, in build\r\n    self.run(build_args, my_env)\r\n  File \"/home/cyj/Documents/pytorch-test/tools/setup_helpers/cmake.py\", line 141, in run\r\n    check_call(command, cwd=self.build_dir, env=env)\r\n  File \"/usr/lib/python3.5/subprocess.py\", line 581, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', 'install', '--config', 'Release', '--', '-j', '8']' returned non-zero exit status 1\r\nI want to know the reason why i met such problem,Does any deploy i have not set? I just follow the official guide!My environment is ubuntu16.04 cuda10.0 gcc 5.4.0 cmake 3.5.1,the source code is newest.Hope for help,tkx.\n\ncc @ezyang @yf225"},{"labels":[null,"api",null],"text":"## üöÄ Feature\r\nThe `setup.py` should emit the CPP version being used for the compilation along with things like `USE_CUDA`, etc. \r\n\r\n## Motivation\r\n\r\nI recently ran into an issue where I got an error stating that pytorch requires atleast C++14 for compilation. Although I managed to compile pytorch after some changes, it was hard to figure out how exactly it is being compiled since I had to browse the compilation output to check the `-std=c++14` flag being passed to gcc.\r\n\r\n## Pitch\r\n\r\nThere should be a `CPP_VERSION: <version number>` in the compilation summary.\r\n\r\n## Alternatives\r\n\r\nMaybe output the library versions used in some text file for easy reference.\r\n\n\ncc @yf225"},{"labels":[null,"api",null,null],"text":"## üöÄ Feature\r\nParallelization: more balanced work distribution among workers\r\n\r\n## Motivation\r\n\r\nI recently checked the code for `at::parallel_for` method and this is what I observed.\r\nSuppose there are `N` indices and `T` workers, then worker `i (0 <= i < T)` receives\r\nindices `[i * ceil(N/T), min(N, (i+1) * ceil(N/T)) )`.\r\n\r\nNow, suppose `N=10, T=4`, then this scheme will have the following distribution : `3|3|3|1`.\r\nDefinitely, something like `3|3|2|2` looks better. The issues is that the current approach is biased against the last worker(s) - it (them) always receive(s) the least work, which **could be even zero**. To elaborate, the whole situation becomes even worse if, for example, `N=100, T=40`. Then work of size 3 is scheduled for each worker, meaning that only 34 workers are going to do something useful, while 6 workers do nothing. And, in general, the situation gets worse if the number of workers scales up with the size of an input.\r\n\r\n## Pitch\r\nWhat about a slightly different distribution? This one **uses all the workers**!\r\nFor a worker `i: 0 <= i < T` let\r\n```\r\nbegin(i) = ceil(N*i/T),\r\nend(i) = begin(i+1),\r\n```\r\nand the worker receives indices `[begin(i), end(i) )`\r\n\r\nIt can be shown that for any `N >= T >= 1`, any `i,j: 0 <= i,j < T`:\r\n```\r\n|(end(i) - begin(i)) - (end(j) - begin(j))| <= 1, \r\nend(i) - begin(i) >= 1, begin(i) < N,\r\n```\r\nso this new scheme is optimally balanced, and each worker will do at least something!\r\n\r\nThe only issue I see is a more likely chance of overflow in computing `begin`\r\n\r\ncc @yf225 @pietern @mrshenli @pritamdamania87 @zhaojuanmao @satgera @rohan-varma @gqchen @aazzolini @xush6528"},{"labels":[null,"api",null,null],"text":"## üêõ Bug\r\n\r\nIt looks like the modules attempt to register undefined tensors without turning off _requires_grad_ and cause a warning when _affine=false_  (default condition for InstanceNorm)\r\n\r\n## To Reproduce\r\n```\r\ntorch::nn::InstanceNorm2d m(64);\r\n\r\nWarning: An undefined tensor cannot require grad. Ignoring the `requires_grad=true` function parameter. (register_parameter at /pytorch/torch/csrc/api/src/nn/module.cpp:316)\r\n```\r\n## Expected behavior\r\n\r\nThere's logic in _nn/modules/batchnorm.h_ that checks the value of affine before attempting to register weight & bias:\r\n```\r\nvoid reset() override {\r\n    if (options.affine()) {\r\n      weight = this->register_parameter(\"weight\", torch::empty({options.num_features()}));\r\n      bias = this->register_parameter(\"bias\", torch::empty({options.num_features()}));\r\n    } else {\r\n      weight = this->register_parameter(\"weight\", Tensor());\r\n      bias = this->register_parameter(\"bias\", Tensor());\r\n    }\r\n```\r\nWhen _affine_ is false, I think the 3rd arg to _register_parameter_ should be false to turn off _requires_grad_ property, or perhaps these parameters need not be registered at all..?\r\n\n\ncc @ezyang @SsnL @albanD @zou3519 @gqchen @yf225"},{"labels":["api",null],"text":"I have notice that `batchnorm.h` in macOS is not the same as the Linux's version.\r\n\r\nIn macOS version, the `batchnorm.h` is \r\n\r\n```\r\n#pragma once\r\n\r\n#include <torch/nn/cloneable.h>\r\n#include <torch/nn/options/batchnorm.h>\r\n#include <torch/nn/pimpl.h>\r\n#include <torch/types.h>\r\n\r\n#include <cstdint>\r\n\r\nnamespace torch {\r\nnamespace nn {\r\n\r\n/// Applies [Batch Normalization](https://arxiv.org/abs/1502.03167) to an input.\r\n///\r\n/// Refer to the documentation for\r\n/// [`BatchNorm1d`](https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm1d)\r\n/// in PyTorch to learn more about the exact semantics of this module, __but see\r\n/// the note below regarding differences between the Python and C++ API__.\r\n///\r\n/// \\rst\r\n/// .. attention::\r\n///   In the Python API, there are separate implementations for 1-D, 2-D and 3-D\r\n///   BatchNorm. In C++, there is only one `BatchNorm` module, which works for\r\n///   any of these dimensions.\r\n/// \\endrst\r\nclass TORCH_API BatchNormImpl : public torch::nn::Cloneable<BatchNormImpl> {\r\n public:\r\n  explicit BatchNormImpl(int64_t features)\r\n      : BatchNormImpl(BatchNormOptions(features)) {}\r\n  explicit BatchNormImpl(const BatchNormOptions& options_);\r\n\r\n  void reset() override;\r\n\r\n  /// Pretty prints the `BatchNorm` module into the given `stream`.\r\n  void pretty_print(std::ostream& stream) const override;\r\n\r\n  /// Applies batch normalization on the `input` using the stored mean and\r\n  /// variance.\r\n  ///\r\n  /// The module must be constructed with `stateful = true` when calling this\r\n  /// method, as the module will otherwise not store running statistics. If you\r\n  /// want to supply the mean and variance yourself, use `pure_forward`.\r\n  Tensor forward(const Tensor& input);\r\n\r\n  /// Applies batch normalization on the `input` using the given `mean` and\r\n  /// `variance` statistics.\r\n  Tensor pure_forward(\r\n      const Tensor& input,\r\n      const Tensor& mean,\r\n      const Tensor& variance);\r\n\r\n  /// The options with which this module was constructed.\r\n  BatchNormOptions options;\r\n\r\n  /// The learned weight.\r\n  /// Only defined if the `affine` option was `true` upon construction.\r\n  Tensor weight;\r\n\r\n  /// The learned bias.\r\n  /// Only defined if the `affine` option was `true` upon construction.\r\n  Tensor bias;\r\n\r\n  /// The running mean.\r\n  /// Only defined if the `stateful` option was `true` upon construction.\r\n  Tensor running_mean;\r\n\r\n  /// The running variance.\r\n  /// Only defined if the `stateful` option was `true` upon construction.\r\n  Tensor running_var;\r\n};\r\n\r\n/// A `ModuleHolder` subclass for `BatchNormImpl`.\r\n/// See the documentation for `BatchNormImpl` class to learn what methods it\r\n/// provides, or the documentation for `ModuleHolder` to learn about PyTorch's\r\n/// module storage semantics.\r\nTORCH_MODULE(BatchNorm);\r\n\r\n} // namespace nn\r\n} // namespace torch\r\n\r\n```\r\n\r\nBut in the Linux's version seems having more contents than macOS's version.\r\n```\r\n#pragma once\r\n\r\n#include <torch/arg.h>\r\n#include <torch/csrc/WindowsTorchApiMacro.h>\r\n#include <torch/nn/options/common.h>\r\n#include <torch/types.h>\r\n\r\nnamespace torch {\r\nnamespace nn {\r\n\r\n/// Options for the `BatchNorm` module.\r\nstruct TORCH_API BatchNormOptions {\r\n  /* implicit */ BatchNormOptions(int64_t num_features);\r\n\r\n  /// The number of features of the input tensor.\r\n  /// Changing this parameter after construction __has no effect__.\r\n  TORCH_ARG(int64_t, num_features);\r\n\r\n  /// The epsilon value added for numerical stability.\r\n  /// Changing this parameter after construction __is effective__.\r\n  TORCH_ARG(double, eps) = 1e-5;\r\n\r\n  /// A momentum multiplier for the mean and variance.\r\n  /// Changing this parameter after construction __is effective__.\r\n  TORCH_ARG(c10::optional<double>, momentum) = 0.1;\r\n\r\n  /// Whether to learn a scale and bias that are applied in an affine\r\n  /// transformation on the input.\r\n  /// Changing this parameter after construction __has no effect__.\r\n  TORCH_ARG(bool, affine) = true;\r\n\r\n  /// Whether to store and update batch statistics (mean and variance) in the\r\n  /// module.\r\n  /// Changing this parameter after construction __has no effect__.\r\n  TORCH_ARG(bool, track_running_stats) = true;\r\n};\r\n\r\nusing BatchNorm1dOptions = BatchNormOptions;\r\nusing BatchNorm2dOptions = BatchNormOptions;\r\nusing BatchNorm3dOptions = BatchNormOptions;\r\n\r\n// ============================================================================\r\n\r\nnamespace functional {\r\n\r\n/// Options for the `BatchNorm` functional.\r\nstruct TORCH_API BatchNormFuncOptions {\r\n  TORCH_ARG(Tensor, weight) = Tensor();\r\n\r\n  TORCH_ARG(Tensor, bias) = Tensor();\r\n\r\n  TORCH_ARG(bool, training) = false;\r\n\r\n  /// A momentum multiplier for the mean and variance.\r\n  /// Changing this parameter after construction __is effective__.\r\n  TORCH_ARG(c10::optional<double>, momentum) = 0.1;\r\n\r\n  /// The epsilon value added for numerical stability.\r\n  /// Changing this parameter after construction __is effective__.\r\n  TORCH_ARG(double, eps) = 1e-5;\r\n};\r\n\r\n} // namespace functional\r\n\r\n} // namespace nn\r\n} // namespace torch\r\n\r\n```\r\n\n\ncc @yf225"},{"labels":["api",null,null,null,null],"text":"## üêõ Bug\r\n\r\nMy program is suffering from a weird bug. It works well with -O0 optimization but crashes with any higher optimization level (-O, -O2 and -O3).\r\n\r\n## To Reproduce\r\n\r\nMy program load the program with the following code\r\n```\r\n    torch::jit::script::Module module;\r\n    try\r\n    {\r\n        // Deserialize the ScriptModule from a file using torch::jit::load().\r\n        module = torch::jit::load(\"../c_model.th\");\r\n    }\r\n    catch (const c10::Error& e)\r\n    {\r\n        std::cerr << \"error loading the model\\n\";\r\n        return -1;\r\n    }\r\n```\r\n\r\nThen pass it by reference to another function, and work about it with the following code\r\n\r\n```\r\n    torch::IntArrayRef size{1,1,64,256};\r\n    at::TensorOptions options(torch::kFloat32);\r\n    auto tensor = torch::empty(size, options);\r\n    //Sadly we have to write the loop to set the value by ourselves.\r\n    auto accessor = tensor.accessor<float, 4>();\r\n    for(size_t i = 0; const auto &frame : mag)\r\n    {\r\n        for(size_t j = 0; const auto mag_entry : frame)\r\n        {\r\n            accessor[0][0][i][j] = mag_entry;\r\n            j++;\r\n        }\r\n        i++;\r\n    }\r\n\r\n    auto result = module.forward({tensor}).toTensor();\r\n    auto result_accessor = result.accessor<float, 2>();\r\n    float x = result_accessor[0][0];\r\n    float y = result_accessor[0][1];\r\n```\r\n\r\nHowever program crashes with the following info printed to console in -O1 or higher optimization level.\r\n\r\n```\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  [enforce fail at CPUAllocator.cpp:47] ((ptrdiff_t)nbytes) >= 0. alloc_cpu() seems to have been called with negative number: 10177264015417475072\r\nframe #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void const*) + 0x6a (0x7ff247458fea in /home/liu/software/pytorch/torch/lib/libc10.so)\r\nframe #1: c10::alloc_cpu(unsigned long) + 0x4f0 (0x7ff2474403f0 in /home/liu/software/pytorch/torch/lib/libc10.so)\r\nframe #2: <unknown function> + 0x179ea (0x7ff2474419ea in /home/liu/software/pytorch/torch/lib/libc10.so)\r\nframe #3: at::native::empty_cpu(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x10b (0x7ff2483c174b in /home/liu/software/pytorch/torch/lib/libtorch.so)\r\nframe #4: <unknown function> + 0x11c0ba0 (0x7ff248632ba0 in /home/liu/software/pytorch/torch/lib/libtorch.so)\r\nframe #5: <unknown function> + 0x11c9dd7 (0x7ff24863bdd7 in /home/liu/software/pytorch/torch/lib/libtorch.so)\r\nframe #6: <unknown function> + 0x16a31 (0x5648e8b7da31 in /home/liu/work/PyTorchCppTest/cmake-build-debug/PyTorchCppTest)\r\nframe #7: <unknown function> + 0x851e (0x5648e8b6f51e in /home/liu/work/PyTorchCppTest/cmake-build-debug/PyTorchCppTest)\r\nframe #8: <unknown function> + 0xa473 (0x5648e8b71473 in /home/liu/work/PyTorchCppTest/cmake-build-debug/PyTorchCppTest)\r\nframe #9: __libc_start_main + 0xeb (0x7ff245714b6b in /lib/x86_64-linux-gnu/libc.so.6)\r\nframe #10: <unknown function> + 0x79aa (0x5648e8b6e9aa in /home/liu/work/PyTorchCppTest/cmake-build-debug/PyTorchCppTest)\r\n```\r\n\r\nI used the debugger to trace down the control flow, it looks like program crashes in ```torch::empty``` function.\r\n\r\n## Expected behavior\r\n\r\nRun correctly in higher optimization level.\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.4.0a0+18ec463\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Ubuntu 19.04\r\nGCC version: (Ubuntu 9.2.1-9ubuntu2) 9.2.1 20191008\r\nCMake version: version 3.13.4\r\n\r\nPython version: 3.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.17.4\r\n[pip3] torchsummary==1.5.1\r\n[conda] blas                      1.0                         mkl  \r\n[conda] mkl                       2019.4                      243  \r\n[conda] mkl-service               2.3.0            py37he904b0f_0  \r\n[conda] mkl_fft                   1.0.14           py37ha843d7b_0  \r\n[conda] mkl_random                1.1.0            py37hd6b4f25_0  \r\n[conda] torch                     1.4.0a0+18ec463          pypi_0    pypi\r\n## Additional context\r\n\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225"},{"labels":[null,"api",null,null],"text":"## üöÄ Feature\r\nBuild `libtorch` with AMD support. \r\n\r\n## Motivation\r\n\r\nI will be working on a new machine that has AMD GPUs, and we would like to avoid the overhead of Python.\r\n\r\n## Pitch\r\n\r\nIf possible, I would like to contribute to this effort. I would appreciate any guidance in that process.\r\n\r\n## Alternatives\r\n\r\nThere could be a binary dump and all associated CMAKE files like the current release of libtorch, but I'd prefer to be able to cook it up myself.\r\n\r\n## Additional context\r\n\r\nThis would be a great step in enabling Pytorch to run on the next generation of supercomputers. :wink:\r\n\n\ncc @yf225"},{"labels":[null,null,"api",null,null],"text":"## üêõ Bug\r\n\r\nAfter the cmake is done, when compiling .cu files in my project, the following error will occur:\r\n```bash\r\nnvcc fatal   : Unknown option 'Wall'\r\n```\r\nThe `flags.make` shows the following result:\r\n```bash\r\n$cat CMakeFiles/train.dir/flags.make\r\n# CMAKE generated file: DO NOT EDIT!\r\n# Generated by \"Unix Makefiles\" Generator, CMake Version 3.15\r\n\r\n# compile CUDA with /usr/local/cuda-9.2/bin/nvcc\r\n# compile CXX with /usr/bin/c++\r\nCUDA_FLAGS =  -O3   -D_GLIBCXX_USE_CXX11_ABI=1 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-unknown-pragmas -Wno-missing-braces -fopenmp -std=c++14\r\n\r\nCUDA_DEFINES = -DAT_PARALLEL_OPENMP=1\r\n......\r\n```\r\nThe `-O3` flag was added using `CMAKE_CUDA_FLAGS` in the `CMakeLists.txt`\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Write a .cu file in the project\r\n2. cmake then make\r\n3. The error occurs\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nThose -Wxxx flags should not be added as cuda flags.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): Compile from source\r\n - OS (e.g., Linux): Ubuntu 16.04\r\n - How you installed PyTorch (`conda`, `pip`, source): source\r\n - Build command you used (if compiling from source):\r\n```bash\r\nBUILD_TORCH=ON \\\r\nCMAKE_PREFIX_PATH=\"/usr/bin/;/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64/;/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/;/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/include/\" \\\r\nCUDA_BIN_PATH=/usr/local/cuda/bin \\\r\nCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda/ \\\r\nCUDNN_LIB_DIR=/usr/local/cuda/lib64 \\\r\nUSE_CUDA=1 \\\r\nUSE_NNPACK=1 \\\r\nMAX_JOBS=8 \\\r\npython3 setup.py build\r\n```\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: 9.2/7.5\r\n - GPU models and configuration: NVIDIA GTX Titan\r\n - Any other relevant information:\r\n\r\n\n\ncc @ezyang @gchanan @zou3519 @malfet @yf225 @glaringlee @ngimel"},{"labels":[null,"api",null],"text":"## üìö Documentation\r\n\r\nDownload libtorch from website, old program using libtorch can not link now:\r\n\r\n```\r\nlibtorch/include/c10/util/C++17.h:20:2: error: #error You need C++14 to compile PyTorch\r\n #error You need C++14 to compile PyTorch\r\n\r\n```\r\n\r\nWhile I have already set C++14 in cmakelists:\r\n\r\n```\r\n\r\nset(CMAKE_CXX_STANDARD 14)\r\nadd_definitions(-std=c++14)\r\n```\r\n\r\nBut keep get such error.\n\ncc @yf225"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To Reproduce\r\nI'm sharing a minor error. \r\nSteps to reproduce the behavior:\r\n\r\n```c++\r\n/*\r\nimages[index] is C * H * W  : 3 *480*640  2D Image tensor\r\nWhen calling interpolation, unknowexception occurs if the data type is not Kfloat.\r\n*/\r\nimages[index] = F::interpolate(images[index], F::InterpolateFuncOptions().scale_factor({ scale_factor }).mode(torch::kLinear).align_corners(false));\r\nimages[index] = normalizeChannels(images[index]);\r\n\r\n/*\r\nIf change data type, it works normally\r\nimg_tensor = img_tensor.toType(at::kFloat);\t\t\r\n*/\r\n```\r\n\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): Libtorch Nightly build date : 19.11.22\r\n - OS (e.g., Linux): Windows 10\r\n - How you installed PyTorch (`conda`, `pip`, source):\r\n - Build command you used (if compiling from source):\r\n - Python version:\r\n - CUDA/cuDNN version: 10.2 , 7.5\r\n - GPU models and configuration: 2080TI\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @yf225"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nRunning the c++ example fails when running the forward calculation on the generator:\r\n\r\n`what():  Calculated padded input size per channel: (1 x 1). Kernel size: (4 x 4). Kernel size can't be greater than actual input size (check_shape_forward at /pytorch/aten/src/ATen/native/Convolution.cpp:436)`\r\n\r\nIs this due to recent changes to use NNPACK for strided convolutions..?\r\n\r\n(There's also a warning about batchnorm being deprecated,\r\nbut that's a simpler fix.)\r\n\r\nThanks\n\ncc @yf225"},{"labels":[null,"api",null,null,null],"text":"## üêõ Bug\r\n\r\nWhen trying to compile with VS2019 but targeting v141 toolchain and cuda 10.0 there seems to be some issues with rewrite of dispatching that was done in recent weeks.\r\n\r\nThis snippet was from building using facebook internal Buck, but I was able to reproduce same thing using cmake.\r\n\r\nCompiling with /permissive- fixed the \"no matching overload\" error, but raises some other cuda errors related to `__nv_hdl_create_wrapper_t`\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. checkout pytorch master\r\n1. pass v141 as toolchain to cmake when generating\r\n1. set cuda sdk root to 10.0\r\n1. try and build torch_cuda\r\n\r\nError without /permissive-\r\n```\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): error C2672: 'c10::impl::boxAndCallBoxedFunc': no matching overloaded function found\r\ncaffe2/aten/src\\ATen/core/dispatch/Dispatcher.h(180): note: see reference to function template instantiation 'Return c10::KernelFunction::callUnboxed<Return,const at::Tensor&,const at::Tensor&,bool,bool>(const c10::OperatorHandle &,const at::Tensor &,const at::Tensor &,bool,bool) const' being compiled\r\n        with\r\n        [\r\n            Return=void\r\n        ]\r\ncaffe2/aten/src\\ATen/core/dispatch/Dispatcher.h(155): note: see reference to function template instantiation 'Return c10::Dispatcher::callUnboxed<Return,const at::Tensor&,const at::Tensor&,bool,bool>(const c10::OperatorHandle &,const at::Tensor &,const at::Tensor &,bool,bool) const' being compiled\r\n        with\r\n        [\r\n            Return=void\r\n        ]\r\ncaffe2\\ATen/core/TensorMethods.h(66): note: see reference to function template instantiation 'Return c10::OperatorHandle::callUnboxed<void,const at::Tensor&,const at::Tensor&,bool,bool>(const at::Tensor &,const at::Tensor &,bool,bool) const' being compiled\r\n        with\r\n        [\r\n            Return=void\r\n        ]\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): error C2770: invalid explicit template argument(s) for 'Result c10::impl::boxAndCallBoxedFunc(c10::KernelFunction::InternalBoxedKernelFunction (__cdecl *),c10::OperatorKernel *,const c10::OperatorHandle &,Args...,enable_if<_Test,_Ty>::type)'\r\n        with\r\n        [\r\n            _Ty=int\r\n        ]\r\ncaffe2/aten/src\\ATen/core/boxing/boxing.h(53): note: see declaration of 'c10::impl::boxAndCallBoxedFunc'\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): error C2893: Failed to specialize function template 'Result c10::impl::boxAndCallBoxedFunc(c10::KernelFunction::InternalBoxedKernelFunction (__cdecl *),c10::OperatorKernel *,const c10::OperatorHandle &,Args...,enable_if<_Test,_Ty>::type)'\r\n        with\r\n        [\r\n            _Ty=int\r\n        ]\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): note: With the following template arguments:\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): note: 'Result=Return'\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): note: 'Args={}'\r\n```\r\nError with /permissive-\r\n```\r\nnvcc_internal_extended_lambda_implementation(542): error C3861: 'args': identifier not found\r\ncaffe2/aten/src/ATen/native/cuda/Copy.cu(62): note: see reference to class template instantiation '__nv_hdl_create_wrapper_t<false,true,__nv_dl_tag<void (__cdecl *)(at::TensorIterator &,bool),at::native::copy_device_to_device,1>>' being compiled\r\n```\r\n\r\n## Expected behavior\r\n\r\nfiles compile\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225 @peterjc123"},{"labels":["api",null],"text":"As part of pull request #28790,\r\nF is redefined globally in nn/modules/batchnorm.h\r\n\r\n`namespace F = torch::nn::functional;`\r\n\r\nF is then used once in batchnorm.h and again in instancenorm.h\r\n\r\nnot a bug, but a problem for anyone using F in some other way.\r\nit's solvable, but I don't see this pattern anywhere else in libtorch,\r\nwas wondering if this use is an anomaly,\r\nand if we could use\r\n\r\n```\r\nreturn torch::nn::functional::detail::batch_norm(\r\nreturn torch::nn::functional::detail::instance_norm(\r\n```\r\nthanks\r\n\n\ncc @yf225"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\n## To Reproduce\r\n - Libtorch Version (1.3.1 stable debug version):\r\n - OS (windows 10):\r\n - How you installed Libtorch ( source):\r\n - Build command you used (visual stdio):\r\n - cpp version:c++11\r\n - cpu version:\r\n\r\n## Additional context\r\nacording to  libtorch documentation FUNCTION TORCH::NN::FUNCTIONAL::PAD should be \r\nin this directory (\"torch/csrc/api/include/torch/nn/functional/\") but   some header files such as  padding.h and ... dont exist\r\n\n\ncc @yf225"},{"labels":[null,"api",null],"text":"## üêõ Bug\r\n\r\nIf a Linear or Conv module is constructed without bias, a subsequent move to another device fails\r\n\r\n## To Reproduce\r\n\r\n```cpp\r\n#include <torch/torch.h>\r\n\r\nint main(int argc, char** argv) {\r\n  torch::nn::Linear test(torch::nn::LinearOptions(10,20).bias(false));\r\n  test->to(torch::kCUDA);\r\n  return 0;\r\n}\r\n```\r\n\r\n\r\n<details><summary>Stack trace</summary>\r\n<p>\r\n\r\n```\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  tensor does not have a device (device at /opt/pytorch/c10/core/TensorImpl.h:463)\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x6a (0x7fffe51c9b1a in /usr/local/torch/lib/libc10.so)\r\nframe #1: <unknown function> + 0x1fd83a6 (0x7fffe73ba3a6 in /usr/local/torch/lib/libtorch.so)\r\nframe #2: at::native::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) + 0xb36 (0x7fffe8c6b1f6 in /usr/local/torch/lib/libtorch.so)\r\nframe #3: <unknown function> + 0x3c22636 (0x7fffe9004636 in /usr/local/torch/lib/libtorch.so)\r\nframe #4: <unknown function> + 0x5882857 (0x7fffeac64857 in /usr/local/torch/lib/libtorch.so)\r\nframe #5: <unknown function> + 0x3c89f2f (0x7fffe906bf2f in /usr/local/torch/lib/libtorch.so)\r\nframe #6: <unknown function> + 0x25e1277 (0x7fffe79c3277 in /usr/local/torch/lib/libtorch.so)\r\nframe #7: void torch::nn::Module::to_impl<c10::Device&, bool&>(c10::Device&, bool&) + 0x196 (0x7fffeb3a8266 in /usr/local/torch/lib/libtorch.so)\r\nframe #8: torch::nn::Module::to(c10::Device, bool) + 0x18 (0x7fffeb3a2fe8 in /usr/local/torch/lib/libtorch.so)\r\nframe #9: main + 0xba (0x4052e8 in /home/tobi/coar_ws/devel/lib/dgcnn/dev_stuff)\r\nframe #10: __libc_start_main + 0xf0 (0x7fffe4855830 in /lib/x86_64-linux-gnu/libc.so.6)\r\nframe #11: _start + 0x29 (0x405049 in /home/tobi/coar_ws/devel/lib/dgcnn/dev_stuff)\r\n\r\n\r\nThread 1 \"dev_stuff\" received signal SIGABRT, Aborted.\r\n0x00007fffe486a428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\r\n54      ../sysdeps/unix/sysv/linux/raise.c: No such file or directory.\r\n(gdb) backtrace\r\n#0  0x00007fffe486a428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\r\n#1  0x00007fffe486c02a in __GI_abort () at abort.c:89\r\n#2  0x00007fffe4ea484d in __gnu_cxx::__verbose_terminate_handler() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#3  0x00007fffe4ea26b6 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#4  0x00007fffe4ea2701 in std::terminate() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#5  0x00007fffe4ea2919 in __cxa_throw () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#6  0x00007fffe73ba3fc in at::Tensor::options() const () from /usr/local/torch/lib/libtorch.so\r\n#7  0x00007fffe8c6b1f6 in at::native::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) () from /usr/local/torch/lib/libtorch.so\r\n#8  0x00007fffe9004636 in at::TypeDefault::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) () from /usr/local/torch/lib/libtorch.so\r\n#9  0x00007fffeac64857 in torch::autograd::VariableType::(anonymous namespace)::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) () from /usr/local/torch/lib/libtorch.so\r\n#10 0x00007fffe906bf2f in c10::detail::wrap_kernel_functor_unboxed_<c10::detail::WrapRuntimeKernelFunctor_<at::Tensor (*)(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat> > >, at::Tensor (at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>)>::call(c10::OperatorKernel*, at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) () from /usr/local/torch/lib/libtorch.so\r\n#11 0x00007fffe79c3277 in at::Tensor::to(c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) const () from /usr/local/torch/lib/libtorch.so\r\n#12 0x00007fffeb3a8266 in void torch::nn::Module::to_impl<c10::Device&, bool&>(c10::Device&, bool&) () from /usr/local/torch/lib/libtorch.so\r\n#13 0x00007fffeb3a2fe8 in torch::nn::Module::to(c10::Device, bool) [clone .localalias.489] () from /usr/local/torch/lib/libtorch.so\r\n#14 0x00000000004052e8 in main (argc=1, argv=0x7fffffffccc8) at /home/tobi/coar_ws/src/dgcnn/src/dev_stuff.cpp:5\r\n```\r\n</p>\r\n</details>\r\n\r\n## Expected behavior\r\n\r\nGetting no error.\r\n\r\n## Environment\r\n\r\n```\r\nCollecting environment information...\r\nCollecting environment information...\r\nPyTorch version: 1.4.0a0+829499e\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 18.04.3 LTS\r\nGCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\nCMake version: version 3.15.3\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration:\r\nGPU 0: Quadro RTX 6000\r\nGPU 1: Quadro RTX 6000\r\n\r\nNvidia driver version: 418.87.00\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.17.4\r\n[pip3] torch==1.4.0a0+94016b1\r\n[conda] Could not collect\r\n\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.4.0a0+829499e\r\n - OS (e.g., Linux): Ubuntu 18.04.3 LTS\r\n - How you installed PyTorch (`conda`, `pip`, source): compiled from source\r\n - Build command you used (if compiling from source): ```CFLAGS=' -D_GLICXX_USE_CXX11_ABI ' USE_OPENCV=1 USE_CUDA=1 MAX_JOBS=7 BUILD_TEST=0 python3 setup.py install ```\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: CUDA 10.1 / cuDNN 7.6.5\r\n - GPU models and configuration: 2x Quadro RTX 6000\r\n\n\ncc @ezyang @gchanan @zou3519 @jerryzh168 @yf225"},{"labels":["api",null,null],"text":"## üêõ Bug\r\n\r\nHi, maybe I found a bug in LibTorch while run codes in CentOS, the codes are very simplify. I have try it in 2 CentOS Machines and 1 Ubuntu Machine, Ubuntu Machine can run it normally, but all of the CentOS Machines run it like follow outputs.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. download libtorch and unzip\r\n2. compile the cpp file\r\n3. run\r\n\r\nHere are the codes:\r\n```c++\r\n#include<iostream>\r\n#include<torch/torch.h>\r\n#include <torch/script.h>\r\n\r\nint main() {\r\n\ttorch::Tensor a = torch::ones({2,4});\r\n\tstd::cout << a << std::endl;\r\n\treturn 0;\r\n}\r\n```\r\n\r\nHere is the CMakeList:\r\n```cmake\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nproject(tr)\r\n\r\nfind_package(Torch REQUIRED)\r\naux_source_directory(. SRC_LIST)\r\nadd_executable(test ${SRC_LIST})\r\nset(CMAKE_CXX_STANDARD 11)\r\ntarget_link_libraries(test \"${TORCH_LIBRARIES}\")\r\nset_property(TARGET test PROPERTY CXX_STANDARD 11)\r\n```\r\n\r\nHere is the output:\r\n```\r\n 1  1  1  1\r\n 1  1  1  1\r\n[ Variable[CPUFloatType]{2,4} ]\r\n*** Error in `./test': free(): invalid pointer: 0x00007f040f871090 ***\r\n======= Backtrace: =========\r\n/lib64/libc.so.6(+0x81679)[0x7f04022b3679]\r\n./test(_ZN9__gnu_cxx13new_allocatorIPNSt8__detail15_Hash_node_baseEE10deallocateEPS3_m+0x20)[0x41fd0e]\r\n./test(_ZNSt10_HashtableISsSt4pairIKSsSsESaIS2_ENSt8__detail10_Select1stESt8equal_toISsESt4hashISsENS4_18_Mod_range_hashingENS4_20_Default_ranged_hashENS4_20_Prime_rehash_policyENS4_17_Hashtable_traitsILb1ELb0ELb1EEEE21_M_deallocate_bucketsEPPNS4_15_Hash_node_baseEm+0x49)[0x41f20f]\r\n./test(_ZNSt10_HashtableISsSt4pairIKSsSsESaIS2_ENSt8__detail10_Select1stESt8equal_toISsESt4hashISsENS4_18_Mod_range_hashingENS4_20_Default_ranged_hashENS4_20_Prime_rehash_policyENS4_17_Hashtable_traitsILb1ELb0ELb1EEEED1Ev+0x36)[0x41df10]\r\n/lib64/libc.so.6(__cxa_finalize+0x9a)[0x7f040226c00a]\r\n/home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so(+0x9fa9d3)[0x7f040367e9d3]\r\n======= Memory map: ========\r\n00400000-00429000 r-xp 00000000 fd:02 186000054                          /home/yyuser/nlp/codes/bd-nlp/tr/alg-service/build/test\r\n00628000-00629000 r--p 00028000 fd:02 186000054                          /home/yyuser/nlp/codes/bd-nlp/tr/alg-service/build/test\r\n00629000-0062a000 rw-p 00029000 fd:02 186000054                          /home/yyuser/nlp/codes/bd-nlp/tr/alg-service/build/test\r\n021b1000-02aee000 rw-p 00000000 00:00 0                                  [heap]\r\n7f03fc000000-7f03fc021000 rw-p 00000000 00:00 0 \r\n7f03fc021000-7f0400000000 ---p 00000000 00:00 0 \r\n7f04018fa000-7f04019fb000 r-xp 00000000 fd:02 1548                       /usr/lib64/libm-2.17.so\r\n7f04019fb000-7f0401bfa000 ---p 00101000 fd:02 1548                       /usr/lib64/libm-2.17.so\r\n7f0401bfa000-7f0401bfb000 r--p 00100000 fd:02 1548                       /usr/lib64/libm-2.17.so\r\n7f0401bfb000-7f0401bfc000 rw-p 00101000 fd:02 1548                       /usr/lib64/libm-2.17.so\r\n7f0401bfc000-7f0401bfe000 r-xp 00000000 fd:02 1546                       /usr/lib64/libdl-2.17.so\r\n7f0401bfe000-7f0401dfe000 ---p 00002000 fd:02 1546                       /usr/lib64/libdl-2.17.so\r\n7f0401dfe000-7f0401dff000 r--p 00002000 fd:02 1546                       /usr/lib64/libdl-2.17.so\r\n7f0401dff000-7f0401e00000 rw-p 00003000 fd:02 1546                       /usr/lib64/libdl-2.17.so\r\n7f0401e00000-7f0401e07000 r-xp 00000000 fd:02 1570                       /usr/lib64/librt-2.17.so\r\n7f0401e07000-7f0402006000 ---p 00007000 fd:02 1570                       /usr/lib64/librt-2.17.so\r\n7f0402006000-7f0402007000 r--p 00006000 fd:02 1570                       /usr/lib64/librt-2.17.so\r\n7f0402007000-7f0402008000 rw-p 00007000 fd:02 1570                       /usr/lib64/librt-2.17.so\r\n7f0402008000-7f040202d000 r-xp 00000000 fd:02 352611484                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libgomp-7c85b1e2.so.1\r\n7f040202d000-7f040222c000 ---p 00025000 fd:02 352611484                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libgomp-7c85b1e2.so.1\r\n7f040222c000-7f040222d000 r--p 00024000 fd:02 352611484                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libgomp-7c85b1e2.so.1\r\n7f040222d000-7f0402232000 rw-p 00025000 fd:02 352611484                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libgomp-7c85b1e2.so.1\r\n7f0402232000-7f04023f5000 r-xp 00000000 fd:02 1540                       /usr/lib64/libc-2.17.so\r\n7f04023f5000-7f04025f5000 ---p 001c3000 fd:02 1540                       /usr/lib64/libc-2.17.so\r\n7f04025f5000-7f04025f9000 r--p 001c3000 fd:02 1540                       /usr/lib64/libc-2.17.so\r\n7f04025f9000-7f04025fb000 rw-p 001c7000 fd:02 1540                       /usr/lib64/libc-2.17.so\r\n7f04025fb000-7f0402600000 rw-p 00000000 00:00 0 \r\n7f0402600000-7f0402615000 r-xp 00000000 fd:02 1311741                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1\r\n7f0402615000-7f0402814000 ---p 00015000 fd:02 1311741                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1\r\n7f0402814000-7f0402815000 r--p 00014000 fd:02 1311741                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1\r\n7f0402815000-7f0402816000 rw-p 00015000 fd:02 1311741                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1\r\n7f0402816000-7f040282d000 r-xp 00000000 fd:02 1566                       /usr/lib64/libpthread-2.17.so\r\n7f040282d000-7f0402a2c000 ---p 00017000 fd:02 1566                       /usr/lib64/libpthread-2.17.so\r\n7f0402a2c000-7f0402a2d000 r--p 00016000 fd:02 1566                       /usr/lib64/libpthread-2.17.so\r\n7f0402a2d000-7f0402a2e000 rw-p 00017000 fd:02 1566                       /usr/lib64/libpthread-2.17.so\r\n7f0402a2e000-7f0402a32000 rw-p 00000000 00:00 0 \r\n7f0402a32000-7f0402a77000 r-xp 00000000 fd:02 352611503                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libc10.so\r\n7f0402a77000-7f0402c77000 ---p 00045000 fd:02 352611503                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libc10.so\r\n7f0402c77000-7f0402c78000 r--p 00045000 fd:02 352611503                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libc10.so\r\n7f0402c78000-7f0402c79000 rw-p 00046000 fd:02 352611503                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libc10.so\r\n7f0402c79000-7f0402c7a000 rw-p 00000000 00:00 0 \r\n7f0402c7a000-7f0402c84000 rw-p 0005f000 fd:02 352611503                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libc10.so\r\n7f0402c84000-7f040f47f000 r-xp 00000000 fd:02 352611487                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so\r\n7f040f47f000-7f040f67f000 ---p 0c7fb000 fd:02 352611487                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so\r\n7f040f67f000-7f040f75d000 r--p 0c7fb000 fd:02 352611487                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so\r\n7f040f75d000-7f040f854000 rw-p 0c8d9000 fd:02 352611487                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so\r\n7f040f854000-7f040f8a6000 rw-p 00000000 00:00 0 \r\n7f040f8a6000-7f040fb5e000 rw-p 0db6f000 fd:02 352611487                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so\r\n7f040fb5e000-7f040fb80000 r-xp 00000000 fd:02 1533                       /usr/lib64/ld-2.17.so\r\n7f040fbe9000-7f040fbff000 rw-p 00000000 00:00 0 \r\n7f040fbff000-7f040fca1000 r--p 00000000 fd:02 9122949                    /usr/lib/libstdc++.so.6.0.26\r\n7f040fca1000-7f040fd20000 r-xp 000a2000 fd:02 9122949                    /usr/lib/libstdc++.so.6.0.26\r\n7f040fd20000-7f040fd61000 r--p 00121000 fd:02 9122949                    /usr/lib/libstdc++.so.6.0.26[1]    14117 abort      ./test\r\n```\r\n\r\n\r\n## Environment\r\n\r\n\r\n - PyTorch Version (e.g., 1.0): 1.3\r\n - OS (e.g., Linux): CentOS Linux release 7.7.1908 (Core) and CentOS Linux release 7.6.1810 (Core) \r\n - How you installed PyTorch (`conda`, `pip`, source): LibTorch(Pre-cxx11 ABI)\r\n - CUDA/cuDNN version: no GPU\r\n - LibTorch download url: [https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-1.3.1%2Bcpu.zip](https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-1.3.1%2Bcpu.zip)\r\n\r\n\n\ncc @ezyang @gchanan @zou3519 @jerryzh168 @yf225"},{"labels":["api",null],"text":"Hello,\r\nI was trying to code example of neural network on CUDA. I have run some examples which they were working on CPU but not on GPU. \r\n\r\nNot sure if it's a bug or my mistake.\r\n\r\nPlease note that CUDA version of [MNIST example](https://github.com/Andrej-sens/libtorch_examples_cpp/blob/master/MNIST_Example_GPU.cpp) is working properly. \r\n\r\nHow to replicate error, just change bias to false. With `bias=true` I am able to move network model to CUDA.\r\n```\r\n#include <torch/torch.h>\r\n\r\n// Define a new Module.\r\nstruct Net : torch::nn::Module {\r\n\tNet() {\r\n\t\ttorch::nn::Conv2d conv = torch::nn::Conv2d(torch::nn::Conv2dOptions(3, 16, 3)\r\n\t\t\t.bias(true)\r\n\t\t\t.stride(1)\r\n\t\t\t.padding(1)\r\n\t\t);\r\n\r\n\t\tmodule->push_back(conv);\r\n\r\n\t\tregister_module(\"Layer\",module);\r\n\t}\r\n\r\n\ttorch::Tensor forward(torch::Tensor x) {\r\n\t\t/**SOME FORWARD**/\r\n\t\treturn x;\r\n\t}\r\n\r\n\ttorch::nn::Sequential module;\r\n};\r\n\r\nint main() {\r\n\tauto net = std::make_shared<Net>();\r\n\tnet->to(at::kCUDA); // It crashes here\r\n}\r\n```\r\n\r\nIt will throw\r\n```\r\nException thrown at 0x00007FFB4A2EA839 in Object_detection.exe: Microsoft C++ exception: c10::Error at memory location 0x000000635F0FDE90.\r\nUnhandled exception at 0x00007FFB4A2EA839 in Object_detection.exe: Microsoft C++ exception: c10::Error at memory location 0x000000635F0FDE90.\r\n```\r\n\r\nThank you very much for any advise.\r\n\n\ncc @ezyang @gchanan @zou3519 @jerryzh168 @yf225"},{"labels":[null,"api",null,null],"text":"Not only C + + interface on IOS\r\nPython may also call torch on IOS\r\nThis can be used for demonstration or introduction to basic learning\r\n\r\nI made some changes when compiling. At present, most of the examples are available through\r\nIt's just that I don't know if pytorch is compatible with this pattern\r\n\r\nDownload APP:\r\n- US https://apps.apple.com/us/app/id1471351733\r\n- CN  https://apps.apple.com/cn/app/id1471351733\r\n\r\nScreenshots:\r\n- ![](https://github.com/goodclass/PythonAI/raw/master/image/torch1.jpg)\r\n- ![](https://github.com/goodclass/PythonAI/raw/master/image/torch2.jpg)\n\ncc @yf225"},{"labels":["api",null,null],"text":"## üêõ Bug\r\n\r\nLoads of errors during C++ code compilation due to problems with namespaces in LibTorch files.\r\n\r\n## What helped\r\nChanges in files:\r\n\r\n1. libtorch/include/ATen/detail/CUDAHooksInterface.h \r\n26 line:\r\n```\r\nnamespace at {\r\nusing c10::Allocator;\t///Changed manually\r\n```\r\n2. libtorch/include/ATen/core/TensorBody.h\r\n35 line: \r\n```\r\nnamespace at {\r\n using c10::Scalar; ///Changed manually\r\n```\r\n## Environment\r\nPyTorch version: 1.3.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1.243\r\n\r\nOS: Ubuntu 16.04.6 LTS\r\nGCC version: (Ubuntu 5.3.1-14ubuntu2) 5.3.1 20160413\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: 9.2.148\r\nGPU models and configuration: GPU 0: Quadro M2000\r\nNvidia driver version: 410.48\r\ncuDNN version: /usr/local/cuda-9.2/lib64/libcudnn.so.7\r\n\r\n\r\n## Additional context\r\n\r\nIt would be great not to have this bug in future versions because original file code change is not the best method of creating robust software. Maybe it is possible to prevent this issue using some commands but I don't know them.\n\ncc @yf225"},{"labels":["api"],"text":"## üêõ Bug\r\nThe following short program does not compile.\r\n\r\n    #include \"torch/torch.h\"\r\n\r\n    int main() {\r\n        torch::Tensor tensor = torch::ones({2, 2});\r\n        tensor.fill_(0); // OK\r\n        tensor = 0; // Gives compile error\r\n    }\r\n\r\n## Expected behavior\r\n\r\nI would expect both the expressions 'tensor.fill_(0)' and 'tensor = 0' to compile and that they would yield the same result.\r\n\r\nLooking at the source code 'aten/src/ATen/TensorOperators.h' the selected assignment operator is defined as follows:\r\n\r\n    inline Tensor & Tensor::operator=(Scalar v) && {\r\n        return fill_(v);\r\n    }\r\n\r\nThat is, it is only defined for rvalues on the lhs of the assignment. I do not understand the rationale behind this restriction.\r\n\r\n## Environment\r\n\r\n```\r\n - PyTorch Version: 1.3.1\r\n - OS: Linux\r\n - How you installed PyTorch:  https://download.pytorch.org/libtorch/cu101/libtorch-cxx11-abi-shared-with-deps-1.3.1.zip\r\n - Build command you used: cmake -DCMAKE_PREFIX_PATH=/absolute/path/to/libtorch .. && make\r\n```\r\nI am building the sample program using the instructions in the [c++ api guide](https://pytorch.org/cppdocs/installing.html)\r\n\n\ncc @yf225"},{"labels":["api"],"text":"I have tried to benchmark and compare a Python script, using a pretrained classification model from the torchvision library with the C++ API implementation in order to make sure it will work with my application.\r\nI have tried the following script in Python:\r\n\r\n```\r\nimport torch\r\nfrom torchvision import transforms\r\nfrom PIL import Image\r\n\r\n\r\n_IMAGE_FILENAME = \"../images/goldfish.jpg\"\r\n_MODEL_JIT_FILENAME = \"../jit_models_bin/traced_mnasnet0_5.pt\"\r\n\r\nmodel = torch.jit.load(_MODEL_JIT_FILENAME)\r\n\r\ntfm = transforms.Compose([ \r\n    transforms.Resize([ 224, 224 ]), \r\n    transforms.ToTensor(), \r\n    transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) \r\n    ])\r\n\r\nimage = Image.open(_IMAGE_FILENAME)\r\nimage = tfm(image)\r\nimage = image.unsqueeze(dim=0)\r\n\r\n\r\noutput = model(image)\r\noutput = torch.softmax(output, 1)\r\n\r\nprob_value, index = torch.max(output, 1)\r\n\r\nprint(\"Probability Value: \")\r\nprint(prob_value)\r\nprint(\"ImageNet Index: \")\r\nprint(index)\r\n```\r\n\r\nAnd I used the following code in C++:\r\n```\r\n#include <iostream>\r\n#include <vector>\r\n#include <string>\r\n\r\n#include <torch/torch.h>\r\n#include <torch/script.h>\r\n\r\n#include <opencv2/core.hpp>\r\n#include <opencv2/imgcodecs.hpp>\r\n#include <opencv2/highgui/highgui.hpp>\r\n#include <opencv2/imgproc.hpp>\r\n\r\n\r\nint main() {\r\n\r\n    const cv::String _IMAGE_FILENAME = \"../images/goldfish.jpg\";\r\n    const std::string _MODEL_JIT_FILENAME= \"../jit_models_bin/traced_mnasnet0_5.pt\";\r\n\r\n    cv::Mat img = cv::imread( _IMAGE_FILENAME, cv::IMREAD_UNCHANGED );\r\n    cv::Size rsz = { 224, 224 };\r\n\r\n    cv::resize( img, img, rsz, 0, 0, cv::INTER_LINEAR );\r\n    img.convertTo( img, CV_32FC3, 1/255.0 );\r\n\r\n    at::Tensor tensorImage = torch::from_blob(img.data, { 1, img.rows, img.cols, 3 }, at::kFloat);\r\n    tensorImage = tensorImage.permute({0, 3, 1, 2});\r\n\r\n    //  Normalize data\r\n    tensorImage[0][0] = tensorImage[0][0].sub(0.485).div(0.229);\r\n    tensorImage[0][1] = tensorImage[0][1].sub(0.456).div(0.224);\r\n    tensorImage[0][2] = tensorImage[0][2].sub(0.406).div(0.225);\r\n\r\n    std::vector<torch::jit::IValue> input;\r\n    input.push_back(tensorImage);\r\n\r\n    torch::jit::script::Module model = torch::jit::load( _MODEL_JIT_FILENAME );\r\n\r\n    at::Tensor output = torch::softmax(model.forward(input).toTensor(), 1);\r\n\r\n    std::tuple<at::Tensor, at::Tensor> result = torch::max(output, 1);\r\n\r\n    std::cout << \"Probability Value: \" << std::endl;\r\n    std::cout << std::get<0>(result) << std::endl;\r\n    std::cout << \"ImageNet Index\" << std::endl;\r\n    std::cout << std::get<1>(result) << std::endl;\r\n\r\n    return 0;\r\n}\r\n\r\n```\r\n\r\nThe results I get in the Python script:\r\nProbability: 0.99, Index: 1, Label: GoldFish\r\n\r\nThe results I get in C++:\r\nProbability: 0.4839, Index: 584\r\n\r\nI used PyTorch 1.3 version in Python 3.7 and the latest corresponding libtorch.\r\n\r\nAny ideas?\n\ncc @yf225"},{"labels":[null,"api",null,null,null,null],"text":"`tensor.type()` gives you a DeprecatedTypeProperties object, but we didn't actually deprecate the call.  We should do this ASAP so we can delete DeprecatedTypeProperties.\r\n\r\nCC @ezyang.\n\ncc @ezyang @gchanan @zou3519 @jerryzh168 @yf225 @SsnL"},{"labels":["api",null],"text":"`torch::tensor` currently accepts braced-init-list (such as `{{1}, {2}}`) as multidimensional input. It would be great if `at::tensor` supports the same as well.\r\n\r\nThis would involve moving `torch/csrc/api/include/torch/detail/TensorDataContainer.h` to ATen, and using it from `aten/src/ATen/templates/NativeFunctions.h`.\n\ncc @yf225"},{"labels":["api",null,null],"text":"After https://github.com/pytorch/pytorch/pull/28523 is merged, C++ `torch::tensor(scalar)` behaves the same as Python `torch.tensor(scalar)` and creates a 0-dim tensor. However, C++ `at::tensor(scalar)` still creates a 1-dim tensor, and it would be great to change the behavior of `at::tensor(scalar)` to create a 0-dim tensor.\n\ncc @yf225"},{"labels":[null,null,"api",null,null],"text":"In order to make rpc, remote and dist autograd APIs run in torch script mode, we need to provide C++ APIs of them and register them as Prim::ops. \r\n\r\nThese APIs include:\r\n\r\nrpc_sync(), rpc_async(), remote(), dist_autograd.backward()\r\n\n\ncc @ezyang @SsnL @albanD @zou3519 @gqchen @yf225 @pietern @mrshenli @pritamdamania87 @zhaojuanmao @satgera @rohan-varma @aazzolini @xush6528"},{"labels":["api",null],"text":"Example:\r\nIn C++:\r\n```cpp\r\ntorch::tensor({1., 2., 3.}).dtype() -> double\r\n```\r\n\r\nIn Python:\r\n```python\r\n>>> torch.tensor([1., 2., 3.]).dtype\r\ntorch.float32\r\n```\n\ncc @yf225"},{"labels":[null,"api",null],"text":"Existing documentation / tutorials show only how to train a `torch::nn::Module` https://pytorch.org/cppdocs/frontend.html#end-to-end-example\r\n\r\nI have attempted to make a training loop in the following manner\r\n```\r\n#include <torch/script.h>\r\n#include <torch/torch.h>\r\n#include <iostream>\r\n#include <vector>\r\n// custom loader code\r\n#include \"nets/nets.h\"\r\n#include \"util/runfiles.h\"\r\n\r\nint main(int argc, char** argv) {\r\n  std::cout << \"Nets example\" << std::endl;\r\n\r\n  // Custom code that loads the module on CUDA\r\n  auto runfiles = MakeRunfiles(argv[0]);\r\n  torch::jit::script::Module script_module = LoadSegnetBackbone(*runfiles);\r\n  script_module.train();\r\n  std::cout << \"Loaded script module\" << std::endl;\r\n\r\n  // Pull parameters out of the script module so we can push them into the\r\n  // optimizer.\r\n  std::vector<at::Tensor> parameters;\r\n  for (const auto& parameter : script_module.get_parameters()) {\r\n    parameters.push_back(parameter.value().toTensor());\r\n  }\r\n  torch::optim::SGD optimizer(std::move(parameters), /*lr=*/0.01);\r\n\r\n  constexpr int kBatchSize = 1;\r\n  for (int epoch = 1; epoch <= 1000; ++epoch) {\r\n    optimizer.zero_grad();\r\n\r\n    // The input is a (kBatchSize,3,300,300) tensor filled with ones\r\n    at::Tensor input = torch::ones({kBatchSize, /*channels (rgb) =*/3,\r\n                                    /*height=*/300, /*width=*/300})\r\n                           .to(at::kFloat)\r\n                           .to(at::kCUDA);\r\n\r\n    // Push the input through the script module\r\n    std::vector<torch::jit::IValue> inputs;\r\n    inputs.push_back(input);\r\n    at::Tensor script_module_forward = script_module.forward(inputs).toTensor();\r\n    // The result is an output tensor of size (kBatchSize, 32, 300, 300)\r\n\r\n    // ground truth is a (kBatchSize, 300, 300) tensor filled with ones\r\n    at::Tensor ground_truth =\r\n        torch::ones({kBatchSize, /*height=*/300, /*width=*/300})\r\n            .to(at::kLong)\r\n            .to(at::kCUDA);\r\n\r\n    at::Tensor loss = torch::nll_loss2d(\r\n        torch::log_softmax(script_module_forward, /*dim=*/1), ground_truth);\r\n    loss.backward();\r\n    optimizer.step();\r\n\r\n    if (epoch % 50 == 0) {\r\n      std::cout << \"Loss was \" << loss.item<float>() << std::endl;\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nbut the loss never changes. I have also posted about this on the pytorch forums. https://discuss.pytorch.org/t/jit-module-parameters-are-not-updating-when-training/58945 \r\n\r\ncc @suo @yf225"},{"labels":["api",null],"text":"Currently, `torch.optim` optimizers in PyTorch C++ API behave slightly differently from the Python API. In order to achieve parity, we should check the following aspects of an optimizer:\r\n\r\n1. Make sure the C++ optimizer takes the same set of constructor arguments as the Python optimizer.\r\n2. Make sure the C++ optimizer's constructor has the exact same logic as the Python optimizer's `__init__()` function. Particularly, we need to support `param_groups` in C++ optimizers.\r\n2. Make sure the C++ optimizer's `step()` function has the exact same logic as the Python optimizer's `step()` function.\r\n3. Add `state` to all optimizers, which is equivalent to the `state` dict in Python optimizers. In the `serialize` function of each C++ optimizer, make sure to serialize the `state` field into a list of `at::IValue`s, and have tests to make sure we can deserialize the `state` field successfully.\r\n    - You might ask \"what should we do with the existing serialization logic in the `serialize` function, and would the change break backward compatibility of the user's existing serialized optimizers?\" The answer is that we should put a \"version number\" in the serialized optimizer, and use that to identify the version - if we find no version number, we know that it's the old version, if we find version number \"1.5\", we know that it's the second version (aka. the version after our changes). We need to have tests to cover deserialization of the old version as well.\r\n\r\nFor more detailed discussions on the class structure design, see https://github.com/pytorch/pytorch/pull/29581.\r\n\r\n## Optimizers\r\n- [x] Adagrad (https://github.com/pytorch/pytorch/pull/29335)\r\n- [x] Adam (https://github.com/pytorch/pytorch/pull/33730)\r\n- [x] LBFGS (https://github.com/pytorch/pytorch/pull/34564)\r\n- [x] RMSprop (https://github.com/pytorch/pytorch/pull/33450)\r\n- [x] SGD (https://github.com/pytorch/pytorch/pull/32592)\r\n- [ ] Adadelta\r\n- [x] AdamW\r\n- [ ] SparseAdam\r\n- [ ] Adamax\r\n- [ ] ASGD\r\n- [ ] Rprop\r\n\r\ncc @yf225"},{"labels":["api",null],"text":"## ‚ùì Questions and Help\r\n\r\n# Motivation\r\ni want to implement nms in parallel processing with libtorch library.\r\ni use this cuda code(https://github.com/gdlg/pytorch_nms)\r\n\r\n# Environment\r\nPyTorch version : 1.2.0\r\nCUDA (nvcc compiler ) : 10.0\r\nlibtorch version : 1.2.0\r\nsystem : win10\r\n\r\n# Operation\r\nthe command :`i use nvcc -c nms_kernel.cu -L -lcudart -I D:\\Code-software\\NNF\\libtorch\\libtorch\\include -I D:\\Code-software\\NNF\\libtorch\\libtorch\\include\\torch\\csrc\\api\\include` to compiled it \r\n\r\n# ERROR\r\n`D:/Code-software/NNF/libtorch/libtorch/include\\torch/csrc/jit/argument_spec.h(181): error: member \"torch::jit::ArgumentSpecCreator::DEPTH_LIMIT\" may not be initialized 1 error detected in the compilation of \"C:/Users/Cason/AppData/Local/Temp/tmpxft_00001b28_00000000-10_nms_kernel.cpp1.ii\"`\r\n\r\nas long as i add `#include <torch/extension.h>` or `#include <torch/script.h>` in cuda files,It makes this kind of mistake.\r\n\r\n\r\n \r\n\r\n\r\n\n\ncc @yf225"},{"labels":[null,"api",null,null,null],"text":"When the model does not contain a custom layer, it can be deployed directly on the C + + side using JIT mechanism and libtorch library.\r\n\r\nBut my model contains a custom c++ and CUDA layer. Now that I'm deploying the model on the c++ side, do I need to compile the custom c++ and CUDA layers into the libtorch library?\r\nThank you!!!\n\ncc @suo @yf225"},{"labels":[null,"api",null,null,null],"text":"  here is my code\r\n  torch::Device deviceInfo(torch::kCUDA, 1);\r\n  module->to(deviceInfo);\r\n\r\n  but i got this error\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  CUDA out of memory. Tried to allocate 240.00 MiB (GPU 0; 10.92 GiB total capacity; 74.36 MiB already allocated; 147.50 MiB free; 11.64 MiB cached) (malloc at ../c10/cuda/CUDACachingAllocator.cpp:267)\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x6a (0x7ff1cbc4201a in /home/training/pytorch/torch/lib/libc10.so)\r\nframe #1: <unknown function> + 0x2009c (0x7ff1c32fd09c in /home/training/pytorch/torch/lib/libc10_cuda.so)\r\nframe #2: <unknown function> + 0x20db3 (0x7ff1c32fddb3 in /home/training/pytorch/torch/lib/libc10_cuda.so)\r\nframe #3: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x282 (0x7ff1ce9fe2b2 in /home/training/pytorch/torch/lib/libtorch.so)\r\nframe #4: <unknown function> + 0x584a765 (0x7ff1d16a0765 in /home/training/pytorch/torch/lib/libtorch.so)\r\nframe #5: at::native::to(at::Tensor const&, c10::Device, c10::ScalarType, bool, bool) + 0x8b9 (0x7ff1cf382889 in /home/training/pytorch/torch/lib/libtorch.so)\r\nframe #6: at::TypeDefault::to(at::Tensor const&, c10::Device, c10::ScalarType, bool, bool) + 0x25 (0x7ff1cf6c7535 in /home/training/pytorch/torch/lib/libtorch.so)\r\nframe #7: <unknown function> + 0x54aca6e (0x7ff1d1302a6e in /home/training/pytorch/torch/lib/libtorch.so)\r\nframe #8: torch::jit::load(std::unique_ptr<caffe2::serialize::ReadAdapterInterface, std::default_delete<caffe2::serialize::ReadAdapterInterface> >, c10::optional<c10::Device>, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >&) + 0x222 (0x7ff1d1304052 in /home/training/pytorch/torch/lib/libtorch.so)\r\nframe #9: torch::jit::load(std::istream&, c10::optional<c10::Device>, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >&) + 0x75 (0x7ff1d13041f5 in /home/training/pytorch/torch/lib/libtorch.so)\r\nframe #10: TorchNet::loadModelEncode(char const*, unsigned char*) + 0x169 (0x40cbe9 in ./vehicleFeature)\r\nframe #11: TorchNet::LoadModel(PES_Params_Config) + 0x5e (0x40cdfe in ./vehicleFeature)\r\nframe #12: TorchOperation::LoadModel(PES_Params_Config) + 0x48 (0x418e98 in ./vehicleFeature)\r\nframe #13: VehicleFeature::VehicleFeature(char const*, int) + 0xc2 (0x4192d2 in ./vehicleFeature)\r\nframe #14: test() + 0x217 (0x41a217 in ./vehicleFeature)\r\nframe #15: main + 0x9 (0x4098c9 in ./vehicleFeature)\r\nframe #16: __libc_start_main + 0xf0 (0x7ff1ca45c830 in /lib/x86_64-linux-gnu/libc.so.6)\r\nframe #17: _start + 0x29 (0x409929 in ./vehicleFeature)\r\n\r\nAborted (core dumped)\r\n\r\n\r\n\r\n\n\ncc @yf225"},{"labels":["api",null],"text":"## üêõ Bug\r\n\r\nL-BFGS optimizer will not work if there is one or more registered parameters (tensors) with no grad in the model:\r\n```\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::view.  This usually means that this function requires a non-empty list of Tensors.  Available functions are [CUDATensorId, QuantizedCPUTensorId, VariableTensorId, CPUTensorId, MkldnnCPUTensorId] (lookup_ at /pytorch/aten/src/ATen/core/dispatch/DispatchTable.h:245)\r\n```\r\n\r\n## To Reproduce\r\n\r\nCode to reproduce the error:\r\n\r\n```\r\n/* A custom dataset for test */\r\nnamespace torch\r\n{\r\n    namespace data\r\n    {\r\n        namespace datasets\r\n        {\r\n            struct TEST_TensorDataset : public Dataset<TEST_TensorDataset>\r\n            {\r\n                private:\r\n                    torch::Tensor data1, data2;\r\n\r\n                public:\r\n                    explicit TEST_TensorDataset(std::vector<torch::Tensor> tensors):\r\n                        data1(tensors[0]), data2(tensors[1]) \r\n                        {}\r\n\r\n                torch::data::Example<> get(size_t index) override\r\n                {\r\n                    return {data1[index], data2[index]};\r\n                }\r\n\r\n                optional<size_t> size() const override\r\n                {\r\n                    return data1.sizes()[0];\r\n                }\r\n            };\r\n        }\r\n    }\r\n}\r\n\r\n/* Test */\r\nint test()\r\n{\r\n    struct Net : torch::nn::Module\r\n    {\r\n        Net():\r\n        fc1(128, 256),\r\n        fc2(256, 1)\r\n        {\r\n            register_module(\"fc1\", fc1);\r\n            register_module(\"fc2\", fc2);\r\n            /* The following line will cause the error */\r\n            tmp = register_parameter(\"tmp\", torch::ones({1,1}), false);\r\n        }\r\n\r\n        torch::Tensor forward(torch::Tensor x)\r\n        {\r\n            x = torch::tanh(fc1->forward(x));\r\n            x = fc2->forward(x);\r\n            return x;\r\n        }\r\n\r\n        torch::nn::Linear fc1;\r\n        torch::nn::Linear fc2;\r\n        torch::Tensor tmp;\r\n    };\r\n\r\n    Net model;\r\n    int batchsize = 16;\r\n    int stop_epoch = 10;\r\n    torch::Tensor data = torch::randn({32, 128});\r\n    torch::Tensor target = torch::randn({32, 1});\r\n    auto dataset = torch::data::datasets::TEST_TensorDataset({data, target}).map(torch::data::transforms::Stack<>());\r\n    auto data_loader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(std::move(dataset), torch::data::DataLoaderOptions().batch_size(batchsize));\r\n    torch::optim::LBFGS optimizer_lbfgs = torch::optim::LBFGS(model.parameters(), torch::optim::LBFGSOptions(1E-2));\r\n    for (int epoch = 0; epoch <= stop_epoch - 1; epoch++)\r\n    {\r\n        int batch_idx = 0;\r\n        bool output_loss = true;\r\n        for (auto & batch : *data_loader)\r\n        {\r\n            output_loss = true;\r\n            auto closure = [&]()\r\n            {\r\n                model.zero_grad();\r\n                torch::Tensor target_net = model.forward(batch.data);\r\n                torch::Tensor loss = torch::mse_loss(target_net, batch.target);\r\n                loss.backward();\r\n                if (output_loss)\r\n                {\r\n                    std::cout << \"Epoch: \" << epoch << \" Batch: \" << batch_idx << \" loss: \" << loss << std::endl;\r\n                    output_loss = false;\r\n                }\r\n                return loss;\r\n            };\r\n            optimizer_lbfgs.step(closure);\r\n            batch_idx++;\r\n        }\r\n    }\r\n\r\n    return 0;\r\n}\r\n```\r\n\r\n## Expected behavior\r\n\r\nIf line 12 in the function **test()**: `tmp = register_parameter(\"tmp\", torch::ones({1,1}), false);` is commented out, then everything goes fine.\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): 1.2.0\r\n - OS (e.g., Linux): Ubuntu 16.04.6 LTS\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.5\r\n - CUDA/cuDNN version: 9.2/7.5\r\n - GPU models and configuration: GeForce GTX TITAN\r\n - Any other relevant information:\r\nGCC version: (Ubuntu 4.9.4-2ubuntu1~16.04) 4.9.4\r\nCMake version: version 3.15.2\r\n\n\ncc @yf225"},{"labels":["api",null],"text":"![image](https://user-images.githubusercontent.com/42128459/66465726-f57a7680-eab3-11e9-91f6-92840c57e70f.png)\r\n\r\nThe above is the data preprocessing stage. The batch input to the model is one.\r\nNow, I want to set batch to four, because will process four channels of video at the same time.\r\nHow should I do ? Hope get your help. Thank you !\n\ncc @yf225"},{"labels":["api",null],"text":"**Description**\r\nDocker (the service) accepts requests with \"Transfer-encoding: chunked\". However the authorization plugin doesn't: \r\nhttps://github.com/moby/moby/blob/master/pkg/authorization/authz.go#L58\r\nIt expects Content-Length to be set. If that header is not set (i.e. when transfer-encoding: chunked), it wrongly assumes a nil body. \r\n\r\nThis leads to issues with libraries such as docker-java and projects building on top of it such as testcontainers-java. Both supported clients in docker-java (okhttp and apache-http) are sending content with transfer-encoding: chunked. \r\n\r\n**Steps to reproduce the issue:**\r\n1. Setup an authorization plugin, e.g. https://github.com/ad-freiburg/docker-no-trivial-root \r\n2. Issue a create call with transfer-encoding: chunked (here with curl, simulating the docker-java code)\r\n```\r\ncurl -v -H 'Content-type: application/json' -H 'Transfer-encoding: chunked' localhost:2375/containers/create -d '{\"Image\": \"ubuntu:latest\"}'\r\n{\"message\":\"plugin no-trivial-root failed with error: AuthZPlugin.AuthZReq: unexpected end of JSON input\"}\r\n```\r\nAuthZ Request debug dump: \r\n``` (authorization.Request) {\r\n  User: (string) \"\",\r\n  UserAuthNMethod: (string) \"\",\r\n  RequestMethod: (string) (len=4) \"POST\",\r\n  RequestURI: (string) (len=18) \"/containers/create\",\r\n  RequestBody: ([]uint8) <nil>,\r\n  RequestHeaders: (map[string]string) (len=3) {\r\n   (string) (len=12) \"Content-Type\": (string) (len=16) \"application/json\",\r\n   (string) (len=10) \"User-Agent\": (string) (len=11) \"curl/7.47.0\",\r\n   (string) (len=6) \"Accept\": (string) (len=3) \"*/*\"\r\n  },\r\n  RequestPeerCertificates: ([]*authorization.PeerCertificate) <nil>,\r\n  ResponseStatusCode: (int) 0,\r\n  ResponseBody: ([]uint8) <nil>,\r\n  ResponseHeaders: (map[string]string) <nil>\r\n }\r\n```\r\nThe plugin failed to parse the request as it receives a nil request body (while it is not)\r\n\r\n**Expected:** \r\nIf docker is able to process a request, then the authorization plugin should be able to do so in the same way. In this case, I'd expect both calls to work equally (as they do with docker without authorization plugin: \r\n\r\n```\r\ncurl -v -H 'Content-type: application/json' -H 'Transfer-encoding: chunked' localhost:2375/containers/create -d '{\"Image\": \"ubuntu:latest\"}'\r\ncurl -v -H 'Content-type: application/json' localhost:2375/containers/create -d '{\"Image\": \"ubuntu:latest\"}'`\r\n```\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.8\r\n API version:       1.40\r\n Go version:        go1.12.17\r\n Git commit:        afacb8b7f0\r\n Built:             Wed Mar 11 01:25:58 2020\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.8\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.12.17\r\n  Git commit:       afacb8b7f0\r\n  Built:            Wed Mar 11 01:24:30 2020\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          1.2.13\r\n  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429\r\n runc:\r\n  Version:          1.0.0-rc10\r\n  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n```\r\nClient:\r\n Debug Mode: false\r\n\r\nServer:\r\n Containers: 87\r\n  Running: 5\r\n  Paused: 0\r\n  Stopped: 82\r\n Images: 112\r\n Server Version: 19.03.8\r\n Storage Driver: overlay2\r\n  Backing Filesystem: <unknown>\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: cgroupfs\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Authorization: no-trivial-root\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: inactive\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429\r\n runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd\r\n init version: fec3683\r\n Security Options:\r\n  apparmor\r\n  seccomp\r\n   Profile: default\r\n  userns\r\n Kernel Version: 4.4.0-187-generic\r\n Operating System: Ubuntu 16.04.7 LTS\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 2\r\n Total Memory: 3.842GiB\r\n Name: scl000102100\r\n ID: GETQ:2BEO:QTOR:FLGH:BSV4:5MTS:3LD2:7S3U:YFCW:CLIU:ZIRJ:6NLM\r\n Docker Root Dir: /var/lib/docker/16170.100000\r\n Debug Mode: true\r\n  File Descriptors: 53\r\n  Goroutines: 57\r\n  System Time: 2020-09-15T12:03:20.872834075+02:00\r\n  EventsListeners: 0\r\n HTTP Proxy: http://gate-zrh-os.swissre.com:8080/\r\n No Proxy: swissre.com\r\n Username: johannessr\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: false\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n\r\nWARNING: API is accessible on http://0.0.0.0:2375 without encryption.\r\n         Access to the remote API is equivalent to root access on the host. Refer\r\n         to the 'Docker daemon attack surface' section in the documentation for\r\n         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface\r\nWARNING: No swap limit support\r\n\r\n```\r\n"},{"labels":["api",null,null,null],"text":"**Description**\r\n\r\nThe SwarmJoin API supports `Availability` (https://github.com/moby/moby/blob/master/daemon/cluster/swarm.go#L147-L188), which the CLI client also uses, but it is not documented in the API docs (https://github.com/moby/moby/blob/master/api/swagger.yaml#L10008).\r\n"},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\nIn api document `/version` response looks like wrong.\r\nhttps://github.com/moby/moby/blob/master/docs/api/v1.40.yaml#L7715\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. `curl --unix-socket /var/run/docker.sock localhost/version`\r\n\r\n**Describe the results you received:**\r\n```\r\n{\r\n  \"Platform\": {\r\n    \"Name\": \"Docker Engine - Community\"\r\n  },\r\n  \"Components\": [\r\n    {\r\n      \"Name\": \"Engine\",\r\n      \"Version\": \"19.03.12\",\r\n      \"Details\": {\r\n        \"ApiVersion\": \"1.40\",\r\n        \"Arch\": \"amd64\",\r\n        \"BuildTime\": \"2020-06-22T15:44:07.000000000+00:00\",\r\n        \"Experimental\": \"false\",\r\n        \"GitCommit\": \"48a66213fe\",\r\n        \"GoVersion\": \"go1.13.10\",\r\n        \"KernelVersion\": \"5.3.0-62-generic\",\r\n        \"MinAPIVersion\": \"1.12\",\r\n        \"Os\": \"linux\"\r\n      }\r\n    },\r\n    ...\r\n  ],\r\n  \"Version\": \"19.03.12\",\r\n  \"ApiVersion\": \"1.40\",\r\n  \"MinAPIVersion\": \"1.12\",\r\n  \"GitCommit\": \"48a66213fe\",\r\n  \"GoVersion\": \"go1.13.10\",\r\n  \"Os\": \"linux\",\r\n  \"Arch\": \"amd64\",\r\n  \"KernelVersion\": \"5.3.0-62-generic\",\r\n  \"BuildTime\": \"2020-06-22T15:44:07.000000000+00:00\"\r\n}\r\n```\r\n\r\n**Describe the results you expected:**\r\nLooks like document is wrong.\r\nWe should update document?\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.12\r\n API version:       1.40\r\n Go version:        go1.13.10\r\n Git commit:        48a66213fe\r\n Built:             Mon Jun 22 15:45:36 2020\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.12\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.13.10\r\n  Git commit:       48a66213fe\r\n  Built:            Mon Jun 22 15:44:07 2020\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          1.2.13\r\n  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429\r\n runc:\r\n  Version:          1.0.0-rc10\r\n  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.12\r\n API version:       1.40\r\n Go version:        go1.13.10\r\n Git commit:        48a66213fe\r\n Built:             Mon Jun 22 15:45:36 2020\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.12\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.13.10\r\n  Git commit:       48a66213fe\r\n  Built:            Mon Jun 22 15:44:07 2020\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          1.2.13\r\n  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429\r\n runc:\r\n  Version:          1.0.0-rc10\r\n  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n[I] docker.vim )\r\n[I] docker.vim ) docker info\r\nClient:\r\n Debug Mode: false\r\n\r\nServer:\r\n Containers: 2\r\n  Running: 1\r\n  Paused: 0\r\n  Stopped: 1\r\n Images: 52\r\n Server Version: 19.03.12\r\n Storage Driver: overlay2\r\n  Backing Filesystem: extfs\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: cgroupfs\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: inactive\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429\r\n runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd\r\n init version: fec3683\r\n Security Options:\r\n  apparmor\r\n  seccomp\r\n   Profile: default\r\n Kernel Version: 5.3.0-62-generic\r\n Operating System: Ubuntu 18.04.4 LTS\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 8\r\n Total Memory: 31.09GiB\r\n Name: thinkpad\r\n ID: EKKH:UC2C:RDMA:JDP2:KDIG:GW2W:T2H3:S3LT:MWNI:D5YG:X24P:K2DC\r\n Docker Root Dir: /var/lib/docker\r\n Debug Mode: false\r\n Username: skanehira\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: false\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n\r\nWARNING: No swap limit support\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nOS: Ubuntu 18.04.01"},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\nHello !\r\n\r\nI have a issue with the Engine API.\r\nWhen I create a service using the API, the service label is created with weird escaped characters instead of my parenthesis. \r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a service with the API (formatted in JSON) and add parenthesis to a label.\r\n\r\n**Received result:**\r\n```\r\n \"traefik.http.routers.test.rule\": \"Headers%28`X-INSTANCE-ID`,`test`%29\",\r\n```\r\n\r\n**Expected result:**\r\n```\r\n \"traefik.http.routers.test.rule\": \"Headers(`X-INSTANCE-ID`,`test`)\",\r\n```\r\n**Additional information:**\r\nI've tried on two different servers, same bug...\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.3\r\n API version:       1.40\r\n Go version:        go1.12.10\r\n Git commit:        a872fc2f86\r\n Built:             Tue Oct  8 00:59:36 2019\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.3\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.12.10\r\n  Git commit:       a872fc2f86\r\n  Built:            Tue Oct  8 00:58:08 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          1.2.10\r\n  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339\r\n runc:\r\n  Version:          1.0.0-rc8+dev\r\n  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nClient:\r\n Debug Mode: false\r\n\r\nServer:\r\n Containers: 2\r\n  Running: 2\r\n  Paused: 0\r\n  Stopped: 0\r\n Images: 170\r\n Server Version: 19.03.3\r\n Storage Driver: overlay2\r\n  Backing Filesystem: extfs\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: cgroupfs\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: active\r\n  NodeID: szgmaj5mz8l5vffvfglf7kwxi\r\n  Is Manager: true\r\n  ClusterID: gqno1oih4phd70sciix2i10t7\r\n  Managers: 1\r\n  Nodes: 1\r\n  Default Address Pool: 10.0.0.0/8\r\n  SubnetSize: 24\r\n  Data Path Port: 4789\r\n  Orchestration:\r\n   Task History Retention Limit: 5\r\n  Raft:\r\n   Snapshot Interval: 10000\r\n   Number of Old Snapshots to Retain: 0\r\n   Heartbeat Tick: 1\r\n   Election Tick: 10\r\n  Dispatcher:\r\n   Heartbeat Period: 5 seconds\r\n  CA Configuration:\r\n   Expiry Duration: 3 months\r\n   Force Rotate: 0\r\n  Autolock Managers: false\r\n  Root Rotation In Progress: false\r\n  Node Address: 192.168.152.129\r\n  Manager Addresses:\r\n   192.168.152.129:2377\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339\r\n runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657\r\n init version: fec3683\r\n Security Options:\r\n  seccomp\r\n   Profile: default\r\n Kernel Version: 4.9.0-7-amd64\r\n Operating System: Debian GNU/Linux 9 (stretch)\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 2\r\n Total Memory: 3.845GiB\r\n Name: bde-backoffice\r\n ID: MPE2:TUTT:TGYF:5XDK:6UQK:RJCG:E2DD:3QW6:DO5Q:UC6V:CNUV:RT6O\r\n Docker Root Dir: /var/lib/docker\r\n Debug Mode: false\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: false\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n\r\nWARNING: No swap limit support\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nDebian 9.6 x64\r\n"},{"labels":["api",null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nDocker introduced the `--gpus` option with 19.03, which enables first class GPU support inside docker. Unfortunately this option doesn't seem to be available using the Docker API v1.40 (most likely should be located inside the HostOptions when creating the container, for reference this is what the current docs state [DOCS](https://docs.docker.com/engine/api/v1.40/#operation/ContainerCreate))\r\n\r\nAlso the changelogs for version 1.40, didnt seem to include a change supporting this case.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Try to launch a container using the new GPU option using the Docker API\r\n\r\n**Describe the results you received:**\r\nOption not available using the API\r\n\r\n**Describe the results you expected:**\r\nOption to be available using the API\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n```\r\n\r\nClient:\r\n Version:           19.03.6\r\n API version:       1.40\r\n Go version:        go1.12.17\r\n Git commit:        369ce74a3c\r\n Built:             Fri Feb 28 23:45:43 2020\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer:\r\n Engine:\r\n  Version:          19.03.6\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.12.17\r\n  Git commit:       369ce74a3c\r\n  Built:            Wed Feb 19 01:06:16 2020\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          1.3.3-0ubuntu1~18.04.2\r\n  GitCommit:        \r\n runc:\r\n  Version:          spec: 1.0.1-dev\r\n  GitCommit:        \r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:   \r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nClient:\r\n Debug Mode: false\r\n\r\nServer:\r\n Containers: 12\r\n  Running: 0\r\n  Paused: 0\r\n  Stopped: 12\r\n Images: 268\r\n Server Version: 19.03.6\r\n Storage Driver: overlay2\r\n  Backing Filesystem: extfs\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: cgroupfs\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: inactive\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: \r\n runc version: \r\n init version: \r\n Security Options:\r\n  apparmor\r\n  seccomp\r\n   Profile: default\r\n Kernel Version: 5.3.0-61-generic\r\n Operating System: Ubuntu 18.04.4 LTS\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 12\r\n Total Memory: 31.29GiB\r\n Name: tanuki\r\n ID: MGDH:HBPR:BX2D:35L4:CRTC:7K34:D6QG:MCJZ:SYJC:GSBV:SWFF:NIEF\r\n Docker Root Dir: /var/lib/docker\r\n Debug Mode: false\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: false\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n\r\nWARNING: No swap limit support\r\n```\r\n"},{"labels":["api"],"text":"Currently API routers are responsible for transforming requests based upon API version, however this has lead to host specific details leaking into the http router.\r\nWe also don't really want API version specific details leaking into the implementation.\r\n\r\nI propose that we add a shim here so that transformations can be made after the request is routed.\r\nThis could look something like:\r\n\r\n```go\r\n// the API router\r\nfunc(r *fooRouter) createFoo(ctx context.Context, w http.Response, req *http.Request) {\r\n  // make a fooConfig from the reuqest\r\n  r.backend.Create(ctx, fooConfig)\r\n}\r\n```\r\n\r\n```go\r\nfunc(b *fooBackend) Create(ctx context.Context, fooConfig Config) {\r\n    b.transform.Create(ctx, &fooConfig)\r\n}\r\n```\r\n\r\n```go\r\nfunc(t *fooTransformer) Create(ctx context.Context, fooConfig) {\r\n  ver := getApiVersion(ctx)\r\n  if ver.LessThan(\"1.2\") {\r\n      // set some value\r\n  }\r\n}\r\n```\r\n\r\nThen the transformer can be configured with host specific details rather than relying on the HTTP router to have these details.\r\nIt also seems like it makes it easier to unit test such transformations."},{"labels":["api",null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nDocker is expected to unshare cgroup namespace by default on cgroup v2 hosts.\r\nHowever, the cgroup namespace is not unshared when a container was created by an older API client.\r\n\r\n\r\n**Steps to reproduce the issue:**\r\nInspect the host cgroup namespace (4026531835):\r\n```console\r\n$ sudo ls -l /proc/1/ns/cgroup\r\nlrwxrwxrwx 1 root root 0 Jun  5 16:36 /proc/1/ns/cgroup -> 'cgroup:[4026531835]'\r\n```\r\n\r\nAPI 1.41 creates a container with a new namespace (4026533000) as expected:\r\n```console\r\n$ DOCKER_API_VERSION=1.41 docker run --rm alpine ls -l /proc/1/ns/cgroup\r\nlrwxrwxrwx    1 root     root             0 Jun  5 07:36 /proc/1/ns/cgroup -> cgroup:[4026533000]\r\n```\r\n\r\nOTOH API 1.40 creates a container with the host cgroup namespace (4026531835):\r\n```console\r\n$ DOCKER_API_VERSION=1.40 docker run --rm alpine ls -l /proc/1/ns/cgroup\r\nlrwxrwxrwx    1 root     root             0 Jun  5 07:36 /proc/1/ns/cgroup -> cgroup:[4026531835]\r\n```\r\n\r\n**Describe the results you received:**\r\nAPI 1.40 creates a container with the host cgroup namespace (4026531835).\r\n\r\n**Describe the results you expected:**\r\nA new cgroup namespace should be always created by default on cgroup v2 hosts..\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:           20.03.0-dev\r\n API version:       1.41\r\n Go version:        go1.13.11\r\n Git commit:        8f14db8df\r\n Built:             Fri Jun  5 07:30:25 2020\r\n OS/Arch:           linux/amd64\r\n Context:           default\r\n Experimental:      true\r\n\r\nServer:\r\n Engine:\r\n  Version:          dev\r\n  API version:      1.41 (minimum version 1.12)\r\n  Go version:       go1.13.11\r\n  Git commit:       fa38a6cd21\r\n  Built:            Fri Jun  5 07:28:36 2020\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     true\r\n containerd:\r\n  Version:          v1.4.0-beta.1-18-g38cb1c1a\r\n  GitCommit:        38cb1c1a54e3180edd29933974d715b69334f0f1\r\n runc:\r\n  Version:          1.0.0-rc10+dev\r\n  GitCommit:        2a0466958d9af23af2ad12bd79d06ed0af4091e2\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nClient:\r\n Context:    default\r\n Debug Mode: false\r\n Plugins:\r\n  buildx: Build with BuildKit (Docker Inc., v0.4.1)\r\n\r\nServer:\r\n Containers: 1\r\n  Running: 1\r\n  Paused: 0\r\n  Stopped: 0\r\n Images: 4\r\n Server Version: dev\r\n Storage Driver: overlay2\r\n  Backing Filesystem: extfs\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: systemd\r\n Cgroup Version: 2\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: inactive\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: 38cb1c1a54e3180edd29933974d715b69334f0f1\r\n runc version: 2a0466958d9af23af2ad12bd79d06ed0af4091e2\r\n init version: fec3683\r\n Security Options:\r\n  apparmor\r\n  seccomp\r\n   Profile: default\r\n  cgroupns\r\n Kernel Version: 5.4.0-33-generic\r\n Operating System: Ubuntu 20.04 LTS\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 2\r\n Total Memory: 7.748GiB\r\n Name: suda-ws01\r\n ID: E2YB:EGZO:6BNW:EPHS:4WFQ:EIDV:ZZ6D:QBZK:6673:CIOR:DLZ6:SI3D\r\n Docker Root Dir: /var/lib/docker\r\n Debug Mode: true\r\n  File Descriptors: 32\r\n  Goroutines: 56\r\n  System Time: 2020-06-05T16:42:51.430978282+09:00\r\n  EventsListeners: 0\r\n Username: akihirosuda\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: true\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n\r\nWARNING: No kernel memory limit support\r\nWARNING: No kernel memory TCP limit support\r\nWARNING: No oom kill disable support\r\nWARNING: Support for cgroup v2 is experimental\r\n```\r\n\r\n"},{"labels":["api",null],"text":"https://docs.docker.com/engine/api/v1.40/#operation/ContainerStats\r\n\"read\": \"2015-01-08T22:57:31.547920715Z\"\r\nIn fact: \"read\":\"2020-03-04T14:59:28.0520539+03:00\".\r\n![image](https://user-images.githubusercontent.com/47747798/82048203-e3515e00-96bc-11ea-999d-65ebbdfb1bba.png)\r\n\r\nHost - Windows Server 2019\r\nhttps://github.com/docker/for-win/issues/5942"},{"labels":["api",null,null],"text":"---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\n**Description**\r\nCurrently using the Docker SDK for GO to build and push images to ECR on Amazon. Whenever i call ImagePush, if i don't take io.ReadCloser and read from it to the end, my images will not appear on ECR. If i do something simple as:\r\n\r\n```go\r\nio.Copy(ioutil.Discard, imagePushResult)\r\n```\r\nit works. \r\n\r\n**Steps to reproduce the issue:**\r\n1. Call ImagePush to push image to ECR repo (have not tried with other repos)\r\n2. Return after the call and don't bother with the io.ReadCloser returned by ImagePush\r\n3. The image will not appear on the repository\r\n\r\n**Describe the results you received:**\r\n\r\n\r\n**Describe the results you expected:**\r\nI expected the image to be on the repo regardless of how i handle the retured io.ReasCloser. \r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.5\r\n API version:       1.40\r\n Go version:        go1.12.12\r\n Git commit:        633a0ea\r\n Built:             Wed Nov 13 07:22:34 2019\r\n OS/Arch:           darwin/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.5\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.12.12\r\n  Git commit:       633a0ea\r\n  Built:            Wed Nov 13 07:29:19 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          v1.2.10\r\n  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339\r\n runc:\r\n  Version:          1.0.0-rc8+dev\r\n  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nClient:\r\n Debug Mode: false\r\n\r\nServer:\r\n Containers: 19\r\n  Running: 0\r\n  Paused: 0\r\n  Stopped: 19\r\n Images: 5\r\n Server Version: 19.03.5\r\n Storage Driver: overlay2\r\n  Backing Filesystem: extfs\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: cgroupfs\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: inactive\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339\r\n runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657\r\n init version: fec3683\r\n Security Options:\r\n  seccomp\r\n   Profile: default\r\n Kernel Version: 4.19.76-linuxkit\r\n Operating System: Docker Desktop\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 4\r\n Total Memory: 1.943GiB\r\n Name: docker-desktop\r\n ID: SGU4:RG3S:FZPA:P67C:J3PQ:3WV5:T522:DART:YO5Y:J2VI:MSLA:JY7V\r\n Docker Root Dir: /var/lib/docker\r\n Debug Mode: true\r\n  File Descriptors: 33\r\n  Goroutines: 60\r\n  System Time: 2020-02-22T19:29:09.8248016Z\r\n  EventsListeners: 3\r\n HTTP Proxy: gateway.docker.internal:3128\r\n HTTPS Proxy: gateway.docker.internal:3129\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: false\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n Product License: Community Engine\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nPushing the images to AWS.\r\n"},{"labels":["api",null],"text":"A long long time ago (in this galaxy, though), we added support for container stats.\r\nThe API was designed to just push stats at an interval until the client disconnects.\r\n\r\nNot too much later, people were wanting to be able to just fetch a single set of stats and be done with it, so we added a query param `stream=false`, which makes dockerd hang up after a single stat is sent. Not the best naming but it did what it needed to do.\r\n\r\nBut then, oh no... now the docker CLI, when using `--no-stream`, always shows 0% CPU usage because there was only 1 CPU stat and nothing compare CPU usage with. It was decided to collect 2 stats instead of just 1 so that the client can calculate the usage.\r\n\r\nFast forward to where we are now....\r\n\r\nHere we have a problem. Any tool wanting to sample docker takes 2x as long (nearly 2 seconds) to collect per container than before the mentioned change (which admittedly was years ago).\r\nMeanwhile every sampling tool is just going to sample as often as it needs to and calculate usage from there and does not care about the primed stats.\r\n\r\nIt would have been nice if we changed the CLI to make 2 collections rather than expecting the engine to do this for them. It wasn't a breaking change to make the engine do 2 collections, but certainly seems (or at least requiring an API bump) to backtrack and only take 1 collection.\r\n\r\nI was hoping to make a patch to work around this problem but I can't really think of one that doesn't involve bumping the API... save for probably a long shot where we could change the engine to accept more than just true/false from the query param (`?stream=`)... but even this could only be taken advantage of by a custom client lib, not the official one because that is accepting a bool in the function arguments.\r\n\r\nSo opening this as an intention to fix this, and also to solicit feedback for ideas we could do possibly as a back-portable patch."},{"labels":["api",null,null,null,null],"text":"The `publish` filter looks to be filtering on the wrong values (and the `TestPsListContainersFilterPorts ` is incorrect); see https://github.com/moby/moby/pull/27557#issuecomment-578016663\r\n\r\nCreate some containers;\r\n\r\n\r\n```bash\r\ndocker run -d --name test_no_ports nginx:alpine\r\ndocker run -d --name test_port_1080 -p 1080:80 nginx:alpine\r\ndocker run -d --name test_port_1090 -p 1090:80 nginx:alpine\r\ndocker run -d --name test_port_80_random -p 80 nginx:alpine\r\ndocker run -d --name test_port_all_random -P nginx:alpine\r\n\r\n\r\ndocker ps --filter name=test_\r\n\r\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                   NAMES\r\n3ce8232cdd04        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   6 seconds ago       Up 6 seconds        0.0.0.0:32775->80/tcp   test_port_all_random\r\n7f8fad7a0eb9        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   7 seconds ago       Up 6 seconds        0.0.0.0:32774->80/tcp   test_port_80_random\r\n3870ccc2f8f7        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   7 seconds ago       Up 6 seconds        0.0.0.0:1090->80/tcp    test_port_1090\r\naa565211513e        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   8 seconds ago       Up 7 seconds        0.0.0.0:1080->80/tcp    test_port_1080\r\nc4a1c6e0e99b        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   8 seconds ago       Up 7 seconds        80/tcp                  test_no_ports\r\n```\r\n\r\nFiltering on the \"exposed\" port works:\r\n\r\n```bash\r\ndocker ps --filter name=test_ --filter expose=80\r\n\r\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                   NAMES\r\n3ce8232cdd04        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   20 seconds ago      Up 19 seconds       0.0.0.0:32775->80/tcp   test_port_all_random\r\n7f8fad7a0eb9        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   21 seconds ago      Up 20 seconds       0.0.0.0:32774->80/tcp   test_port_80_random\r\n3870ccc2f8f7        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   21 seconds ago      Up 20 seconds       0.0.0.0:1090->80/tcp    test_port_1090\r\naa565211513e        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   22 seconds ago      Up 20 seconds       0.0.0.0:1080->80/tcp    test_port_1080\r\nc4a1c6e0e99b        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   22 seconds ago      Up 21 seconds       80/tcp                  test_no_ports\r\n\r\ndocker ps --filter name=test_ --filter expose=90\r\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\r\n```\r\n\r\nFiltering on the \"published\" port doesn't (trying some variations below):\r\n\r\n```bash\r\ndocker ps --filter name=test_ --filter publish=1080\r\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                 NAME\r\n\r\n\r\ndocker ps --filter name=test_ --filter publish=1080/tcp\r\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                 NAMES\r\n\r\ndocker ps --filter name=test_ --filter publish=1080/udp\r\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                 NAMES\r\n```\r\n\r\nHowever, using the \"exposed\" port number instead of the \"published\" port shows _some_ results:\r\n\r\n\r\n```bash\r\ndocker ps --filter name=test_ --filter publish=80\r\nCONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS                   NAMES\r\n7f8fad7a0eb9        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   About a minute ago   Up About a minute   0.0.0.0:32774->80/tcp   test_port_80_random\r\n3870ccc2f8f7        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   About a minute ago   Up About a minute   0.0.0.0:1090->80/tcp    test_port_1090\r\naa565211513e        nginx:alpine        \"nginx -g 'daemon of‚Ä¶\"   About a minute ago   Up About a minute   0.0.0.0:1080->80/tcp    test_port_1080\r\n```\r\n\r\nIt appears it's filtering on the wrong value; also, the container with \"random\" port-mapping for all ports is missing in this case (perhaps it's filtering on ports that were _explicitly_ configured to be published?)\r\n\r\n\r\nNote that the `TestPsListContainersFilterPorts` test-case doesn't appear to catch this issue because it appears to be filtering on port `80` (which is published to a _random_ port);\r\n\r\nhttps://github.com/moby/moby/blob/b95fad8e51bd064be4f4e58a996924f343846c85/integration-cli/docker_cli_ps_test.go#L809-L832\r\n\r\n\r\n```bash\r\ndocker run -d --publish 80 busybox top\r\n537c87330e660cc4d7a7426dcddd771a3b1bb3f7c21c7750a4b1a3358e976b1c\r\n\r\ndocker ps --filter publish=80\r\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                   NAMES\r\n537c87330e66        busybox             \"top\"                    19 seconds ago      Up 18 seconds       0.0.0.0:32776->80/tcp   sleepy_khorana\r\n...\r\n```"},{"labels":["api"],"text":"<!-- Download Docker Desktop 'Edge' (latest build) here: https://hub.docker.com/editions/community/docker-ce-desktop-windows -->\r\n  - [x] I have tried with the latest version of my channel (Stable or Edge)\r\n  - [x] I have uploaded Diagnostics\r\n  - Diagnostics ID: 17E86123-291D-4E3C-8572-433BD0017ADA/20200108195342\r\n\r\n### Expected behavior\r\nchunk contains CRLF at the end of stream\r\n\r\n### Actual behavior\r\nthere is only LF on windows\r\n\r\n### Steps to reproduce the behavior\r\nsee https://github.com/docker-java/docker-java/issues/698#issuecomment-572228590 for steps to reproduce\r\n\r\nEDIT: I have updated original \"docker-java\" issue, seems no problem anymore. Sorry for that."},{"labels":["api",null,null,null],"text":"I noticed that we still have some old release branches in this repository. Some of those branches have changes that never made it into a release (or documentation cherry-picks that were published in the documentation, but not tagged as a release)\r\n\r\n\r\nBranch                                               | Changes not in a release\r\n-----------------------------------------------------|--------------------------------------------------------------\r\n[1.12.x](https://github.com/moby/moby/tree/1.12.x)   | https://github.com/moby/moby/compare/v1.12.6...1.12.x\r\n[1.13.x](https://github.com/moby/moby/tree/1.13.x)   | https://github.com/moby/moby/compare/v1.13.1...1.13.x\r\n[17.03.x](https://github.com/moby/moby/tree/17.03.x) | https://github.com/moby/moby/compare/v17.03.2-ce...17.03.x\r\n[17.04.x](https://github.com/moby/moby/tree/17.04.x) | https://github.com/moby/moby/compare/v17.04.0-ce...17.04.x\r\n[17.05.x](https://github.com/moby/moby/tree/17.05.x) | https://github.com/moby/moby/compare/v17.05.0-ce...17.05.x (no diff)\r\n[docs](https://github.com/moby/moby/tree/docs)       | documentation-only changes\r\n\r\n\r\nSome care should be taken when removing these branches, because the docker documentation fetches some resources from some of these branches; https://github.com/docker/docker.github.io/blob/ec57364ede82a135021e2e762bd0833d92a0cc0f/_scripts/fetch-upstream-resources.sh#L74 https://github.com/docker/docker.github.io/blob/ec57364ede82a135021e2e762bd0833d92a0cc0f/_scripts/fetch-upstream-resources.sh#L89-L95\r\n\r\n\r\nIn addition, with the introduction of the Swagger file (which is used to document current versions of the API), this repository only has a definition of the _current_ version of the API. Older versions of the API need to be fetched from either tags in various repositories, or from release-branches in those repositories. Having those files spread in various locations makes building the docs complicated, but also makes it more difficult to _compare_ changes between API versions, or to make fixes to the API documentation (if there's a bug or missing documentation in existing API versions).\r\n\r\nI'm planning to add copies of the swagger.yml for each API version. in this repository to address that.\r\n\r\n- [x] update docker-ce-packaging to build from upstream repositories instead of the mono-repo; https://github.com/docker/docker-ce-packaging/pull/449\r\n    - note: more changes needed in the private release packaging repositories, but those are tracked separately\r\n- [x] update fetch-upstream-resources.sh script in documentation repository to not depend on these branches (https://github.com/docker/docker.github.io/pull/10101)\r\n    - [x] https://github.com/docker/docker.github.io/pull/10343 Engine API: use template for API reference pages\r\n    - [x] https://github.com/docker/docker.github.io/pull/10348 Simplify use of \"ENGINE_BRANCH\" and \"DISTRIBUTION_BRANCH\"\r\n    - [x] https://github.com/docker/docker.github.io/pull/10344 [WIP] simplify fetching API versions\r\n    - [x] https://github.com/docker/docker.github.io/pull/10578 Engine API: remove per-branch fetching of API docs\r\n- [x] backport fetch-upstream-resources.sh changes to documentation archive branches\r\n    - [x] v18.09 archive branch https://github.com/docker/docker.github.io/pull/10196\r\n    - [x] v18.03 archive branch https://github.com/docker/docker.github.io/pull/10349\r\n    - [x] ~v17.12 archive branch~ won't fix\r\n    - [x] ~v17.09 archive branch~ won't fix\r\n    - [x] ~v17.06 archive branch~ won't fix\r\n    - [x] ~v17.03 archive branch~ won't fix\r\n    - [x] ~v1.13 archive branch~ won't fix\r\n- [x] add a copy of the swagger.yml for each released version of the API\r\n    - [x] v1.40 - docker v19.03 https://github.com/moby/moby/pull/40570 \r\n    - [x] v1.39 - docker v18.09 https://github.com/moby/moby/pull/40570 \r\n    - [x] v1.38 - docker v18.06 https://github.com/moby/moby/pull/40570 \r\n    - [x] v1.37 - docker v18.03 - v18.05 https://github.com/moby/moby/pull/40778\r\n    - [x] v1.36 - docker v18.02 https://github.com/moby/moby/pull/40778\r\n    - [x] v1.35 - docker v17.12 - v18.01 https://github.com/moby/moby/pull/40778\r\n    - [x] v1.34 - docker v17.11 https://github.com/moby/moby/pull/40778\r\n    - [x] v1.33 - docker v17.10 https://github.com/moby/moby/pull/40778\r\n    - [x] v1.32 - docker v17.09 https://github.com/moby/moby/pull/40778\r\n    - [x] v1.31 - docker v17.07 https://github.com/moby/moby/pull/40778\r\n    - [x] v1.30 - docker v17.06 https://github.com/moby/moby/pull/40778\r\n    - [x] v1.29 - docker v17.05 https://github.com/moby/moby/pull/40570 \r\n    - [x] v1.28 - docker v17.04 https://github.com/moby/moby/pull/40570 \r\n    - [x] v1.27 - docker v17.03 https://github.com/moby/moby/pull/40570 \r\n    - [x] v1.26 - docker v1.13.1 https://github.com/moby/moby/pull/40570 \r\n    - [x] v1.25 - docker v1.13.0 https://github.com/moby/moby/pull/40570 \r\n- [x] cherry-pick copy of swagger.yaml to current release branch\r\n    - [x] https://github.com/moby/moby/pull/40575 [19.03 backport] docs: add API versions v1.25 - v1.29, v1.38 - v1.40\r\n    - [x] https://github.com/moby/moby/pull/40779 [19.03 backport] docs: add API versions v1.30 - v1.37\r\n- [x] ~remove unused release-branches~ we can't update all archives, so we may want to keep the old branches (but eventually, \"archive\" the docker/docker-ce repository once it's no longer used in the build pipeline\r\n"},{"labels":["api",null],"text":"The `docker inspect` documentation doesn't describe the `Health` object being returned once healthchecks are configured.\r\n\r\n\r\n**Steps to reproduce the issue:**\r\n1. `docker run -it --rm nginx`\r\n2. _docker inspect_ the container: `docker inspect --format '{{json .State.Health }}' ` and observe `null` according to the documentation (since the field doesn't exist). \r\n3. `docker run -it --rm --health-cmd=\"exit 0\" nginx`\r\n4. _docker inspect_ the container: `docker inspect --format '{{json .State.Health }}' ` and observe a valid JSON:\r\n\r\n `{\"Status\":\"healthy\",\"FailingStreak\":0,\"Log\":[{\"Start\":\"2019-12-22T10:59:05.6385933Z\",\"End\":\"2019-12-22T10:59:05.8078452Z\",\"ExitCode\":0,\"Output\":\"\"}]}`\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.5\r\n API version:       1.40\r\n Go version:        go1.12.12\r\n Git commit:        633a0ea\r\n Built:             Wed Nov 13 07:22:34 2019\r\n OS/Arch:           darwin/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.5\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.12.12\r\n  Git commit:       633a0ea\r\n  Built:            Wed Nov 13 07:29:19 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          v1.2.10\r\n  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339\r\n runc:\r\n  Version:          1.0.0-rc8+dev\r\n  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nClient:\r\n Debug Mode: false\r\n\r\nServer:\r\n Containers: 2\r\n  Running: 2\r\n  Paused: 0\r\n  Stopped: 0\r\n Images: 51\r\n Server Version: 19.03.5\r\n Storage Driver: overlay2\r\n  Backing Filesystem: extfs\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: cgroupfs\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: inactive\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339\r\n runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657\r\n init version: fec3683\r\n Security Options:\r\n  seccomp\r\n   Profile: default\r\n Kernel Version: 4.9.184-linuxkit\r\n Operating System: Docker Desktop\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 4\r\n Total Memory: 4.833GiB\r\n Name: docker-desktop\r\n ID: CBCJ:MNIU:ICXC:77PL:YXBA:K5EF:NE3L:5OHR:BIE4:TFOW:G4BB:2A2N\r\n Docker Root Dir: /var/lib/docker\r\n Debug Mode: false\r\n HTTP Proxy: gateway.docker.internal:3128\r\n HTTPS Proxy: gateway.docker.internal:3129\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: false\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n Product License: Community Engine\r\n```\r\n"},{"labels":["api",null,null],"text":"I found this issue(https://github.com/docker/cli/issues/2071) in the cli repository but tracked the source of the issue here. I'm just going to copy/paste the original issue description as its still relevant. \r\n\r\n> **Description**\r\n> \r\n> The [documentation for `docker system prune` on 19.03](https://docs.docker.com/engine/reference/commandline/system_prune/) states that the `until` filter supports timestamps, but it doesn't work.\r\n> \r\n> **Steps to reproduce the issue:**\r\n> \r\n>     1. Run `docker system prune --force --all --filter \"until=2006-01-02T15:04:05\"`\r\n> \r\n> \r\n> **Describe the results you received:**\r\n> \r\n> ```\r\n> Error response from daemon: failed to prune build cache: \"until\" filter expects a duration (e.g., '24h'): time: unknown unit - in duration 2006-01-02T15:04:05\r\n> ```\r\n> \r\n> **Describe the results you expected:**\r\n> The prune to work with the timestamp.\r\n> \r\n> **Output of `docker version`:**\r\n> \r\n> ```\r\n> Client: Docker Engine - Community\r\n>  Version:           19.03.1\r\n>  API version:       1.40\r\n>  Go version:        go1.12.5\r\n>  Git commit:        74b1e89\r\n>  Built:             Thu Jul 25 21:22:03 2019\r\n>  OS/Arch:           linux/amd64\r\n>  Experimental:      false\r\n> \r\n> Server: Docker Engine - Community\r\n>  Engine:\r\n>   Version:          19.03.1\r\n>   API version:      1.40 (minimum version 1.12)\r\n>   Go version:       go1.12.5\r\n>   Git commit:       74b1e89\r\n>   Built:            Thu Jul 25 21:20:35 2019\r\n>   OS/Arch:          linux/amd64\r\n>   Experimental:     false\r\n>  containerd:\r\n>   Version:          1.2.6\r\n>   GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb\r\n>  runc:\r\n>   Version:          1.0.0-rc8\r\n>   GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f\r\n>  docker-init:\r\n>   Version:          0.18.0\r\n>   GitCommit:        fec3683\r\n> ```\r\n> \r\n> **Output of `docker info`:**\r\n> \r\n> ```\r\n> Client:\r\n>  Debug Mode: false\r\n> \r\n> Server:\r\n>  Containers: 42\r\n>   Running: 0\r\n>   Paused: 0\r\n>   Stopped: 42\r\n>  Images: 144\r\n>  Server Version: 19.03.1\r\n>  Storage Driver: aufs\r\n>   Root Dir: /var/lib/docker/aufs\r\n>   Backing Filesystem: extfs\r\n>   Dirs: 611\r\n>   Dirperm1 Supported: true\r\n>  Logging Driver: json-file\r\n>  Cgroup Driver: cgroupfs\r\n>  Plugins:\r\n>   Volume: local\r\n>   Network: bridge host ipvlan macvlan null overlay\r\n>   Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n>  Swarm: inactive\r\n>  Runtimes: runc\r\n>  Default Runtime: runc\r\n>  Init Binary: docker-init\r\n>  containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb\r\n>  runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f\r\n>  init version: fec3683\r\n>  Security Options:\r\n>   apparmor\r\n>   seccomp\r\n>    Profile: default\r\n>  Kernel Version: 4.19.0-5-amd64\r\n>  Operating System: Debian GNU/Linux 10 (buster)\r\n>  OSType: linux\r\n>  Architecture: x86_64\r\n>  CPUs: 12\r\n>  Total Memory: 15.62GiB\r\n>  Name: server123\r\n>  ID: ZSS4:GQ3D:IWCX:FTWI:WBPU:7X4W:AMW7:6JWJ:ISPK:PSBG:HZXH:J6MU\r\n>  Docker Root Dir: /var/lib/docker\r\n>  Debug Mode: false\r\n>  Registry: https://index.docker.io/v1/\r\n>  Labels:\r\n>  Experimental: false\r\n>  Insecure Registries:\r\n>   127.0.0.0/8\r\n>  Live Restore Enabled: false\r\n> \r\n> WARNING: the aufs storage-driver is deprecated, and will be removed in a future release.\r\n> ```\r\n"},{"labels":["api",null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\nCurrently attempting to use ansibles [`docker_image` module](https://docs.ansible.com/ansible/latest/modules/docker_image_module.html#requirements) (which in turn uses do [Docker SDK for python](https://github.com/docker/docker-py)) and was was seeing success in our log, but the image never got updated.  After much digging, we finally discovered the cause was that the [Docker API call](https://docs.docker.com/engine/api/v1.30/#operation/ImageLoad) is supposed to return a 500 on failure, but instead returns a 200.  Details are described in [this other issue](https://github.com/docker/docker-py/issues/1488#issuecomment-554666565).\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. Fill up filesystem \r\n2. Invoke the [ImageLoad](https://docs.docker.com/engine/api/v1.30/#operation/ImageLoad) endpoint\r\n3. See HTTP 200\r\n\r\n**Describe the results you received:**\r\nHTTP 200\r\n\r\n**Describe the results you expected:**\r\nHTTP 500\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:         1.13.1\r\n API version:     1.26\r\n Package version: docker-1.13.1-103.git7f2769b.el7.centos.x86_64\r\n Go version:      go1.10.3\r\n Git commit:      7f2769b/1.13.1\r\n Built:           Sun Sep 15 14:06:47 2019\r\n OS/Arch:         linux/amd64\r\n\r\nServer:\r\n Version:         1.13.1\r\n API version:     1.26 (minimum version 1.12)\r\n Package version: docker-1.13.1-103.git7f2769b.el7.centos.x86_64\r\n Go version:      go1.10.3\r\n Git commit:      7f2769b/1.13.1\r\n Built:           Sun Sep 15 14:06:47 2019\r\n OS/Arch:         linux/amd64\r\n Experimental:    false\r\n\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 1\r\n Running: 1\r\n Paused: 0\r\n Stopped: 0\r\nImages: 1\r\nServer Version: 1.13.1\r\nStorage Driver: overlay2\r\n Backing Filesystem: xfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: journald\r\nCgroup Driver: systemd\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: docker-runc runc\r\nDefault Runtime: docker-runc\r\nInit Binary: /usr/libexec/docker/docker-init-current\r\ncontainerd version:  (expected: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1)\r\nrunc version: 9c3c5f853ebf0ffac0d087e94daef462133b69c7 (expected: 9df8b306d01f59d3a8029be411de015b7304dd8f)\r\ninit version: fec3683b971d9c3ef73f284f176672c44b448662 (expected: 949e6facb77383876aeff8a6944dde66b3089574)\r\nSecurity Options:\r\n seccomp\r\n  WARNING: You're not using the default seccomp profile\r\n  Profile: /etc/docker/seccomp.json\r\n selinux\r\nKernel Version: 3.10.0-957.27.2.el7.x86_64\r\nOperating System: CentOS Linux 7 (Core)\r\nOSType: linux\r\nArchitecture: x86_64\r\nNumber of Docker Hooks: 3\r\nCPUs: 2\r\nTotal Memory: 3.699 GiB\r\nName: example.local\r\nID: 2UGF:JTKQ:JC6Y:5YIB:NGUF:ESNS:RWQQ:MPIY:3S4S:WHU5:7MPB:EHLR\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\nRegistries: docker.io (secure)\r\n\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null,null,null,null],"text":"**Description**\r\n\r\nVolume create event is emitted on `docker create` independently if volume already exists. I would expect a single volume create event since I 've created the volume myself prior to creating the container.\r\n\r\nAccording to my tests, this started happening after 18.03.1 (excluding) and 18.06.3 (including) and it is reproducible up to and including 19.03.2.\r\n\r\n**Steps to reproduce the issue:**\r\n1. `docker events` (on another terminal)\r\n2. `docker create volume foo`\r\n3. `docker run -v foo:/bar busybox` \r\n\r\n**Describe the results you received:**\r\n\r\n```\r\n2019-10-06T17:33:50.529598724+03:00 volume create foo (driver=local)\r\n2019-10-06T17:34:06.642690750+03:00 volume create foo (driver=local)\r\n2019-10-06T17:34:06.673619523+03:00 container create 0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358 (image=busybox, name=great_poitras)\r\n2019-10-06T17:34:06.678983859+03:00 container attach 0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358 (image=busybox, name=great_poitras)\r\n2019-10-06T17:34:06.732641855+03:00 network connect 92b1bfd9f57ce29a27127d07ee8268a04b2ce5c35b3472960f73858fa0642c4b (container=0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358, name=bridge, type=bridge)\r\n2019-10-06T17:34:06.741265314+03:00 volume mount foo (container=0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358, destination=/bar, driver=local, propagation=, read/write=true)\r\n```\r\n\r\n**Describe the results you expected:**\r\n```\r\n2019-10-06T17:33:50.529598724+03:00 volume create foo (driver=local)\r\n2019-10-06T17:34:06.673619523+03:00 container create 0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358 (image=busybox, name=great_poitras)\r\n2019-10-06T17:34:06.678983859+03:00 container attach 0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358 (image=busybox, name=great_poitras)\r\n2019-10-06T17:34:06.732641855+03:00 network connect 92b1bfd9f57ce29a27127d07ee8268a04b2ce5c35b3472960f73858fa0642c4b (container=0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358, name=bridge, type=bridge)\r\n2019-10-06T17:34:06.741265314+03:00 volume mount foo (container=0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358, destination=/bar, driver=local, propagation=, read/write=true)\r\n```\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:           18.06.3-ce\r\n API version:       1.38\r\n Go version:        go1.10.3\r\n Git commit:        d7080c1\r\n Built:             Wed Feb 20 02:27:18 2019\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\nServer:\r\n Engine:\r\n  Version:          18.06.3-ce\r\n  API version:      1.38 (minimum version 1.12)\r\n  Go version:       go1.10.3\r\n  Git commit:       d7080c1\r\n  Built:            Wed Feb 20 02:26:20 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 0\r\nServer Version: 18.06.3-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: active\r\n NodeID: f9bd8fw4occfpqwk6fccpgy1y\r\n Is Manager: true\r\n ClusterID: p5akkh9kxo9zlt7tmziyv6mu1\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 10\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n  Force Rotate: 0\r\n Autolock Managers: false\r\n Root Rotation In Progress: false\r\n Node Address: 127.0.0.1\r\n Manager Addresses:\r\n  127.0.0.1:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 468a545b9edcd5932818eb9de8e72413e616e86e\r\nrunc version: a592beb5bc4c4092b1b1bac971afed27687340c5\r\ninit version: fec3683\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.15.0-1037-gcp\r\nOperating System: Ubuntu 16.04.6 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 7.298GiB\r\nName: travis-job-ca6d6f0b-880f-450b-9a4a-5d10e659112b\r\nID: BYBT:L62W:A24Q:UNFC:SG5Q:Z47D:C5QK:DXTM:44FB:QYIO:5IDE:7VLA\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nRegistry Mirrors:\r\n https://mirror.gcr.io/\r\nLive Restore Enabled: false\r\n```"},{"labels":["api",null,null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\nIf you use --link and the linked image isn't running, the top level image you're trying to run reports as not found. \r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n\r\n**Steps to reproduce the issue:**\r\n1. docker run --link thisdoesntexist python\r\n2. Unable to find image 'python:latest' locally\r\n\r\n**Describe the results you received:**\r\n\r\nThe image to run has to already have been built. It is noticed if you run \r\ndocker run --link thisdoesntexist python\r\nit first downloads python, then correctly says \"unable to find thisdoesntexist\" only if python hasn't downloaded before\r\n\r\n**Describe the results you expected:**\r\nCorrectly report the linked image name that's missing\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```Œª docker version\r\nClient: Docker Engine - Community\r\n Version:           19.03.1\r\n API version:       1.40\r\n Go version:        go1.12.5\r\n Git commit:        74b1e89\r\n Built:             Thu Jul 25 21:21:05 2019\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.1\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.12.5\r\n  Git commit:       74b1e89\r\n  Built:            Thu Jul 25 21:19:41 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          1.2.6\r\n  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb\r\n runc:\r\n  Version:          1.0.0-rc8\r\n  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```Œª docker info\r\nClient:\r\n Debug Mode: false\r\n\r\nServer:\r\n Containers: 11\r\n  Running: 4\r\n  Paused: 0\r\n  Stopped: 7\r\n Images: 89\r\n Server Version: 19.03.1\r\n Storage Driver: overlay2\r\n  Backing Filesystem: extfs\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: cgroupfs\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: inactive\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb\r\n runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f\r\n init version: fec3683\r\n Security Options:\r\n  apparmor\r\n  seccomp\r\n   Profile: default\r\n Kernel Version: 4.15.0-55-generic\r\n Operating System: Ubuntu 18.04.2 LTS\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 2\r\n Total Memory: 3.852GiB\r\n Name: kross\r\n ID: EPUW:J7KX:4IAV:MMOT:MWDW:GPIT:O32V:U4AO:WQSC:FF53:ZT6K:PLQN\r\n Docker Root Dir: /var/lib/docker\r\n Debug Mode: false\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: false\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n\r\nWARNING: No swap limit support\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null],"text":"It's unfortunately common for projects to mount the docker socket into (privileged) containers. A configuration option for specifying additional sockets with limited privileges would be fairly simple and would make it easier to do it easily without doing it wrong.\r\n\r\nEssentially, in the docker configuration, users would be able to specify the path of an additional socket with a limited set of permissions:\r\n\r\n`[(socket_path, [permissions,]),]`\r\n\r\nOr maybe also able to specify read-only access:\r\n\r\n`[(socket_path, {principal: 'rw', principal2: 'r'},]`\r\n\r\nI am aware that there are a number of far more complete RBAC solutions to limiting privileges; but I think creating said additional socket(s) with limited docker API privileges would be a fairly simple improvement that could help avoid granting unnecessarily broad privileges (e.g for easy ACME cert reloads and load balancing).\r\n\r\nAn example use case: securing the Traefik docker driver:\r\n\r\n- \"Docker integration: Exposing Docker socket to Traefik container is a serious security risk\" https://github.com/containous/traefik/issues/4174#issuecomment-446600393\r\n  > It seems it only require (read) operations : ServerVersion, ContainerList, ContainerInspect, ServiceList, NetworkList, TaskList & Events. \r\n  - https://github.com/liquidat/ansible-role-traefik\r\n    > This role does exactly that: it launches two containers, a traefik one and another to securely provide limited access to the docker socket. It also provides the necessary configuration.\r\n    - https://github.com/Tecnativa/docker-socket-proxy/issues/13\r\n      - Creates a HAproxy container that proxies limited access to the docket socket\r\n \r\nWith such a proposed configuration option for additional docker sockets with limited privileges, such an additional docker socket proxy container would be unnecessary."},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nDocker API v1.37 \"auth\" endpoint return an empty `IdentityToken`\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\nI'm calling the Docker API `auth` endpoint from the local host\r\n\r\n`curl -X POST http://localhost:2375/v1.37/auth -H \"Content-Type: application/json\" -d '{\"username\":\"AWS\", \"password\": \"'$password'\", \"serveraddress\": \"https://<account ID>.dkr.ecr.us-east-2.amazonaws.com/\"}'`\r\nI'm getting the following output back:\r\n\r\n`{\"IdentityToken\":\"\",\"Status\":\"Login Succeeded\"}`\r\n\r\n**Steps to reproduce the issue:**\r\n1.\r\n2.\r\n3.\r\n\r\n**Describe the results you received:**\r\nI'm getting back `{\"IdentityToken\":\"\",\"Status\":\"Login Succeeded\"}`\r\n\r\n**Describe the results you expected:**\r\nI'm expecting to receive back an identity `IdentityToken`\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:           18.09.3\r\n API version:       1.39\r\n Go version:        go1.10.8\r\n Git commit:        774a1f4\r\n Built:             Thu Feb 28 06:40:58 2019\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          18.09.3\r\n  API version:      1.39 (minimum version 1.12)\r\n  Go version:       go1.10.8\r\n  Git commit:       774a1f4\r\n  Built:            Thu Feb 28 05:59:55 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 1\r\n Running: 0\r\n Paused: 0\r\n Stopped: 1\r\nImages: 2\r\nServer Version: 18.09.3\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: nvidia runc\r\nDefault Runtime: nvidia\r\nInit Binary: docker-init\r\ncontainerd version: e6b3f5632f50dbc4e9cb6288d911bf4f5e95b18e\r\nrunc version: 12f6a991201fdb8f82579582d5e00e28fba06d0a-dirty\r\ninit version: fec3683\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-1060-aws\r\nOperating System: Ubuntu 16.04.4 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 7.795GiB\r\nName: ip-10-220-3-78\r\nID: YZ6T:HXM4:XJNW:GUDY:XA6J:U2KX:R7CJ:TQHE:TPXY:HCNA:R4VL:M3AZ\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\nProduct License: Community Engine\r\n\r\nWARNING: API is accessible on http://0.0.0.0:2375 without encryption.\r\n         Access to the remote API is equivalent to root access on the host. Refer\r\n         to the 'Docker daemon attack surface' section in the documentation for\r\n         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface\r\nWARNING: No swap limit support\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nI'm running on an AWS EC2 instance which has full access to ECR repos through an instance profile"},{"labels":["api",null],"text":"There were two process running. They all used docker python SDK to connect to the local docker engine(18.03). One process would to remove a container which met an error cause the container was running ( this is another issue), almost at the same time, another process would to create a container.  Configs of these two container do not conflict . Then I get an error like this:\r\n\r\n```\r\n Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/api/client.py\", line 229, in _raise_for_status\r\n    response.raise_for_status()\r\n  File \"/usr/local/lib/python3.5/dist-packages/requests/models.py\", line 939, in raise_for_status\r\n    raise HTTPError(http_error_msg, response=self)\r\nrequests.exceptions.HTTPError: 409 Client Error: Conflict for url: http://192.168.1.120:2375/v1.35/containers/create\r\n```\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"worker.py\", line 205, in process_job\r\n    **job.get('other', {}) \r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/api/container.py\", line 411, in create_container\r\n    return self.create_container_from_config(config, name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/api/container.py\", line 422, in create_container_from_config\r\n    return self._result(res, True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/api/client.py\", line 235, in _result\r\n    self._raise_for_status(response)\r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/api/client.py\", line 231, in _raise_for_status\r\n    raise create_api_error_from_http_exception(e)\r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/errors.py\", line 31, in create_api_error_from_http_exception\r\n    raise cls(e, response=response, explanation=explanation)\r\ndocker.errors.APIError: 409 Client Error: Conflict (\"You cannot remove a running container 9c31e308532433a712e9e56792726678ca78ff32e7de116097d27c243ed018a0. Stop the container before attempting removal or force remove\")\r\n```\r\n\r\n It is normal to perform these two operations at different times which only got  an 409 error when to  remove a running container. Looks like the docker engine or the API server doesn't support concurrency, does it?"},{"labels":["api",null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nWhen attempting to build images using the docker engine API (API v1.39, Docker v18.09.1), I am greeted with a 404 page not found response.\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. Make an API request to POST `/build` or POST `/v1.39/build`\r\n\r\n**Describe the results you received:**\r\n\r\nI received a 404 status code and a `{ \"message\": \"page not found\" }` response body.\r\n\r\n**Describe the results you expected:**\r\n\r\nI expected docker to start building the image I provided.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n```\r\nClient:\r\n Version:           18.09.1\r\n API version:       1.39\r\n Go version:        go1.10.6\r\n Git commit:        4c52b90\r\n Built:             Wed Jan  9 19:35:31 2019\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          18.09.1\r\n  API version:      1.39 (minimum version 1.12)\r\n  Go version:       go1.10.6\r\n  Git commit:       4c52b90\r\n  Built:            Wed Jan  9 19:02:44 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 2\r\n Running: 0\r\n Paused: 0\r\n Stopped: 2\r\nImages: 25\r\nServer Version: 18.09.1\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 9754871865f7fe2f4e74d43e2fc7ccd237edcbce\r\nrunc version: 96ec2177ae841256168fcf76954f7177af9446eb\r\ninit version: fec3683\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.15.0-43-generic\r\nOperating System: Ubuntu 18.04.1 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 8\r\nTotal Memory: 15.62GiB\r\nName: printer-MS-7A59\r\nID: VKKZ:CZRV:W4G4:63AX:DQH4:UVIT:GOXU:RCJQ:UTRD:EWZ4:4ILG:Y42I\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\nProduct License: Community Engine\r\n\r\nWARNING: API is accessible on http://0.0.0.0:4243 without encryption.\r\n         Access to the remote API is equivalent to root access on the host. Refer\r\n         to the 'Docker daemon attack surface' section in the documentation for\r\n         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface\r\nWARNING: No swap limit support\r\n\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nphysical"},{"labels":["api",null],"text":"**Description**\r\n\r\nDocker API returns null value for Warnings field.\r\n\r\nAccording to a definition it probably should never be null. It has `x-nullable: false\r\n\r\nhttps://github.com/moby/moby/blob/master/api/swagger.yaml#L4659-L4676\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n1. Send correct, /containers/create request to API https://docs.docker.com/engine/api/v1.37/#operation/ContainerCreate\r\n2. Check response\r\n\r\n\r\nExample response's body:\r\n```json\r\n{\r\n    \"Id\": \"6ce9cb39c1d6a905c0fc7909235b74491d5a0f184ff097bb73ffe9a30cd7743a\",\r\n    \"Warnings\": null\r\n}\r\n```\r\n\r\ninstead of:\r\n```json\r\n{\r\n    \"Id\": \"6ce9cb39c1d6a905c0fc7909235b74491d5a0f184ff097bb73ffe9a30cd7743a\",\r\n    \"Warnings\": []\r\n}\r\n```\r\n"},{"labels":["api",null,null],"text":"I'd like to propose eventually adding a new Engine REST API which exposes buildkit's `Solve` more directly than `/build` which is focused around the dockerfile frontend specific use case and has some quirks due to that (and for legacy/historical reasons).\r\n\r\nI've prototyped running a custom frontend via the `/build` API but it's a bit hacky and not terribly satisfactory (injecting a stub `Dockerfile` with a `syntax` directive in it, passing options by mapping to various `Dockerfile`-ish options etc). \r\n\r\nOther potentially interesting things  to expose are local exporter, debugger, shared session, multiple local sources and the ability to run a frontend client side (cf `Build` rather than `Solve` in the buildkit control API).\r\n\r\nIt's possible we could just extend on the current `/build` API to cover more underlying functionality (e.g. add a `Frontend` field to it), enhance the format of the returned body to remove the legacy framing etc.\r\n\r\nOr we could perhaps expose a new endpoint mapping the underlying `Solve` call a little more directly that the `/build` endpoint, with most of the options passed through or lightly adjusted/filtered (e.g maybe the full set of `Exporter`/`ExporterAttrs` flexibility shouldn't be exposed?). The `Session` side would be the same as with `/build` (an upgraded conn to `/session`). The body returned would be the Status stream, I guess as a direct JSON stream of `StatusResponse` rather than wrapping in a `JSONMessage` like `/build` had to do (for compat reasons I suppose). I'm not entirely sure about `SolveResponse`, so I guess maybe there needs to be a little more structure to the body stream, but ideally not `JSONMessage`, just a simple union type map.\r\n\r\nA possibly simple (but IMHO not at all ideal) would be a simple API end point which opens the entire control API gRPC via a /session-like endpoint. I don't think that is really what we want though (control API is not considered stable, might be too much low level power being exposed).\r\n\r\n/cc @tonistiigi @tiborvass "},{"labels":["api",null,null,null,null],"text":"(as reported by @waseemshahwan in https://github.com/moby/moby/issues/31909#issuecomment-435742609)\r\n\r\nLooks like a regression was introduced somewhere between Docker 17.07 and 17.09.1, causing the status code for a \"conflict\" to change from a 409 to a 500;\r\n\r\n\r\nTo reproduce; run a \"service create\" request _twice_ (second time should return a \"conflict\";\r\n\r\n```bash\r\ncurl -v \\\r\n  --unix-socket /var/run/docker.sock \\\r\n  -X POST \\\r\n  \"http://localhost/v1.30/services/create\" \\\r\n  -H \"Content-Type: application/json\" \\\r\n  -d '{\"EndpointSpec\":{\"Mode\":\"vip\"},\"Labels\":{},\"Mode\":{\"Replicated\":{}},\"Name\":\"testing\",\"TaskTemplate\":{\"ContainerSpec\":{\"DNSConfig\":{},\"Image\":\"nginx:alpine@sha256:ae5da813f8ad7fa785d7668f0b018ecc8c3a87331527a61d83b3b5e816a0f03c\",\"Init\":false},\"ForceUpdate\":0,\"Placement\":{\"Platforms\":[{\"Architecture\":\"amd64\",\"OS\":\"linux\"},{\"OS\":\"linux\"},{\"Architecture\":\"arm64\",\"OS\":\"linux\"},{\"Architecture\":\"386\",\"OS\":\"linux\"},{\"Architecture\":\"ppc64le\",\"OS\":\"linux\"},{\"Architecture\":\"s390x\",\"OS\":\"linux\"}]},\"Resources\":{\"Limits\":{},\"Reservations\":{}}}}'\r\n```\r\n\r\n\r\nOn Docker 17.07.0-ce\r\n\r\n```\r\n> POST /v1.30/services/create HTTP/1.1\r\n> Host: localhost\r\n> User-Agent: curl/7.61.1\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 536\r\n> \r\n* upload completely sent off: 536 out of 536 bytes\r\n< HTTP/1.1 409 Conflict\r\n< Api-Version: 1.31\r\n< Content-Type: application/json\r\n< Docker-Experimental: false\r\n< Ostype: linux\r\n< Server: Docker/17.07.0-ce (linux)\r\n< Date: Mon, 05 Nov 2018 16:10:58 GMT\r\n< Content-Length: 86\r\n< \r\n{\"message\":\"rpc error: code = Unknown desc = name conflicts with an existing object\"}\r\n```\r\n\r\nOn Docker 17.09.1-ce\r\n\r\n```\r\n> POST /v1.30/services/create HTTP/1.1\r\n> Host: localhost\r\n> User-Agent: curl/7.61.1\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 536\r\n> \r\n* upload completely sent off: 536 out of 536 bytes\r\n< HTTP/1.1 500 Internal Server Error\r\n< Api-Version: 1.32\r\n< Content-Type: application/json\r\n< Docker-Experimental: false\r\n< Ostype: linux\r\n< Server: Docker/17.09.1-ce (linux)\r\n< Date: Mon, 05 Nov 2018 16:11:59 GMT\r\n< Content-Length: 86\r\n< \r\n{\"message\":\"rpc error: code = Unknown desc = name conflicts with an existing object\"}\r\n```\r\n\r\nOn 18.06.1-ce (still reproduces)\r\n\r\n```\r\n*   Trying /var/run/docker.sock...\r\n* Connected to localhost (/var/run/docker.sock) port 80 (#0)\r\n> POST /v1.30/services/create HTTP/1.1\r\n> Host: localhost\r\n> User-Agent: curl/7.61.1\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 536\r\n> \r\n* upload completely sent off: 536 out of 536 bytes\r\n< HTTP/1.1 500 Internal Server Error\r\n< Api-Version: 1.38\r\n< Content-Type: application/json\r\n< Docker-Experimental: false\r\n< Ostype: linux\r\n< Server: Docker/18.06.1-ce (linux)\r\n< Date: Mon, 05 Nov 2018 10:31:29 GMT\r\n< Content-Length: 86\r\n< \r\n{\"message\":\"rpc error: code = Unknown desc = name conflicts with an existing object\"}\r\n* Connection #0 to host localhost left intact\r\n```\r\n\r\n"},{"labels":["api",null,null,null],"text":"There are a HostConfig.DiskQuota option with description \"Disk limit (in bytes).\" on https://docs.docker.com/engine/api/v1.37/#operation/ContainerCreate.\r\n\r\nBut, unfortunately, I can't find any other information about what does it mean. What constrains of use does it have? Is it can be used on all platfroms/storage drivers? What would be if this limit will be exceeded?"},{"labels":["api",null],"text":"**Description**\r\n\r\nWhen volume inspect command is fired by the user and the volume plugin fails for some reason and tries to report the error by setting \"Err\" in the response, the error message is not displayed by Docker CLI. Instead, it always displays\r\n\r\n```sh\r\n[]\r\nError: No such volume: xxx\r\n```\r\n\r\nAs per the documentation for Docker REST API [/VolumeDriver.Get](https://docs.docker.com/engine/extend/plugins_volume/#volumedriverget), the response can contain error as below:\r\n\r\n```sh\r\n{\r\n  \"Volume\": {\r\n    \"Name\": \"volume_name\",\r\n    \"Mountpoint\": \"/path/under/PropagatedMount\",\r\n    \"Status\": {}\r\n  },\r\n  \"Err\": \"\"\r\n}\r\n```\r\n\r\n**Steps to reproduce the issue:**\r\n1. In the implementation of [/VolumeDriver.Get](https://docs.docker.com/engine/extend/plugins_volume/#volumedriverget), return error message in the response.\r\n\r\n**Describe the results you received:**\r\n```sh\r\n[]\r\nError: No such volume: xxx\r\n```\r\n\r\n**Describe the results you expected:**\r\nError message set by the volume plugin within the response is expected to be displayed by the Docker CLI\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nDocker version 17.06.2-ee-16, build 9ef4f0a\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 14\r\n Running: 1\r\n Paused: 0\r\n Stopped: 13\r\nImages: 1247\r\nServer Version: 17.06.2-ee-16\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 786\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 6e23458c129b551d5c9871e5174f6b1b7f6d1170\r\nrunc version: 462c82662200a17ee39e74692f536067a3576a50\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-21-generic\r\nOperating System: Ubuntu 16.04.5 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 40\r\nTotal Memory: 62.79GiB\r\nName: xxxxxxxxxxxxx\r\nID: OWR5:HJYY:KAO5:H6GT:2NEU:JHHQ:YZ3G:67GJ:BKRV:SZ4P:Q3WJ:FDXS\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nUsername: xxxxxxxxx\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n\r\nWARNING: No swap limit support\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null],"text":"**Description**\r\n\r\nI have noticed that, while a service has a task that is running, that task has a status with `ContainerStatus.ExitCode: 0`. That is a misleading value. \r\n\r\nI believe `0` is being used here as a stand-in for `null` (or `nil`). But those values are distinct. A `null` value (or `nil`, or no value at all) should mean \"the container has not yet reported an exit value\". Any non-`null` value should mean \"the container *has* exited, and its process has reported this exit code\". `0` in particular is a special value because it is the only value indicating success.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a service with a command that will continue running for at least a few seconds.\r\n```\r\n$ docker service create --name service_name busybox:latest sleep 120\r\neeest5s97viw1qzoy8pvllbkm\r\noverall progress: 1 out of 1 tasks\r\n1/1: running   [==================================================>]\r\nverify: Service converged\r\n```\r\n2. Get the task status. I am not aware of a way to do this with the CLI, so I use the API.\r\n```\r\n$ curl -s --unix-socket /var/run/docker.sock http://localhost/tasks?filters%3D%5B%22service%22%3A%22service_name%22%5D | jq '.[].Status'\r\n{\r\n  \"Timestamp\": \"2018-08-01T15:41:54.007243253Z\",\r\n  \"State\": \"running\",\r\n  \"Message\": \"started\",\r\n  \"ContainerStatus\": {\r\n    \"ContainerID\": \"a14116edc1b8e8222efde70af7b7531bb71c702b813e5a8d81f848b8dfa1013c\",\r\n    \"PID\": 6947,\r\n    \"ExitCode\": 0\r\n  },\r\n  \"PortStatus\": {}\r\n}\r\n```\r\n\r\n**Describe the results you received:**\r\nThe task is in `\"State\": \"running\"` but the `\"ContainerStatus.ExitCode\"` value is `0`.\r\n\r\n**Describe the results you expected:**\r\nEither no `\"ExitCode\"` property within `\"ContainerStatus\"`, or one with a `null` value.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:           18.06.0-ce\r\n API version:       1.38\r\n Go version:        go1.10.3\r\n Git commit:        0ffa825\r\n Built:             Wed Jul 18 19:11:02 2018\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer:\r\n Engine:\r\n  Version:          18.06.0-ce\r\n  API version:      1.38 (minimum version 1.12)\r\n  Go version:       go1.10.3\r\n  Git commit:       0ffa825\r\n  Built:            Wed Jul 18 19:09:05 2018\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n```"},{"labels":["api"],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\nIn my golang project, I used moby/client package. It build failed, because:\r\n\r\n```golang\r\nvar _ APIClient = &Client{}\r\n```\r\nClient BuildCancel use golang.org/x/net/context\r\n```golang\r\npackage client // import \"github.com/docker/docker/client\"\r\n\r\nimport (\r\n\t\"net/url\"\r\n\r\n\t\"golang.org/x/net/context\"\r\n)\r\n\r\n// BuildCancel requests the daemon to cancel ongoing build request\r\nfunc (cli *Client) BuildCancel(ctx context.Context, id string) error {\r\n\tquery := url.Values{}\r\n\tquery.Set(\"id\", id)\r\n\r\n\tserverResp, err := cli.post(ctx, \"/build/cancel\", query, nil, nil)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer ensureReaderClosed(serverResp)\r\n\r\n\treturn nil\r\n}\r\n```\r\nAPIClient BuildCancel use standard context package in client/interface.go\r\n\r\nso ... \r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1.\r\n2.\r\n3.\r\n\r\n**Describe the results you received:**\r\n\r\n\r\n**Describe the results you expected:**\r\n\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\n(paste your output here)\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\n(paste your output here)\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null,null],"text":"https://github.com/opencontainers/runtime-spec/blob/master/config-linux.md#memory\r\n\r\n`.linux.resources.memory.kernelTCP` is defined in runtime spec and supported by runc.\r\n\r\nHowever, Docker/Moby does not expose API/CLI for setting this value currently, unlike [`.linux.resources.memory.kernel`](https://github.com/moby/moby/blob/3a633a712c8bbb863fe7e57ec132dd87a9c4eff7/api/types/container/host_config.go#L331).\r\n"},{"labels":["api",null],"text":"**Description**\r\nfilters api does not support exclude syntaxÔºå but api doc imply they are supported.\r\nsource code: https://github.com/moby/moby/blob/master/api/types/filters/parse.go,\r\nand the api doc: https://docs.docker.com/engine/api/v1.34/#operation/NetworkPrune.\r\n\r\n**Steps to reproduce the issue:**\r\nEMPTY\r\n\r\n**Describe the results you received:**\r\nEMPTY\r\n\r\n**Describe the results you expected:**\r\nEMPTY\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nEMPTY\r\n\r\n**Output of `docker version`:**\r\nEMPTY\r\n\r\n\r\n**Output of `docker info`:**\r\nEMPTY\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null],"text":"The `api/types` package should only contain the types used to serialize/deserialize requests and responses for the HTTP API. This is the case for most of the types in this package and sub packages.\r\n\r\nThere are two exceptions:\r\n* `api/types/client.go` contains types that are used by `APIClient` interface in the `client` package\r\n* `api/types/backend` contains types that are used by the backend interfaces between the API routers and the server implementation\r\n\r\nThese two categories of types are never used for serialization/deserialization.\r\n\r\nI propose we move these types to a more appropriate place:\r\n* `api/types/client.go` should move to `client/types`\r\n* `api/types/backend` could be split up and moved to `api/server/router/<component>` or moved to `api/server/backend/types`\r\n\r\ncc @tiborvass @vdemeester @cpuguy83 "},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\nPulling private image from docker hub or from a private docker registry doesn't return `http.StatusUnauthorized` or an error.\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n- Using golang SDK\r\n- Call `client.ImagePull()`\r\n- Using a private docker registry and/or private image on docker hub.\r\n- `ImagePull()` should fail to auth on the first attempt and fall back to call `ImagePullOptions.PrivilegeFunc` or exit with `err != nil`. \r\n\r\nIt doesn't, `imagePull()` doesn't call `ImagePullOptions.PrivilegeFunc` and doesn't return any errors. The only error is sent to the returned `io.ReaderCloser` and it says image not found.\r\n\r\nThe exact behavior is seen when trying to pull a private image from docker hub.\r\n**Steps to reproduce the issue:**\r\nhttps://github.com/rancher/rke/blob/185534a07f1e986c7c0427c8a05b341dd3467425/docker/docker.go#L161\r\n```\r\n// simplified code, actual code in the link above\r\nfunc pullImage( dClient *client.Client, privateRegistry v3.PrivateRegistry) error {\r\n\r\n\tpullOptions := types.ImagePullOptions{}\r\n\tpullOptions.PrivilegeFunc = tryRegistryAuth(privateRegistry)\r\n\t\t\r\n\tout, err := dClient.ImagePull(ctx, containerImage, pullOptions)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Can't pull Docker image [%s] for host [%s]: %v\", containerImage, hostname, err)\r\n\t}\r\n\tdefer out.Close()\r\n\tif logrus.GetLevel() == logrus.DebugLevel {\r\n\t\tio.Copy(os.Stdout, out)\r\n\t} else {\r\n\t\tio.Copy(ioutil.Discard, out)\r\n\t}\r\n\r\n\treturn nil\r\n}\r\n\r\nfunc tryRegistryAuth(pr v3.PrivateRegistry) types.RequestPrivilegeFunc {\r\n\treturn func() (string, error) {\r\n\t\tauthConfig := types.AuthConfig{\r\n\t\tUsername: pr.User,\r\n\t\tPassword: pr.Password,\r\n\t}\r\n\tencodedJSON, _ := json.Marshal(authConfig)\r\n\treturn base64.URLEncoding.EncodeToString(encodedJSON), nil\r\n\t}\r\n}\r\n\r\n```\r\n**Describe the results you received:**\r\nI should be able to get the image pulled after authentication, or an error.\r\n\r\n**Describe the results you expected:**\r\n`client.ImagePull()` doesn't return an error and doesn't try to authenticate to the registry, instead, returned io.ReaderCloser shows:\r\n```\r\n{\"status\":\"Pulling repository private-registry.test:5000/alpine\"}\r\n{\"errorDetail\":{\"message\":\"Error: image alpine:latest not found\"},\"error\":\"Error: image alpine:latest not found\"}\r\n```\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nroot@ip-10-0-1-142:~#  docker version\r\nClient:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Tue Jan 10 20:38:45 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Tue Jan 10 20:38:45 2017\r\n OS/Arch:      linux/amd64\r\n\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 1\r\nServer Version: 1.12.6\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 1\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: host overlay bridge null\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: apparmor seccomp\r\nKernel Version: 4.4.0-1049-aws\r\nOperating System: Ubuntu 16.04.3 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 1.952 GiB\r\nName: ip-10-0-1-142\r\nID: 5GAW:FRVA:BFZC:BR4H:V335:COAX:HNL7:VGXJ:27EA:N3KP:IHZL:TN7N\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nInsecure Registries:\r\nprivate-registry.test:5000\r\n 127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nAWS. "},{"labels":["api",null],"text":"You have probably seen this before, but just in case\r\n\r\nI run this:\r\n`$docker ps -a`\r\n\r\nand I see this:\r\n\r\n```bash\r\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                      NAMES\r\nef71b9269e92        cdt-prod            \"/bin/bash /home/new‚Ä¶\"   15 seconds ago      Up 34 seconds       0.0.0.0:3055->3055/tcp     cdt-prod-container\r\n282d1f0d0f5a        mongo:2.4           \"/entrypoint.sh mong‚Ä¶\"   20 seconds ago      Up 39 seconds       0.0.0.0:27017->27017/tcp   cdt-mongo\r\n```\r\n\r\nseems wrong - the status column has bigger numbers than created column?"},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\nI'd appreciate the API endpoint for `/stack` at the Docker API in order to deploy a composition of service in a `docker-compose.yml` file like it is possible on the command line\r\n```sh\r\n$ docker stack deploy -c my-compose.file.yml myStack\r\n```\r\n\r\nKubernetes support this feature with a POD spec. See [here](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#pod-v1-core) for details.\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n\r\n\r\n**Steps to reproduce the issue:**\r\n1.\r\n2.\r\n3.\r\n\r\n**Describe the results you received:**\r\n\r\n\r\n**Describe the results you expected:**\r\n\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n-->\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.09.1-ce\r\n API version:  1.32\r\n Go version:   go1.8.3\r\n Git commit:   19e2cf6\r\n Built:        Thu Dec  7 22:22:25 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.09.1-ce\r\n API version:  1.32 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   19e2cf6\r\n Built:        Thu Dec  7 22:28:28 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n<!--\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n-->"},{"labels":["api",null,null,null],"text":"While attaching a a container to an overlay network I get the following logs. There are two distinct issues here:\r\n- an error isn't handled properly which causes a FIXME to trigger\r\n- there is an error attempting to connect a task to an overlay network using API version 1.24\r\n\r\nUsing API 1.34 it works.\r\n\r\nThe logs for API 1.24 (generated using the docker-py python package):\r\n```\r\nDec 28 11:14:35 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:35.145284405+01:00\" level=debug msg=\"Calling POST /v1.24/networks/testnet/connect\"\r\nDec 28 11:14:35 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:35.145510531+01:00\" level=debug msg=\"form data: {\\\"Container\\\":\\\"65caedc6bf67\\\",\\\"EndpointConfig\\\":{}}\"\r\nDec 28 11:14:35 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:35.174343060+01:00\" level=debug msg=\"RequestAddress(GlobalDefault/10.0.0.0/24, <nil>, map[com.docker.network.ipam.serial:true])\"\r\nDec 28 11:14:35 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:35.177173023+01:00\" level=debug msg=\"Successfully attached to network testnet with task id yaciegbxsj47ntrqym2r9mcsm\"\r\nDec 28 11:14:35 swarm-1 ntpd[595]: Listen normally on 54 vethd3fa572 fe80::f4cc:73ff:fe5a:b1fc UDP 123\r\nDec 28 11:14:35 swarm-1 ntpd[595]: peers refreshed\r\nDec 28 11:14:38 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:38.766448656+01:00\" level=debug msg=\"memberlist: Stream connection from=10.1.54.13:52630\"\r\nDec 28 11:14:38 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:38.769253102+01:00\" level=info msg=\"Node join event for 41aeb0ed7cf7/10.1.54.13\"\r\nDec 28 11:14:55 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:55.157261962+01:00\" level=debug msg=\"ReleaseAddress(GlobalDefault/10.0.0.0/24, 10.0.0.35)\"\r\nDec 28 11:14:55 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:55.159347612+01:00\" level=debug msg=\"FIXME: Got an API for which error does not match any expected type!!!: attaching to network \r\nfailed, make sure your network options are correct and check manager logs: context deadline exceeded\" error_type=\"*errors.errorString\" module=api\r\nDec 28 11:14:55 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:55.160099338+01:00\" level=error msg=\"Handler for POST /v1.24/networks/testnet/connect returned error: attaching to network failed\r\n, make sure your network options are correct and check manager logs: context deadline exceeded\"\r\nDec 28 11:14:55 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:55.161338714+01:00\" level=debug msg=\"FIXME: Got an API for which error does not match any expected type!!!: attaching to network \r\nfailed, make sure your network options are correct and check manager logs: context deadline exceeded\" error_type=\"*errors.errorString\" module=api\r\nDec 28 11:15:02 swarm-1 dockerd[588]: time=\"2017-12-28T11:15:02.512053576+01:00\" level=debug msg=\"memberlist: Stream connection from=10.1.54.13:52634\"\r\n```\r\n\r\nWhen using the docker command tool you get the following logs (it works):\r\n```\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.115209171+01:00\" level=debug msg=\"Calling POST /v1.34/networks/testnet/connect\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.115456767+01:00\" level=debug msg=\"form data: {\\\"Container\\\":\\\"65caedc6bf67\\\",\\\"EndpointConfig\\\":{\\\"Aliases\\\":[],\\\"DriverOpts\\\":null,\\\"EndpointID\\\":\\\"\\\",\\\"Gateway\\\":\\\"\\\",\\\"GlobalIPv6Address\\\":\\\"\\\",\\\"GlobalIPv6PrefixLen\\\":0,\\\"IPAMConfig\\\":{},\\\"IPAddress\\\":\\\"\\\",\\\"IPPrefixLen\\\":0,\\\"IPv6Gateway\\\":\\\"\\\",\\\"Links\\\":null,\\\"MacAddress\\\":\\\"\\\",\\\"NetworkID\\\":\\\"\\\"}}\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.119363648+01:00\" level=debug msg=\"Assigning addresses for endpoint cranky_booth's interface on network testnet\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.121522694+01:00\" level=debug msg=\"RequestAddress(LocalDefault/10.0.0.0/24, <nil>, map[])\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.147177068+01:00\" level=debug msg=\"Assigning addresses for endpoint cranky_booth's interface on network testnet\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.199794382+01:00\" level=debug msg=\"checkEncryption(bfg309z, <nil>, 4096, true)\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.334967494+01:00\" level=debug msg=\"Creating service for vip 10.0.0.13 fwMark 262 ingressPorts []*libnetwork.PortConfig(nil) in sbox 9027cf8 (65caedc)\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.462069418+01:00\" level=debug msg=\"EnableService 65caedc6bf673cd1773d123d84752d4eff7ad8439d50c2b78d2b5d19d9bfe525 START\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.463087411+01:00\" level=debug msg=\"addServiceInfoToCluster START for  b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.463963840+01:00\" level=debug msg=\"addContainerNameResolution b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1 65caedc6bf67\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.464915615+01:00\" level=debug msg=\"b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1 (bfg309z).addSvcRecords(65caedc6bf67, 10.0.0.2, <nil>, true) addServiceInfoToCluster sid:b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.465904144+01:00\" level=debug msg=\"b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1 (bfg309z).addSvcRecords(65caedc6bf67, 10.0.0.2, <nil>, true) addServiceInfoToCluster sid:b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.467076144+01:00\" level=debug msg=\"addServiceInfoToCluster END for  b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.467121412+01:00\" level=debug msg=\"EnableService 65caedc6bf673cd1773d123d84752d4eff7ad8439d50c2b78d2b5d19d9bfe525 DONE\"\r\n```\r\n\r\nSituation:\r\n- \r\n- Normal container on the first node, trying to attach to an overlay network\r\n\r\n**Steps to reproduce the issue:**\r\n1. Swarm with three nodes: manager with availability drain, worker, normal manager\r\n2. Normal container on the first node, trying to attach to an overlay network\r\n3. Use docker-py 2.0.2 to attach container to network.\r\n\r\n**Describe the results you received:**\r\n\r\nTimeout plus failure\r\n\r\n**Describe the results you expected:**\r\n\r\nContainer attached to network\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.11.0-ce\r\n API version:  1.34\r\n Go version:   go1.8.3\r\n Git commit:   1caf76c\r\n Built:        Mon Nov 20 18:36:33 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.11.0-ce\r\n API version:  1.34 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   1caf76c\r\n Built:        Mon Nov 20 18:35:05 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 34\r\n Running: 5\r\n Paused: 0\r\n Stopped: 29\r\nImages: 20\r\nServer Version: 17.11.0-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: active\r\n NodeID: 2hpr816nia1fi7afdkq6135ti\r\n Is Manager: true\r\n ClusterID: ciep4cws4f9al3i8dxvosidkm\r\n Managers: 2\r\n Nodes: 3\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n  Force Rotate: 0\r\n Autolock Managers: false\r\n Root Rotation In Progress: false\r\n Node Address: 10.1.54.13\r\n Manager Addresses:\r\n  10.1.54.11:2377\r\n  10.1.54.13:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 992280e8e265f491f7a624ab82f3e238be086e49\r\nrunc version: 0351df1c5a66838d0c392b4ac4cf9450de844e2d\r\ninit version: 949e6fa\r\nKernel Version: 4.9.0-0.bpo.4-amd64\r\nOperating System: Debian GNU/Linux 8 (jessie)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 1.957GiB\r\nName: swarm-3\r\nID: SGID:6EJY:JKNE:F4LM:R434:4EB6:IMXC:PV5O:77LI:6MAR:S3DO:AD6J\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 119\r\n Goroutines: 261\r\n System Time: 2017-12-28T11:38:41.64341161+01:00\r\n EventsListeners: 5\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null],"text":"**Description**\r\n\r\nDocker attach API do use `application/vnd.docker.raw-stream` content type, which has two implementations:\r\n- multiplexed stdout/stderr streams\r\n- raw tty output\r\n\r\nfrom API response there's no way (afaict) to determine which one is used\r\nI suggest a header is introduced to document which mode is being used\r\n\r\n**Steps to reproduce the issue:**\r\n1. ask a friend to create a container, setting tty= to a random value kept secret\r\n2. invoke containers/{id}/attach\r\n3. try to guess the raw.stream format in use\r\n\r\n**Describe the results you received:**\r\n\r\nhave to try parsing a multiplexed frame, then admit I was wrong.\r\n\r\n**Describe the results you expected:**\r\n\r\nsimple way to determine the parsing logic to use\r\n"},{"labels":["api",null,null],"text":"Originally filed in https://github.com/docker/for-mac/issues/2300, but moved to here as it's a problem within Moby.\r\n\r\n**Description**\r\n\r\nWhen a container creation request provides an `EndpointSettings` value of nil in the `NetworkConfig.EndpointConfig`, the API will respond with `bad response from Docker engine`. Either this error should not be happening in the first place, or an error that is more clear should be returned.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\nA minimum example that will exhibit the problem is the following client code:\r\n\r\n\r\n```go\r\npackage main\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"log\"\r\n\r\n\t\"github.com/moby/moby/client\"\r\n\r\n\t\"github.com/docker/docker/api/types\"\r\n\t\"github.com/docker/docker/api/types/container\"\r\n\t\"github.com/docker/docker/api/types/network\"\r\n)\r\n\r\nfunc main() {\r\n\tclient, err := client.NewEnvClient()\r\n\tif err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\tnetworkName := \"mynetwork\"\r\n\tendpoints := make(map[string]*network.EndpointSettings, 1)\r\n\tendpoints[networkName] = nil\r\n\t// If the above line is replaced with the following line, everything works fine.\r\n\t// endpoints[networkName] = &network.EndpointSettings{}\r\n\tresp, err := client.ContainerCreate(\r\n\t\tcontext.TODO(),\r\n\t\t&container.Config{\r\n\t\t\tImage: \"myimage\",\r\n\t\t},\r\n\t\tnil,\r\n\t\t&network.NetworkingConfig{\r\n\t\t\tEndpointsConfig: endpoints,\r\n\t\t},\r\n\t\t\"\",\r\n\t)\r\n\tif err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\tif err := client.ContainerStart(context.TODO(), resp.ID, types.ContainerStartOptions{}); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n}\r\n```\r\n\r\n**Describe the results you received:**\r\n- A container is created, and when attempting to start it an engine error is returned.\r\n\r\n**Describe the results you expected:**\r\n- A container is created and started.\r\n\r\n**Output of `docker version`:** \r\n\r\n```\r\nlient:\r\n Version:      17.09.0-ce\r\n API version:  1.32\r\n Go version:   go1.8.3\r\n Git commit:   afdb6d4\r\n Built:        Tue Sep 26 22:40:09 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.09.0-ce\r\n API version:  1.32 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   afdb6d4\r\n Built:        Tue Sep 26 22:45:38 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 2\r\n Running: 0\r\n Paused: 0\r\n Stopped: 2\r\nImages: 9\r\nServer Version: 17.09.0-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0\r\nrunc version: 3f2f8b84a77f73d38244dd690525642a72156c64\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.49-moby\r\nOperating System: Alpine Linux v3.5\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 1.952GiB\r\nName: moby\r\nID: Z6L4:JUOG:LGE3:VTWQ:TXTA:545D:33JF:R4EQ:NIN5:NVXF:FLDM:NWMG\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 19\r\n Goroutines: 32\r\n System Time: 2017-12-09T01:38:05.1673997Z\r\n EventsListeners: 1\r\nNo Proxy: *.local, 169.254/16\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```"},{"labels":["api",null],"text":"**Description**\r\n\r\n`HostConfig` in swagger spec declares PortBindings as an object with Map/Dictionary properties https://github.com/moby/moby/blob/master/api/swagger.yaml#L608\r\nNested tuple object (HostIp, HostPort) is declared here as an Object, but the API actually returns an array (see https://groups.google.com/forum/#!topic/docker-dev/Ydz6-YcaSG0 if you wonder why)\r\n\r\n**Steps to reproduce the issue:**\r\n1. generate model form swagger spec.\r\n2. use it to inspect a container\r\n3. \r\n\r\n**Describe the results you received:**\r\n\r\n`Expected BEGIN_OBJECT but was BEGIN_ARRAY at line 1 column 1402 path $.HostConfig.PortBindings.`\r\n\r\n**Describe the results you expected:**\r\n\r\ninspect response object mapped\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nServer:\r\n Version:      17.11.0-ce-rc3\r\n API version:  1.34 (minimum version 1.12)\r\n Go version:   go1.8.5\r\n Git commit:   5b4af4f\r\n Built:        Wed Nov  8 03:09:46 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nI'm using swagger-codegen to generate java model : https://github.com/Dockins/jocker/blob/master/pom.xml#L55\r\n"},{"labels":["api",null,null],"text":"**Description**\r\n\r\nRemote API: rename container responds with HTTP 400, should be HTTP 409. This happens on both 17.10 and 17.09.\r\n\r\n**Steps to reproduce the issue:**\r\nCreate two containers.\r\nRename one container. (For example, to \"foo\".)\r\nUsing the remote API, POST to /containers/(id or name)/rename?name=foo, i.e. rename the second container to the same name as the first.\r\n\r\n**Describe the results you received:**\r\nThe request fails with HTTP 400 bad request.\r\n\r\n{\"message\":\"Error when allocating new name: Conflict. The container name \\\"/1afabc65711aace8-6bf9bc24d807db13\\\" is already in use by container \\\"ca4a1c2132f5debe445c791216bae7c7d0ecacee62b1f5393df2ec21501b37e5\\\". You have to remove (or rename) that container to be able to reuse that name.\"}\r\n\r\n\r\n**Describe the results you expected:**\r\nThe request fails with HTTP 409 Conflict, message name already assigned, as described in the [remote API docs][api-doc].\r\n\r\n  [api-doc]: https://docs.docker.com/engine/api/v1.33/#operation/ContainerRename\r\n\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.10.0-ce\r\n API version:  1.33\r\n Go version:   go1.8.3\r\n Git commit:   f4ffd25\r\n Built:        Tue Oct 17 19:00:43 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.10.0-ce\r\n API version:  1.33 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   f4ffd25\r\n Built:        Tue Oct 17 19:05:23 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 288\r\n Running: 1\r\n Paused: 0\r\n Stopped: 287\r\nImages: 121\r\nServer Version: 17.10.0-ce\r\nStorage Driver: aufs\r\n Root Dir: /mnt/sda1/var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 729\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: active\r\n NodeID: lpzh1yir70ysu8q5y5h1pzug1\r\n Is Manager: true\r\n ClusterID: rxvk8l7smfzkcfy99g03q91ce\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n  Force Rotate: 0\r\n Autolock Managers: true\r\n Root Rotation In Progress: false\r\n Node Address: 127.0.0.1\r\n Manager Addresses:\r\n  127.0.0.1:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0\r\nrunc version: 0351df1c5a66838d0c392b4ac4cf9450de844e2d\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.93-boot2docker\r\nOperating System: Boot2Docker 17.10.0-ce (TCL 7.2); HEAD : 34fe485 - Wed Oct 18 17:16:34 UTC 2017\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 1.955GiB\r\nName: 17.10.0\r\nID: ORAB:O2DJ:HFXW:BCAA:RCAU:3UTJ:JTY2:3G4Z:VMQJ:4DY3:425W:HM5A\r\nDocker Root Dir: /mnt/sda1/var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 216\r\n Goroutines: 331\r\n System Time: 2017-11-13T01:24:12.130585157Z\r\n EventsListeners: 0\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\n provider=virtualbox\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\nA similar issue was [reported here ](https://github.com/moby/moby/issues/21016) before."},{"labels":["api"],"text":"The [Swagger spec](https://github.com/moby/moby/blob/a21654c/api/swagger.yaml) for endpoints like [`/images/create`](https://github.com/moby/moby/blob/a21654c/api/swagger.yaml#L6246) advertise a `produces` MIME type of `\"application/json\"`. In reality, the endpoint produces line delimited JSON, which is not valid JSON per se, and for which an appropriate MIME type might be [`\"application/x-ndjson\"`](http://ndjson.org/).\r\n\r\nDifferentiating such endpoints from regular `application/json` endpoints will allow consumers such as codegenerators to generate suitable client implementations for handling the streaming output, instead of just trying to parse the response as JSON and exploding."},{"labels":["api",null,null],"text":"There is already a websocket endpoint to attach to a container.\r\nNow that service logs are available in the API, I'd be happy to be able to use websocket to fetch them.\r\nHijacking a TCP connection is not something we can easily do in a browser.\r\n\r\n"},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n`docker top <containerID>` should by default return same result as if you are doing `ps -ef` in the container. This is documented, say V1.24 docker API.\r\nhttps://docs.docker.com/engine/api/v1.24/\r\n\"Query parameters:\r\n\r\nps_args ‚Äì ps arguments to use (e.g., aux), defaults to -ef\"\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. download minishift and start minishift\r\n2. minishift ssh to VM\r\n3. docker top on any runnning container\r\n\r\n**Describe the results you received:**\r\n\r\n```docker@minishift:~$ docker top c37\r\nPID                 USER                COMMAND\r\n6475                tc                  {standalone.sh} /bin/sh /wildfly/bin/standalone.sh -b 0.0.0.0 -bmanagement 0.0.0.0\r\n6647                tc                  java -D[Standalone] -server -XX:+UseParallelGC -Xms40m -Xmx256m -XX:+AggressiveOpts -XX:MinHeapFreeRatio=20 -XX:MaxHeapFreeRatio=40 -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -Dorg.apache.tomcat.util.LOW_MEMORY=true -DOPENSHIFT_APP_UUID= -Djboss.modules.system.pkgs=org.jboss.byteman -Djava.awt.headless=true -Dorg.jboss.resolver.warning=true -Djava.net.preferIPv4Stack=true -Dfile.encoding=UTF-8 -Djboss.node.name=fan-wildfly-2-twhnd -Djgroups.bind_addr=0.0.0.0 -Dorg.apache.coyote.http11.Http11Protocol.COMPRESSION=on -Dorg.jboss.boot.log.file=/wildfly/standalone/log/server.log -Dlogging.configuration=file:/wildfly/standalone/configuration/logging.properties -jar /wildfly/jboss-modules.jar -mp /wildfly/provided_modules:/wildfly/modules org.jboss.as.standalone -Djboss.home.dir=/wildfly -Djboss.server.base.dir=/wildfly/standalone -b 0.0.0.0 -bmanagement 0.0.0.0\r\n```\r\n\r\n\r\n**Describe the results you expected:**\r\n\r\n```\r\nbash-4.2$ ps -ef\r\nUID        PID  PPID  C STIME TTY          TIME CMD\r\ndefault      1     0  0 16:14 ?        00:00:00 /bin/sh /wildfly/bin/standalone.sh -b 0.0.0.0 -bmanagement 0.0.0.0\r\ndefault    163     1  4 16:14 ?        00:09:44 java -D[Standalone] -server -XX:+UseParallelGC -Xms40m -Xmx256m -XX:+AggressiveOpts -XX:MinHeapFreeRatio=20 -XX:MaxHeapFreeRatio=40 -XX:GCTimeRatio=4 -XX:Ad\r\n```\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nalways reproducible\r\n**Output of `docker version`:**\r\n\r\n```\r\ndocker@minishift:~$ docker version\r\nClient:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Wed Jan 11 00:23:16 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Wed Jan 11 00:23:16 2017\r\n OS/Arch:      linux/amd64\r\n\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\ndocker@minishift:~$ docker version\r\nClient:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Wed Jan 11 00:23:16 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Wed Jan 11 00:23:16 2017\r\n OS/Arch:      linux/amd64\r\ndocker@minishift:~$ docker info\r\nContainers: 28\r\n Running: 11\r\n Paused: 0\r\n Stopped: 17\r\nImages: 14\r\nServer Version: 1.12.6\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 104\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: null host overlay bridge\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: seccomp\r\nKernel Version: 4.4.41-boot2docker\r\nOperating System: Minishift Boot2Docker ISO Version: 1.2.0\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 1.955 GiB\r\nName: minishift\r\nID: W6TJ:ZWT4:ZPGW:AMOZ:QN3G:OLO5:S566:CGEZ:ZVFP:XRXM:EZXZ:ALUR\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 95\r\n Goroutines: 86\r\n System Time: 2017-10-27T20:10:00.566488403Z\r\n EventsListeners: 0\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\n provider=kvm\r\nInsecure Registries:\r\n 172.30.0.0/16\r\n 127.0.0.0/8\r\n\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nopenshift(minishift)"},{"labels":["api",null,null],"text":"Hi\r\n\r\nMaybe it has been asked before, but I haven't been able to find it.\r\n\r\nActually docker inspect on an exited container returns:\r\n```\r\n        ...\r\n        \"State\": {\r\n            \"Status\": \"exited\",\r\n            \"Running\": false,\r\n            \"Paused\": false,\r\n            \"Restarting\": false,\r\n            \"OOMKilled\": true,\r\n            \"Dead\": false,\r\n            \"Pid\": 0,\r\n            \"ExitCode\": 137,\r\n            \"Error\": \"\",\r\n            \"StartedAt\": \"2017-10-12T05:50:23.819164201Z\",\r\n            \"FinishedAt\": \"2017-10-12T06:45:33.520387397Z\"\r\n        },\r\n        ...\r\n```\r\n\r\nIt would be possible to preserve the PID after container exited, in order to easily match logs with atop/kernel OOM and so?\r\n\r\nThanks."},{"labels":["api",null,null,null],"text":"**Description**\r\n\r\nDocker stopped rejecting API requests with version numbers greater than the maximum version supported by the daemon. This happened in https://github.com/moby/moby/commit/e98e4a71110fd33852bb755a9b8b4ebc9df904db#diff-14051df1b5de1608aaba3a983f2a87e3 as part of https://github.com/moby/moby/pull/27745 and has affected every version of Docker since 1.13.0.\r\n\r\nThis change breaks the capability detection logic used by the Amazon ECS agent. The Amazon ECS agent is designed to work with all Docker versions >= 1.5.0, and we enable or disable features depending on the capabilities of the Docker version used. We use Remote API version as we expected this to be more stable than the daemon version; the daemon version has gone through a few changes since we started (roughly semver-like to year-month plus edition). We currently call the `/_ping` API with a range of different versions to discover which API versions are supported by the Docker daemon, but this change makes it so that every request with an API version >= 1.12 will result in success. This is causing incorrect behavior where features are being enabled with incompatible Docker versions; see https://github.com/aws/amazon-ecs-agent/issues/1008 .\r\n\r\nIn https://docs.docker.com/engine/api/version-history/#v125-api-changes , I see a note about a new header returned that specifies the maximum API version of the daemon. However, I do not see a note about the change in behavior to start accepting requests that have a specified version greater than the maximum.\r\n\r\n**Steps to reproduce the issue:**\r\nRun `curl --verbose --unix-socket /var/run/docker.sock http://localhost/v9999.9999/_ping`\r\n\r\n**Describe the results you received:**\r\nOn Docker versions prior to 1.13.0, you'll see an HTTP 400 with an error message \"client is newer than server\"\r\nOn Docker versions 1.13.0 or greater, you'll see an HTTP 200 OK.\r\n\r\n**Describe the results you expected:**\r\nI expected all versions of Docker to reject the API call because the specified API version was too new."},{"labels":["api",null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nFor programmatically checking whether a container is running, I would expect\r\n\r\n```\r\ndocker ps -q -f name=foobar\r\n```\r\n\r\nto return a nonzero exit status if no running container matching the filter was found.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Run a container, say `docker run --name foobar --rm mycontainer`\r\n2. Check for its existence with `docker ps -q -f name=foobar && echo yes`\r\n3. Stop the container\r\n4 Check for its existence again; observe that exit status is still zero, in spite of no output\r\n\r\n**Describe the results you received:**\r\n\r\nCommand exit status is zero, indicating success.\r\n\r\n**Describe the results you expected:**\r\n\r\nCommand exit status should be nonzero to indicate failure to match.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\n$ docker --version\r\nDocker version 17.06.2-ce, build cec0b72\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 12\r\n Running: 0\r\n Paused: 0\r\n Stopped: 12\r\nImages: 139\r\nServer Version: 17.06.2-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 6e23458c129b551d5c9871e5174f6b1b7f6d1170\r\nrunc version: 810190ceaa507aa2727d7ae6f4790c76ec150bd2\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.41-moby\r\nOperating System: Alpine Linux v3.5\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 1.952GiB\r\nName: moby\r\nID: IWAM:QARS:YQWX:F7HX:KZSD:7HFN:UDTG:ZLF4:LSX7:CGPD:ZEQN:ZSKP\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 18\r\n Goroutines: 31\r\n System Time: 2017-10-02T08:50:24.949181594Z\r\n EventsListeners: 1\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nThis is on a Mac, but the behavior should obviosly be platform-independent.\r\n\r\nThere are probably many other Docker commands which should be properly scriptable.\r\n\r\nI was surprised that I could not find an open duplicate of this bug; sorry if this has already been requested."},{"labels":["api",null],"text":"**Description**\r\nCreating containers with duplicated name used to return a 409 HTTP response, however, since 17.09 release it now returns a 400 response breaking compatibility for API users. \r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a container `docker create --name c1 busybox`\r\n2. Run `curl -v -XPOST -H\"Content-Type: application/json\" -d'{\"Image\":\"busybox\"}' http://localhost:2375/containers/create?name=c1`\r\n\r\n**Describe the results you received:**\r\n\r\nThe HTTP response will be 400 Bad Request.\r\n\r\n**Describe the results you expected:**\r\n\r\nPrior to 17.09 the response would be 409 Conflict\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.09.0-ce\r\n API version:  1.32\r\n Go version:   go1.8.3\r\n Git commit:   afdb6d4\r\n Built:        Tue Sep 26 22:42:18 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.09.0-ce\r\n API version:  1.32 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   afdb6d4\r\n Built:        Tue Sep 26 22:40:56 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 7\r\n Running: 6\r\n Paused: 0\r\n Stopped: 1\r\nImages: 18\r\nServer Version: 17.09.0-ce\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 55\r\n Dirperm1 Supported: true\r\nLogging Driver: syslog\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: active\r\n NodeID: ug3ojsrrreyxeq63nbwyikv3f\r\n Is Manager: true\r\n ClusterID: n2efj7ylwed1onrdxy0sp4dp1\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n  Force Rotate: 0\r\n Autolock Managers: false\r\n Root Rotation In Progress: false\r\n Node Address: 192.168.50.4\r\n Manager Addresses:\r\n  192.168.50.4:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0\r\nrunc version: 3f2f8b84a77f73d38244dd690525642a72156c64\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-31-generic\r\nOperating System: Ubuntu 16.04.2 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 2.915GiB\r\nName: vagrant\r\nID: QCSK:UDNT:AMC2:P6TV:M4LV:UZQE:7Z2W:TEHN:VJ75:YQTG:QIBD:TYJC\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 85\r\n Goroutines: 180\r\n System Time: 2017-09-28T14:10:12.894604072Z\r\n EventsListeners: 1\r\nUsername: cezarsa\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.1:5000\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nVirtualbox"},{"labels":["api",null,null,null],"text":"If the base64url or json decoding of the X-Registry-Auth header fails, the error is swallowed and the credentials are taken as empty.\r\nhttps://github.com/moby/moby/blob/4bf8714fac11e95e835cf78eb15ba5a518c67c4b/api/server/router/image/image_routes.go#L98-L107\r\n\r\nThe code comments states:\r\n```\r\n\t// for a pull it is not an error if no auth was given\r\n\t// to increase compatibility with the existing api it is defaulting to be empty\r\n```\r\n\r\nBut this situation is not that no auth was given, but that it was badly encoded. If there is a backward compatibility issue, there should be a better way to tackle it than ignoring the header entirely on error."},{"labels":["api",null,null],"text":"**Description**\r\n\r\nWhile calling `docker volume prune`, the pruning of a volume doesn't create an event entry.\r\n\r\n**Steps to reproduce the issue:**\r\n1. `docker events > events.log &` to listen docker events\r\n2. `docker volume create chazam` to create a test volume\r\n3. `docker volume prune` to delete volumes\r\n\r\n**Describe the results you received:**\r\nOn the events.log file you should, only, see the creation event:\r\n`2017-09-23T07:10:44.965370986Z volume create chazam (driver=local)`\r\n\r\n**Describe the results you expected:**\r\nI should expect to have an event entry on the volume deletion.\r\n\r\n**Problem localisation**\r\nThe problem is on the `daemon/prune.go` file. More precisely the `VolumesPrune` function, line `143`.\r\nWe should call `err = daemon.VolumeRm(v.Name(), false)` instead of the actual `err = daemon.volumes.Remove(v)`.\r\n\r\n**Output of `docker version`:**\r\n```\r\nClient:\r\n Version:      17.06.0-ce\r\n API version:  1.30\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:15:15 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.06.0-dev\r\n API version:  1.32 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   c982ee8\r\n Built:        Sat Sep 23 07:09:43 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 0\r\nServer Version: 17.06.0-dev\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0\r\nrunc version: 1c81e2a794c6e26a4c650142ae8893c47f619764\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.41-moby\r\nOperating System: Debian GNU/Linux 9 (stretch) (containerized)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 1.952GiB\r\nName: 977aaa405be0\r\nID: K6M2:ALHJ:AVJ5:XVW7:E4X5:W34D:35XQ:K6HK:YVOF:EA2N:U4BO:6QRT\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 17\r\n Goroutines: 28\r\n System Time: 2017-09-23T07:12:39.720242284Z\r\n EventsListeners: 1\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n"},{"labels":["api",null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\nDocker container start API used to return 500 status code when the mounting share/file of container not exists. But now, I'm using docker API 1.29 and found that it returns 404, which means no such container in Document (https://docs.docker.com/engine/api/v1.29/#operation/ContainerStart). I wonder it's by design or a bug. Thanks.\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. docker run -it --name test -v /volume1/abc:/test ubuntu\r\n2. rm /volume1/abc\r\n3. curl --unix-socket /var/run/docker.sock -X POST http:/v1.29/containers/test/start -v\r\n\r\n**Describe the results you received:**\r\nstatus code 404\r\n\r\n**Describe the results you expected:**\r\nstatus code 500\r\n\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n```\r\nClient:\r\n Version:      17.05.0-ce\r\n API version:  1.29\r\n Go version:   go1.8\r\n Git commit:   5259590\r\n Built:        Thu Aug  3 17:53:06 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.05.0-ce\r\n API version:  1.29 (minimum version 1.12)\r\n Go version:   go1.8\r\n Git commit:   5259590\r\n Built:        Thu Aug  3 17:53:06 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 16\r\n Running: 6\r\n Paused: 0\r\n Stopped: 10\r\nImages: 21\r\nServer Version: 17.05.0-ce\r\nStorage Driver: btrfs\r\nLogging Driver: db\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: fd189da3e13a3ef3d6d9eb73c5cd4697b4536cdd (expected: 9048e5e50717ea4497b757314bad98ea3763c145)\r\nrunc version: a2d6e07aab95ff37fb63cf5dec3c40d29940194f (expected: 9c2d8d184e5da67c95d601382adf14862e4f2228)\r\ninit version: 7a83305 (expected: 949e6fa)\r\nSecurity Options:\r\n apparmor\r\nKernel Version: 3.10.105\r\nOperating System: <unknown>\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 988.7MiB\r\nName: tricia713p-2\r\nID: N44J:NJHE:EQG2:TY6P:QYPH:DXP5:2X2G:F5C2:2ONN:OGTF:J45U:LCVG\r\nDocker Root Dir: /volume1/@docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 56\r\n Goroutines: 74\r\n System Time: 2017-08-23T18:21:30.329449102+08:00\r\n EventsListeners: 0\r\nUsername: \r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\nI wonder how to create services with yml files using remote api.\r\n'docker stack deploy' is dedicated with docker cli and there is no api to call  with yml file.\r\nI knew docker-compose is another option to launch containers with yml file.\r\nHowever, I don't want to take care docker-compose dependency.(I know libcompose)\r\n'docker stack deploy' will create services by swarm, it would be easier to manage for me.\r\nAlso, DOCKER_HOST is set in my remote side and I can use remoe api all to request for dockerd.\r\nIs there a way how to use docker stack deploy without cli, should I develope yml parser in my client?\r\n\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. \r\n2.\r\n3.\r\n\r\n**Describe the results you received:**\r\n\r\n\r\n**Describe the results you expected:**\r\n\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.05.0-ce\r\n API version:  1.29\r\n Go version:   go1.7.5\r\n Git commit:   89658be\r\n Built:        Thu May  4 22:10:54 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.05.0-ce\r\n API version:  1.29 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   89658be\r\n Built:        Thu May  4 22:10:54 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 2\r\n Running: 2\r\n Paused: 0\r\n Stopped: 0\r\nImages: 14\r\nServer Version: 17.05.0-ce\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 35\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins: \r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: active\r\n NodeID: ij7fc2f203vddkjy7ob4q9esp\r\n Is Manager: true\r\n ClusterID: fp4p2rdim6mmlrey1hhfybm77\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 1\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 127.0.0.1\r\n Manager Addresses:\r\n  127.0.0.1:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145\r\nrunc version: 9c2d8d184e5da67c95d601382adf14862e4f2228\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-89-generic\r\nOperating System: Ubuntu 16.04.2 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 8\r\nTotal Memory: 7.708GiB\r\nName: namsulee\r\nID: 3VEC:YWEK:CJVK:ABOZ:N2MK:X2X4:3XPC:RJ3R:MDNL:WCWW:JCOD:6AFM\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nHttp Proxy: http://10.112.1.184:8080/\r\nHttps Proxy: http://10.112.1.184:8080/\r\nNo Proxy: localhost,127.0.0.1,docker-registry.your.corp\r\nUsername: namsulee\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 10.113.62.204:443\r\n 13.124.64.10:443\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null,null],"text":"Hi !\r\n\r\nI'm writing a tool (in Python) to get the logs from any containers through the Docker Engine's HTTP API.\r\n\r\nAfter reading [the doc](https://docs.docker.com/engine/api/v1.30/), and trying to implement something, I founded that the protocol used seems to be different from the one for Attach, it seems to be :\r\n\r\n```{\\xFF}\\r\\n{\\xFF}{datas}```\r\n\r\nWhere the first hex number is the size of the message, and the second one seems to be (empirical deduction) the number of bytes that are supposed to be ignored before the start of the actual payload (so the log).\r\nAnd it seems to work, for some containers at least ...\r\n\r\n**EDIT** : The second seems to be the number of bytes that are supposed to be ignored IF the container has ```tty: false```, otherwise, it seems to be the start of the log **END of the edit**\r\n\r\nWith one strange deduction : if ```\\x07``` is found, then it overrides the second {\\xFF} size, and the message starts after this value...\r\n\r\nAm I missing a part of the documentation, or am I not using the HTTP API in a wrong way ?\r\n\r\nThanks for your time,\r\n\r\n**NB** : The protocol above seems to be specific for the logs endpoint, it's not working for the events' endpoint.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.05.0-ce\r\n API version:  1.29\r\n Go version:   go1.7.5\r\n Git commit:   89658be\r\n Built:        Thu May  4 22:10:54 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.05.0-ce\r\n API version:  1.29 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   89658be\r\n Built:        Thu May  4 22:10:54 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n"},{"labels":["api",null,null,null,null],"text":"\r\n**Description**\r\n\r\nWhen create a network with name already existed using docker-py, and set arg `check_duplicated=True`, the error should be `409 Conflict`, but `500 Internal Server Error` returns.\r\n\r\n**Steps to reproduce the issue:**\r\nIn python console\r\n```\r\n>>> import docker\r\n>>> c = docker.from_env()\r\n>>> c.networks.create('net1')\r\n<Network: 4c7d2d08e3>\r\n>>> c.networks.create('net1', check_duplicate=True)\r\n```\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\n>>> c.networks.create('net1', check_duplicate=True)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python2.7/site-packages/docker/models/networks.py\", line 144, in create\r\n    resp = self.client.api.create_network(name, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/docker/utils/decorators.py\", line 35, in wrapper\r\n    return f(self, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/network.py\", line 134, in create_network\r\n    return self._result(res, json=True)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/client.py\", line 220, in _result\r\n    self._raise_for_status(response)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/client.py\", line 216, in _raise_for_status\r\n    raise create_api_error_from_http_exception(e)\r\n  File \"/usr/lib/python2.7/site-packages/docker/errors.py\", line 30, in create_api_error_from_http_exception\r\n    raise cls(e, response=response, explanation=explanation)\r\ndocker.errors.APIError: 500 Server Error: Internal Server Error for url: http+docker://localunixsocket/v1.24/networks/create (\"network with name net1 already exists\")\r\n>>> \r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\n```\r\n>>> c.networks.create('net1', check_duplicate=True)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python2.7/site-packages/docker/models/networks.py\", line 144, in create\r\n    resp = self.client.api.create_network(name, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/docker/utils/decorators.py\", line 35, in wrapper\r\n    return f(self, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/network.py\", line 134, in create_network\r\n    return self._result(res, json=True)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/client.py\", line 220, in _result\r\n    self._raise_for_status(response)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/client.py\", line 216, in _raise_for_status\r\n    raise create_api_error_from_http_exception(e)\r\n  File \"/usr/lib/python2.7/site-packages/docker/errors.py\", line 30, in create_api_error_from_http_exception\r\n    raise cls(e, response=response, explanation=explanation)\r\ndocker.errors.APIError: 409 Client Error: Conflict for url: http+docker://localunixsocket/v1.24/networks/create (\"network with name net1 already exists\")\r\n>>> \r\n```\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.06.0-ce\r\n API version:  1.30\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:20:36 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.06.0-ce\r\n API version:  1.30 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:21:56 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 1\r\nServer Version: 17.06.0-ce\r\nStorage Driver: overlay\r\n Backing Filesystem: xfs\r\n Supports d_type: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins: \r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: active\r\n NodeID: 7ty93f9vgo9gb2nmwk4km10hb\r\n Is Manager: true\r\n ClusterID: fofqp1rgom60nftnc5fwkz1st\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n  Force Rotate: 0\r\n Root Rotation In Progress: false\r\n Node Address: 192.168.249.129\r\n Manager Addresses:\r\n  192.168.249.129:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088a\r\nrunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 3.10.0-514.el7.x86_64\r\nOperating System: CentOS Linux 7 (Core)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 472.5MiB\r\nName: swarm_manager\r\nID: YRD2:DTIW:AKEF:RXJY:RKXM:OJU2:N7B6:K7JK:XDOG:4E5S:NWFU:SGWY\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 40\r\n Goroutines: 184\r\n System Time: 2017-08-08T14:20:57.288514678+08:00\r\n EventsListeners: 0\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 10.27.37.40:5000\r\n 10.37.210.125:5001\r\n 127.0.0.0/8\r\nRegistry Mirrors:\r\n https://2h3po24q.mirror.aliyuncs.com/\r\nLive Restore Enabled: false\r\n\r\nWARNING: bridge-nf-call-ip6tables is disabled\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n```\r\ndocker-py version 2.1.0\r\n```"},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\nDocker images load API return `200` status code when it actually failed. I wonder it's by design or a bug.\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n```bash\r\ncat /mychai/PACKAGE_ICON.PNG |curl -v --unix-socket  /var/run/docker.sock -H \"Content-Type: application/x-tar\"  --data-binary @- -X POST http:/v1.29/images/load\r\n```\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\n> POST /images/load HTTP/1.1\r\n> Host: v1.29\r\n> User-Agent: curl/7.54.0\r\n> Accept: */*\r\n> Content-Type: application/x-tar\r\n> Content-Length: 7164\r\n> Expect: 100-continue\r\n>\r\n< HTTP/1.1 100 Continue\r\n< HTTP/1.1 200 OK\r\n< Api-Version: 1.29\r\n< Content-Type: application/json\r\n< Docker-Experimental: false\r\n< Ostype: linux\r\n< Server: Docker/17.05.0-ce (linux)\r\n< Date: Mon, 07 Aug 2017 05:48:35 GMT\r\n< Transfer-Encoding: chunked\r\n<\r\n{\"errorDetail\":{\"message\":\"Error processing tar file(exit status 1): archive/tar: invalid tar header\"},\"error\":\"Error processing tar file(exit status 1): archive/tar: invalid tar header\"}\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\n```\r\n< HTTP/1.1 500 \r\n```\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.05.0-ce\r\n API version:  1.29\r\n Go version:   go1.8\r\n Git commit:   54e4c6c-synology\r\n Built:        Fri Aug  4 22:43:08 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.05.0-ce\r\n API version:  1.29 (minimum version 1.12)\r\n Go version:   go1.8\r\n Git commit:   54e4c6c-synology\r\n Built:        Fri Aug  4 22:43:08 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 12\r\n Running: 1\r\n Paused: 0\r\n Stopped: 11\r\nImages: 27\r\nServer Version: 17.05.0-ce\r\nStorage Driver: btrfs\r\nLogging Driver: db\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: fd189da3e13a3ef3d6d9eb73c5cd4697b4536cdd (expected: 9048e5e50717ea4497b757314bad98ea3763c145)\r\nrunc version: a2d6e07aab95ff37fb63cf5dec3c40d29940194f (expected: 9c2d8d184e5da67c95d601382adf14862e4f2228)\r\ninit version: 7a83305 (expected: 949e6fa)\r\nSecurity Options:\r\n apparmor\r\nKernel Version: 3.10.105\r\nOperating System: <unknown>\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 988.7MiB\r\nName: tricia713p-2\r\nID: N44J:NJHE:EQG2:TY6P:QYPH:DXP5:2X2G:F5C2:2ONN:OGTF:J45U:LCVG\r\nDocker Root Dir: /volume1/@docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 20\r\n Goroutines: 29\r\n System Time: 2017-08-07T13:53:50.426017437+08:00\r\n EventsListeners: 0\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n\r\nWARNING: No kernel memory limit support\r\nWARNING: No cpu cfs quota support\r\nWARNING: No cpu cfs period support\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nLinux "},{"labels":["api",null,null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1.docker run -tid --name=test0 ubuntu bash\r\n2.docker run -tid --name=test1 --net=container:test0 ubuntu bash\r\n3.docker rename test0 test2\r\n4.docker restart test1\r\n\r\n**Describe the results you received:**\r\nError response from daemon: Cannot restart container test1: No such container: test0\r\n\r\nWhen replace the \"--net\" to \"--pid\" or \"--ipc\" will get :\r\nPost http://%2Fvar%2Frun%2Fdocker.sock/v1.29/containers/test3/restart: EOF\r\n\r\n**Describe the results you expected:**\r\ntest1 restart succuss\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n```\r\nClient:\r\n Version:      17.05.0-ce\r\n API version:  1.29\r\n Go version:   go1.7.5\r\n Git commit:   89658be\r\n Built:        Fri May  5 15:36:11 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.05.0-ce\r\n API version:  1.29 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   89658be\r\n Built:        Fri May  5 15:36:11 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n\r\n```\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 15\r\n Running: 13\r\n Paused: 0\r\n Stopped: 2\r\nImages: 60\r\nServer Version: 17.05.0-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: xfs\r\n Supports d_type: false\r\n Native Overlay Diff: false\r\nLogging Driver: journald\r\nCgroup Driver: cgroupfs\r\nPlugins: \r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145\r\nrunc version: 9c2d8d184e5da67c95d601382adf14862e4f2228\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 3.10.0-514.21.2.el7.x86_64\r\nOperating System: CentOS Linux 7 (Core)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 8\r\nTotal Memory: 7.639GiB\r\nName: 16\r\nID: 5PRJ:JAJY:H6IP:OBMF:7QQ6:AQJ2:JHGD:KOHN:K4PZ:ETTR:JPUA:KZ2P\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 95\r\n Goroutines: 128\r\n System Time: 2017-07-30T02:26:57.040522467+08:00\r\n EventsListeners: 0\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n demoregistry.dataman-inc.com\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**"},{"labels":["api",null,null],"text":"The responsible of the `client` package is to transform a go struct into an HTTP request, perform the HTTP request, and convert the HTTP response into a go struct + error.\r\n\r\n`client/service_update.go` and `client/service_create.go` have a bunch of application logic that does not belong in this package. We should remove it and move it into a separate package.\r\n\r\nIt looks like this logic was first introduced in #32388 and subsequently updated in #33239, and #33575.\r\n\r\nThis is related to #34242 and https://github.com/docker/cli/pull/386 \r\n\r\ncc @thaJeztah @nishanttotla @aaronlehmann "},{"labels":["api",null],"text":"Docker API documentation needs to be updated.\r\n\r\nThe `/plugins` endpoint returns the following response: https://github.com/moby/moby/blob/0ac25dfc751fa4304ab45afd5cd8705c2235d101/api/types/plugin_responses.go#L1\r\n\r\nBased on https://github.com/moby/moby/blob/0ac25dfc751fa4304ab45afd5cd8705c2235d101/api/types/plugin.go#L8-L31\r\n\r\nThe plugin object is quite different from the one documented in the 200 response sample at https://docs.docker.com/engine/api/v1.30/#operation/PluginList\r\n"},{"labels":["api",null,null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\nI'm using the API to consume container stats streams.\r\n\r\nContainer stat streams for containers that are being removed sporadically contain samples that are partial or contain empty or null data. This has only appeared after upgrading from docker:1.13 to docker-ce:17.06.\r\n\r\nHere is an example of what I would consider bad data.\r\n- read timestamp is \"0001-01-01T00:00:00Z\"\r\n- blkio_stats are all set to null\r\n- cpu_stats are all set to zero and percpu_usage and throttling_data is missing\r\n- memory stats is completely empty\r\n- networks list is missing\r\n```\r\n{\r\n   \"read\":\"0001-01-01T00:00:00Z\",\r\n   \"preread\":\"0001-01-01T00:00:00Z\",\r\n   \"pids_stats\":{\r\n\r\n   },\r\n   \"blkio_stats\":{\r\n      \"io_service_bytes_recursive\":null,\r\n      \"io_serviced_recursive\":null,\r\n      \"io_queue_recursive\":null,\r\n      \"io_service_time_recursive\":null,\r\n      \"io_wait_time_recursive\":null,\r\n      \"io_merged_recursive\":null,\r\n      \"io_time_recursive\":null,\r\n      \"sectors_recursive\":null\r\n   },\r\n   \"num_procs\":0,\r\n   \"storage_stats\":{\r\n\r\n   },\r\n   \"cpu_stats\":{\r\n      \"cpu_usage\":{\r\n         \"total_usage\":0,\r\n         \"usage_in_kernelmode\":0,\r\n         \"usage_in_usermode\":0\r\n      },\r\n      \"throttling_data\":{\r\n         \"periods\":0,\r\n         \"throttled_periods\":0,\r\n         \"throttled_time\":0\r\n      }\r\n   },\r\n   \"precpu_stats\":{\r\n      \"cpu_usage\":{\r\n         \"total_usage\":0,\r\n         \"usage_in_kernelmode\":0,\r\n         \"usage_in_usermode\":0\r\n      },\r\n      \"throttling_data\":{\r\n         \"periods\":0,\r\n         \"throttled_periods\":0,\r\n         \"throttled_time\":0\r\n      }\r\n   },\r\n   \"memory_stats\":{\r\n\r\n   },\r\n   \"name\":\"/test-coffeescript-5-coffeescript-1676635391\",\r\n   \"id\":\"fe236c2e2d8d8c7db08a6049d61b2903b850f0a39fc4e70c8483cdb8f9f3d334\"\r\n}\r\n```\r\n\r\nHere is an example of what I would consider good data.\r\n```\r\n{\r\n   \"read\":\"2017-07-20T00:31:05.56000684Z\",\r\n   \"preread\":\"0001-01-01T00:00:00Z\",\r\n   \"pids_stats\":{\r\n\r\n   },\r\n   \"blkio_stats\":{\r\n      \"io_service_bytes_recursive\":[\r\n         {\r\n            \"major\":8,\r\n            \"minor\":0,\r\n            \"op\":\"Read\",\r\n            \"value\":18477056\r\n         },\r\n         {\r\n            \"major\":8,\r\n            \"minor\":0,\r\n            \"op\":\"Write\",\r\n            \"value\":0\r\n         },\r\n         {\r\n            \"major\":8,\r\n            \"minor\":0,\r\n            \"op\":\"Sync\",\r\n            \"value\":0\r\n         },\r\n         {\r\n            \"major\":8,\r\n            \"minor\":0,\r\n            \"op\":\"Async\",\r\n            \"value\":18477056\r\n         },\r\n         {\r\n            \"major\":8,\r\n            \"minor\":0,\r\n            \"op\":\"Total\",\r\n            \"value\":18477056\r\n         },\r\n         {\r\n            \"major\":252,\r\n            \"minor\":0,\r\n            \"op\":\"Read\",\r\n            \"value\":18477056\r\n         },\r\n         {\r\n            \"major\":252,\r\n            \"minor\":0,\r\n            \"op\":\"Write\",\r\n            \"value\":0\r\n         },\r\n         {\r\n            \"major\":252,\r\n            \"minor\":0,\r\n            \"op\":\"Sync\",\r\n            \"value\":0\r\n         },\r\n         {\r\n            \"major\":252,\r\n            \"minor\":0,\r\n            \"op\":\"Async\",\r\n            \"value\":18477056\r\n         },\r\n         {\r\n            \"major\":252,\r\n            \"minor\":0,\r\n            \"op\":\"Total\",\r\n            \"value\":18477056\r\n         }\r\n      ],\r\n      \"io_serviced_recursive\":[\r\n         {\r\n            \"major\":8,\r\n            \"minor\":0,\r\n            \"op\":\"Read\",\r\n            \"value\":371\r\n         },\r\n         {\r\n            \"major\":8,\r\n            \"minor\":0,\r\n            \"op\":\"Write\",\r\n            \"value\":0\r\n         },\r\n         {\r\n            \"major\":8,\r\n            \"minor\":0,\r\n            \"op\":\"Sync\",\r\n            \"value\":0\r\n         },\r\n         {\r\n            \"major\":8,\r\n            \"minor\":0,\r\n            \"op\":\"Async\",\r\n            \"value\":371\r\n         },\r\n         {\r\n            \"major\":8,\r\n            \"minor\":0,\r\n            \"op\":\"Total\",\r\n            \"value\":371\r\n         },\r\n         {\r\n            \"major\":252,\r\n            \"minor\":0,\r\n            \"op\":\"Read\",\r\n            \"value\":371\r\n         },\r\n         {\r\n            \"major\":252,\r\n            \"minor\":0,\r\n            \"op\":\"Write\",\r\n            \"value\":0\r\n         },\r\n         {\r\n            \"major\":252,\r\n            \"minor\":0,\r\n            \"op\":\"Sync\",\r\n            \"value\":0\r\n         },\r\n         {\r\n            \"major\":252,\r\n            \"minor\":0,\r\n            \"op\":\"Async\",\r\n            \"value\":371\r\n         },\r\n         {\r\n            \"major\":252,\r\n            \"minor\":0,\r\n            \"op\":\"Total\",\r\n            \"value\":371\r\n         }\r\n      ],\r\n      \"io_queue_recursive\":[\r\n\r\n      ],\r\n      \"io_service_time_recursive\":[\r\n\r\n      ],\r\n      \"io_wait_time_recursive\":[\r\n\r\n      ],\r\n      \"io_merged_recursive\":[\r\n\r\n      ],\r\n      \"io_time_recursive\":[\r\n\r\n      ],\r\n      \"sectors_recursive\":[\r\n\r\n      ]\r\n   },\r\n   \"num_procs\":0,\r\n   \"storage_stats\":{\r\n\r\n   },\r\n   \"cpu_stats\":{\r\n      \"cpu_usage\":{\r\n         \"total_usage\":153445917,\r\n         \"percpu_usage\":[\r\n            75907230,\r\n            54946048,\r\n            20596622,\r\n            1996017\r\n         ],\r\n         \"usage_in_kernelmode\":30000000,\r\n         \"usage_in_usermode\":100000000\r\n      },\r\n      \"system_cpu_usage\":36458710000000,\r\n      \"online_cpus\":4,\r\n      \"throttling_data\":{\r\n         \"periods\":8,\r\n         \"throttled_periods\":0,\r\n         \"throttled_time\":0\r\n      }\r\n   },\r\n   \"precpu_stats\":{\r\n      \"cpu_usage\":{\r\n         \"total_usage\":0,\r\n         \"usage_in_kernelmode\":0,\r\n         \"usage_in_usermode\":0\r\n      },\r\n      \"throttling_data\":{\r\n         \"periods\":0,\r\n         \"throttled_periods\":0,\r\n         \"throttled_time\":0\r\n      }\r\n   },\r\n   \"memory_stats\":{\r\n      \"usage\":32563200,\r\n      \"max_usage\":34340864,\r\n      \"stats\":{\r\n         \"active_anon\":11812864,\r\n         \"active_file\":1028096,\r\n         \"cache\":18497536,\r\n         \"dirty\":4096,\r\n         \"hierarchical_memory_limit\":419430400,\r\n         \"inactive_anon\":0,\r\n         \"inactive_file\":17469440,\r\n         \"mapped_file\":14819328,\r\n         \"pgfault\":6767,\r\n         \"pgmajfault\":155,\r\n         \"pgpgin\":10252,\r\n         \"pgpgout\":2852,\r\n         \"rss\":11812864,\r\n         \"rss_huge\":0,\r\n         \"total_active_anon\":11812864,\r\n         \"total_active_file\":1028096,\r\n         \"total_cache\":18497536,\r\n         \"total_dirty\":4096,\r\n         \"total_inactive_anon\":0,\r\n         \"total_inactive_file\":17469440,\r\n         \"total_mapped_file\":14819328,\r\n         \"total_pgfault\":6767,\r\n         \"total_pgmajfault\":155,\r\n         \"total_pgpgin\":10252,\r\n         \"total_pgpgout\":2852,\r\n         \"total_rss\":11812864,\r\n         \"total_rss_huge\":0,\r\n         \"total_unevictable\":0,\r\n         \"total_writeback\":0,\r\n         \"unevictable\":0,\r\n         \"writeback\":0\r\n      },\r\n      \"limit\":419430400\r\n   },\r\n   \"name\":\"/test-coffeescript-0-coffeescript-7120097801\",\r\n   \"id\":\"b45e7064834ba64acd2bda01cc533345b2b3ec06fca2c173eac1ac9d433f0721\",\r\n   \"networks\":{\r\n      \"eth0\":{\r\n         \"rx_bytes\":168,\r\n         \"rx_packets\":2,\r\n         \"rx_errors\":0,\r\n         \"rx_dropped\":0,\r\n         \"tx_bytes\":0,\r\n         \"tx_packets\":0,\r\n         \"tx_errors\":0,\r\n         \"tx_dropped\":0\r\n      }\r\n   }\r\n}\r\n```\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a large number of containers\r\n2. Subscribe to each container's stats. Validate that each stats sample contains networks.\r\n3. Remove the large number of containers so that removal is slowed down allowing race condition to occur.\r\n\r\n**Describe the results you received:**\r\n- json stats samples missing the networks property\r\n- json stats samples with cpu and other values set to zero or null\r\n\r\n**Describe the results you expected:**\r\nI expect to not receive any stats samples after a container starts to be removed.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nThis only seems to happen as a race condition when removal takes longer than normal.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.06.0-ce\r\n API version:  1.30\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:19:16 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.06.0-ce\r\n API version:  1.30 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:17:13 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 134\r\n Paused: 0\r\n Stopped: 0\r\nImages: 33\r\nServer Version: 17.06.0-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: false\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088a\r\n:WARNING: No swap limit support\r\nrunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\nKernel Version: 4.2.0-27-generic\r\nOperating System: Ubuntu 14.04.4 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 2.922GiB\r\nName: ubuntu\r\nID: V75U:CH5I:M2Q6:2C7F:CYWI:2THL:SXX3:3AV5:PNVA:7PVS:SXY4:6RAS\r\nDocker Root Dir: /data/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n- Running in production on Ubuntu 14.04 gce instance.\r\n- Running in test on a Ubuntu 14.04 VM running locally on macOS Sierra."},{"labels":["api",null,null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nThe API returns a `500 Internal Server Error` if the body is empty when creating a volume.\r\n\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n```bash\r\n$ curl --unix-socket /var/run/docker.sock -v -X POST http://localhost/volumes/create\r\n\r\n*   Trying /var/run/docker.sock...\r\n* Connected to localhost (/Users/sebastiaan/Library/Containers/com.dock) port 80 (#0)\r\n> POST /volumes/create HTTP/1.1\r\n> Host: localhost\r\n> User-Agent: curl/7.51.0\r\n> Accept: */*\r\n>\r\n< HTTP/1.1 500 Internal Server Error\r\n< Api-Version: 1.30\r\n< Content-Length: 18\r\n< Content-Type: application/json\r\n< Date: Wed, 19 Jul 2017 11:29:26 GMT\r\n< Docker-Experimental: true\r\n< Ostype: linux\r\n< Server: Docker/17.06.0-ce (linux)\r\n<\r\n{\"message\":\"EOF\"}\r\n* Curl_http_done: called premature == 0\r\n* Connection #0 to host localhost left intact\r\n```\r\n\r\n**Describe the results you received:**\r\n\r\nThe API returns a `500 Internal Server Error`\r\n\r\n**Describe the results you expected:**\r\n\r\nhe API handles the error, and returns a 4xx error code (`400 Bad Request`)\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.06.0-ce\r\n API version:  1.30\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:31:53 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.06.0-ce\r\n API version:  1.30 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:51:55 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\nnot relevant\r\n\r\n"},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nOn querying images list each image list will be having `Containers` property with value -1 regardless of amount of containers using this image.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Run container from the image(for example `docker run -ti ubuntu bash`)\r\n2. Get list of images from the API(`curl --unix-socket /var/run/docker.sock \"http:/v1.30/images/json\"`)\r\n\r\n**Describe the results you received:**\r\n\r\n\"ubuntu\" image has `Containers` property with value -1.\r\n\r\n**Describe the results you expected:**\r\n\r\n`Containers` property with value 1\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.06.0-ce\r\n API version:  1.30\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:31:53 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.06.0-ce\r\n API version:  1.30 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:51:55 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 4\r\n Running: 2\r\n Paused: 0\r\n Stopped: 2\r\nImages: 40\r\nServer Version: 17.06.0-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088a\r\nrunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.31-moby\r\nOperating System: Alpine Linux v3.5\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 1.952GiB\r\nName: moby\r\nID: QN2D:44BC:EQ5U:GCN2:Z2XT:DSNU:GGTI:FNKB:MHAJ:3I7E:ASHB:RJTT\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 34\r\n Goroutines: 48\r\n System Time: 2017-07-07T10:18:20.598658487Z\r\n EventsListeners: 1\r\nNo Proxy: *.local, 169.254/16\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n jenkin-registry.gsintlab.com\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n"},{"labels":["api",null,null,null,null],"text":"**Description**\r\nAfter updating to Docker 17.06.0-ce, there is a functionality change in the `docker wait` command compared to 17.05, when issued against a container name that doesn't exist. I can't seem to find any documentation on this change, and am unsure if it's a bug (it appears to be).\r\n\r\n**Steps to reproduce the issue:**\r\n1. Upgrade to Docker 17.06.0-ce\r\n2. Issue `docker wait` for a container that doesn't exist\r\n3. Docker will hang.\r\n\r\n**Describe the results you received:**\r\nIn 17.06, if you issue a `docker wait` for a container name that doesn't exist, the docker command will hang indefinitely.\r\n\r\n**Describe the results you expected:**\r\nIn 17.05, if you issue a `docker wait` for a container name that doesn't exist, you get a non-zero exit with the following error:\r\n```\r\n$ docker wait kube-rsync-5095346036-5-v1.8.3-2\r\nError response from daemon: No such container: kube-rsync-5095346036-5-v1.8.3-2\r\n```\r\n\r\nSimilarly, if you issue a `docker kill` in either 17.06 or 17.05, you get a similar error (what I expect to be desired functionality):\r\n```\r\ndocker kill kube-rsync-5095346036-5-v1.8.3-2\r\nError response from daemon: Cannot kill container kube-rsync-5095346036-5-v1.8.3-2: No such container: kube-rsync-5095346036-5-v1.8.3-2\r\n```\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.06.0-ce\r\n API version:  1.30\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:31:53 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.06.0-ce\r\n API version:  1.30 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:51:55 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 0\r\nServer Version: 17.06.0-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins: \r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088a\r\nrunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.31-moby\r\nOperating System: Alpine Linux v3.5\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 1.952GiB\r\nName: moby\r\nID: ZV2V:GX2D:5RZF:47YT:NFFB:TPFP:6KBC:QFF3:QJSN:EUAK:PKOP:3NVP\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 17\r\n Goroutines: 28\r\n System Time: 2017-07-04T20:07:55.056942415Z\r\n EventsListeners: 1\r\nNo Proxy: *.local, 169.254/16\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null],"text":"**Description**\r\n\r\nLooking at the [Docker Engine API docs](https://docs.docker.com/engine/api/v1.26/#operation/ContainerCreate) (scroll down and expand HostConfig, then scroll down to find the Binds documentation), I don't see anything related to the SELinux Context, which is mentioned in the docker documentation [here](https://docs.docker.com/engine/tutorials/dockervolumes/#volume-labels).\r\n\r\nHowever, it seems that the `:Z` or `:z` which are SELinux flags are accepted as I'm able to pass them (See reproduction of the issue).\r\n\r\n\r\n**Steps to reproduce the issue:**\r\n\r\nIf you have vagrant : \r\n1. create a `Vagrantfile` containing \r\n\r\n```\r\n# -*- mode: ruby -*-\r\n# vi: set ft=ruby :\r\n\r\nVagrant.configure(\"2\") do |config|\r\n  config.vm.box = \"fedora/25-cloud-base\"\r\n\r\n  config.vm.provision \"shell\", inline: <<-SHELL\r\n    set -eux\r\n\r\n    # prepare the system and install dependencies\r\n    dnf install -q -y docker\r\n    systemctl start docker\r\n    docker pull alpine:latest\r\n    \r\n    # Sanity check, to make sure unwanted argument do not pass\r\n    curl -s --unix-socket /var/run/docker.sock -H \"Content-Type: application/json\" \\\r\n    -d '{\"Image\": \"alpine\", \"Binds\": [\"/vagrant/Vagrantfile:/Vagrantfile:a\"]}' \\\r\n    -X POST http:/v1.24/containers/create\r\n\r\n    curl -s --unix-socket /var/run/docker.sock -H \"Content-Type: application/json\" \\\r\n    -d '{\"Image\": \"alpine\", \"Binds\": [\"/vagrant/Vagrantfile:/Vagrantfile:Z\"]}' \\\r\n    -X POST http:/v1.24/containers/create\r\n  SHELL\r\nend\r\n```\r\n2. run `vagrant up` in the same directory\r\n\r\nIf you don't use vagrant, make sure you have docker installed and run the two curl commands manually.\r\n\r\n**Describe the results you received:**\r\n\r\nThe first curl command failed which is normal, the api shouldn't accept invalid specifications, but the second succeeds, which is also normal as it is SELinux related. However, it is not specified in the documentation.\r\n\r\nI will work on a fix in the documentation as soon as possible. However, I have a question about it, should we add a link to the [documentation](https://docs.docker.com/engine/tutorials/dockervolumes/#volume-labels) for reference or should we just specify more examples ?\r\n\r\nThank you."},{"labels":["api",null],"text":"**Motivation:**\r\nCurrently an application that would like to integrate with Docker by calling it's APIs has to either rely on docker listening on the default socket or be (manually) configured with the socket in case it differs from the default. \r\n\r\nSuch an application can try detecting the socket by parsing a running Docker process command line parameters and might need to parse the Docker configuration file. However, this duplicates Docker's logic inside the application and it's very brittle. Inspecting Docker's open file descriptors (e.g. through /proc) is not optimal either as file descriptors other than the API socket/s are held open. \r\n\r\nExposing the API sockets may also facilitate Docker CLI such that it will be able to communicate with a Docker host that is not listening on the default socket (changes to Docker CLI will go into a separate issue).\r\n\r\n**Implementation:**\r\nThe idea is to publish the socket info into a file, say similar to publishing the Docker PID through the docker.pid file.\r\n"},{"labels":["api",null,null],"text":"**Description**\r\n\r\n`NetworkSettings.Networks[*].Aliases` content is shown with `docker inspect` but not with `moby/client.`\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create the following `docker-compose.yml`:\r\n```\r\nversion: '2'\r\n\r\nservices:\r\n  compcont:\r\n    image: friendlyhello\r\n    networks:\r\n      default:\r\n      builds:\r\n        aliases: [ \"mycompcont\" ]\r\n\r\nnetworks:\r\n  default:\r\n    external:\r\n      name: othernet\r\n  builds:\r\n    external:\r\n      name: mynet\r\n```\r\n2. Create both networks and bring compose up:\r\n```\r\n$ docker network create mynet\r\n$ docker network create othernet\r\n$ docker-compose up\r\n```\r\n3. Inspect the container:\r\n```\r\n$ docker inspect test_compcont_1\r\n...\r\n        \"NetworkSettings\": {\r\n...\r\n            \"Networks\": {\r\n                \"mynet\": {\r\n...\r\n                    \"Aliases\": [\r\n                        \"compcont\",\r\n                        \"b41fa65b66dc\",\r\n                        \"mycompcont\"\r\n                    ],\r\n...\r\n                    \"Gateway\": \"172.18.0.1\",\r\n                    \"IPAddress\": \"172.18.0.2\",\r\n                },\r\n                \"othernet\": {\r\n...\r\n                    \"Aliases\": [\r\n                        \"compcont\",\r\n                        \"b41fa65b66dc\"\r\n                    ],\r\n...\r\n                    \"Gateway\": \"172.19.0.1\",\r\n                    \"IPAddress\": \"172.19.0.2\",\r\n                }\r\n            }\r\n        }\r\n...\r\n```\r\n4. Write a simple app with the client library:\r\n```\r\npackage main\r\n\r\nimport (\r\n  \"context\"\r\n  \"fmt\"\r\n  \"github.com/docker/docker/api/types\"\r\n  \"github.com/docker/docker/client\"\r\n)\r\n\r\nfunc main() {\r\n  cli, err := client.NewEnvClient()\r\n  if err != nil { panic(err) }\r\n\t\r\n  conts, err := cli.ContainerList(context.Background(), types.ContainerListOptions{All:true})\r\n  if err != nil { panic(err) }\r\n\t\r\n  for _, cont := range conts {\r\n    fmt.Println(cont.Names)\r\n    for k, n := range cont.NetworkSettings.Networks {\r\n      fmt.Println(\"\\t\", k, \"\\t\", n.Gateway, \"\\t\", n.IPAddress, \"\\t\", n.Aliases)\r\n    }\r\n  }\r\n}\r\n```\r\n5. `go run main.go`\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\n$ go run main.go\r\n[/test_compcont_1]\r\n         othernet   172.19.0.1  172.19.0.2   []\r\n         mynet       172.18.0.1  172.18.0.2  []\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\n```\r\n$ go run main.go\r\n[/test_compcont_1]\r\n         othernet   172.19.0.1  172.19.0.2   [\"compcont\", \"b41fa65b66dc\"]\r\n         mynet       172.18.0.1  172.18.0.2  [\"compcont\", \"b41fa65b66dc\", \"mycompcont\"]\r\n```\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nI cannot switch from `docker/docker/client` to `moby/moby/client`:\r\n\r\n```\r\n$ go get github.com/moby/moby/client\r\n# github.com/moby/moby/client\r\nC:\\Users\\eine\\go\\src\\github.com\\moby\\moby\\client\\service_create.go:38: cannot use distributionInspect.Descriptor.Digest (type \"github.com/docker/docker/vendor/github.com/opencontainers/go-digest\".Digest) as type \"github.com/moby/moby/vendor/github.com/opencontainers/go-digest\".Digest in argument to imageWithDigestString\r\nC:\\Users\\eine\\go\\src\\github.com\\moby\\moby\\client\\service_update.go:50: cannot use distributionInspect.Descriptor.Digest (type \"github.com/docker/docker/vendor/github.com/opencontainers/go-digest\".Digest) as type \"github.com/moby/moby/vendor/github.com/opencontainers/go-digest\".Digest in argument to imageWithDigestString\r\n```\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.03.1-ce\r\n API version:  1.27\r\n Go version:   go1.7.5\r\n Git commit:   c6d412e\r\n Built:        Tue Mar 28 00:40:02 2017\r\n OS/Arch:      windows/amd64\r\n\r\nServer:\r\n Version:      17.03.1-ce\r\n API version:  1.27 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   c6d412e\r\n Built:        Fri Mar 24 00:00:50 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 1\r\n Running: 1\r\n Paused: 0\r\n Stopped: 0\r\nImages: 22\r\nServer Version: 17.03.1-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 4ab9917febca54791c5f071a9d1f404867857fcc\r\nrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfe\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.27-moby\r\nOperating System: Alpine Linux v3.5\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 1.934 GiB\r\nName: moby\r\nID: LDKB:3CJT:OB3Q:KFV3:5VPW:P63T:KGBQ:CWKE:O2AU:5Q54:7N2Y:DJA7\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 26\r\n Goroutines: 51\r\n System Time: 2017-06-22T06:24:06.3841556Z\r\n EventsListeners: 1\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n"},{"labels":["api",null],"text":"As seen there: https://github.com/moby/moby/blob/df4ca50805baa1d1488d811e82125f607c8daa09/integration-cli/docker_api_swarm_service_test.go#L63,\r\nthere is an `insertDefaults` query parameter not stated in the docs."},{"labels":["api",null],"text":"Using Docker version 17.05.0-ce, build 89658be, I can see the new service spec UpdateConfig and RollbackConfig using `docker service inpspect`.\r\nHowever, despite what is stated in the API docs, those objects are not present in the json returned by the GET /v1.28/service/{id} endpoint.\r\n\r\nBelow are the different output for the same service:\r\n<details><summary>docker inspect output</summary>\r\n<pre>\r\nroot@hosta:/home/cghislai# docker inspect slwksjopffpyist8s6377ptis\r\n[\r\n    {\r\n        \"ID\": \"slwksjopffpyist8s6377ptis\",\r\n        \"Version\": {\r\n            \"Index\": 415670\r\n        },\r\n        \"CreatedAt\": \"2017-04-11T22:50:08.710756004Z\",\r\n        \"UpdatedAt\": \"2017-06-03T14:40:58.679541888Z\",\r\n        \"Spec\": {\r\n            \"Name\": \"proxy_apache2\",\r\n            \"Labels\": {\r\n                \"com.docker.stack.namespace\": \"proxy\"\r\n            },\r\n            \"TaskTemplate\": {\r\n                \"ContainerSpec\": {\r\n                    \"Image\": \"hosta:5000/valuya/proxy:swarm-merge-2@sha256:055b78822db9b3c119a0705e594d4d692583a46cbfd455b4d3d568feabf8015d\",\r\n                    \"Labels\": {\r\n                        \"com.docker.stack.namespace\": \"proxy\"\r\n                    },\r\n                    \"Mounts\": [\r\n                        {\r\n                            \"Type\": \"volume\",\r\n                            \"Source\": \"proxy_config\",\r\n                            \"Target\": \"/etc/apache2\",\r\n                            \"VolumeOptions\": {\r\n                                \"Labels\": {\r\n                                    \"com.docker.stack.namespace\": \"proxy\"\r\n                                }\r\n                            }\r\n                        },\r\n                        {\r\n                            \"Type\": \"volume\",\r\n                            \"Source\": \"proxy_logs\",\r\n                            \"Target\": \"/var/log\",\r\n                            \"VolumeOptions\": {\r\n                                \"Labels\": {\r\n                                    \"com.docker.stack.namespace\": \"proxy\"\r\n                                }\r\n                            }\r\n                        },\r\n                        {\r\n                            \"Type\": \"volume\",\r\n                            \"Source\": \"proxy_webroot\",\r\n                            \"Target\": \"/var/www/html\",\r\n                            \"VolumeOptions\": {\r\n                                \"Labels\": {\r\n                                    \"com.docker.stack.namespace\": \"proxy\"\r\n                                }\r\n                            }\r\n                        },\r\n                        {\r\n                            \"Type\": \"volume\",\r\n                            \"Source\": \"letsencrypt-certificates\",\r\n                            \"Target\": \"/etc/letsencrypt\",\r\n                            \"VolumeOptions\": {}\r\n                        }\r\n                    ],\r\n                    \"StopGracePeriod\": 10000000000,\r\n                    \"DNSConfig\": {}\r\n                },\r\n                \"Resources\": {\r\n                    \"Limits\": {\r\n                        \"MemoryBytes\": 1073741824\r\n                    }\r\n                },\r\n                \"RestartPolicy\": {\r\n                    \"Condition\": \"on-failure\",\r\n                    \"Delay\": 5000000000,\r\n                    \"MaxAttempts\": 0\r\n                },\r\n                \"Placement\": {\r\n                    \"Constraints\": [\r\n                        \"node.labels.role.proxy == true\"\r\n                    ]\r\n                },\r\n                \"ForceUpdate\": 0\r\n            },\r\n            \"Mode\": {\r\n                \"Replicated\": {\r\n                    \"Replicas\": 1\r\n                }\r\n            },\r\n            \"UpdateConfig\": {\r\n                \"Parallelism\": 1,\r\n                \"FailureAction\": \"pause\",\r\n                \"Monitor\": 5000000000,\r\n                \"MaxFailureRatio\": 0,\r\n                \"Order\": \"stop-first\"\r\n            },\r\n            \"RollbackConfig\": {\r\n                \"Parallelism\": 1,\r\n                \"FailureAction\": \"pause\",\r\n                \"Monitor\": 5000000000,\r\n                \"MaxFailureRatio\": 0,\r\n                \"Order\": \"stop-first\"\r\n            },\r\n            \"Networks\": [\r\n                {\r\n                    \"Target\": \"jqij1df2j8ouj9vbxonssp5a3\",\r\n                    \"Aliases\": [\r\n                        \"apache2\"\r\n                    ]\r\n                }\r\n            ],\r\n            \"EndpointSpec\": {\r\n                \"Mode\": \"vip\",\r\n                \"Ports\": [\r\n                    {\r\n                        \"Protocol\": \"tcp\",\r\n                        \"TargetPort\": 80,\r\n                        \"PublishedPort\": 80,\r\n                        \"PublishMode\": \"ingress\"\r\n                    },\r\n                    {\r\n                        \"Protocol\": \"tcp\",\r\n                        \"TargetPort\": 443,\r\n                        \"PublishedPort\": 443,\r\n                        \"PublishMode\": \"ingress\"\r\n                    },\r\n                    {\r\n                        \"Protocol\": \"tcp\",\r\n                        \"TargetPort\": 5000,\r\n                        \"PublishedPort\": 5000,\r\n                        \"PublishMode\": \"ingress\"\r\n                    }\r\n                ]\r\n            }\r\n        },\r\n        \"PreviousSpec\": {\r\n            \"Name\": \"proxy_apache2\",\r\n            \"Labels\": {\r\n                \"com.docker.stack.namespace\": \"proxy\"\r\n            },\r\n            \"TaskTemplate\": {\r\n                \"ContainerSpec\": {\r\n                    \"Image\": \"hosta:5000/valuya/proxy:swarm-merge-2@sha256:055b78822db9b3c119a0705e594d4d692583a46cbfd455b4d3d568feabf8015d\",\r\n                    \"Labels\": {\r\n                        \"com.docker.stack.namespace\": \"proxy\"\r\n                    },\r\n                    \"Mounts\": [\r\n                        {\r\n                            \"Type\": \"volume\",\r\n                            \"Source\": \"proxy_config\",\r\n                            \"Target\": \"/etc/apache2\",\r\n                            \"VolumeOptions\": {\r\n                                \"Labels\": {\r\n                                    \"com.docker.stack.namespace\": \"proxy\"\r\n                                }\r\n                            }\r\n                        },\r\n                        {\r\n                            \"Type\": \"volume\",\r\n                            \"Source\": \"proxy_logs\",\r\n                            \"Target\": \"/var/log\",\r\n                            \"VolumeOptions\": {\r\n                                \"Labels\": {\r\n                                    \"com.docker.stack.namespace\": \"proxy\"\r\n                                }\r\n                            }\r\n                        },\r\n                        {\r\n                            \"Type\": \"volume\",\r\n                            \"Source\": \"proxy_webroot\",\r\n                            \"Target\": \"/var/www/html\",\r\n                            \"VolumeOptions\": {\r\n                                \"Labels\": {\r\n                                    \"com.docker.stack.namespace\": \"proxy\"\r\n                                }\r\n                            }\r\n                        },\r\n                        {\r\n                            \"Type\": \"volume\",\r\n                            \"Source\": \"letsencrypt-certificates\",\r\n                            \"Target\": \"/etc/letsencrypt\",\r\n                            \"VolumeOptions\": {}\r\n                        }\r\n                    ]\r\n                },\r\n                \"Resources\": {\r\n                    \"Limits\": {\r\n                        \"MemoryBytes\": 1073741824\r\n                    }\r\n                },\r\n                \"RestartPolicy\": {\r\n                    \"Condition\": \"on-failure\",\r\n                    \"MaxAttempts\": 0\r\n                },\r\n                \"Placement\": {\r\n                    \"Constraints\": [\r\n                        \"node.labels.role.proxy == true\"\r\n                    ]\r\n                },\r\n                \"ForceUpdate\": 0\r\n            },\r\n            \"Mode\": {\r\n                \"Replicated\": {\r\n                    \"Replicas\": 1\r\n                }\r\n            },\r\n            \"Networks\": [\r\n                {\r\n                    \"Target\": \"jqij1df2j8ouj9vbxonssp5a3\",\r\n                    \"Aliases\": [\r\n                        \"apache2\"\r\n                    ]\r\n                }\r\n            ],\r\n            \"EndpointSpec\": {\r\n                \"Mode\": \"vip\",\r\n                \"Ports\": [\r\n                    {\r\n                        \"Protocol\": \"tcp\",\r\n                        \"TargetPort\": 80,\r\n                        \"PublishedPort\": 80,\r\n                        \"PublishMode\": \"ingress\"\r\n                    },\r\n                    {\r\n                        \"Protocol\": \"tcp\",\r\n                        \"TargetPort\": 443,\r\n                        \"PublishedPort\": 443,\r\n                        \"PublishMode\": \"ingress\"\r\n                    },\r\n                    {\r\n                        \"Protocol\": \"tcp\",\r\n                        \"TargetPort\": 5000,\r\n                        \"PublishedPort\": 5000,\r\n                        \"PublishMode\": \"ingress\"\r\n                    }\r\n                ]\r\n            }\r\n        },\r\n        \"Endpoint\": {\r\n            \"Spec\": {\r\n                \"Mode\": \"vip\",\r\n                \"Ports\": [\r\n                    {\r\n                        \"Protocol\": \"tcp\",\r\n                        \"TargetPort\": 80,\r\n                        \"PublishedPort\": 80,\r\n                        \"PublishMode\": \"ingress\"\r\n                    },\r\n                    {\r\n                        \"Protocol\": \"tcp\",\r\n                        \"TargetPort\": 443,\r\n                        \"PublishedPort\": 443,\r\n                        \"PublishMode\": \"ingress\"\r\n                    },\r\n                    {\r\n                        \"Protocol\": \"tcp\",\r\n                        \"TargetPort\": 5000,\r\n                        \"PublishedPort\": 5000,\r\n                        \"PublishMode\": \"ingress\"\r\n                    }\r\n                ]\r\n            },\r\n            \"Ports\": [\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"TargetPort\": 80,\r\n                    \"PublishedPort\": 80,\r\n                    \"PublishMode\": \"ingress\"\r\n                },\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"TargetPort\": 443,\r\n                    \"PublishedPort\": 443,\r\n                    \"PublishMode\": \"ingress\"\r\n                },\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"TargetPort\": 5000,\r\n                    \"PublishedPort\": 5000,\r\n                    \"PublishMode\": \"ingress\"\r\n                }\r\n            ],\r\n            \"VirtualIPs\": [\r\n                {\r\n                    \"NetworkID\": \"wyzjnl9m9atethbyevoiynxuj\",\r\n                    \"Addr\": \"10.255.0.4/16\"\r\n                },\r\n                {\r\n                    \"NetworkID\": \"jqij1df2j8ouj9vbxonssp5a3\",\r\n                    \"Addr\": \"10.0.0.2/24\"\r\n                }\r\n            ]\r\n        }\r\n    }\r\n]\r\n</pre>\r\n</details>\r\n\r\n<details><summary>API response body</summary>\r\n<pre>\r\nroot@hosta:/home/cghislai# curl -sG http://localhost:4242/v1.28/services/slwksjopffpyist8s6377ptis | python -m json.tool\r\n{\r\n    \"CreatedAt\": \"2017-04-11T22:50:08.710756004Z\",\r\n    \"Endpoint\": {\r\n        \"Ports\": [\r\n            {\r\n                \"Protocol\": \"tcp\",\r\n                \"PublishMode\": \"ingress\",\r\n                \"PublishedPort\": 80,\r\n                \"TargetPort\": 80\r\n            },\r\n            {\r\n                \"Protocol\": \"tcp\",\r\n                \"PublishMode\": \"ingress\",\r\n                \"PublishedPort\": 443,\r\n                \"TargetPort\": 443\r\n            },\r\n            {\r\n                \"Protocol\": \"tcp\",\r\n                \"PublishMode\": \"ingress\",\r\n                \"PublishedPort\": 5000,\r\n                \"TargetPort\": 5000\r\n            }\r\n        ],\r\n        \"Spec\": {\r\n            \"Mode\": \"vip\",\r\n            \"Ports\": [\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"PublishMode\": \"ingress\",\r\n                    \"PublishedPort\": 80,\r\n                    \"TargetPort\": 80\r\n                },\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"PublishMode\": \"ingress\",\r\n                    \"PublishedPort\": 443,\r\n                    \"TargetPort\": 443\r\n                },\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"PublishMode\": \"ingress\",\r\n                    \"PublishedPort\": 5000,\r\n                    \"TargetPort\": 5000\r\n                }\r\n            ]\r\n        },\r\n        \"VirtualIPs\": [\r\n            {\r\n                \"Addr\": \"10.255.0.4/16\",\r\n                \"NetworkID\": \"wyzjnl9m9atethbyevoiynxuj\"\r\n            },\r\n            {\r\n                \"Addr\": \"10.0.0.2/24\",\r\n                \"NetworkID\": \"jqij1df2j8ouj9vbxonssp5a3\"\r\n            }\r\n        ]\r\n    },\r\n    \"ID\": \"slwksjopffpyist8s6377ptis\",\r\n    \"PreviousSpec\": {\r\n        \"EndpointSpec\": {\r\n            \"Mode\": \"vip\",\r\n            \"Ports\": [\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"PublishMode\": \"ingress\",\r\n                    \"PublishedPort\": 80,\r\n                    \"TargetPort\": 80\r\n                },\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"PublishMode\": \"ingress\",\r\n                    \"PublishedPort\": 443,\r\n                    \"TargetPort\": 443\r\n                },\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"PublishMode\": \"ingress\",\r\n                    \"PublishedPort\": 5000,\r\n                    \"TargetPort\": 5000\r\n                }\r\n            ]\r\n        },\r\n        \"Labels\": {\r\n            \"com.docker.stack.namespace\": \"proxy\"\r\n        },\r\n        \"Mode\": {\r\n            \"Replicated\": {\r\n                \"Replicas\": 1\r\n            }\r\n        },\r\n        \"Name\": \"proxy_apache2\",\r\n        \"Networks\": [\r\n            {\r\n                \"Aliases\": [\r\n                    \"apache2\"\r\n                ],\r\n                \"Target\": \"jqij1df2j8ouj9vbxonssp5a3\"\r\n            }\r\n        ],\r\n        \"TaskTemplate\": {\r\n            \"ContainerSpec\": {\r\n                \"Image\": \"hosta:5000/valuya/proxy:swarm-merge-2@sha256:055b78822db9b3c119a0705e594d4d692583a46cbfd455b4d3d568feabf8015d\",\r\n                \"Labels\": {\r\n                    \"com.docker.stack.namespace\": \"proxy\"\r\n                },\r\n                \"Mounts\": [\r\n                    {\r\n                        \"Source\": \"proxy_config\",\r\n                        \"Target\": \"/etc/apache2\",\r\n                        \"Type\": \"volume\",\r\n                        \"VolumeOptions\": {\r\n                            \"Labels\": {\r\n                                \"com.docker.stack.namespace\": \"proxy\"\r\n                            }\r\n                        }\r\n                    },\r\n                    {\r\n                        \"Source\": \"proxy_logs\",\r\n                        \"Target\": \"/var/log\",\r\n                        \"Type\": \"volume\",\r\n                        \"VolumeOptions\": {\r\n                            \"Labels\": {\r\n                                \"com.docker.stack.namespace\": \"proxy\"\r\n                            }\r\n                        }\r\n                    },\r\n                    {\r\n                        \"Source\": \"proxy_webroot\",\r\n                        \"Target\": \"/var/www/html\",\r\n                        \"Type\": \"volume\",\r\n                        \"VolumeOptions\": {\r\n                            \"Labels\": {\r\n                                \"com.docker.stack.namespace\": \"proxy\"\r\n                            }\r\n                        }\r\n                    },\r\n                    {\r\n                        \"Source\": \"letsencrypt-certificates\",\r\n                        \"Target\": \"/etc/letsencrypt\",\r\n                        \"Type\": \"volume\",\r\n                        \"VolumeOptions\": {}\r\n                    }\r\n                ]\r\n            },\r\n            \"ForceUpdate\": 0,\r\n            \"Placement\": {\r\n                \"Constraints\": [\r\n                    \"node.labels.role.proxy == true\"\r\n                ]\r\n            },\r\n            \"Resources\": {\r\n                \"Limits\": {\r\n                    \"MemoryBytes\": 1073741824\r\n                }\r\n            },\r\n            \"RestartPolicy\": {\r\n                \"Condition\": \"on-failure\",\r\n                \"MaxAttempts\": 0\r\n            }\r\n        }\r\n    },\r\n    \"Spec\": {\r\n        \"EndpointSpec\": {\r\n            \"Mode\": \"vip\",\r\n            \"Ports\": [\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"PublishMode\": \"ingress\",\r\n                    \"PublishedPort\": 80,\r\n                    \"TargetPort\": 80\r\n                },\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"PublishMode\": \"ingress\",\r\n                    \"PublishedPort\": 443,\r\n                    \"TargetPort\": 443\r\n                },\r\n                {\r\n                    \"Protocol\": \"tcp\",\r\n                    \"PublishMode\": \"ingress\",\r\n                    \"PublishedPort\": 5000,\r\n                    \"TargetPort\": 5000\r\n                }\r\n            ]\r\n        },\r\n        \"Labels\": {\r\n            \"com.docker.stack.namespace\": \"proxy\"\r\n        },\r\n        \"Mode\": {\r\n            \"Replicated\": {\r\n                \"Replicas\": 1\r\n            }\r\n        },\r\n        \"Name\": \"proxy_apache2\",\r\n        \"Networks\": [\r\n            {\r\n                \"Aliases\": [\r\n                    \"apache2\"\r\n                ],\r\n                \"Target\": \"jqij1df2j8ouj9vbxonssp5a3\"\r\n            }\r\n        ],\r\n        \"TaskTemplate\": {\r\n            \"ContainerSpec\": {\r\n                \"Image\": \"hosta:5000/valuya/proxy:swarm-merge-2@sha256:055b78822db9b3c119a0705e594d4d692583a46cbfd455b4d3d568feabf8015d\",\r\n                \"Labels\": {\r\n                    \"com.docker.stack.namespace\": \"proxy\"\r\n                },\r\n                \"Mounts\": [\r\n                    {\r\n                        \"Source\": \"proxy_config\",\r\n                        \"Target\": \"/etc/apache2\",\r\n                        \"Type\": \"volume\",\r\n                        \"VolumeOptions\": {\r\n                            \"Labels\": {\r\n                                \"com.docker.stack.namespace\": \"proxy\"\r\n                            }\r\n                        }\r\n                    },\r\n                    {\r\n                        \"Source\": \"proxy_logs\",\r\n                        \"Target\": \"/var/log\",\r\n                        \"Type\": \"volume\",\r\n                        \"VolumeOptions\": {\r\n                            \"Labels\": {\r\n                                \"com.docker.stack.namespace\": \"proxy\"\r\n                            }\r\n                        }\r\n                    },\r\n                    {\r\n                        \"Source\": \"proxy_webroot\",\r\n                        \"Target\": \"/var/www/html\",\r\n                        \"Type\": \"volume\",\r\n                        \"VolumeOptions\": {\r\n                            \"Labels\": {\r\n                                \"com.docker.stack.namespace\": \"proxy\"\r\n                            }\r\n                        }\r\n                    },\r\n                    {\r\n                        \"Source\": \"letsencrypt-certificates\",\r\n                        \"Target\": \"/etc/letsencrypt\",\r\n                        \"Type\": \"volume\",\r\n                        \"VolumeOptions\": {}\r\n                    }\r\n                ]\r\n            },\r\n            \"ForceUpdate\": 0,\r\n            \"Placement\": {\r\n                \"Constraints\": [\r\n                    \"node.labels.role.proxy == true\"\r\n                ]\r\n            },\r\n            \"Resources\": {\r\n                \"Limits\": {\r\n                    \"MemoryBytes\": 1073741824\r\n                }\r\n            },\r\n            \"RestartPolicy\": {\r\n                \"Condition\": \"on-failure\",\r\n                \"MaxAttempts\": 0\r\n            }\r\n        }\r\n    },\r\n    \"UpdatedAt\": \"2017-06-03T14:40:58.679541888Z\",\r\n    \"Version\": {\r\n        \"Index\": 415670\r\n    }\r\n}\r\n</pre>\r\n</details>"},{"labels":["api",null],"text":"Now that the websocket endpoint is returning binary frames, it should include an header to differentiate the different streams, similarly to what is done for the /attach endpoint when tty is disabled.\r\nAs frames are atomic and contain a whole log line, a single byte header would probably be sufficient (ie no need to get the frame length, it is already known)\r\n\r\nUnless Im missing something, there is currently no way to differentiate stderr from stdout."},{"labels":["api",null,null,null,null],"text":"**Description**\r\n\r\nMaking an API request to start a container with an empty JSON string in the body will return the following error:\r\n`{\"message\":\"starting container with non-empty request body was deprecated since v1.10 and removed in v1.12\"}`\r\n\r\nThis functionality worked in all previous versions of docker but is now broken in 17.06.0-rc1\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a container\r\n2. Send a request to start the container via the API and an empty JSON string `{}`\r\n3. Get the above error\r\n\r\n```\r\n$ docker create --name my-test alpine top\r\n$ curl -vvv --unix-socket /var/run/docker.sock -X POST -H 'Content-Type: application/json' -d '{}' http://1.29/containers/my-test/start\r\nNote: Unnecessary use of -X or --request, POST is already inferred.\r\n*   Trying /var/run/docker.sock...\r\n...\r\n> POST /containers/my-test/start HTTP/1.1\r\n> Host: 1.29\r\n> User-Agent: curl/7.51.0\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 2\r\n>\r\n* upload completely sent off: 2 out of 2 bytes\r\n< HTTP/1.1 400 Bad Request\r\n< Api-Version: 1.30\r\n< Content-Length: 109\r\n< Content-Type: application/json\r\n< Date: Fri, 02 Jun 2017 21:57:20 GMT\r\n< Docker-Experimental: true\r\n< Ostype: linux\r\n< Server: Docker/17.06.0-ce-rc1 (linux)\r\n<\r\n{\"message\":\"starting container with non-empty request body was deprecated since v1.10 and removed in v1.12\"}\r\n* Curl_http_done: called premature == 0\r\n* Connection #0 to host 1.29 left intact\r\n```\r\nTo make it work:\r\n```\r\n$ curl --unix-socket /var/run/docker.sock -X POST -H 'Content-Type: application/json' -d '' http://1.29/containers/my-test/start\r\n```\r\n\r\n**Describe the results you received:**\r\n`{\"message\":\"starting container with non-empty request body was deprecated since v1.10 and removed in v1.12\"}`\r\n\r\n**Describe the results you expected:**\r\nFor the container to start\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nhttps://github.com/moby/moby/blob/master/api/server/router/container/container_routes.go#L144\r\n\r\n\r\n\r\n**Output of `docker version`:**\r\n\r\n```                                                                                                                                          \r\nClient:\r\n Version:      17.06.0-ce-rc1\r\n API version:  1.30\r\n Go version:   go1.8.1\r\n Git commit:   7f8486a\r\n Built:        Wed May 31 02:56:01 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.06.0-ce-rc1\r\n API version:  1.30 (minimum version 1.12)\r\n Go version:   go1.8.1\r\n Git commit:   7f8486a\r\n Built:        Wed May 31 03:00:14 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nVersion 17.06.0-rc1-ce-mac13 (18169)\r\n"},{"labels":["api",null,null,null],"text":"While discussing https://github.com/moby/moby/issues/31115 with @aaronlehmann, it came to light that the service inspect API may not expose all properties of services. As a result, changes in service-specs may not be visible when doing `docker service inspect` (and thus hide _what_ changed in a service, causing the tasks to be re-deployed).\r\n\r\nOpening this issue for discussion / tracking\r\n\r\nAlso ping @aluzzardi - possibly for e2e testing"},{"labels":["api",null,null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\nWhen trying to authenticate through the API via cURL request, calling /auth returns `Status: Login Succeeded` and an empty `IdentityToken`.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Call this:\r\n```\r\ncurl --unix-socket /var/run/docker.sock -X POST http:/auth --data '{\"username\": \"my_username\", \"password\": \"my_secret_password\", \"serveraddress\": \"myserver.dockeraddress.com\"}'\r\n```\r\n\r\n**Describe the results you received:**\r\n`{\"IdentityToken\":\"\",\"Status\":\"Login Succeeded\"}`\r\n\r\n**Describe the results you expected:**\r\n`{\"IdentityToken\":\"someIdentityToken\",\"Status\":\"Login Succeeded\"}`\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nHappens every time. Can't get it working.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.05.0-ce\r\n API version:  1.29\r\n Go version:   go1.7.5\r\n Git commit:   89658be\r\n Built:        Thu May  4 22:10:54 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.05.0-ce\r\n API version:  1.29 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   89658be\r\n Built:        Thu May  4 22:10:54 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 3\r\n Running: 2\r\n Paused: 0\r\n Stopped: 1\r\nImages: 53\r\nServer Version: 17.05.0-ce\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 92\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins: \r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145\r\nrunc version: 9c2d8d184e5da67c95d601382adf14862e4f2228\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-78-generic\r\nOperating System: Ubuntu 16.04.2 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 8\r\nTotal Memory: 7.609GiB\r\nName: hans\r\nID: AIQ4:OYGK:GH5C:TRQI:34ZC:DMGO:HTII:EDOY:F65B:RAVX:EHHB:OLW7\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nPhysical personal machine"},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\nThe current `swagger.yaml` file on the master branch, when rendered, causes some fields to not render, and the page then hangs.\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. `make swagger-docs`\r\n2. Go to `localhost:9000` in your browser\r\n3. Go to `/services/create`, click on `TaskTemplate`\r\n4. Try clicking anywhere else on the page\r\n\r\n**Describe the results you received:**\r\nThe page hangs\r\n\r\n**Describe the results you expected:**\r\nThe page shouldn't hang, and it should be possible to continue viewing fields."},{"labels":["api",null,null],"text":"**Description**\r\n\r\nDocker prune commands are not taking `reference` into account when filtering.  I have tested with the volume and image subcommands, there may be others.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n1. Run a prune command\r\n\r\n`docker pull alpine`\r\n`docker image prune --filter reference=alpine`\r\n`docker image ls`\r\n\r\n**Describe the results you received:**\r\n\r\nThe filter isn't picking up the reference specified.\r\n\r\n**Describe the results you expected:**\r\n\r\nExpect the prune command to remove only the alpine image, but it doesn't remove any.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nHere's the full output of the image prune command:\r\n\r\n```\r\ndocker image prune --filter reference=alpine\r\nWARNING! This will remove all dangling images.\r\nAre you sure you want to continue? [y/N] y\r\nTotal reclaimed space: 0B\r\n```\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\n docker version                                                                                                                                                                                      joshuareichardt@Joshuas-MacBook-Pro\r\nClient:\r\n Version:      17.05.0-ce-rc1\r\n API version:  1.29\r\n Go version:   go1.7.5\r\n Git commit:   2878a85\r\n Built:        Tue Apr 11 20:55:05 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.05.0-ce-rc1\r\n API version:  1.29 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   2878a85\r\n Built:        Tue Apr 11 20:55:05 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\ndocker info                                                                                                                                                                                         joshuareichardt@Joshuas-MacBook-Pro\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 11\r\nServer Version: 17.05.0-ce-rc1\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145\r\nrunc version: 9c2d8d184e5da67c95d601382adf14862e4f2228\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.21-moby\r\nOperating System: Alpine Linux v3.5\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 1.952GiB\r\nName: moby\r\nID: R663:ASEF:JLSY:ZWUY:D46M:3X47:K4SY:67GO:2QGQ:NML4:JKEW:XIJV\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 19\r\n Goroutines: 29\r\n System Time: 2017-05-10T17:14:49.298869229Z\r\n EventsListeners: 1\r\nNo Proxy: *.local, 169.254/16\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n localhost:5000\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):** Docker for mac (17.05.0-ce-rc1-mac8)\r\n"},{"labels":["api",null,null,null],"text":"Some error messages returned by the daemon / API are referring to CLI flags not being valid, for example;\r\n\r\n- [runconfig/hostconfig_windows.go#L34](https://github.com/moby/moby/blob/4af3389d43d93f50d9b4fa217de148ec45abf8cb/runconfig/hostconfig_windows.go#L34)\r\n- [hostconfig_windows.go#L49](https://github.com/moby/moby/blob/4af3389d43d93f50d9b4fa217de148ec45abf8cb/runconfig/hostconfig_windows.go#L49)\r\n\r\nGiven that these are returned by the API, not the CLI, and we cannot assume that the _docker_ CLI is used as a client (it can be any (API) client), we should make these messages more generic and have them refer to the API-option that is not supported, not the CLI flag."},{"labels":["api",null],"text":"**Description**\r\n\r\nI'm in the process of interfacing with the Docker Engine API. I'm using the json-output of `/events`, and I noticed the exec-related events are a bit strange. I'm not sure I should call it a bug or a feature request, but I'm leaning towards the former.\r\n\r\nIn the docs at https://docs.docker.com/engine/api/v1.28/#operation/SystemEvents it states that it can report certain container events: `attach, ... exec_create, exec_detach, exec_start, ..., update`.\r\nThe example json response shows these values are being returned in the `Action`-field at the root of the json-object. \r\n\r\nFor the exec-related events, the value in that Action field is suffixed with the command being executed, which makes it harder to parse. For example, `docker exec [container] touch /tmp/foobar` will result in `{ ..., \"Action\":\"exec_create: touch /tmp/foobar\", ...}` and `{..., \"Action\":\"exec_start: touch /tmp/foobar\", ...}`. The `status`-field shows the same data.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\nThis works with every image / exec-command, as far as I know:\r\n\r\n1. Run `docker run --name eventstuff -d phusion/baseimage`\r\n2. In a second terminal run `curl --no-buffer --unix-socket /var/run/docker.sock http:/v1.28/events`\r\n3. In the first terminal run `docker exec eventstuff touch /tmp/foobar`\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\n{\"status\":\"exec_create: touch /tmp/foobar\",\"id\":\"[...]\",\"from\":\"phusion/baseimage\",\"Type\":\"container\",\"Action\":\"exec_create: touch /tmp/foobar\",\"Actor\":{\"ID\":\"[...]\",\"Attributes\":{\"image\":\"phusion/baseimage\",\"name\":\"eventstuff\"}},\"time\":1493976336,\"timeNano\":1493976336680190415}\r\n{\"status\":\"exec_start: touch /tmp/foobar\",\"id\":\"[...]\",\"from\":\"phusion/baseimage\",\"Type\":\"container\",\"Action\":\"exec_start: touch /tmp/foobar\",\"Actor\":{\"ID\":\"[...]\",\"Attributes\":{\"image\":\"phusion/baseimage\",\"name\":\"eventstuff\"}},\"time\":1493976336,\"timeNano\":1493976336680626546}\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\n```\r\n{\"status\":\"exec_create\",\"id\":\"[...]\",\"from\":\"phusion/baseimage\",\"Type\":\"container\",\"Action\":\"exec_create\",\"Actor\":{\"ID\":\"[...]\",\"Attributes\":{\"image\":\"phusion/baseimage\",\"name\":\"eventstuff\"}},\"time\":1493976336,\"timeNano\":1493976336680190415}\r\n{\"status\":\"exec_start\",\"id\":\"[...]\",\"from\":\"phusion/baseimage\",\"Type\":\"container\",\"Action\":\"exec_start\",\"Actor\":{\"ID\":\"[...]\",\"Attributes\":{\"image\":\"phusion/baseimage\",\"name\":\"eventstuff\"}},\"time\":1493976336,\"timeNano\":1493976336680626546}\r\n```\r\n\r\nThe main problem is that the suffixed command should not be in the `Action`-field. There are a few other remarks I have about the exec-events:\r\n\r\n- the exec events could have their own type, so they can return their instance-id (to be used with `GET /exec/[id]/json`) and the container-id.\r\n- the exec events could also include an event for when the exec-instance has died, so the full lifecycle is covered. Ideally, this event will also return the exit-code of the instance.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.04.0-ce\r\n API version:  1.28\r\n Go version:   go1.8\r\n Git commit:   4845c567eb\r\n Built:        Sat Apr  8 18:55:45 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.04.0-ce\r\n API version:  1.28 (minimum version 1.12)\r\n Go version:   go1.8\r\n Git commit:   4845c567eb\r\n Built:        Sat Apr  8 18:55:45 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 36\r\n Running: 28\r\n Paused: 0\r\n Stopped: 8\r\nImages: 17\r\nServer Version: 17.04.0-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins: \r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: \r\ncontainerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73\r\nrunc version: 9c2d8d184e5da67c95d601382adf14862e4f2228\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.10.13-1-ARCH\r\nOperating System: Arch Linux\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 8\r\nTotal Memory: 15.56GiB\r\nName: thebringeroflight\r\nID: M552:GIKC:2YPD:PVD2:GRRY:QFCA:6XPE:FXHB:6JYK:N4NN:BCBI:JWAL\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nProbably not relevant, but I'm running this on my development workstation, a physical machine.\r\n"},{"labels":["api",null],"text":"### Documentation Problem Description\r\n\r\nPer @gdevillele , the API reference topic [Delete unused volumes](https://docs.docker.com/engine/api/v1.28/#operation/VolumePrune) mentions a `filters` query parameter, but doesn‚Äôt mention any supported argument (because there isn‚Äôt any). This doesn‚Äôt make sense, we should not mention this ‚Äúfilters‚Äù parameter.\r\n\r\n### Where Found\r\n\r\n[Delete unused volumes](https://docs.docker.com/engine/api/v1.28/#operation/VolumePrune) in the API reference docs. \r\n\r\n### About the docs\r\n\r\nCurrently, the  API docs source lives here in the `moby/moby` codebase, not in the docs repository https://github.com/docker/docker.github.io. \r\n\r\n@thaJeztah need guidance on how we will deal with the relationship between `moby/moby` and the docs repository going forward. I don't have permissions to assign issues, but I suggest assigning to @mstanleyjones ?\r\n\r\n### Reviewers\r\n\r\n@gdevillele @johndmulhausen @thaJeztah \r\n\r\n"},{"labels":["api",null],"text":"A couple of metrics we have are not following Prometheus naming conventions.\r\n\r\nSince they're still experimental, we can fix those:\r\n```\r\n$ curl http://localhost:3000/metrics | promtool check-metrics\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100  155k  100  155k    0     0  9472k      0 --:--:-- --:--:-- --:--:-- 9692k\r\nengine_daemon_events_subscribers_total: non-counter metrics should not have \"_total\" suffix\r\nhttp_request_duration_microseconds: use base unit \"seconds\" instead of \"microseconds\"\r\n```\r\n\r\n/cc @crosbymichael  @juliusv @thaJeztah "},{"labels":["api",null,null,null],"text":"Hello,\r\n\r\ni have an error using this page (click into \"Labels\" men√π):\r\n\r\nhttps://docs.docker.com/engine/api/v1.28/#operation/ServiceCreate\r\n\r\nJS Console stacktrace:\r\n\r\nError: Can't load component schema at /paths/~1services~1create/post/parameters/0/schema/properties/Labels\r\n    at d (redoc.1.11.0.min.js:43)\r\n    at e.init (redoc.1.11.0.min.js:17)\r\n    at e.t.preinit (redoc.1.11.0.min.js:9)\r\n    at e.preinit (redoc.1.11.0.min.js:9)\r\n    at e.ngOnInit (redoc.1.11.0.min.js:17)\r\n    at t.ngDoCheck (redoc.1.11.0.min.js:15)\r\n    at e.detectChangesInternal (redoc.1.11.0.min.js:15)\r\n    at e.t.detectChanges (redoc.1.11.0.min.js:7)\r\n    at t.detectChangesInNestedViews (redoc.1.11.0.min.js:7)\r\n    at e.detectChangesInternal (redoc.1.11.0.min.js:16)\r\n    at e.t.detectChanges (redoc.1.11.0.min.js:7)\r\n    at t.detectChangesInNestedViews (redoc.1.11.0.min.js:7)\r\n    at e.detectChangesInternal (redoc.1.11.0.min.js:16)\r\n    at e.t.detectChanges (redoc.1.11.0.min.js:7)\r\n    at t.detectChangesInNestedViews (redoc.1.11.0.min.js:7)"},{"labels":["api",null,null,null],"text":"The docker CLI is moving to it's own repository, `docker/cli` See https://github.com/moby/moby/pull/32694\r\n\r\nThe current plan is to leave the HTTP engine API in the moby repo. It will work for now because \"docker engine\" is still a monolith, but it will get problematic as soon as we start splitting it into components.\r\n\r\nWe need a plan moving forward. Suggestions welcome :D"},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\nThe http endpoint `GET /networks` always returns an empty containers list. If requesting a single network, with `GET /networks/<network>` the containers are shown. \r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. Run `curl --unix-socket /var/run/docker.sock http:/v1.28/networks`\r\n\r\n**Describe the results you received:**\r\nReturns the following output: https://gist.github.com/Grisu118/1a15ea9a2abb6b04f45eb911a2f1c7f7#file-networks-json\r\n\r\n**Describe the results you expected:**\r\nI expect the output contains a container list like the /networks/development request:\r\nhttps://gist.github.com/Grisu118/1a15ea9a2abb6b04f45eb911a2f1c7f7#file-networks_development-json\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nWorked in 13.x (don't know the exact version which was running before reboot)\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.04.0-ce\r\n API version:  1.28\r\n Go version:   go1.7.3\r\n Git commit:   4845c56\r\n Built:        Wed Apr 12 22:57:26 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.04.0-ce\r\n API version:  1.28 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   4845c56\r\n Built:        Wed Apr 12 22:57:26 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 28\r\n Running: 25\r\n Paused: 0\r\n Stopped: 3\r\nImages: 37\r\nServer Version: 17.04.0-ce\r\nStorage Driver: overlay\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary:\r\ncontainerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73\r\nrunc version: 9c2d8d184e5da67c95d601382adf14862e4f2228\r\ninit version: N/A (expected: 949e6facb77383876aeff8a6944dde66b3089574)\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.10.9-coreos\r\nOperating System: Container Linux by CoreOS 1381.0.0 (Ladybug)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 15.68GiB\r\nName: test01\r\nID: NDXW:B2RO:4U2N:CQRG:P7QK:DT53:DNTE:GH3A:N7IZ:2MSK:HHXC:MRTU\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n\r\nWARNING: bridge-nf-call-iptables is disabled\r\nWARNING: bridge-nf-call-ip6tables is disabled\r\n```\r\n"},{"labels":["api",null],"text":"Docker REST API 1.27 cannot be loaded with the SwaggerUI. It gives the error:\r\n\r\n```\r\n{\r\n\"messages\": [\r\n\"attribute definitions.RestartPolicy.default is not of type `string`\"\r\n]\r\n}\r\n```\r\n\r\nThe error can be seen at https://online.swagger.io/validator/debug?url=https://docs.docker.com/engine/api/v1.27/swagger.yaml.\r\n"},{"labels":["api"],"text":"Saw this in `UpdateStatus`:\r\n\r\n```\r\n        \"UpdateStatus\": {\r\n            \"State\": \"updating\",\r\n            \"StartedAt\": \"2017-04-14T17:10:03.226607162Z\",\r\n            \"CompletedAt\": \"1970-01-01T00:00:00Z\",\r\n            \"Message\": \"update in progress\"\r\n        }\r\n```\r\n\r\n#29041 was supposed to prevent this. It seems not to be working properly."},{"labels":["api",null,null],"text":"I've looked through tickets, code, google, but do not see any procedure for calling dockerd through the latest API and running a similar command as:\r\n```\r\ndocker stack deploy -c docker-compose-stack.yml foo\r\n```\r\n\r\nI'd like to be able to build my own service running in a container then call the hosts docker service (if appropriate) to deploy into swarm mode. I'd like to do this without something hacky like SSHing back into the host and running a shell. That would unnecessary require additional pem and account configuration on the host.\r\n\r\nIf you know a work around or a best practice, please advise. Else this should be added as a feature to the API."},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nLinks property always is null, even whether the container has links.\r\n\r\n**Steps to reproduce the issue:**\r\n1. `docker run --net=dore-network -d --name node1 busybox tail -f /dev/null`\r\n2. `docker run --net=dore-network --link node1 -d --name node2 busybox tail -f /dev/null`\r\n3. `docker inspect node2`\r\n4. `curl --unix-socket /var/run/docker.sock http:/v1.26/containers/json | grep Links`\r\n\r\n**Describe the results you received:**\r\n\r\ninspect command:\r\n\r\n```\r\n...\r\n\"Networks\": {\r\n  \"dore-network\": {\r\n    ....\r\n    \"Links\": [\r\n      \"node1\"\r\n    ],\r\n    ...\r\n    }\r\n  }\r\n....\r\n```\r\n\r\nwith cURL command:\r\n\r\n```\r\n[{\"Id\":\"a43c96d41cacad628b5a51860650aa123c25416e16c563790a8eb76001d1b86f\",\"Names\":[\"/node2\"],\"Image\":\"busybox\",\"ImageID\":\"sha256:00f017a8c2a6e1fe2ffd05c281f27d069d2a99323a8cd514dd35f228ba26d2ff\",\"Command\":\"tail -f /dev/null\",\"Created\":1491275358,\"Ports\":[],\"Labels\":{},\"State\":\"running\",\"Status\":\"Up About a minute\",\"HostConfig\":{\"NetworkMode\":\"dore-network\"},\"NetworkSettings\":{\"Networks\":{\"dore-network\":{\"IPAMConfig\":null,\"Links\":null,\"Aliases\":null,\"NetworkID\":\"0c312941cff131e01bc038a9e7d196a0faf77c03ed38c365715755dc3c61b2ae\",\"EndpointID\":\"62df24f75be4a2b47eba58802c76417dc4cc6bb0a8b07c5908e2269e6bc0aa8a\",\"Gateway\":\"172.18.0.1\",\"IPAddress\":\"172.18.0.3\",\"IPPrefixLen\":16,\"IPv6Gateway\":\"\",\"GlobalIPv6Address\":\"\",\"GlobalIPv6PrefixLen\":0,\"MacAddress\":\"02:42:ac:12:00:03\"}}},\"Mounts\":[]},{\"Id\":\"3640df7f388ee551cb00b8c9040cca240e89891b2f11235943567e533b1f013e\",\"Names\":[\"/node1\"],\"Image\":\"busybox\",\"ImageID\":\"sha256:00f017a8c2a6e1fe2ffd05c281f27d069d2a99323a8cd514dd35f228ba26d2ff\",\"Command\":\"tail -f /dev/null\",\"Created\":1491275350,\"Ports\":[],\"Labels\":{},\"State\":\"running\",\"Status\":\"Up About a minute\",\"HostConfig\":{\"NetworkMode\":\"dore-network\"},\"NetworkSettings\":{\"Networks\":{\"dore-network\":{\"IPAMConfig\":null,\"Links\":null,\"Aliases\":null,\"NetworkID\":\"0c312941cff131e01bc038a9e7d196a0faf77c03ed38c365715755dc3c61b2ae\",\"EndpointID\":\"164c2b50d545660089b0eacb98a90e7334ebdbeca7cc16ce4448d283e644b076\",\"Gateway\":\"172.18.0.1\",\"IPAddress\":\"172.18.0.2\",\"IPPrefixLen\":16,\"IPv6Gateway\":\"\",\"GlobalIPv6Address\":\"\",\"GlobalIPv6PrefixLen\":0,\"MacAddress\":\"02:42:ac:12:00:02\"}}},\"Mounts\":[]}]\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\nInspect and Curl must be consistent. Curl response should have the Links information.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.1\r\n API version:  1.26\r\n Go version:   go1.7.5\r\n Git commit:   092cba3\r\n Built:        Wed Feb  8 06:50:14 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.1\r\n API version:  1.26 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   092cba3\r\n Built:        Wed Feb  8 06:50:14 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 2\r\n Running: 2\r\n Paused: 0\r\n Stopped: 0\r\nImages: 33\r\nServer Version: 1.13.1\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 171\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins: \r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1\r\nrunc version: 9df8b306d01f59d3a8029be411de015b7304dd8f\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-71-generic\r\nOperating System: Ubuntu 16.04.2 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 7.75 GiB\r\nName: my name\r\nID: Y4B7:ICGF:AXJG:HHJT:6LUD:W3IA:FUAY:TZNX:LYXF:U3V3:VI2R:5UF6\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n"},{"labels":["api",null,null,null,null],"text":"**Description**\r\n\r\nI foundt that SwarmKit in docker does not validate health check parameters in a service create request.\r\n\r\n**Steps to reproduce the issue:**\r\n1. use api to create a service, in the service spec, we add parameter of HealthCheck.\r\n2. in parameter, we add an invalid value, like `timeout -1s, retries -1`, valid timeout should be larger than 1s, and valid retires should be a positive integer.\r\n3. send the request to create this service\r\n\r\nrequest like the following pic:\r\n![wechatimg8](https://cloud.githubusercontent.com/assets/9465626/24639949/eb42ecb8-1925-11e7-8154-6f05a47ad069.jpeg)\r\n\r\n\r\n\r\n**Describe the results you received:**\r\nService created OK\r\n\r\n**Describe the results you expected:**\r\nparameter invalid\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nroot@ubuntu:~# docker version\r\nClient:\r\n Version:      17.03.0-ce\r\n API version:  1.26\r\n Go version:   go1.7.5\r\n Git commit:   60ccb22\r\n Built:        Thu Feb 23 10:57:47 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.03.0-ce\r\n API version:  1.26 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   60ccb22\r\n Built:        Thu Feb 23 10:57:47 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nroot@ubuntu:~# docker info\r\nContainers: 3\r\n Running: 3\r\n Paused: 0\r\n Stopped: 0\r\nImages: 116\r\nServer Version: 17.03.0-ce\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 148\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: active\r\n NodeID: vfb7vr7wp1dirmop8fbvmmgh7\r\n Is Manager: true\r\n ClusterID: mzzbi2s44h4vesargizzywryz\r\n Managers: 1\r\n Nodes: 2\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 192.168.59.103\r\n Manager Addresses:\r\n  192.168.59.103:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 977c511eda0925a723debdc94d09459af49d082a\r\nrunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\nKernel Version: 3.19.0-25-generic\r\nOperating System: Ubuntu 14.04.3 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 1.954 GiB\r\nName: ubuntu\r\nID: FXOY:JCOY:HKDI:VO5U:FYDM:UEXV:YIFN:AISM:NR6U:VMW5:V4MZ:RQWF\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 52\r\n Goroutines: 154\r\n System Time: 2017-03-27T14:28:38.061668428+08:00\r\n EventsListeners: 3\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null,null],"text":"---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\n**Description**\r\nUsing the `--since` and `--tail` flags with the command line tool, or the `since` or `tail` parameters via the API, does not yield expected results.\r\n\r\n**Steps to reproduce the issue:**\r\nThe following is true for either the cli or the API, but I'll describe it for the cli to keep things simple:\r\n\r\n1. Run `docker service logs --tail 1 [SERVICE]` or `docker service logs [1491249483 || 1m10s etc.] [SERVICE]`\r\n\r\n**Describe the results you received:**\r\nMany lines returned, and in the case of failing services which are retrying every n seconds, this is _thousands_ of lines.\r\n\r\n**Describe the results you expected:**\r\nWith `--tail 1`, only 1 line returned. With `--since [TIMESTAMP]` only lines returned since that timestamp.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nIt seems that the extra lines are the result of grabbing logs from all service tasks, though I could be wrong.\r\n\r\nQuerying the individual containers created by the `docker service` command, the `--tail` and `--since` options work as expected.\r\n\r\n**Output of `docker version`:**\r\n\r\nOutput is from my Mac, but the same thing happens for the same version on Linux:\r\n```\r\nClient:\r\n Version:      17.03.1-ce\r\n API version:  1.27\r\n Go version:   go1.7.5\r\n Git commit:   c6d412e\r\n Built:        Tue Mar 28 00:40:02 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.03.1-ce\r\n API version:  1.27 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   c6d412e\r\n Built:        Fri Mar 24 00:00:50 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\nAgain this is from my Mac, but the tests were also performed on Linux with a proper swarm, with the same results:\r\n```\r\nContainers: 6                                                                                                                                                             [25/4682]\r\n Running: 1\r\n Paused: 0\r\n Stopped: 5\r\nImages: 350\r\nServer Version: 17.03.1-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins: \r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\nSwarm: active\r\n NodeID: mp9up3hu4ik275i4nl23hx1zv\r\n Is Manager: true\r\n ClusterID: flbky82mvb51ngvbmb3a0pvqn\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 192.168.65.2\r\n Manager Addresses:\r\n  192.168.65.2:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 4ab9917febca54791c5f071a9d1f404867857fcc\r\nrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfe\r\ninit version: N/A (expected: 949e6facb77383876aeff8a6944dde66b3089574)\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.13-moby\r\nOperating System: Alpine Linux v3.5\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 1.952 GiB\r\nName: moby\r\nID: IJXO:PQVJ:Z5IQ:AV2T:PNJX:B5IK:L3FW:EOFM:TLUX:WM56:GTBA:GH4W\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 39\r\n Goroutines: 143\r\n System Time: 2017-04-03T19:46:12.33482745Z\r\n EventsListeners: 2\r\nNo Proxy: *.local, 169.254/16\r\nUsername: afrazkhan\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n"},{"labels":["api",null,null,null],"text":"**Description**\r\n\r\nWhen using the format string on `docker inspect`, `.Size` and `.VirtualSize` are an int64, except if you use `.Id` somewhere, in which case they become a float64.   This is specific to images, since container inspect does not have `Size` or `VirtualSize`. \r\n\r\n**Steps to reproduce the issue:**\r\n1. `docker inspect -f '{{printf \"%d\" .Size}} {{.Id}}' alpine`\r\n2. while this works: `docker inspect -f '{{printf \"%d\" .Size}}' alpine`\r\n\r\n**Describe the results you received:**\r\n```console\r\n$ docker inspect -f '{{.VirtualSize}}' alpine\r\n3983636\r\n$ docker inspect -f '{{.VirtualSize}} {{.Id}}' alpine\r\n3.983636e+06 sha256:651aa95985aa4a17a38ffcf71f598ec461924ca96865facc2c5782ef2d2be07f\r\n$ docker inspect -f '{{printf \"%d\" .VirtualSize}}' alpine\r\n3983636\r\n$ docker inspect -f '{{printf \"%d\" .VirtualSize}} {{.Id}}' alpine\r\n%!d(float64=3.983636e+06) sha256:651aa95985aa4a17a38ffcf71f598ec461924ca96865facc2c5782ef2d2be07f\r\n```\r\n\r\n**Describe the results you expected:**\r\n```console\r\n$ docker inspect -f '{{.VirtualSize}}' alpine\r\n3983636\r\n$ docker inspect -f '{{.VirtualSize}} {{.Id}}' alpine\r\n3983636 sha256:651aa95985aa4a17a38ffcf71f598ec461924ca96865facc2c5782ef2d2be07f\r\n$ docker inspect -f '{{printf \"%d\" .VirtualSize}}' alpine\r\n3983636\r\n$ docker inspect -f '{{printf \"%d\" .VirtualSize}} {{.Id}}' alpine\r\n3983636 sha256:651aa95985aa4a17a38ffcf71f598ec461924ca96865facc2c5782ef2d2be07f\r\n```\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nRan a test of all other keys when output with `.Size`. `.VirtualSize` behaves in the same way.\r\n```console\r\n$ for key in $(docker inspect -f '{{ range $k, $v := . }}{{ $k }}{{ \" \" }}{{ end }}' bash); do docker inspect -f '{{ printf \"Size: %d\" .Size }} '\"$key: \"'{{ .'\"$key\"' }}' bash; done\r\nSize: 12156318 Architecture: amd64\r\nSize: 12156318 Author: \r\nSize: 12156318 Comment: \r\nSize: 12156318 Config: {f78b191c4c87   false false false map[] false false false [PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin _BASH_GPG_KEY=7C0135FB088AAF6C66C650B9BB5869F064EA74AB _BASH_VERSION=4.4 _BASH_PATCH_LEVEL=0 _BASH_LATEST_PATCH=12] [bash] <nil> true sha256:d96e9ab22a9f45a482d1015781dfe702ef9a0497395506872f2d20981e6f53ac map[]  [docker-entrypoint.sh] false  [] map[]  <nil> []}\r\nSize: 12156318 Container: 81f48c4148367410a39fe784fa97ee1a7c23800f23da2c5fa17d8e53db2be560\r\nSize: 12156318 ContainerConfig: {f78b191c4c87   false false false map[] false false false [PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin _BASH_GPG_KEY=7C0135FB088AAF6C66C650B9BB5869F064EA74AB _BASH_VERSION=4.4 _BASH_PATCH_LEVEL=0 _BASH_LATEST_PATCH=12] [/bin/sh -c #(nop)  CMD [\"bash\"]] <nil> true sha256:d96e9ab22a9f45a482d1015781dfe702ef9a0497395506872f2d20981e6f53ac map[]  [docker-entrypoint.sh] false  [] map[]  <nil> []}\r\nSize: 12156318 Created: 2017-03-29T22:37:00.2132178Z\r\nSize: 12156318 DockerVersion: 1.13.1\r\nSize: 12156318 GraphDriver: {overlay map[RootDir:/mnt/spare/docker/overlay/1e17e7a5f76a4bc369a5b73a738d61559ff25f55726fee4d8b0192248da6b3be/root]}\r\nSize: %!d(float64=1.2156318e+07) Id: sha256:c60747d6e1cf2cd4e37d83bc015eb0d5d1be6f49b657c974bad9a6b42b6437b9\r\nSize: 12156318 Os: linux\r\nSize: 12156318 Parent: sha256:d96e9ab22a9f45a482d1015781dfe702ef9a0497395506872f2d20981e6f53ac\r\nSize: 12156318 RepoDigests: []\r\nSize: 12156318 RepoTags: [bash:4 bash:4.4 bash:4.4.12 bash:latest bashbrew/cache:d09e0f0d3ce02d3af7f8bd1148fe6f91f84a50016aa3243b484d799a4c1eb7d1]\r\nSize: 12156318 RootFS: {layers [sha256:9c833b2fdbc966e83b07fdee671b4112949cec9fc34ba84f4444e072de0604c7 sha256:2c03c42f290e3df0cf51b65aa06942024b2496c543d402068c63a0260b6c5ec8 sha256:12953c9fc8d81952ddc76dc592bca6b413d6075783856a94f9bc1e380d3ebbd1] }\r\nSize: 12156318 Size: 12156318\r\nSize: 12156318 VirtualSize: 12156318\r\n```\r\n**Output of `docker version`:**\r\n\r\n```console\r\n$ docker version\r\nClient:\r\n Version:      17.03.1-ce\r\n API version:  1.27\r\n Go version:   go1.8\r\n Git commit:   c6d412e\r\n Built:        Thu Mar 30 12:57:47 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.03.1-ce\r\n API version:  1.27 (minimum version 1.12)\r\n Go version:   go1.8\r\n Git commit:   c6d412e\r\n Built:        Thu Mar 30 12:57:47 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```console\r\n$ docker info\r\nContainers: 4\r\n Running: 4\r\n Paused: 0\r\n Stopped: 0\r\nImages: 9137\r\nServer Version: 17.03.1-ce\r\nStorage Driver: overlay\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins: \r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: v0.2.5 (expected: 4ab9917febca54791c5f071a9d1f404867857fcc)\r\nrunc version: c91b5be (expected: 54296cf40ad8143b62dbcaa1d90e520a2136ddfe)\r\ninit version: N/A (expected: 949e6facb77383876aeff8a6944dde66b3089574)\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.10.2-gentoo\r\nOperating System: Gentoo/Linux\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 8\r\nTotal Memory: 30.87 GiB\r\nName: isengard\r\nID: UOCM:3F65:5FZC:6H5L:W3HY:34G4:A5XZ:SUOV:S2D4:XQTO:4KGA:6XSE\r\nDocker Root Dir: /mnt/spare/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nNot that this should matter: physical box, Gentoo\r\n\r\n**Cute Animal:**\r\n![](http://wallpaper-gallery.net/images/cute-animal-desktop-wallpaper/cute-animal-desktop-wallpaper-27.jpg)"},{"labels":["api",null,null,null],"text":"Hello,\r\n\r\nI have a service with secret parameters and i cannot create it using docker swarm API\r\n\r\nCan you expose secret params into docker swarm API (POST /services/create)?\r\n\r\nThanks\r\n\r\n"},{"labels":["api",null],"text":"Basically https://github.com/docker/docker/blob/master/api/server/httputils/errors.go#L52 has gone on far too long.\r\n\r\nTo replace this, we've tried a couple of different approaches which were pretty disastrous:\r\n\r\n- errcode, which while there's nothing wrong with the errcode package, we used it horribly wrong and for the wrong reasons.\r\n- HTTP errors package - https://github.com/docker/docker/blob/master/api/errors/errors.go#L13\r\n\r\nerrcode was a neat concept but in practice was misused and made the entire codebase just became absolutely horrible to work on where as before the horribleness was contained to just the API layer.\r\n\r\nThis lead to the http errors package currently in use for certain cases. This also seems like an \"ok\" thing, but in practice is also not really used correctly and generally more of a shortcut to correct error handling. We end up with low-level bits worried about HTTP status codes.\r\n\r\nWe need to standardize on a way to handle errors in the API. This potentially needs to be regardless of how the request came in (HTTP, GRPC, or even a direct function call...e.g. cluster->daemon).\r\n\r\nThe goal of good error handling is that the caller knows, or at least knows how to find out, the class of error that occurred so that the error can be dealt with appropriately. This is true of function calls and it is true across the \"remote\" API barrier.\r\n\r\n### Goals\r\n\r\n- API backends (e.g. `daemon`) should ideally not be concerned with HTTP.\r\n- API clients should be able to read a returned error and be able to know *what* an error is.\r\n- Reduce the cognitive overhead in trying to determine how to return an error\r\ni. Example, what status code? (400, 409, 422, 412)\r\nii. How do I get the API to produce that status code I expect?\r\niii. How would non-remote API callers handle my error?\r\n- Ensure status codes don't change because of either a change to the error text, or hopefully even a change to the low-level error type.\r\n\r\nThe way I see it there are really two ways to deal with this (in no particular order):\r\n\r\n### Error class defined in common API package\r\n\r\nThis means in the API package we define several error classes like so (psuedo-code):\r\n\r\n```go\r\npackage api\r\n\r\ntype Error interface {\r\n    error\r\n    NotFound() bool\r\n    // other fn's for conflict, invalid arg, etc\r\n}\r\n\r\ntype apiError struct { \r\n    err error\r\n    notFound bool\r\n    conflict bool\r\n    invalidArg bool\r\n}\r\n\r\nfunc (e *apiError) Error() string { return e.err.Error() }\r\nfunc (e *apiError) NotFound() bool { return e.notFound }\r\n\r\nfunc NewNotFoundError(err error) Error {\r\n    return &apiError{err: err, notFound: true}\r\n}\r\n```\r\n\r\nFrom here the HTTP layer can determine both the error message and the class of error (not found) and the status code to return.\r\n\r\nThis approach is similar to the current approach we have except it's moving the http handling to the http layer and non-http code can just deal with this error type.\r\n\r\nAnother slight alternative but generally the same thing to this would be to use the well defined grpc error codes instead of defining our own. This could fit in well since part of the daemon is already using grpc anyway.\r\n\r\n### Define error handling interfaces on backends\r\n\r\nIn this method, backends would be required to define a set of functions for error handling:\r\n\r\nExample:\r\n\r\n```go\r\npackage api\r\n\r\ntype ErrorInspector interface {\r\n    IsNotFound(error) bool\r\n    IsConflict(error) bool\r\n    IsInvalidArgument(error) bool\r\n}\r\n```\r\n\r\n```go\r\npackage container // container router\r\n\r\nimport \"github.com/docker/docker/api\"\r\n\r\ntype ContainerBackend interface {\r\n    CreateContainer(...) error\r\n    DeleteContainer(...) error\r\n    api.ErrorInspector\r\n}\r\n\r\nfunc(r *containerRouter) getContainer(w http.ResponseWriter, req *http.Request) error {\r\n    err := r.backend.DeleteContainer(...)\r\n    if err != nil {\r\n        if r.backend.IsNotFound(err) {\r\n           // make an HTTP 404\r\n       }\r\n       // make an HTTP 500 probably\r\n    }\r\n\r\n    // normal\r\n}\r\n```\r\n\r\nWriting out the above it seems a little risky since it requires the router to know the failure-modes of the backend. Maybe could be cleaned up a bit.\r\n\r\n\r\nInterested in your thoughts, other alternatives, etc.\r\n\r\nping @docker/core-engine-maintainers "},{"labels":["api",null],"text":"**Description**\r\n\r\nI foundt that SwarmKit in docker does not validate hosts parameters in a service create request.\r\n\r\n**Steps to reproduce the issue:**\r\n1. use api to create a service, in the service spec, we add parameter of Hosts.\r\n2. in parameter, we add an invalid value, like `aaaa`, valid value should has a format of `name:ip`\r\n3. send the request to create this service\r\n\r\nrequest like the following pic:\r\n![wechatimg1](https://cloud.githubusercontent.com/assets/9465626/24343493/57225ae6-12f9-11e7-803e-6d6a9cada977.jpeg)\r\n\r\n\r\n**Describe the results you received:**\r\nService created OK\r\n\r\n**Describe the results you expected:**\r\nparameter invalid\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nroot@ubuntu:~# docker version\r\nClient:\r\n Version:      17.03.0-ce\r\n API version:  1.26\r\n Go version:   go1.7.5\r\n Git commit:   60ccb22\r\n Built:        Thu Feb 23 10:57:47 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.03.0-ce\r\n API version:  1.26 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   60ccb22\r\n Built:        Thu Feb 23 10:57:47 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nroot@ubuntu:~# docker info\r\nContainers: 3\r\n Running: 3\r\n Paused: 0\r\n Stopped: 0\r\nImages: 116\r\nServer Version: 17.03.0-ce\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 148\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: active\r\n NodeID: vfb7vr7wp1dirmop8fbvmmgh7\r\n Is Manager: true\r\n ClusterID: mzzbi2s44h4vesargizzywryz\r\n Managers: 1\r\n Nodes: 2\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 192.168.59.103\r\n Manager Addresses:\r\n  192.168.59.103:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 977c511eda0925a723debdc94d09459af49d082a\r\nrunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\nKernel Version: 3.19.0-25-generic\r\nOperating System: Ubuntu 14.04.3 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 1.954 GiB\r\nName: ubuntu\r\nID: FXOY:JCOY:HKDI:VO5U:FYDM:UEXV:YIFN:AISM:NR6U:VMW5:V4MZ:RQWF\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 52\r\n Goroutines: 154\r\n System Time: 2017-03-27T14:28:38.061668428+08:00\r\n EventsListeners: 3\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api"],"text":"In the gRPC API, `NetworkAttachmentConfig.Target` is always a network ID. In the REST API, the client inserts network names in this field, and they are converted in the daemon before submitting the spec over gRPC.\r\n\r\nI thought this should be filed as an issue because differences between the two APIs are very confusing and lead to bugs. Ideally, we should not be mutating the spec inside the daemon, because that hacks around the declarative nature of the API. The client should be resolving the network IDs and inserting them in the spec."},{"labels":["api",null,null,null],"text":"**Description**\r\n\r\nThe `DiskUsage` call (which backs `docker system df`) can take an extremely long time to finish, since it walks through every container and volume's filesystem. In cases where you have lots of containers or volumes with lots of files, we've seen `DiskUsage` take minutes or even hours to complete, chewing up CPU and disk I/O the whole time. This isn't necessarily incorrect behavior, per se, but it is at least very surprising, especially since `ContainerStats` isn't expensive at all.\r\n\r\nI'm not sure how feasible it would be to improve the performance of `DiskUsage`, but if that's not possible, there should be more messaging around the costs of this API call.\r\n\r\nAlso, is there any way to get the size of an individual volume, or can you only get the size of every volume at once with `DiskUsage`?"},{"labels":["api",null,null],"text":"Debugging the daemon can be quite gruesome work.\r\nEven one of the simplest things like collecting a goroutine stack dump (most common request) is difficult to explain and even more difficult to collect.\r\n\r\nWe already have some API endpoints to aid in debugging but it's only available if debug mode is actually enabled.... forcing a daemon reload (also difficult to explain and perform) to enable it can even mess up the results.\r\n\r\nI propose:\r\n\r\n1. Enable debug endpoints (namely `/debug/pprof/*`) by default.\r\n2. Add a new CLI subcommand `docker debug` which includes a suite of subcommands for pulling the desired information\r\ni. `docker debug stack` -> generates a goroutine stack dump\r\nii. `docker debug profile <blah>` -> generates pprof formatted reports (whatever happens to be supported by the language runtime)\r\nii. `docker debug profile ls` -> List available profiles (this requires a call to the daemon, otherwise would include in `--help` output)\r\n\r\nThese commands either send output directly to stdout or optionally to an output file.\r\n\r\nPotentially also interesting is grabbing a trace or a cpu profile (explicitly not supported above), perhaps by adding a `--trace` or `--cpu-profile` to a `docker` command.... but this may be left as another exercise.\r\n\r\n**note**: not tied to the layout/naming of those commands\r\n\r\nAnything under `/debug` or `docker debug` should be considered non-formal API that is subject to change outside the scope of API versioning.\r\n\r\nIn the future these endpoints can be used to generate something like a support tarball via `docker debug support`."},{"labels":["api",null,null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nWhen I create a secret, then try to create a new secret with the same name, the HTTP error code I get back is wrong.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a secret (either through the command line or the REST API).\r\n```bash\r\n$ echo \"secrets\" | docker secret create my-secret -\r\n```\r\n2. Attempt to create another secret with the same name (this time using the REST API, so you can see the HTTP status you get back.)\r\n```bash\r\n$ curl -i --unix-socket /var/run/docker.sock -X POST -H 'content-type: application/json' -d '{\"Name\": \"my-secret\", \"Data\": \"c2VjcmV0cwo=\"}' http://localhost/secrets/create\r\n```\r\n\r\n**Describe the results you received:**\r\nHTTP 500\r\n```\r\nHTTP/1.1 500 Internal Server Error\r\nApi-Version: 1.26\r\nContent-Length: 73\r\nContent-Type: application/json\r\nDate: Fri, 17 Mar 2017 03:04:56 GMT\r\nDocker-Experimental: true\r\nServer: Docker/17.03.0-ce (linux)\r\n\r\n{\"message\":\"rpc error: code = 6 desc = secret my-secret already exists\"}\r\n```\r\n\r\n**Describe the results you expected:**\r\nHTTP 409 conflict, [as stated in the swagger spec](https://github.com/docker/docker/blob/master/api/swagger.yaml#L7982).\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.03.0-ce\r\n API version:  1.26\r\n Go version:   go1.7.5\r\n Git commit:   60ccb22\r\n Built:        Thu Feb 23 10:40:59 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.03.0-ce\r\n API version:  1.26 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   3a232c8\r\n Built:        Tue Feb 28 07:52:04 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 2\r\n Running: 0\r\n Paused: 0\r\n Stopped: 2\r\nImages: 20\r\nServer Version: 17.03.0-ce\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 34\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\nSwarm: active\r\n NodeID: 2n2g46cvu27nk0yuoowhe1t8b\r\n Is Manager: true\r\n ClusterID: 3j26e6low77hibavv55u87hvp\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 192.168.65.2\r\n Manager Addresses:\r\n  192.168.65.2:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 977c511eda0925a723debdc94d09459af49d082a\r\nrunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.12-moby\r\nOperating System: Alpine Linux v3.5\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 1.952 GiB\r\nName: moby\r\nID: 3NXV:6OUU:O7VQ:BPBV:XDC2:ZPMT:IRSG:VJ3I:SL2H:ZWC2:ECT6:7X4R\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 33\r\n Goroutines: 131\r\n System Time: 2017-03-17T03:11:47.838534917Z\r\n EventsListeners: 1\r\nNo Proxy: *.local, 169.254/16\r\nUsername: xnat\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nI have seen this on Docker for Mac and Ubuntu 14.04, the latter using docker versions [1.13.1](https://travis-ci.org/spotify/docker-client/jobs/211952225#L3753) and [17.03.0-ce](https://travis-ci.org/spotify/docker-client/jobs/211952226#L3762)."},{"labels":["api",null,null,null],"text":"When we changed the Docker release versioning in #31075 there were a lot of complaints that we were not using semver http://semver.org/ for the release numbers, or that we had stopped using semver (which was not the case, we have never used it). The part of Docker that is most important for compatibility is the API not the release number, so I want to open a discussion about using semver for that. I have looked at the major points of the semver spec and discussed how they would apply to our release process.\r\n\r\nNote this proposal in no way changes the fact that the daemon supports multiple API versions simultaneously. We would continue to support the current 1.x versions as before. We would bump the API to 2.0.0 when Semver is introduced. In addition to all the pre-semver API versions we currently support, each new release will support older minor versions, at some patch version level.\r\n\r\nFor future backward compatibility, we would need to decide which patch versions we support. For example if the 17.06 release ships with 2.0.0 API, and then we find a bug and we release 17.06.1 with 2.0.1 after 17.07 has shipped with 2.1.0, in most cases we might not forward port the patch bump to the old API support, so 17.07 might just support the original 2.0.0. Alternatively, if the patch was something that also affected 17.07, we could patch bump it to 2.1.1 and patch bump its backport to 2.0.1 at the same time if this was convenient. In general clients SHOULD be written to support any server with the same major version, but if they need particular functionality they MAY require that the server also has a particular minor version. You cannot use the protocol negotiation to request a particular minor version.\r\n\r\nThis proposal only directly affects the Docker HTTP-JSON API, ie the API from the Docker socket. Other deprecations such as changes in the `Dockerfile` MUST also be included as sending a Dockerfile is part of the supported client communication with the daemon. The Prometheus endpoint is not currently included, but could be added later, or versioned seperately, when it leaves experimental.\r\n\r\nLooking at the key points from the semver spec:\r\n\r\n_Patch version Z (x.y.Z | x > 0) MUST be incremented if only backwards compatible bug fixes are introduced. A bug fix is defined as an internal change that fixes incorrect behavior._\r\n\r\n- These changes would be introduced in major or minor releases as often as needed when bugs are fixed that affect the API.\r\n- Addition of a new field in JSON could be a bug fix if it can be safely ignored, such as the recent case with the stats API, if it is needed to fix a bug. Clients SHOULD ignore unknown fields. If they cannot they will be tied to specific patch releases.\r\n- Changes in http return codes would be a common reason for patch version changes, as now we have a schema for the API rather than just saying it is REST so we should increment if new return codes are introduced.\r\n- If we are currently supporting two releases with the same minor version, we should always increment their patch versions in lockstep by cherry picking the same fixes.\r\n- Once a version of Docker is released we MUST only make patch version changes to its API, not minor or major version changes, as new versions of a release are only bugfixes.\r\n- non semantic changes, such as JSON field ordering or encoding, or informational http headers do not require a patch release change.\r\n\r\n_Minor version Y (x.Y.z | x > 0) MUST be incremented if new, backwards compatible functionality is introduced to the public API. It MUST be incremented if any public API functionality is marked as deprecated. It MAY be incremented if substantial new functionality or improvements are introduced within the private code. It MAY include patch level changes. Patch version MUST be reset to 0 when minor version is incremented._\r\n\r\n- We MAY increment this at the three monthly release for the \"substantial new functionality\" reason. This allows each long term support release to have its own API patch versions, rather than the current interleaving that we have, in case of bug fixes in the API of patch versions. We could increment it more often if needed, if for example a security release causes addition of a new backwards compatible change. We could instead increment the minor version in the monthly after the LTS release to get out of its way, if we have made API changes in the monthly.\r\n- Note the minor version is incremented when a deprecation is announced, so this will be marked in the API docs for that release, even though the functionality cannot be removed until the next major version increment.\r\n- Addition of new http endpoints and methods, and new JSON values are examples of fully compatible changes that do not need a major bump.\r\n\r\n_Major version X (X.y.z | X > 0) MUST be incremented if any backwards incompatible changes are introduced to the public API. It MAY include minor and patch level changes. Patch and minor version MUST be reset to 0 when major version is incremented._\r\n\r\n- This would happen when we deprecate functionality, or when functionality is changed in a backward incompatible way, such as changing the types of a field.\r\n- Previously we would deprecate functionality on a rolling basis, around nine months after the deprecation announcement. As this now involves a major version change, it would make sense to bunch these, as generally the number of inccompatible changes is small, and deprecation would be the main reason for bumps.\r\n- I suggest bunching deprecations at suitable intervals of no less than one year. When a deprecation is announced, rather than an exact date, we should announce a \"no earlier than date\" corresponding to the current deprecation period of around nine months, but to decide when to actually deprecate we should look at the urgency, if there are other reasons for a major bump such as incompatible changes, and decide when to increment based on the context.\r\n\r\ncc @docker/maintainers @friism @shykes "},{"labels":["api",null],"text":"(Note that the title is a joke, referring to [swagger.yaml line 818](https://github.com/docker/docker/blob/master/api/swagger.yaml#L818): `\"TODO check is correct\"`.)\r\n\r\nIn the swagger spec for inspecting a container (`operationId: \"ContainerInspect\"`), one of the object properties is `NetworkSettings`. For that value, the spec refers to the object definition at `#/definitions/NetworkConfig`. However, that definition is not complete.\r\n\r\nHere is the incomplete `NetworkConfig` swagger spec:\r\n```yaml\r\nNetworkConfig:\r\n  description: \"TODO: check is correct\"\r\n  type: \"object\"\r\n  properties:\r\n    Bridge:\r\n      type: \"string\"\r\n    Gateway:\r\n      type: \"string\"\r\n    Address:\r\n      type: \"string\"\r\n    IPPrefixLen:\r\n      type: \"integer\"\r\n    MacAddress:\r\n      type: \"string\"\r\n    PortMapping:\r\n      type: \"string\"\r\n    Ports:\r\n      type: \"array\"\r\n      items:\r\n        $ref: \"#/definitions/Port\"\r\n```\r\n\r\nThe spec for inspecting a container gives an example `NetworkSettings` with many more properties than are defined in the `NetworkConfig` spec that supposedly defines it:\r\n```yaml\r\nNetworkSettings:\r\n  Bridge: \"\"\r\n  SandboxID: \"\"\r\n  HairpinMode: false\r\n  LinkLocalIPv6Address: \"\"\r\n  LinkLocalIPv6PrefixLen: 0\r\n  SandboxKey: \"\"\r\n  SecondaryIPAddresses: null\r\n  SecondaryIPv6Addresses: null\r\n  EndpointID: \"\"\r\n  Gateway: \"\"\r\n  GlobalIPv6Address: \"\"\r\n  GlobalIPv6PrefixLen: 0\r\n  IPAddress: \"\"\r\n  IPPrefixLen: 0\r\n  IPv6Gateway: \"\"\r\n  MacAddress: \"\"\r\n  Networks:\r\n    bridge:\r\n      NetworkID: \"7ea29fc1412292a2d7bba362f9253545fecdfa8ce9a6e37dd10ba8bee7129812\"\r\n      EndpointID: \"7587b82f0dada3656fda26588aee72630c6fab1536d36e394b2bfbcf898c971d\"\r\n      Gateway: \"172.17.0.1\"\r\n      IPAddress: \"172.17.0.2\"\r\n      IPPrefixLen: 16\r\n      IPv6Gateway: \"\"\r\n      GlobalIPv6Address: \"\"\r\n      GlobalIPv6PrefixLen: 0\r\n      MacAddress: \"02:42:ac:12:00:02\"\r\n```\r\n\r\nThe properties in the example should be added to the `NetworkConfig` definition. This should be mostly straightforward, with a couple exceptions. The `Networks` property will follow the same spec from `ContainerSummary`:\r\n```yaml\r\nNetworks:\r\n  type: \"object\"\r\n  additionalProperties:\r\n    $ref: \"#/definitions/EndpointSettings\"\r\n```\r\n\r\nI'm not sure about the two `null` properties from the example: `SecondaryIPAddresses` and `SecondaryIPv6Addresses`. Are they lists of strings? Some object?"},{"labels":["api",null,null,null,null],"text":"The markdown API docs are missing any description for the `NetworkingConfig` object that is included in the config to create a container. This object is included in the example JSON that gets POSTed to `/containers/create` in the 1.22, 1.23, and 1.24 docs, but is not mentioned in the following \"JSON Parameters\" section. In particular, its child object `EndpointsConfig` is not fully defined.\r\n\r\nThis issue only affects the older markdown API docs. The objects mentioned above are defined in more detail in `api/swagger.yaml`. For the most part, the various places in the swagger description of the API that accept or produce information about networks refer to `#/definitions/EndpointSettings`.\r\n\r\n"},{"labels":["api",null,null,null],"text":"**Description**\r\nOur monitoring detected docker performance problems rising slowly - checked with `docker ps`, `docker info` and `docker run` calls. At the same time about 100 processes with \"D\" state were detected in the system. Increasing number of \"D\" processes eventually renders docker daemon unresponsive. This was confirmed on multiple occasions (at least 5 times).\r\n\r\n**Steps to reproduce the issue:**\r\n1. Make some processes running within container stuck in \"D\" (like on a read from failed remote file system)\r\n2. Observe docker API performance as the number of \"D\" processes increases.\r\n\r\n**Describe the results you received:**\r\nDocker API response time grow and eventually render the whole daemon unresponsive.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nIs repeatable, happens every time the number of \"D\" processes on the host rises.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.12.3-cs4\r\n API version:  1.24\r\n Go version:   go1.6.3\r\n Git commit:   65c6c4c\r\n Built:        Fri Nov 11 16:23:03 2016\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.12.3-cs4\r\n API version:  1.24\r\n Go version:   go1.6.3\r\n Git commit:   65c6c4c\r\n Built:        Fri Nov 11 16:23:03 2016\r\n OS/Arch:      linux/amd64\r\n\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 464\r\n Running: 363\r\n Paused: 0\r\n Stopped: 101\r\nImages: 761\r\nServer Version: 1.12.3-cs4\r\nStorage Driver: aufs\r\n Root Dir: /opt/io1/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 3837\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge null host overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: apparmor seccomp\r\nKernel Version: 4.4.0-62-generic\r\nOperating System: Ubuntu 16.04.2 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 128\r\nTotal Memory: 1.876 TiB\r\nName: ip-10-69-11-89\r\nID: UGZS:UFD3:GB4C:W5MX:JU2L:K7PH:6ZWS:4GPM:27Q5:UNNN:X3DC:YDT7\r\nDocker Root Dir: /opt/io1/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 2410\r\n Goroutines: 2766\r\n System Time: 2017-02-22T13:10:59.794584753Z\r\n EventsListeners: 1\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nInsecure Registries:\r\n 127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n* instance type: x1.32\r\n* host: docker-linux-1\r\n* OS: ubuntu 16.04 LTS\r\n* kernel version: `Linux ip-10-69-11-89 4.4.0-59-generic #80-Ubuntu SMP Fri Jan 6 17:47:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux`"},{"labels":["api",null,null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\nAfter a fresh installation of docker and pulling the container I cannot copy any file into the container\r\nI get the following:\r\n```\r\ndocker run -it microsoft/dotnet-framwork cmd\r\ndocker cp D:\\x\\1.txt <container_name>:c:\\1.txt\r\n\r\nError response from daemon: hcsshim::ActivateLayer failed in Win32: \r\nThe process cannot access the file because it is being used by another process. (0x20) id=d1ad2f812e3b7a37da79538611d7fb4496b0a89369b2ba430e08a28d73f1ab50 flavour=1\r\n```\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.03.0-ce\r\n API version:  1.26\r\n Go version:   go1.7.5\r\n Git commit:   60ccb22\r\n Built:        Thu Feb 23 10:40:59 2017\r\n OS/Arch:      windows/amd64\r\n\r\nServer:\r\n Version:      17.03.0-ce\r\n API version:  1.26 (minimum version 1.24)\r\n Go version:   go1.7.5\r\n Git commit:   60ccb22\r\n Built:        Thu Feb 23 10:40:59 2017\r\n OS/Arch:      windows/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 5\r\n Running: 1\r\n Paused: 0\r\n Stopped: 4\r\nImages: 2\r\nServer Version: 17.03.0-ce\r\nStorage Driver: windowsfilter\r\n Windows:\r\nLogging Driver: json-file\r\nPlugins:\r\n Volume: local\r\n Network: l2bridge l2tunnel nat null overlay transparent\r\nSwarm: inactive\r\nDefault Isolation: hyperv\r\nKernel Version: 10.0 14393 (14393.206.amd64fre.rs1_release.160915-0644)\r\nOperating System: Windows 10 Pro\r\nOSType: windows\r\nArchitecture: x86_64\r\nCPUs: 8\r\nTotal Memory: 31.91 GiB\r\nName: wk-ofir\r\nID: PKF6:LKFA:ROVD:X2LP:I2NL:HJZF:NSGN:BLOM:JDBH:RXA7:F3HQ:B3TK\r\nDocker Root Dir: C:\\ProgramData\\Docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: -1\r\n Goroutines: 33\r\n System Time: 2017-03-07T15:19:34.6735797+02:00\r\n EventsListeners: 1\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n\r\n"},{"labels":["api",null,null,null],"text":"Currently, dockerd itself supports a \"single\" and \"static\" way to protect /run/docker.sock using a tlskey file. But it is not suitable for swarm.\r\n\r\nJust like swarm token has its expired time, tlskey should also have, especially when the key has been exposed to public.\r\n\r\n\"single\" means the key takes effect for only 1 node, thus, swarm cluster requires people to update key on each of active swarm nodes once the key is changed.\r\n\r\n\"static\" indicates we have to restart all daemons once the key is changed to apply for changes.\r\n\r\nTaking advantage of built-in etcd storage, Swarm node should record a key-value pair in it which enables a \"non-single\" way to solve the problem. For example, assume there are 5 swarm nodes, post a request to 1 node about to change the password, swarm stores the new password, and then all other swarm nodes will get the updated automatically. Besides, all swarm nodes needn't restart to apply for changes if we provide standard WWW-Auth like Basic-Auth.\r\n\r\n\r\n"},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\n<!--\r\ndocker volume inspect doesn't show connected containers.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. docker volume -d local local-100\r\n2. docker run -d -v local-100:/opt/ nginx:latest\r\n3. docker volume inspect local-100\r\n\r\n**Describe the results you received:**\r\nmissing attached containers.\r\n[\r\n    {\r\n        \"Driver\": \"local\",\r\n        \"Labels\": {},\r\n        \"Mountpoint\": \"/var/lib/docker/volumes/local-100/_data\",\r\n        \"Name\": \"local-100\",\r\n        \"Options\": {},\r\n        \"Scope\": \"local\"\r\n    }\r\n]\r\n\r\n**Describe the results you expected:**\r\n[\r\n    {\r\n        \"Driver\": \"local\",\r\n        \"Labels\": {},\r\n        \"Mountpoint\": \"/var/lib/docker/volumes/local-100/_data\",\r\n        \"Name\": \"local-100\",\r\n        \"Containers\": []\r\n        \"Options\": {},\r\n        \"Scope\": \"local\"\r\n    }\r\n]\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.1\r\n API version:  1.26\r\n Go version:   go1.7.5\r\n Git commit:   092cba3\r\n Built:        Wed Feb  8 06:42:29 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.1\r\n API version:  1.26 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   092cba3\r\n Built:        Wed Feb  8 06:42:29 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 6\r\n Running: 5\r\n Paused: 0\r\n Stopped: 1\r\nImages: 62\r\nServer Version: 1.13.1\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 315\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1\r\nrunc version: 9df8b306d01f59d3a8029be411de015b7304dd8f\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\nKernel Version: 4.4.0-51-generic\r\nOperating System: Ubuntu 14.04.5 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 1.945 GiB\r\nName: dchq-gak\r\nID: 2MMO:IKKV:QTKW:SS3E:E5MY:7IIV:PBAV:PWDE:BMV5:FMG5:PG44:AQ2S\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nUsername: hypergrid\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null],"text":"Working with the API and Swarm, inspecting a service or listing services on a swarm does not include the node that the service is currently running on.\r\n\r\nCould this be included in a future update? Or is there already a mechanism for that, besides just running through all nodes and listing containers?"},{"labels":["api",null,null,null],"text":"**Description**\r\n\r\nThe `ContainerStatPath` method in the client library returns different errors than the error reported by the API.\r\nThe first case is when running the method on a container ID that doesn't exist, the other one if the container ID does exist, but the path does not exist.\r\n\r\n**Steps to reproduce the issue:**\r\n_case 1_\r\n\r\nCompile and run the following program:\r\n\r\n```go\r\nfunc TestContainerStatPathIssue(t *testing.T) {\r\n\tcli, err := client.NewEnvClient()\r\n\tif err != nil {\r\n\t\tt.Fatal(err)\r\n\t}\r\n\t_, err = cli.ContainerStatPath(context.TODO(), \"foo\", \"bar\")\r\n\tif err != nil {\r\n\t\tt.Fatal(err)\r\n\t}\r\n}\r\n```\r\n\r\n_case 2_\r\nRun command `docker create --name=foo alpine:latest /bin/sh` and run the program from case 1 again.\r\n\r\n**Describe the results you received:**\r\nCase 1 returns:\r\n> Error: request returned Not Found for API route and version http://<ip>:4243/v1.24/containers/foo/archive?path=bar, check if the server supports the requested API version\r\n\r\nRunning `curl` on that URL returns:\r\n```json\r\n{\"message\":\"No such container: foo\"}\r\n```\r\n\r\nCase 2 returns:\r\n> Error: request returned Not Found for API route and version http://<ip>:4243/v1.24/containers/foo/archive?path=bar, check if the server supports the requested API version\r\n\r\nRunning `curl` on that URL returns:\r\n```json\r\n{\"message\":\"lstat /var/lib/docker/overlay/116c08d9b5aedea0fa868effeaa4562ed28cc8f8d2e06dcd1e557fca48815026/merged/bar: no such file or directory\"}\r\n```\r\n\r\n**Describe the results you expected:**\r\nIn both cases I expect an error that is more in line with the error returned from the API.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nThe docker version I'm running supports API version `1.25`, setting `DOCKER_API_VERSION=1.25` results in the same behavior as above.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:55:28 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.0\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:55:28 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 3\r\n Running: 0\r\n Paused: 0\r\n Stopped: 3\r\nImages: 9\r\nServer Version: 1.13.0\r\nStorage Driver: overlay\r\n Backing Filesystem: xfs\r\n Supports d_type: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e\r\nrunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3e\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 3.10.0-514.6.1.el7.x86_64\r\nOperating System: CentOS Linux 7 (Core)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 992.7 MiB\r\nName: localhost.localdomain\r\nID: MFQW:WT3K:SL5H:LVNK:NCRK:MMAV:YLUG:XCCG:LTO6:KXMN:2GBN:52TN\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nRunning on VirtualBox."},{"labels":["api",null,null],"text":"It appears some code was written with the assumption that API version 1.26 corresponds to Docker 1.14. When 1.13.1 was released, it took over that version number, and 1.14 is now supposed to be 1.27. We need to check the code and make sure 1.14-specific features and changes aren't gated on API version 1.26.\r\n\r\nGrepping, here are a few spots that may be affected:\r\n\r\n```\r\napi/server/router/container/container_routes.go:                // In case version is higher than 1.26,\r\n a binary frame will be sent.\r\napi/server/router/container/container_routes.go:                if versions.GreaterThanOrEqualTo(versio\r\nn, \"1.26\") {\r\n```\r\n\r\n```\r\napi/server/router/network/network_routes.go:            // Versions < 1.26 fetches all the containers a\r\nttached to a network\r\napi/server/router/network/network_routes.go:            // run across all the networks. Starting API ve\r\nrsion 1.26, this detailed\r\napi/server/router/network/network_routes.go:            if versions.LessThan(httputils.VersionFromConte\r\nxt(ctx), \"1.26\") {\r\n```\r\n\r\ncc @thaJeztah @vdemeester"},{"labels":["api",null,null],"text":"I'd like to print image name from my current running containers, while showing statistics. The issue si similar to https://github.com/docker/docker/issues/20973, but referring to image name:\r\n\r\ndocker stats --format \"table {{.Container}}\\t{{.Name}}\\t{{**.ImageName**}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\\t{{.BlockIO}}\\t{{.NetIO}}\"\r\n\r\nRequest is: property .ImageName should be available to format shown statistics\r\n"},{"labels":["api"],"text":"#25820 added metrics to the engine (great).\r\n\r\nAt that point it was decided to expose metrics on an entirely different endpoint, controlled via `--metrics-addr` (an experimental flag).\r\n\r\nThis raises a few concerns regarding exposing an unprotected port. For some exposing a plain text port is fine, for others leaking container IDs etc is bad.\r\n\r\nThere are a few ways to get around that, one would be to use the TLS configuration but it feels pretty meh to me.\r\n\r\nWhat I'd suggest is to expose the `/metrics` endpoint on the regular Docker API. One can easily achieve the `--metrics-addr` behavior by running a container on the machine that listens to a port and exposes just the `/metrics` endpoint of the API (by querying the local daemon).\r\n\r\nOne could also chose to deploy this same service with an overlay network, thus not requiring to bind the external port.\r\n\r\nLong story short: I believe exposing metrics under the same API server leads to a more consistent exposure level (TLS, authentication, ...) while enabling the same use case as `--metrics-addr` and then some.\r\n\r\nThoughts?\r\n\r\n/cc @crosbymichael @stevvooe @dhiltgen @vieux @icecrime "},{"labels":["api"],"text":"In this issue, we are proposing a simple pagination system for the Docker remote API. The need for pagination of resource collection responses is growing as the Docker API expands from being a single-node API to a cluster-wide API where the number of objects in a collection may increase by many orders of magnitude depending on the size of the cluster.\r\n\r\nThe current List APIs include:\r\n\r\n- Containers\r\n- Images\r\n- Networks\r\n- Volumes\r\n- Secrets\r\n- Nodes\r\n- Services\r\n- Tasks\r\n- Plugins\r\n\r\nThe proposed method of pagination is mostly server-driven:\r\n\r\n- The set of resources to be listed should have a stable ordering. For most resources in Docker, this would either be the resource name or ID.\r\n- The server may decide on a default page size (number of records to return) if the client does not specify a `pageSize` query parameter. The server should also impose a max page size.\r\n- If there are additional pages of results available, the server should return a `X-Next-Page-Start` response header indicating the point in the stable ordering of resources where the next page begins. The absence of this header indicates that no additional pages are available.\r\n- If the client wishes to fetch the next page of results, it need only set a `pageStart` query parameter to the value in the returned `X-Next-Page-Start` header. This instructs the server to skip to the first value in the stable ordering of resources where the ordering key (either name or ID) is greater than or equal to the  `nextPageStart` value.\r\n\r\nConsiderations:\r\n\r\n- Any filtering parameters should not affect the ordering of results.\r\n- If multiple orderings of the result set are available, the API should use an `orderBy` query parameter to specify the desired ordering. Pagination of results is consistent as long as the desired ordering is also consistent between successive page requests.\r\n- If the client would like to know the size of the entire resource collection, the client should specify a `count=true` query parameter to indicate to the server that it should return the entire size of the resource set in the response. This MAY be done in either a `X-Resource-Count` response header or as a `resourceCount` field in the response payload itself (many of the existing Docker API endpoints return a JSON array and would use the response header). The server may also simply choose to always return the resource count regardless of whether the client specified a `count=true` query parameter. The returned resource collection count should *not* consider any filtering parameters in the request as doing so may be an expensive operation."},{"labels":["api",null,null,null],"text":"\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nWhen using docker-compose up with the yml file below, container will run in priviledged mode.\r\n\r\n```\r\nversion: \"2.1\"\r\n\r\nservices:\r\n  web:\r\n    build: .\r\n    command: nodemon -L --debug=5858\r\n\r\n    privileged: true\r\n    tty: true\r\n    ports:\r\n      - \"3000:3000\"\r\n      - \"5858:5858\"\r\nnetworks:\r\n  default:\r\n    external:\r\n      name: nat\r\n```\r\n\r\n\r\ndockerfile for base node image\r\n\r\n```\r\nFROM microsoft/windowsservercore\r\n\r\nENV NPM_CONFIG_LOGLEVEL info  \r\n\r\nRUN powershell -Command \"wget -Uri https://nodejs.org/dist/v6.9.5/node-v6.9.5-x64.msi -OutFile node.msi -UseBasicParsing\"\r\n\r\nRUN msiexec.exe /q /i node.msi\r\n\r\nCMD [ \"node\" ]  \r\n```\r\n\r\ndockerfile for hapi server with serialport\r\n\r\n```\r\nFROM node:695\r\n\r\nWORKDIR /app\r\n\r\nRUN npm install --silent --progress=false -g nodemon@1.10.2\r\n\r\nCOPY package.json /app/package.json\r\nRUN npm install \r\n\r\n\r\nCOPY . /app\r\n\r\nCMD [\"npm.cmd\", \"start\"]\r\n```\r\n\r\n\r\nSteps to reproduce the behavior\r\n\r\n1. docker build -t node . (the first dockerfile from above)\r\n2. docker tag node:latest node:695\r\n3. docker-compose build\r\n4. docker-compose up\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\nWhen docker-compose up is run the initialization fails with the following error\r\n\r\nPS C:\\Users\\honeyws\\Documents\\ComApiNodeWindows> docker-compose up\r\nRemoving comapinodewindows_web_1\r\nRecreating f8442170a78f_comapinodewindows_web_1\r\n\r\nERROR: for web  Cannot start service web: container c1e3bd481a189a4f68566e4dd470af1ef385288ec7e831633e39363809358613 enc\r\nountered an error during CreateProcess: failure in a Windows system call: The system cannot find the file specified. (0x\r\n2) extra info: {\"ApplicationName\":\"\",\"CommandLine\":\"nodemon -L --debug=5858\",\"User\":\"\",\"WorkingDirectory\":\"C:\\\\app\",\"Env\r\nironment\":{\"NPM_CONFIG_LOGLEVEL\":\"info\"},\"EmulateConsole\":true,\"CreateStdInPipe\":true,\"CreateStdOutPipe\":true,\"CreateStd\r\nErrPipe\":false,\"ConsoleSize\":[0,0]}\r\nERROR: Encountered errors while bringing up the project.\r\nPS C:\\Users\\honeyws\\Documents\\ComApiNodeWindows>\r\n```\r\n\r\n**Describe the results you expected:**\r\n Container should start in priviledged mode\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nDiagnostic id:  ID 097756B2-58F4-436C-901D-FFC79D6EA8B6/2017-02-15_15-24-44\r\n\r\noriginally reported:\r\nhttps://github.com/docker/for-win/issues/501\r\n\r\n**Output of `docker version`:**\r\n```\r\nPS C:\\Users\\honeyws\\Documents\\ComApiNodeWindows> docker version\r\nClient:\r\n Version:      1.13.1\r\n API version:  1.26\r\n Go version:   go1.7.5\r\n Git commit:   092cba3\r\n Built:        Wed Feb  8 08:47:51 2017\r\n OS/Arch:      windows/amd64\r\n\r\nServer:\r\n Version:      1.13.1\r\n API version:  1.26 (minimum version 1.24)\r\n Go version:   go1.7.5\r\n Git commit:   092cba3\r\n Built:        Wed Feb  8 08:47:51 2017\r\n OS/Arch:      windows/amd64\r\n Experimental: true\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nWindows 10 pro\r\n"},{"labels":["api",null,null,null],"text":"**Description**\r\n\r\nRepeatedly calling `docker service update` may trigger an `update out of sequence` error. This seems to happen because the api call to service inspect (`GET /services/{id}`) returns an old `Version.Index` even after the successful return of previous a call to service update (`POST /services/{id}/update`).\r\n\r\n**Steps to reproduce the issue:**\r\n```\r\ndocker swarm init\r\ndocker service create --name test busybox tail -f /dev/null\r\nwhile docker service update test --constraint-add \"node.labels.a != b\"; do true; done\r\n```\r\n\r\n**Describe the results you received:**\r\n\r\nAfter some time repeatedly updating the service (~30s on my machine) the last command will fail with the error `Error response from daemon: rpc error: code = 2 desc = update out of sequence`.\r\n\r\n**Describe the results you expected:**\r\n\r\nI expected that successful calls to `POST /service/{id}/update` would guarantee that subsequent calls to `GET /service/{id}` returned an updated `Version.Index`. This seems not to be the case. I'm not sure if this behavior is intended or not, if this is working as expected I think a clarification in the API documentation would be nice.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\n$ docker version\r\nClient:\r\n Version:      1.13.1-rc1\r\n API version:  1.25\r\n Go version:   go1.7.4\r\n Git commit:   2527cfc\r\n Built:        Fri Jan 27 21:54:54 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.1-rc1\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.4\r\n Git commit:   2527cfc\r\n Built:        Fri Jan 27 21:54:54 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\nThe problem also happens with `1.13.0` and `1.12.6`\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\n$ docker info\r\nContainers: 26\r\n Running: 4\r\n Paused: 0\r\n Stopped: 22\r\nImages: 264\r\nServer Version: 1.13.1-rc1\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 397\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: active\r\n NodeID: n2osx48m66gag48ggoyg1w1pc\r\n Is Manager: true\r\n ClusterID: 66490aoqoo9cdx00t5n95hw34\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 192.168.50.4\r\n Manager Addresses:\r\n  192.168.50.4:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e\r\nrunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3e\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-31-generic\r\nOperating System: Ubuntu 16.04.1 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 2.915 GiB\r\nName: vagrant\r\nID: XXOL:4PPB:VZV3:W7ZD:QRDT:FY6D:L2WN:OI5T:3Z3I:HZS5:TI6Z:BXJN\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 58\r\n Goroutines: 153\r\n System Time: 2017-02-07T17:31:31.46294919Z\r\n EventsListeners: 1\r\nUsername: cezarsa\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nExperimental: false\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nTested on Vagrant + Virtualbox and also on Ubuntu 14.04 on private Cloudstack."},{"labels":["api",null,null],"text":"**docker run --rm reports an error when attempting to remove container in version 1.13 with 1.24 API**\r\n\r\nThis appears to be a side effect of [PR #20848](https://github.com/docker/docker/pull/20848). When using a newer client and server, but reverting the API to something before 1.25, I'm seeing an error from a failed attempt to remove a container. This is generating nuisance errors with the classic swarm as seen in [issue #2620](https://github.com/docker/swarm/issues/2620).\r\n\r\n**Steps to reproduce the issue:**\r\n```\r\n$ # normal result\r\n$ docker run -it --rm busybox echo hello\r\nhello\r\n\r\n$ # error when using an older api version\r\n$ DOCKER_API_VERSION=1.24 docker run -it --rm busybox echo hello\r\nhello\r\nERRO[0002] error removing container: Error response from daemon: removal of container dc8b9e47ddfdea3c8d5c6abfd5b6fd4d703a5aa43fd5a712be3dcc8d730a163c is already in progress\r\n```\r\n\r\n**Describe the results you received:**\r\nThe container is removed by the docker daemon and then the docker client attempts to also remove the container, resulting in the error message.\r\n\r\n**Describe the results you expected:**\r\nWhen using an API before 1.25, the docker server should not perform the auto remove, it should instead be performed by the client. I'm not sure if this change needs to be made as part of the client request or the daemon processing of the request.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nI've reproduced this issue in multiple environments\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:44:08 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.0\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:44:08 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 4\r\n Running: 3\r\n Paused: 0\r\n Stopped: 1\r\nImages: 233\r\nServer Version: 1.13.0\r\nStorage Driver: aufs\r\n Root Dir: /home/var-docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 578\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: active\r\n NodeID: w4dwja2i927qhe4tbuuirwhkg\r\n Is Manager: true\r\n ClusterID: am788rn0mc5vdqtqna79g237a\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 192.168.234.174\r\n Manager Addresses:\r\n  192.168.234.174:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e\r\nrunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3e\r\ninit version: 949e6fa\r\nKernel Version: 3.16.0-4-amd64\r\nOperating System: Debian GNU/Linux 8 (jessie)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 5.75 GiB\r\nName: bmitch-asusr556l\r\nID: LTRH:V6W7:3UHO:4AV2:OSYM:6G4R:WKJR:2BRK:MGCO:Z4KJ:UPTF:LTRU\r\nDocker Root Dir: /home/var-docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nUsername: bmitch3020\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No kernel memory limit support\r\nWARNING: No cpu cfs quota support\r\nWARNING: No cpu cfs period support\r\nLabels:\r\n foo=bar\r\n env=laptop\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nSeen on physical and virtual machines, Debian and RHEL."},{"labels":["api",null],"text":"**Description**\r\n\r\nincorrect images/create API call returns response 200 OK and 2 json messages, one of them is error description\r\n\r\n**Steps to reproduce the issue:**\r\n`$ curl -v --unix-socket /var/run/docker.sock -X POST \"http:/v1.25/images/create?repo=acme.com%2Ftest&fromSrc=%2Fdata%2Ffile.tar\"`\r\nor\r\n```\r\nimport docker\r\nd = docker.from_env()\r\nprint(d.images.client.api.import_image(\"/data/file.tar\", \"acme.com/test\"))\r\n```\r\n\r\n**Describe the results you received:**\r\n```\r\n*   Trying /var/run/docker.sock...\r\n* Connected to http (/var/run/docker.sock) port 80 (#0)\r\n> POST /v1.25/images/create?repo=acme.com%2Ftest&fromSrc=%2Fdata%2Ffile.tar HTTP/1.1\r\n> Host: http\r\n> User-Agent: curl/7.47.0\r\n> Accept: */*\r\n>\r\n< HTTP/1.1 200 OK\r\n< Api-Version: 1.25\r\n< Content-Type: application/json\r\n< Docker-Experimental: true\r\n< Server: Docker/1.13.0 (linux)\r\n< Date: Fri, 03 Feb 2017 15:03:38 GMT\r\n< Transfer-Encoding: chunked\r\n<\r\n{\"status\":\"Downloading from http://%2Fdata%2Ffile.tar\"}\r\n{\"errorDetail\":{\"message\":\"parse http://%2Fdata%2Ffile.tar: invalid URL escape \\\"%2F\\\"\"},\"error\":\"parse http://%2Fdata%2Ffile.tar: invalid URL escape \\\"%2F\\\"\"}\r\n* Connection #0 to host http left intact\r\n```\r\nor\r\n```\r\n{\"status\":\"Downloading from http://%2Fdata%2Ffile.tar\"}\r\n{\"errorDetail\":{\"message\":\"parse http://%2Fdata%2Ffile.tar: invalid URL escape \\\"%2F\\\"\"},\"error\":\"parse http://%2Fdata%2Ffile.tar: invalid URL escape \\\"%2F\\\"\"}\r\n```\r\n\r\n**Describe the results you expected:**\r\nI would expect non 200 response and single json message, so response could be parsed.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nI'm using python docker API which does not raise exception on this incorrect request, as response code is 200. Also python API returns response as text and could not parse response if I specify json response type as there are 2 messages in response.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:58:26 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.0\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:58:26 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 19\r\n Running: 14\r\n Paused: 0\r\n Stopped: 5\r\nImages: 102\r\nServer Version: 1.13.0\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 110\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e\r\nrunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3e\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-59-generic\r\nOperating System: Ubuntu 16.04.1 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 30\r\nTotal Memory: 31.42 GiB\r\nName: jbuild\r\nID: TNIU:DAHP:PAIG:EGPV:HVX4:E4P6:KENQ:TOAX:QDEP:A3VD:JSPL:JQME\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nExperimental: true\r\nInsecure Registries:\r\n docker.acme.com\r\n registry-proxy.acme.com\r\n 127.0.0.0/8\r\nRegistry Mirrors:\r\n registry-proxy.acme.com\r\nLive Restore Enabled: true\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nDocker daemon running in Ubuntu 16.04 VM on ESXi 6 host. Client is docker python API 2.0.2 running on physical Windows 10 host."},{"labels":["api",null,null],"text":"I read the v1.25 document, but I can't find any related information.  I was wondering if \"docker stack deploy\" api was the on roadmap.  "},{"labels":["api",null,null],"text":"**Description**\r\ndocker build fails of content of file hosted on remote http server and golang is not able to detect content length.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Host file on github with content ```FROM codenvy/ubuntu_jdk8:latest```\r\n2. Run docker build ```curl -X POST --unix-socket /var/run/docker.sock http://v1.25/build?remote=https://raw.githubusercontent.com/mkuznyetsov/dockerfiles/master/Dockerfile```\r\n\r\n**Describe the results you received:**\r\nBuild fails\r\n\r\n```\r\n{\"stream\":\"Step 1 : FROM codenvy/ubuntu_jdk8:latest\\n\"}\r\n{\"stream\":\" ---\\u003e 4074bfc5705b\\n\"}\r\n{\"stream\":\"Step 2 : \\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000 \\n\"}\r\n{\"errorDetail\":{\"message\":\"Unknown instruction: \\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\"},\"error\":\"Unknown instruction: \\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\"}\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\nBuild completed successful \r\n\r\n**Additional information you deem important :**\r\nIt happens because for some unknown to me reason golang can't see ContentLength \r\n\r\n```\r\ncurl -v https://raw.githubusercontent.com/mkuznyetsov/dockerfiles/master/Dockerfile\r\n*   Trying 151.101.192.133...\r\n* TCP_NODELAY set\r\n* Connected to raw.githubusercontent.com (151.101.192.133) port 443 (#0)\r\n* TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\r\n* Server certificate: www.github.com\r\n* Server certificate: DigiCert SHA2 High Assurance Server CA\r\n* Server certificate: DigiCert High Assurance EV Root CA\r\n> GET /mkuznyetsov/dockerfiles/master/Dockerfile HTTP/1.1\r\n> Host: raw.githubusercontent.com\r\n> User-Agent: curl/7.51.0\r\n> Accept: */*\r\n>\r\n< HTTP/1.1 200 OK\r\n< Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'\r\n< Strict-Transport-Security: max-age=31536000\r\n< X-Content-Type-Options: nosniff\r\n< X-Frame-Options: deny\r\n< X-XSS-Protection: 1; mode=block\r\n< ETag: \"7f1a7fe71285bcb07dd7103e1707a4ee82640e2e\"\r\n< Content-Type: text/plain; charset=utf-8\r\n< Cache-Control: max-age=300\r\n< X-Geo-Block-List:\r\n< X-GitHub-Request-Id: 0D88:11B40:3AD930:3CB1C8:588B1267\r\n< Content-Length: 32\r\n< Accept-Ranges: bytes\r\n< Date: Fri, 27 Jan 2017 09:29:09 GMT\r\n< Via: 1.1 varnish\r\n< Connection: keep-alive\r\n< X-Served-By: cache-ams4139-AMS\r\n< X-Cache: HIT\r\n< X-Cache-Hits: 1\r\n< X-Timer: S1485509349.879799,VS0,VE0\r\n< Vary: Authorization,Accept-Encoding\r\n< Access-Control-Allow-Origin: *\r\n< X-Fastly-Request-ID: fd7175b3069b69290632cc1eb14efa97a9a0a1e3\r\n< Expires: Fri, 27 Jan 2017 09:34:09 GMT\r\n< Source-Age: 126\r\n<\r\nFROM codenvy/ubuntu_jdk8:latest\r\n* Curl_http_done: called premature == 0\r\n* Connection #0 to host raw.githubusercontent.com left intact\r\n````\r\n\r\n\r\nMethod https://github.com/docker/docker/blob/master/builder/remote.go#L132 incorrectly behavies in case of  ContentLength = -1\r\n\r\nI assume that insted of \r\n```\r\n\tpreambleR := bytes.NewReader(preamble)\r\n```\t\r\n\r\nshould be \r\n```\r\n\tpreambleR := bytes.NewReader(preamble[:rlen])\r\n```\t\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Wed Jan 11 00:23:16 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Wed Jan 11 00:23:16 2017\r\n OS/Arch:      linux/amd64\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 32\r\n Running: 0\r\n Paused: 0\r\n Stopped: 32\r\nImages: 147\r\nServer Version: 1.12.6\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 431\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge null host overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: seccomp\r\nKernel Version: 4.4.41-moby\r\nOperating System: Alpine Linux v3.4\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 3\r\nTotal Memory: 3.854 GiB\r\nName: moby\r\nID: WK3O:EPUK:PUBI:P7CQ:X35H:FERW:QGNO:7G3N:7PIP:BHZL:7Y66:IAHX\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 20\r\n Goroutines: 33\r\n System Time: 2017-01-27T09:39:47.432783198Z\r\n EventsListeners: 1\r\nNo Proxy: *.local, 169.254/16\r\nUsername: ksmster\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No kernel memory limit support\r\nInsecure Registries:\r\n 127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null,null],"text":"**Description**\r\nI am trying to invoke Docker Remote API using Elixirl as explained at:\r\nhttps://docs.docker.com/engine/reference/api/docker_remote_api/\r\n\r\nHere is the exact command used:\r\n\r\n```\r\n$ curl https://188.166.86.204:2376/_ping \\\r\n  --cert ~/docker_workspaces/certs/cert.pem \\\r\n  --key ~/docker_workspaces/certs/key.pem \\\r\n  --cacert ~/docker_workspaces/certs/ca.pem\r\n\r\nOK\r\n\r\niex>\r\noptions = [] \\\r\n  |> Keyword.merge([\r\n  hackney: [\r\n    ssl_options: [\r\n      certfile: \"~/docker_workspaces/certs/cert.pem\",\r\n      keyfile: \"~/docker_workspaces/certs/key.pem\",\r\n      cacertfile: \"~/docker_workspaces/certs/ca.pem\"\r\n    ]\r\n  ]\r\n])\r\nHTTPoison.request(:get, \"https://188.166.86.204:2376/_ping\", \"\", [], options)\r\n\r\n[error] SSL: :certify: tls_connection.erl:619:Fatal error: handshake failure - malformed_handshake\r\n{:error, %HTTPoison.Error{id: nil, reason: {:tls_alert, 'handshake failure'}}}\r\n```\r\nThis works fine when I connect to v1.12.5, but for some reason v1.13.0 is not working.\r\n\r\n\r\n**Relevant versions:**\r\n```\r\n$ curl -v\r\ncurl 7.52.1 (x86_64-apple-darwin16.1.0) libcurl/7.52.1 OpenSSL/1.0.2j zlib/1.2.8\r\nProtocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp smb smbs smtp smtps telnet tftp \r\nFeatures: IPv6 Largefile NTLM NTLM_WB SSL libz TLS-SRP UnixSockets HTTPS-proxy \r\n```\r\n\r\n```\r\n$ erl --version\r\nErlang/OTP 19 [erts-8.2] [source] [64-bit] [smp:8:8] [async-threads:10] [hipe] [kernel-poll:false] \r\n```\r\n\r\n```\r\n$ elixir --version\r\nErlang/OTP 19 [erts-8.2] [source] [64-bit] [smp:8:8] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]\r\n\r\nElixir 1.4.0\r\n```\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a new docker machine using the cli\r\n2. curl the rest-api with the correct certs (should return ok)\r\n3. Use Hackey/HTTPoison and the same certs to query the rest api.\r\n\r\n**Output of `docker version`:**\r\nWorking:\r\n```\r\nroot@7396d938:~# docker version\r\nClient:\r\n Version:      1.12.5\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   7392c3b\r\n Built:        Fri Dec 16 02:42:17 2016\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.12.5\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   7392c3b\r\n Built:        Fri Dec 16 02:42:17 2016\r\n OS/Arch:      linux/amd64\r\n```\r\n\r\nNot working:\r\n```\r\nroot@6f3778bf:~# docker version\r\nClient:\r\n Version:      1.13.0\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:58:26 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.0\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:58:26 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\nroot@6f3778bf:~#\r\n```\r\n"},{"labels":["api",null,null],"text":"The docs at https://docs.docker.com/engine/reference/commandline/version/ say to get the template fields for `docker version` output, use `docker version --format '{{json .}}'` which gives me:\r\n\r\n```\r\n{\"Client\":{\"Version\":\"1.13.0\",\"ApiVersion\":\"1.25\",\"GitCommit\":\"49bf474\",\"GoVersion\":\"go1.7.3\",\"Os\":\"darwin\",\"Arch\":\"amd64\",\"BuildTime\":\"Wed Jan 18 16:20:26 2017\"},\"Server\":{\"Version\":\"1.13.0\",\"ApiVersion\":\"1.25\",\"MinAPIVersion\":\"1.12\",\"GitCommit\":\"49bf474\",\"GoVersion\":\"go1.7.3\",\"Os\":\"linux\",\"Arch\":\"amd64\",\"KernelVersion\":\"4.9.5-moby\",\"Experimental\":true,\"BuildTime\":\"Wed Jan 18 16:20:26 2017\"}}\r\n```\r\n\r\nSo I try\r\n```\r\ndocker version --format '{{.Server.ApiVersion}}'\r\n\r\ntemplate: :1:9: executing \"\" at <.Server.ApiVersion>: can't evaluate field ApiVersion in type *types.Version\r\n```\r\n\r\nEventually I guess and try\r\n```\r\ndocker version --format '{{.Server.APIVersion}}'\r\n1.25\r\n```\r\n\r\nSo the output on the JSON list has a different casing, making it hard to work out what the Go names are. I blame Go's weird JSON handling, but I wonder if it can be fixed? Or maybe the docs just could add a note?\r\n\r\nActually the JSON has the same name\r\n```\r\ndocker version --format '{{json .Server.ApiVersion}}'\r\n\r\ntemplate: :1:14: executing \"\" at <.Server.ApiVersion>: can't evaluate field ApiVersion in type *types.Version\r\ndocker version --format '{{json .Server.APIVersion}}'\r\n\"1.25\"\r\n```\r\n\r\n```\r\nClient:\r\n Version:      1.13.0\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Wed Jan 18 16:20:26 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      1.13.0\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Wed Jan 18 16:20:26 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\ncc @thaJeztah "},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. Restart Docker\r\n\r\n**Describe the results you received:**\r\n\r\nDocker can't boot up after a restart. An error from journal:\r\n\r\n```\r\ndockerd[30701]: time=\"2017-01-22T08:38:55.077780858Z\" level=fatal msg=\"can't create unix socket /var/run/docker.sock: is a directory\"\r\n```\r\n\r\nAt this point `/var/run/docker.sock` is indeed, a directory. (wut?)\r\n\r\n```\r\n$ ls -lah /var/run/docker.sock\r\ntotal 0\r\ndrwxr-xr-x  2 root root   40 Jan 22 08:37 .\r\ndrwxr-xr-x 30 root root 1.2K Jan 22 08:38 ..\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\nTo restart Docker without an error\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nThis happened from time to time upon restart of `dockerd` daemon. After I removed this directory manually, Docker boots up easily creating a socket, but after several restarts, this issue came back.  \r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Wed Jan 11 00:23:16 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Wed Jan 11 00:23:16 2017\r\n OS/Arch:      linux/amd64\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 42\r\n Running: 20\r\n Paused: 0\r\n Stopped: 22\r\nImages: 14\r\nServer Version: 1.12.6\r\nStorage Driver: overlay\r\n Backing Filesystem: xfs\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: overlay bridge null host\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: apparmor seccomp\r\nKernel Version: 4.4.0-57-generic\r\nOperating System: Ubuntu 16.04.1 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 7.795 GiB\r\nName: <node-name>\r\nID: <id>\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nInsecure Registries:\r\n 127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nAWS EC2 instance"},{"labels":["api",null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nDocker stats doesn't output memory stats fail count\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n```\r\ncurl -sSL --unix-socket /var/run/docker.sock http://localhost/containers/220353af852e/stats?stream=False|jq -r .memory_stats.failcnt\r\n```\r\n\r\n**Describe the results you received:**\r\n\r\nnull\r\n\r\n**Describe the results you expected:**\r\n\r\n0\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:44:08 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.0\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:44:08 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 19\r\n Running: 17\r\n Paused: 0\r\n Stopped: 2\r\nImages: 1025\r\nServer Version: 1.13.0\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins: \r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e\r\nrunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3e\r\ninit version: 949e6fa\r\nKernel Version: 4.9.0-1-amd64\r\nOperating System: Debian GNU/Linux 9 (stretch)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 15.4 GiB\r\nName: debian\r\nID: D6YZ:RQ4R:GATU:BDEN:2BMU:YHSC:BUUD:VEI7:S252:OZ2J:4GTM:BDLQ\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: bridge-nf-call-iptables is disabled\r\nWARNING: bridge-nf-call-ip6tables is disabled\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\n\r\n"},{"labels":["api",null,null],"text":"**Description**\r\n\r\nSometimes he delete container API returns a 400. Retrying the same request after waiting for 2 seconds fixes the issue. The same code that was running for a month all of a sudden started having this error show up fairly frequently.\r\n\r\nHere is a log of the behavior from my client code.\r\n\r\n```\r\n2017-01-12T20:29:00.344289890+00:00 DEBUG volcano_agent - Removing container 491f5859c671db6d809a46c54631ef7b3ef207126b2a530ce361b534d905fa7c\r\n2017-01-12T20:29:00.344489346+00:00 DEBUG hyper::http::h1 - request line: Delete \"/containers/491f5859c671db6d809a46c54631ef7b3ef207126b2a530ce361b534d905fa7c?v=false\" Http11\r\n2017-01-12T20:29:00.344534623+00:00 DEBUG hyper::http::h1 - headers=Headers { Content-Length: 0, Host: ///var/run/docker.sock:0, }\r\n2017-01-12T20:29:00.344782407+00:00 DEBUG hyper::client::response - version=Http11, status=BadRequest\r\n2017-01-12T20:29:00.344804377+00:00 DEBUG hyper::client::response - headers=Headers { Content-Type: text/plain, Connection: close, }\r\n2017-01-12T20:29:00.344851455+00:00 DEBUG volcano_agent - remove container error 1\r\n2017-01-12T20:29:01.345225504+00:00 DEBUG hyper::http::h1 - request line: Delete \"/containers/491f5859c671db6d809a46c54631ef7b3ef207126b2a530ce361b534d905fa7c?v=false\" Http11\r\n2017-01-12T20:29:01.345325732+00:00 DEBUG hyper::http::h1 - headers=Headers { Content-Length: 0, Host: ///var/run/docker.sock:0, }\r\n2017-01-12T20:29:01.345600473+00:00 DEBUG hyper::client::response - version=Http11, status=BadRequest\r\n2017-01-12T20:29:01.345634780+00:00 DEBUG hyper::client::response - headers=Headers { Content-Type: text/plain, Connection: close, }\r\n2017-01-12T20:29:01.345682352+00:00 DEBUG volcano_agent - remove container error 2\r\n2017-01-12T20:29:02.346634708+00:00 DEBUG hyper::http::h1 - request line: Delete \"/containers/491f5859c671db6d809a46c54631ef7b3ef207126b2a530ce361b534d905fa7c?v=false\" Http11\r\n2017-01-12T20:29:02.346882532+00:00 DEBUG hyper::http::h1 - headers=Headers { Host: ///var/run/docker.sock:0, Content-Length: 0, }\r\n2017-01-12T20:29:02.357925431+00:00 DEBUG hyper::client::response - version=Http11, status=NoContent\r\n2017-01-12T20:29:02.358021182+00:00 DEBUG hyper::client::response - headers=Headers { Date: Thu, 12 Jan 2017 20:29:02 GMT, Server: Docker/1.12.3 (linux), Connection: close, }\r\n```\r\n\r\nI would show the docker log, but even though I turned on `--debug` and I could see detail on all other API requests, nothing showed up in the docker logs!\r\n\r\nI am just using the docker socket.\r\n\r\n\r\n**Describe the results you received:**\r\n\r\nThe delete container API returns a 400. Waiting for more than 1 second and retrying fixes the issue. \r\n\r\n**Describe the results you expected:**\r\n\r\nEither a 50x HTTP error code or a successful delete\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nDocker version 1.12.6, build 7392c3b/1.12.6\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 10\r\n Running: 6\r\n Paused: 0\r\n Stopped: 4\r\nImages: 6\r\nServer Version: 1.12.6\r\nStorage Driver: overlay\r\n Backing Filesystem: extfs\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: null host overlay bridge\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options:\r\nKernel Version: 4.4.41-35.53.amzn1.x86_64\r\nOperating System: Amazon Linux AMI 2016.09\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 32\r\nTotal Memory: 58.97 GiB\r\nName: ip-10-40-4-50\r\nID: XUZT:PPPI:W7PD:ENFJ:NKSX:M63C:F4DT:FRJG:MZOB:VUA4:IIEW:EVXR\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nInsecure Registries:\r\n 127.0.0.0/8\r\n```\r\n\r\nAbove information is a production system on AWS. I have also re-produced this behavior on my Local LInux computer, information below:\r\n\r\n```\r\nDocker version 1.12.3, build 6b644ec\r\n```\r\n\r\n```\r\nContainers: 4\r\n Running: 2\r\n Paused: 0\r\n Stopped: 2\r\nImages: 397\r\nServer Version: 1.12.3\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 594\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge null overlay host\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: apparmor seccomp\r\nKernel Version: 4.4.0-57-generic\r\nOperating System: Ubuntu 16.04.1 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 8\r\nTotal Memory: 15.6 GiB\r\nName: greg-Galago-UltraPro\r\nID: 3IGP:EOTD:QI7P:YIK5:RFY7:UE7S:HNEC:7ZVB:5ITE:AFWR:PETC:P3RG\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 24\r\n Goroutines: 38\r\n System Time: 2017-01-13T21:16:20.300684426-08:00\r\n EventsListeners: 1\r\nUsername: gregweber\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nInsecure Registries:\r\n 127.0.0.0/8\r\n```"},{"labels":["api"],"text":"Hello, in preparation for Go1.8, I detected this misuse of the `http.Hijacker` API.\r\n\r\nThe following uses of `Hijack`:\r\n* [api/server/router/container/container_routes.go](https://github.com/docker/docker/blob/a6be56b54e871c4e7a6e72881770a64676c27c3c/api/server/router/container/container_routes.go#L440)\r\n* [api/server/httputils/httputils.go](https://github.com/docker/docker/blob/64981b9f095459ae65954ca80a86c8f4a735ef24/api/server/httputils/httputils.go#L24)\r\n\r\nmake calls to `Hijack`, but ignores the returned `bufio.ReadWriter` and proceeds to directly use the connection. In Go1.8, the probability that data is buffered in the `bufio.Reader` is increased, such that there is a higher change that this logic fails. The proper fix is probably to handle the data in the read buffer (accessed via `brw.Reader.Peek(brw.Reader.Buffered())`) and create a wrapped `net.Conn` that reads the buffered data before calling `net.Conn.Read`.\r\n\r\n```go\r\ntype rbufConn struct {\r\n\tnet.Conn\r\n\trbuf []byte\r\n}\r\n\r\nfunc (c *rbufConn) Read(p []byte) (int, error) {\r\n\tif len(c.rbuf) > 0 {\r\n\t\tn := copy(p, c.rbuf)\r\n\t\tc.rbuf = c.rbuf[n:]\r\n\t\treturn n, nil\r\n\t}\r\n\treturn c.Conn.Read(p)\r\n}\r\n\r\nfunc (c *rbufConn) Close() error {\r\n\tc.rbuf = nil\r\n\treturn c.Conn.Close()\r\n}\r\n```"},{"labels":["api",null],"text":"I'm using Docker v1.3, I want to pass secret on `POST /services/create` remote API.\r\n\r\nIn docker command line, it will be equal to `docker service create --secret login-password  ubuntu`.\r\n\r\nHowever [documentation on the website](https://docs.docker.com/engine/reference/api/docker_remote_api_v1.24/) is only showing for v1.2. \r\n\r\nSo how to pass secret on  `POST /services/create` remote API?"},{"labels":["api",null,null],"text":"---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\n\r\n**Description**\r\n\r\nSendging a GET to the endpoint `/containers/[CONTAINER_ID OR NAME]/stats` never gets a response (hangs).\r\n\r\n**Steps to reproduce the issue:**\r\nSend a call like `GET /containers/[CONTAINER_NAME or ID]/stats`\r\n\r\nAlso tested with the raw socket:\r\n```\r\ncurl --unix-socket /var/run/docker.sock http://localhost/containers/[CONTAINER_ID]/stats\r\n```\r\n\r\n**Describe the results you received:**\r\nDocker daemon logs show:\r\n```\r\nlevel=debug msg=\"Calling GET /containers/f32f765cf23c1e56900460807f7c482aa988d37648e28d50875151322df6885f/stats\"\r\n```\r\nSo the request is received, but never gets a response.\r\n\r\n**Describe the results you expected:**\r\nhttps://docs.docker.com/engine/reference/api/docker_remote_api_v1.24/#/get-container-stats-based-on-resource-usage\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Wed Jan 11 00:23:16 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      1.12.6\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   78d1802\r\n Built:        Wed Jan 11 00:23:16 2017\r\n OS/Arch:      linux/amd64\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 15\r\n Running: 3\r\n Paused: 0\r\n Stopped: 12\r\nImages: 162\r\nServer Version: 1.12.6\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 420\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host null overlay\r\nSwarm: active\r\n NodeID: 4oh2xqqiexi4rk8julf5o9rj6\r\n Is Manager: true\r\n ClusterID: a6h0antslmorusyo7dx1z3fph\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 192.168.65.2\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: seccomp\r\nKernel Version: 4.4.41-moby\r\nOperating System: Alpine Linux v3.4\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 1.951 GiB\r\nName: moby\r\nID: 4TDG:QGRX:JGMX:TP4V:KZQ4:W2A4:DY4X:SYQY:E7PK:KNTI:WS77:IAYI\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 66\r\n Goroutines: 176\r\n System Time: 2017-01-13T10:50:53.415533429Z\r\n EventsListeners: 4\r\nNo Proxy: *.local, 169.254/16\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No kernel memory limit support\r\nInsecure Registries:\r\n 0.0.0.0:5000\r\n 127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nTested on Mac only."},{"labels":["api",null],"text":"https://github.com/docker/docker/blob/313502488e8809910127891d8923672baf43a742/api/types/plugin.go#L31 has the `Tag` separated out. We have been slowly undoing this separation to avoid having to parse image references on the client-side.\r\n\r\nHaving a separate field here is a _massive_ step back. We'll need to deprecate this field."},{"labels":["api",null,null],"text":"When the server is running Docker 1.13.0-rc5, when the client runs `docker images` the sizes will be reported as -1\r\n\r\n```\r\n$ docker version\r\nClient:\r\n Version:      1.11.1\r\n API version:  1.23\r\n Go version:   go1.5.4\r\n Git commit:   5604cbe\r\n Built:        Wed Apr 27 00:34:20 2016\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      1.13.0-rc5\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   43cc971\r\n Built:        Thu Jan  5 03:07:30 2017\r\n OS/Arch:      linux/amd64\r\n```\r\n\r\n```\r\n$ docker images\r\nREPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE\r\nkatacoda/docker-http-server       large               1e023cfd8ba8        18 hours ago        -1 B\r\nkatacoda/docker-http-server       latest              c6dfc1d5003f        18 hours ago        -1 B\r\nkatacoda/docker-http-server       v1                  c6dfc1d5003f        18 hours ago        -1 B\r\n```\r\n\r\nUpgrading the client to Docker 1.13 fixes the issue.\r\n\r\n```\r\n$ docker version\r\nClient:\r\n Version:      1.13.0-rc5\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   43cc971\r\n Built:        Thu Jan  5 03:07:30 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      1.13.0-rc5\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   43cc971\r\n Built:        Thu Jan  5 03:07:30 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n```\r\n$ docker images\r\nREPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE\r\nkatacoda/docker-http-server       large               1e023cfd8ba8        18 hours ago        771 MB\r\nkatacoda/docker-http-server       latest              c6dfc1d5003f        18 hours ago        7.59 MB\r\nkatacoda/docker-http-server       v1                  c6dfc1d5003f        18 hours ago        7.59 MB\r\n```"},{"labels":["api",null,null],"text":"**Description**\r\n\r\nWhen I call networks API with filter type=custom docker API returns response 200 with body null.\r\nIt happens when no custom networks exist.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Ensure no custom networks exist in a system. E.g. **docker network ls** returns bridge, host, none only.\r\n2. Execute \r\n```\r\ncurl localhost:2375/v1.20/networks?filters=%7B%22type%22:%5B%22custom%22%5D%7D\r\n```\r\n\r\n**Describe the results you received:**\r\nDocker returns response 200 with body\r\n```\r\nnull\\n\r\n```\r\n\r\n**Describe the results you expected:**\r\nDocker returns response 200 with body\r\n```\r\n[]\r\n```\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\nVersion:      1.12.1\r\nAPI version:  1.24\r\nGo version:   go1.6.3\r\nGit commit:   23cf638\r\nBuilt:        \r\nOS/Arch:      linux/amd64\r\n\r\nServer:\r\nVersion:      1.12.1\r\nAPI version:  1.24\r\nGo version:   go1.6.3\r\nGit commit:   23cf638\r\nBuilt:        \r\nOS/Arch:      linux/amd64\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 6\r\nRunning: 3\r\nPaused: 0\r\nStopped: 3\r\nImages: 9\r\nServer Version: 1.12.1\r\nStorage Driver: devicemapper\r\nPool Name: docker-253:0-2097431-pool\r\nPool Blocksize: 65.54 kB\r\nBase Device Size: 10.74 GB\r\nBacking Filesystem: xfs\r\nData file: /dev/loop0\r\nMetadata file: /dev/loop1\r\nData Space Used: 2.911 GB\r\nData Space Total: 107.4 GB\r\nData Space Available: 85.6 GB\r\nMetadata Space Used: 4.801 MB\r\nMetadata Space Total: 2.147 GB\r\nMetadata Space Available: 2.143 GB\r\nThin Pool Minimum Free Space: 10.74 GB\r\nUdev Sync Supported: true\r\nDeferred Removal Enabled: false\r\nDeferred Deletion Enabled: false\r\nDeferred Deleted Device Count: 0\r\nData loop file: /var/lib/docker/devicemapper/devicemapper/data\r\nWARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.\r\nMetadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\r\nLibrary Version: 1.02.122 (2016-04-09)\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\nVolume: local\r\nNetwork: null bridge host overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: seccomp\r\nKernel Version: 4.7.6-200.fc24.x86_64\r\nOperating System: Fedora 24 (Workstation Edition)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 31.39 GiB\r\nName: *******************************************\r\nID: XZ57:ZSSX:MXN6:OX6H:WM54:BL5T:46ZT:OOFV:2FCP:CWF2:HAQ2:ZBFY\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nInsecure Registries:\r\n127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nphysical\r\nReproduced on several distributions, such as CentOS, Fedora, Ubuntu.\r\nReproduced on Docker 1.12.1, 1.12.5."},{"labels":["api",null,null],"text":"---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nWhen using the `/services/[SERVICE_NAME]/update` endpoint, it fails with \"changing network in service is not supported\" if the service being updated is using a custom network. If the service was created without specifying the `--network` option however, it succeeds.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a service with the option `--network` set to a user created overlay network\r\n2. Try to send a POST to change something about the service. e.g.\r\n```\r\n{\r\n  \"TaskTemplate\": {\r\n    \"ContainerSpec\": {\r\n      \"Image\": \"busybox\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n**Describe the results you received:**\r\n`{\"message\":\"rpc error: code = 2 desc = changing network in service is not supported\"}`\r\n\r\n**Describe the results you expected:**\r\nSame as when the service is created without specifying `--network`: 200 response, and service update successful.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nThe endpoint works correctly if the service is not using a custom network.\r\n\r\n**Output of `docker version`:**\r\n```\r\nClient:\r\n Version:      1.12.5\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   7392c3b\r\n Built:        Fri Dec 16 06:14:34 2016\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      1.12.5\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   7392c3b\r\n Built:        Fri Dec 16 06:14:34 2016\r\n OS/Arch:      linux/amd64\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 11\r\n Running: 1\r\n Paused: 0\r\n Stopped: 10\r\nImages: 160\r\nServer Version: 1.12.5\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 394\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: host null overlay bridge\r\nSwarm: active\r\n NodeID: 4oh2xqqiexi4rk8julf5o9rj6\r\n Is Manager: true\r\n ClusterID: a6h0antslmorusyo7dx1z3fph\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 192.168.65.2\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: seccomp\r\nKernel Version: 4.4.39-moby\r\nOperating System: Alpine Linux v3.4\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 1.951 GiB\r\nName: moby\r\nID: HC4B:YUGH:5UQ2:C2C3:O6BD:PH5P:MVDJ:UFCC:OA3S:VZUS:R4EX:F7WX\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 51\r\n Goroutines: 195\r\n System Time: 2017-01-04T13:30:39.75392208Z\r\n EventsListeners: 2\r\nNo Proxy: *.local, 169.254/16\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No kernel memory limit support\r\nInsecure Registries:\r\n 0.0.0.0:5000\r\n 127.0.0.0/8\r\n```\r\n"},{"labels":["api",null,null,null],"text":"I have the same issu like #28528 but with1.13.0-rc4:\r\nError response from daemon: rpc error: code = 3 desc = driver name: if driver is specified name is required.\r\nI get the error when i'm trying to define a static IP address for a container.\r\n**My version is:**\r\nClient:\r\nVersion: 1.13.0-rc4\r\nAPI version: 1.25\r\nGo version: go1.7.3\r\nGit commit: 88862e7\r\nBuilt: Fri Dec 16 22:55:47 2016\r\nOS/Arch: linux/amd64\r\n\r\nServer:\r\nVersion: 1.13.0-rc4\r\nAPI version: 1.25 (minimum version 1.12)\r\nGo version: go1.7.3\r\nGit commit: 88862e7\r\nBuilt: Fri Dec 16 22:55:47 2016\r\nOS/Arch: linux/amd64\r\nExperimental: true\r\n\r\n**My compose file is (i'm using docker stacks):**\r\n```yaml\r\nnetworks:\r\ndefault_network:\r\ndriver: overlay\r\nipam:\r\nconfig:\r\n- subnet: 10.5.0.0/16\r\ngateway: 10.5.0.1\r\n```"},{"labels":["api",null],"text":"---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\n\r\n**Description**\r\n\r\nCreating volumes with the Remote API doesn't support properly support **DriverOptions**\r\n\r\n**Steps to reproduce the issue:**\r\n1.  Create a volume \r\n```json\r\n{ \"Name\":\"curl-aserver\", \"Driver\":\"local\", \"DriverOpts\": { \"o\": \"uid=1000,gid=1000,gripid=1000\" } }\r\n```\r\n2.  run `docker volume inspect curl-aserver`\r\n3.  run `sudo ls -la` on the directory just about _data for the volume\r\n4.  see that _data is root:root instead of whatever user has uid 100 and whatever group is gid:1000\r\n\r\n**Describe the results you received:**\r\nSee Step 4 above.\r\n\r\n**Describe the results you expected:**\r\nwhen you run:\r\n```shell\r\ndocker volume create --name shell-aserver --driver local --opts o=uid=1000,gid=1000,grpid=1000\r\n````\r\n\r\nand then check the permissions of the _data dir it has the user with UID 1000 and the group with GID 1000 listed as the file system permissions.  I expect the remote API to match.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.12.5\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   7392c3b\r\n Built:        Fri Dec 16 02:23:59 2016\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.12.5\r\n API version:  1.24\r\n Go version:   go1.6.4\r\n Git commit:   7392c3b\r\n Built:        Fri Dec 16 02:23:59 2016\r\n OS/Arch:      linux/amd64\r\n\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 68\r\nServer Version: 1.12.5\r\nStorage Driver: devicemapper\r\n Pool Name: docker-253:2-274722043-pool\r\n Pool Blocksize: 65.54 kB\r\n Base Device Size: 107.4 GB\r\n Backing Filesystem: xfs\r\n Data file: /dev/loop0\r\n Metadata file: /dev/loop1\r\n Data Space Used: 60 GB\r\n Data Space Total: 107.4 GB\r\n Data Space Available: 47.38 GB\r\n Metadata Space Used: 34.69 MB\r\n Metadata Space Total: 2.147 GB\r\n Metadata Space Available: 2.113 GB\r\n Thin Pool Minimum Free Space: 10.74 GB\r\n Udev Sync Supported: true\r\n Deferred Removal Enabled: false\r\n Deferred Deletion Enabled: false\r\n Deferred Deleted Device Count: 0\r\n Data loop file: /home/lib/docker/devicemapper/devicemapper/data\r\n WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.\r\n Metadata loop file: /home/lib/docker/devicemapper/devicemapper/metadata\r\n Library Version: 1.02.107-RHEL7 (2015-12-01)\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: overlay bridge null host\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: seccomp\r\nKernel Version: 3.10.0-327.18.2.el7.x86_64\r\nOperating System: CentOS Linux 7 (Core)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 15.5 GiB\r\nName: labip1128.lab.lowes.com\r\nID: QZ46:IC4D:B4E5:IDCN:SPU7:4YKP:UYWS:ZQ3I:UQA5:HLHN:LHRG:RV6O\r\nDocker Root Dir: /home/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: bridge-nf-call-iptables is disabled\r\nWARNING: bridge-nf-call-ip6tables is disabled\r\nInsecure Registries:\r\n 127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nThis client is running inside of a virtual machine, VMWare I think. I don't know the details. "},{"labels":["api",null,null],"text":"I spent a bunch of time debugging a [bearer token](https://github.com/docker/docker/issues/29257) issue.  A lot of it was wasted because I hadn't introspected the bearer token to discover that my `access` section was empty.  Perhaps there's an easier way, but I ended up downloading the [JWT Debugger](https://jwt.io/) and manually copying the long tokens.\r\n\r\nTo reduce the complexity of debugging, it'd be nice if there was an API endpoint that returned a simple JSON structure showing the access rights granted by the request."},{"labels":["api"],"text":"Pull request https://github.com/docker/docker/pull/28532 changed the status code for Swarm API endpoints from `406 Not Acceptable` to `503 Service Unavailable`\r\n\r\nThere are two issues with this change currently, that **must** be addressed / decided on before 1.13 GA\r\n\r\n\r\n1. **The change in status code must be versioned**\r\n\r\n    (see https://github.com/docker/docker/pull/28349#issuecomment-262236124); currently, a docker 1.13 daemon returns status `503 Service Unavailable` for all API versions, including for API 1.24, whereas a docker 1.12 daemon returns status `406`. Given that we cannot change a versioned API, we should update the code to return `406` for API 1.24, and `503` (or what we decide on, see `2.`) for API 1.25 and up\r\n\r\n    I don't think there are discussions about this change, it just needs to be implemented.\r\n\r\n2. **We must decide on the correct status code**\r\n\r\n     See https://github.com/docker/docker/pull/28532#issuecomment-265839863; it is disputed that a `5xx` status code is correct; reasoning there is that if Swarm mode is inactive, the Swarm API endpoints are not implemented, hence \"not available\". For that reason a `404` status code is suggested. \r\n\r\n    w.r.t. https://github.com/docker/docker/pull/28532#issuecomment-265868008;\r\n    > \"It also allows a client to differentiate between missing and not part of the server at all.\" \r\n\r\n   we should look if there _are_ other actions to be taken by the client; what other actions do we expect the client to take if swarm mode is not enabled; if it's just \"print the error message\", then this may not be a problem.\r\n\r\n\r\nping @stevvooe @justincormack @vieux @bfirsh PTAL. I made this a P0 so that we make the required changes before GA"},{"labels":["api",null],"text":"Hi. I use the \"/containers/(id)/stats\" API to collect the information of a container.\r\nWhat I get is as below:\r\n```\r\n{\"read\":\"2016-12-11T02:18:01.857174651Z\",\"preread\":\"0001-01-01T00:00:00Z\",\"pids_stats\":{},\"blkio_stats\":{\"io_service_bytes_recursive\":[],\"io_serviced_recursive\":[],\"io_queue_recursive\":[],\"io_service_time_recursive\":[],\"io_wait_time_recursive\":[],\"io_merged_recursive\":[],\"io_time_recursive\":[],\"sectors_recursive\":[]},\"num_procs\":0,\"storage_stats\":{},\"cpu_stats\":{\"cpu_usage\":{\"total_usage\":723671739199,\"percpu_usage\":[158849409169,105266278971,265007316045,194548735014],\"usage_in_kernelmode\":1360000000,\"usage_in_usermode\":724010000000},\"system_cpu_usage\":23733220000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"precpu_stats\":{\"cpu_usage\":{\"total_usage\":0,\"usage_in_kernelmode\":0,\"usage_in_usermode\":0},\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"memory_stats\":{\"usage\":856064,\"max_usage\":2486272,\"stats\":{\"active_anon\":610304,\"active_file\":0,\"cache\":0,\"dirty\":0,\"hierarchical_memory_limit\":8796093018112,\"inactive_anon\":0,\"inactive_file\":0,\"mapped_file\":0,\"pgfault\":1700,\"pgmajfault\":0,\"pgpgin\":836,\"pgpgout\":687,\"rss\":610304,\"rss_huge\":0,\"total_active_anon\":610304,\"total_active_file\":0,\"total_cache\":0,\"total_dirty\":0,\"total_inactive_anon\":0,\"total_inactive_file\":0,\"total_mapped_file\":0,\"total_pgfault\":1700,\"total_pgmajfault\":0,\"total_pgpgin\":836,\"total_pgpgout\":687,\"total_rss\":610304,\"total_rss_huge\":0,\"total_unevictable\":0,\"total_writeback\":0,\"unevictable\":0,\"writeback\":0},\"limit\":970485760},\"name\":\"/ser2.1.8be6xmrx7mshozj5suaxdzl7a\",\"id\":\"9e84fd9c570c2952f6ef272e20af1d639a8e0cb80ca33c6679a42b9cf59d9a4d\",\"networks\":{\"eth0\":{\"rx_bytes\":30954,\"rx_packets\":120,\"rx_errors\":0,\"rx_dropped\":2,\"tx_bytes\":906,\"tx_packets\":11,\"tx_errors\":0,\"tx_dropped\":0}}}\r\n```\r\n\r\nBy the command \"docker stats\", what I get is as below:\r\n```\r\nCONTAINER           CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS\r\n9e84fd9c570c        57.69%              836 KiB / 925.5 MiB   0.09%               31.7 kB / 906 B     0 B / 0 B           0\r\n```\r\n\r\nI wonder how to calculate the CPU usage in percentage based on the above information.\r\n\r\nThanks a lot."},{"labels":["api",null,null,null,null],"text":"Currently, `docker service logs` expects a service name or ID and will stream the combined output of every task that is part of the service.\r\n\r\nIt would be neat to support `docker service logs <task ID>`.\r\n\r\nThis is already implemented in the SwarmKit backend, so it's really a matter of plumbing it into the API/CLI.\r\n\r\nRelevant bits: In `daemon/cluster/cluster.go` there is:\r\n```go\r\n\tstream, err := state.logsClient.SubscribeLogs(ctx, &swarmapi.SubscribeLogsRequest{\r\n\t\tSelector: &swarmapi.LogSelector{\r\n\t\t\tServiceIDs: []string{service.ID},\r\n\t\t},\r\n\t\tOptions: &swarmapi.LogSubscriptionOptions{\r\n\t\t\tFollow: config.Follow,\r\n\t\t},\r\n\t})\r\n```\r\n\r\nIn order to stream logs for a task using SwarmKit, one would need to use the exact same code, using a different selector: `TaskIDs: []string{task.ID}`.\r\n\r\nI think the workflow would look like:\r\n1) The user calls `docker service logs <something>`\r\n2) The CLI attempts to call `/services/<something>/inspect`\r\n3) If that succeeds, then it continues with `/services/<something>/logs`, and the rest of the code is the same\r\n4) If it fails, then it attempts to call `/tasks/<something>/inspect`\r\n5) If that works, it calls `/tasks/<something>/logs` and continues with the rest of the code\r\n6) if that also fails, the CLI errors out saying <something> is neither a service nor a task\r\n\r\n/cc @thaJeztah @aaronlehmann "},{"labels":["api",null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\nDocker Repository API to get images with filter returns \"RepoDigests\" as null.\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. Call Docker API on a repository without a filter (i.e. `.../images/json`)\r\n2. Call Docker API on a repository with a filter (e.g. `.../images/json?filter=<anImageName>`)\r\n3. Compare the returned \"RepoDigests\" fields of the first response with that of the second response\r\n\r\n**Describe the results you received:**\r\nThe API responds with a null \"RepoDigests\" when a filter is used\r\n\r\n**Describe the results you expected:**\r\nI expect the API to return the same response whether I use the filter or not\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nN/A\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.12.3\r\n API version:  1.24\r\n Go version:   go1.6.3\r\n Git commit:   6b644ec\r\n Built:        Thu Oct 27 00:09:21 2016\r\n OS/Arch:      windows/amd64\r\n Experimental: true\r\n\r\nServer:\r\n Version:      1.12.3\r\n API version:  1.24\r\n Go version:   go1.6.3\r\n Git commit:   6b644ec\r\n Built:        Thu Oct 27 00:09:21 2016\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 26\r\n Running: 25\r\n Paused: 0\r\n Stopped: 1\r\nImages: 26\r\nServer Version: 1.12.3\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge overlay null host\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: seccomp\r\nKernel Version: 4.4.27-moby\r\nOperating System: Alpine Linux v3.4\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 6\r\nTotal Memory: 7.775 GiB\r\nName: moby\r\nID: Z26R:GZO7:W4TE:77XS:6XQT:XS7R:ABTC:DFAA:LJLL:AR7W:QIPL:HBK6\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No kernel memory limit support\r\nExperimental: true\r\nInsecure Registries:\r\n md1drepo01.lnx.ix.com:5000\r\n 127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nNone"},{"labels":["api",null,null],"text":"**Description**\r\n\r\nIn Docker 1.12, making a POST request to the `/v1.24/swarm/leave` endpoint to an engine not part of a Swarm would respond with status code `406 (NOT ACCEPTABLE)`. \r\nIn Docker 1.13, the same POST request now responds with status code `503 (SERVICE UNAVAILABLE)`.\r\n\r\nThis is a breaking change for this endpoint at a pre-existing API version.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Set up a Docker engine node that is not part of a Swarm and exposes the API over HTTP (e.g. `sudo docker -H 127.0.0.1:2375 daemon`)\r\n2. Make a POST request to the `/v1.24/swarm/leave` endpoint:\r\n```\r\ncurl -v -d '' http://127.0.0.1:2375/v1.24/swarm/leave\r\n```\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\n$ curl -v -d '' http://127.0.0.1:2375/v1.24/swarm/leave\r\n*   Trying 127.0.0.1...\r\n* Connected to 127.0.0.1 (127.0.0.1) port 2375 (#0)\r\n> POST /v1.24/swarm/leave HTTP/1.1\r\n> Host: 127.0.0.1:2375\r\n> User-Agent: curl/7.47.0\r\n> Accept: */*\r\n> Content-Length: 0\r\n> Content-Type: application/x-www-form-urlencoded\r\n> \r\n< HTTP/1.1 503 Service Unavailable\r\n< Api-Version: 1.25\r\n< Content-Type: application/json\r\n< Docker-Experimental: false\r\n< Server: Docker/1.13.0-rc3 (linux)\r\n< Date: Tue, 06 Dec 2016 20:07:31 GMT\r\n< Content-Length: 47\r\n* HTTP error before end of send, stop sending\r\n< \r\n{\"message\":\"This node is not part of a swarm\"}\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\n`HTTP/1.1 406 Not Acceptable`, as indicated in the [Remote API 1.24 reference](https://docs.docker.com/engine/reference/api/docker_remote_api_v1.24/#leave-a-swarm)\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0-rc3\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   4d92237\r\n Built:        Mon Dec  5 19:05:57 2016\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.0-rc3\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   4d92237\r\n Built:        Mon Dec  5 19:05:57 2016\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n"},{"labels":["api",null,null,null],"text":"While discussing https://github.com/docker/docker/issues/26714, it was reported that tmpfs options are not working for services.\r\n\r\nhttps://github.com/docker/docker/pull/26837 added these options to the \"Mount\" type, https://github.com/docker/docker/pull/26833 changed the service API to use these types, and https://github.com/docker/docker/pull/28150 added tmpfs specific options (for docker run)\r\n\r\nIt looks like something was not wired through, though;\r\n\r\nRunning this on https://github.com/docker/docker/commit/45ed6a75795918d466054e63c462a1a8b553c8c0 (https://github.com/docker/docker/pull/28150)\r\n\r\n    docker service create --name test --mount type=tmpfs,target=/foo,tmpfs-size=4194304 nginx:alpine\r\n\r\nThe container has;\r\n\r\n`HostConfig`:\r\n\r\n    \"Tmpfs\": {\r\n      \"/foo\": \"\"\r\n    },\r\n\r\n`Mounts`:\r\n\r\n     \"Mounts\": [],\r\n\r\n\r\nRunning from https://github.com/docker/docker/commit/821aeb6a6f72f070ae045cb7813759cbbaba7bda (https://github.com/docker/docker/pull/26833)\r\n\r\n    docker service create --name test --mount type=tmpfs,target=/foo,tmpfs-size=4194304 nginx:alpine\r\n\r\n\r\nThe container has;\r\n\r\n`HostConfig`:\r\n\r\n    \"Tmpfs\": {\r\n        \"/foo\": \"\"\r\n    },\r\n    \"Mounts\": [\r\n        {\r\n            \"Type\": \"tmpfs\",\r\n            \"Target\": \"/foo\"\r\n        }\r\n    ]\r\n\r\n`Mounts`:\r\n\r\n    \"Mounts\": [\r\n        {\r\n            \"Type\": \"tmpfs\",\r\n            \"Source\": \"\",\r\n            \"Destination\": \"/foo\",\r\n            \"Mode\": \"\",\r\n            \"RW\": true,\r\n            \"Propagation\": \"\"\r\n        }\r\n    ],\r\n\r\n\r\n\r\nRunning on master (a756c1ac659468bb8d6ec9ee2e1182fc6cae4002)\r\n\r\n    docker service create --name test --mount type=tmpfs,target=/foo,tmpfs-size=4194304 nginx:alpine\r\n\r\nThis request is sent (looks good);\r\n\r\n```json\r\n{\r\n  \"EndpointSpec\": {},\r\n  \"Mode\": {\r\n    \"Replicated\": {}\r\n  },\r\n  \"Name\": \"test\",\r\n  \"TaskTemplate\": {\r\n    \"ContainerSpec\": {\r\n      \"DNSConfig\": {},\r\n      \"Image\": \"nginx:alpine\",\r\n      \"Mounts\": [\r\n        {\r\n          \"Target\": \"/foo\",\r\n          \"TmpfsOptions\": {\r\n            \"SizeBytes\": 4194304\r\n          },\r\n          \"Type\": \"tmpfs\"\r\n        }\r\n      ]\r\n    },\r\n    \"ForceUpdate\": 0,\r\n    \"Placement\": {},\r\n    \"Resources\": {\r\n      \"Limits\": {},\r\n      \"Reservations\": {}\r\n    },\r\n    \"RestartPolicy\": {}\r\n  },\r\n  \"UpdateConfig\": {\r\n    \"FailureAction\": \"pause\",\r\n    \"MaxFailureRatio\": 0,\r\n    \"Parallelism\": 1\r\n  }\r\n}\r\n```\r\n\r\nHowever, `docker service inspect` does not show that;\r\n\r\n\r\n```JSON\r\n[\r\n    {\r\n        \"ID\": \"oao6qenv51cdid1y7ookqe5ql\",\r\n        \"Version\": {\r\n            \"Index\": 11\r\n        },\r\n        \"CreatedAt\": \"2016-12-02T13:22:29.706211456Z\",\r\n        \"UpdatedAt\": \"2016-12-02T13:22:29.706211456Z\",\r\n        \"Spec\": {\r\n            \"Name\": \"test\",\r\n            \"TaskTemplate\": {\r\n                \"ContainerSpec\": {\r\n                    \"Image\": \"nginx:alpine@sha256:aee97412fee873bd3d8fc2331b80862d7bd58913f7b12740cae8515edc1a66e4\",\r\n                    \"Mounts\": [\r\n                        {\r\n                            \"Type\": \"tmpfs\",\r\n                            \"Target\": \"/foo\"\r\n                        }\r\n                    ],\r\n                    \"DNSConfig\": {}\r\n                },\r\n                \"Resources\": {\r\n                    \"Limits\": {},\r\n                    \"Reservations\": {}\r\n                },\r\n                \"RestartPolicy\": {\r\n                    \"Condition\": \"any\",\r\n                    \"MaxAttempts\": 0\r\n                },\r\n                \"Placement\": {},\r\n                \"ForceUpdate\": 0\r\n            },\r\n            \"Mode\": {\r\n                \"Replicated\": {\r\n                    \"Replicas\": 1\r\n                }\r\n            },\r\n            \"UpdateConfig\": {\r\n                \"Parallelism\": 1,\r\n                \"FailureAction\": \"pause\",\r\n                \"MaxFailureRatio\": 0\r\n            },\r\n            \"EndpointSpec\": {\r\n                \"Mode\": \"vip\"\r\n            }\r\n        },\r\n        \"Endpoint\": {\r\n            \"Spec\": {}\r\n        },\r\n        \"UpdateStatus\": {\r\n            \"StartedAt\": \"0001-01-01T00:00:00Z\",\r\n            \"CompletedAt\": \"0001-01-01T00:00:00Z\"\r\n        }\r\n    }\r\n]\r\n```\r\n\r\nAnd the backing container also doesn't show;\r\n\r\n```JSON\r\n[\r\n    {\r\n        \"Id\": \"65d6a139685f0467194bb7ac3a2c404f42595d0285522a425c3ed9916435d02b\",\r\n        \"Created\": \"2016-12-02T13:22:38.009036877Z\",\r\n        \"Path\": \"nginx\",\r\n        \"Args\": [\r\n            \"-g\",\r\n            \"daemon off;\"\r\n        ],\r\n        \"State\": {\r\n            \"Status\": \"running\",\r\n            \"Running\": true,\r\n            \"Paused\": false,\r\n            \"Restarting\": false,\r\n            \"OOMKilled\": false,\r\n            \"Dead\": false,\r\n            \"Pid\": 561,\r\n            \"ExitCode\": 0,\r\n            \"Error\": \"\",\r\n            \"StartedAt\": \"2016-12-02T13:22:38.958195446Z\",\r\n            \"FinishedAt\": \"0001-01-01T00:00:00Z\"\r\n        },\r\n        \"Image\": \"sha256:d964ab5d0abe650e824c6b5fdfdf33df306ca6d4d59b1f9ca2c494324d6d37f3\",\r\n        \"ResolvConfPath\": \"/var/lib/docker/containers/65d6a139685f0467194bb7ac3a2c404f42595d0285522a425c3ed9916435d02b/resolv.conf\",\r\n        \"HostnamePath\": \"/var/lib/docker/containers/65d6a139685f0467194bb7ac3a2c404f42595d0285522a425c3ed9916435d02b/hostname\",\r\n        \"HostsPath\": \"/var/lib/docker/containers/65d6a139685f0467194bb7ac3a2c404f42595d0285522a425c3ed9916435d02b/hosts\",\r\n        \"LogPath\": \"/var/lib/docker/containers/65d6a139685f0467194bb7ac3a2c404f42595d0285522a425c3ed9916435d02b/65d6a139685f0467194bb7ac3a2c404f42595d0285522a425c3ed9916435d02b-json.log\",\r\n        \"Name\": \"/test.1.nv0cc9h0rxz4n6kep9ar0fwon\",\r\n        \"RestartCount\": 0,\r\n        \"Driver\": \"aufs\",\r\n        \"MountLabel\": \"\",\r\n        \"ProcessLabel\": \"\",\r\n        \"AppArmorProfile\": \"\",\r\n        \"ExecIDs\": null,\r\n        \"HostConfig\": {\r\n            \"Binds\": null,\r\n            \"ContainerIDFile\": \"\",\r\n            \"LogConfig\": {\r\n                \"Type\": \"json-file\",\r\n                \"Config\": {}\r\n            },\r\n            \"NetworkMode\": \"default\",\r\n            \"PortBindings\": {},\r\n            \"RestartPolicy\": {\r\n                \"Name\": \"\",\r\n                \"MaximumRetryCount\": 0\r\n            },\r\n            \"AutoRemove\": false,\r\n            \"VolumeDriver\": \"\",\r\n            \"VolumesFrom\": null,\r\n            \"CapAdd\": null,\r\n            \"CapDrop\": null,\r\n            \"Dns\": null,\r\n            \"DnsOptions\": null,\r\n            \"DnsSearch\": null,\r\n            \"ExtraHosts\": null,\r\n            \"GroupAdd\": null,\r\n            \"IpcMode\": \"\",\r\n            \"Cgroup\": \"\",\r\n            \"Links\": null,\r\n            \"OomScoreAdj\": 0,\r\n            \"PidMode\": \"\",\r\n            \"Privileged\": false,\r\n            \"PublishAllPorts\": false,\r\n            \"ReadonlyRootfs\": false,\r\n            \"SecurityOpt\": null,\r\n            \"UTSMode\": \"\",\r\n            \"UsernsMode\": \"\",\r\n            \"ShmSize\": 67108864,\r\n            \"Runtime\": \"runc\",\r\n            \"ConsoleSize\": [\r\n                0,\r\n                0\r\n            ],\r\n            \"Isolation\": \"\",\r\n            \"CpuShares\": 0,\r\n            \"Memory\": 0,\r\n            \"NanoCpus\": 0,\r\n            \"CgroupParent\": \"\",\r\n            \"BlkioWeight\": 0,\r\n            \"BlkioWeightDevice\": null,\r\n            \"BlkioDeviceReadBps\": null,\r\n            \"BlkioDeviceWriteBps\": null,\r\n            \"BlkioDeviceReadIOps\": null,\r\n            \"BlkioDeviceWriteIOps\": null,\r\n            \"CpuPeriod\": 0,\r\n            \"CpuQuota\": 0,\r\n            \"CpuRealtimePeriod\": 0,\r\n            \"CpuRealtimeRuntime\": 0,\r\n            \"CpusetCpus\": \"\",\r\n            \"CpusetMems\": \"\",\r\n            \"Devices\": null,\r\n            \"DiskQuota\": 0,\r\n            \"KernelMemory\": 0,\r\n            \"MemoryReservation\": 0,\r\n            \"MemorySwap\": 0,\r\n            \"MemorySwappiness\": -1,\r\n            \"OomKillDisable\": false,\r\n            \"PidsLimit\": 0,\r\n            \"Ulimits\": null,\r\n            \"CpuCount\": 0,\r\n            \"CpuPercent\": 0,\r\n            \"IOMaximumIOps\": 0,\r\n            \"IOMaximumBandwidth\": 0,\r\n            \"Mounts\": [\r\n                {\r\n                    \"Type\": \"tmpfs\",\r\n                    \"Target\": \"/foo\"\r\n                }\r\n            ]\r\n        },\r\n        \"GraphDriver\": {\r\n            \"Name\": \"aufs\",\r\n            \"Data\": null\r\n        },\r\n        \"Mounts\": [\r\n            {\r\n                \"Type\": \"tmpfs\",\r\n                \"Source\": \"\",\r\n                \"Destination\": \"/foo\",\r\n                \"Mode\": \"\",\r\n                \"RW\": true,\r\n                \"Propagation\": \"\"\r\n            }\r\n        ],\r\n        \"Config\": {\r\n            \"Hostname\": \"65d6a139685f\",\r\n            \"Domainname\": \"\",\r\n            \"User\": \"\",\r\n            \"AttachStdin\": false,\r\n            \"AttachStdout\": false,\r\n            \"AttachStderr\": false,\r\n            \"ExposedPorts\": {\r\n                \"443/tcp\": {},\r\n                \"80/tcp\": {}\r\n            },\r\n            \"Tty\": false,\r\n            \"OpenStdin\": false,\r\n            \"StdinOnce\": false,\r\n            \"Env\": [\r\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\r\n                \"NGINX_VERSION=1.11.6\"\r\n            ],\r\n            \"Cmd\": [\r\n                \"nginx\",\r\n                \"-g\",\r\n                \"daemon off;\"\r\n            ],\r\n            \"ArgsEscaped\": true,\r\n            \"Image\": \"nginx@sha256:aee97412fee873bd3d8fc2331b80862d7bd58913f7b12740cae8515edc1a66e4\",\r\n            \"Volumes\": null,\r\n            \"WorkingDir\": \"\",\r\n            \"Entrypoint\": null,\r\n            \"OnBuild\": null,\r\n            \"Labels\": {\r\n                \"com.docker.swarm.node.id\": \"nu0ip7usli91dikmeclsum063\",\r\n                \"com.docker.swarm.service.id\": \"oao6qenv51cdid1y7ookqe5ql\",\r\n                \"com.docker.swarm.service.name\": \"test\",\r\n                \"com.docker.swarm.task\": \"\",\r\n                \"com.docker.swarm.task.id\": \"nv0cc9h0rxz4n6kep9ar0fwon\",\r\n                \"com.docker.swarm.task.name\": \"test.1.nv0cc9h0rxz4n6kep9ar0fwon\"\r\n            }\r\n        },\r\n        \"NetworkSettings\": {\r\n            \"Bridge\": \"\",\r\n            \"SandboxID\": \"a35107b0b1cbf27f63669328d5c8ca3bccedeac7d9dc0ec8a43af10f1fc14522\",\r\n            \"HairpinMode\": false,\r\n            \"LinkLocalIPv6Address\": \"\",\r\n            \"LinkLocalIPv6PrefixLen\": 0,\r\n            \"Ports\": {\r\n                \"443/tcp\": null,\r\n                \"80/tcp\": null\r\n            },\r\n            \"SandboxKey\": \"/var/run/docker/netns/a35107b0b1cb\",\r\n            \"SecondaryIPAddresses\": null,\r\n            \"SecondaryIPv6Addresses\": null,\r\n            \"EndpointID\": \"c6c4250db69a4516e5e23aa4567e5fbfaa640ff6e8d16505008bf3b1933e6592\",\r\n            \"Gateway\": \"172.18.0.1\",\r\n            \"GlobalIPv6Address\": \"\",\r\n            \"GlobalIPv6PrefixLen\": 0,\r\n            \"IPAddress\": \"172.18.0.2\",\r\n            \"IPPrefixLen\": 16,\r\n            \"IPv6Gateway\": \"\",\r\n            \"MacAddress\": \"02:42:ac:12:00:02\",\r\n            \"Networks\": {\r\n                \"bridge\": {\r\n                    \"IPAMConfig\": null,\r\n                    \"Links\": null,\r\n                    \"Aliases\": null,\r\n                    \"NetworkID\": \"29ebdfc034bf747d22b4b5bf19149c2a3bfb8f177de46c7d53c923a6a791b2f7\",\r\n                    \"EndpointID\": \"c6c4250db69a4516e5e23aa4567e5fbfaa640ff6e8d16505008bf3b1933e6592\",\r\n                    \"Gateway\": \"172.18.0.1\",\r\n                    \"IPAddress\": \"172.18.0.2\",\r\n                    \"IPPrefixLen\": 16,\r\n                    \"IPv6Gateway\": \"\",\r\n                    \"GlobalIPv6Address\": \"\",\r\n                    \"GlobalIPv6PrefixLen\": 0,\r\n                    \"MacAddress\": \"02:42:ac:12:00:02\"\r\n                }\r\n            }\r\n        }\r\n    }\r\n]\r\n```\r\n\r\n\r\nNote that on 1.13.0-rc2, this works (`--mount` is still present on `docker run`, but removed in https://github.com/docker/docker/pull/28838);\r\n\r\n    docker run -dit --rm --mount type=tmpfs,target=/foo,tmpfs-size=1m busybox\r\n\r\n`HostConfig.Mounts`:\r\n\r\n```\r\n\"Mounts\": [\r\n    {\r\n        \"Type\": \"tmpfs\",\r\n        \"Target\": \"/foo\",\r\n        \"TmpfsOptions\": {\r\n            \"SizeBytes\": 1048576\r\n        }\r\n    }\r\n]\r\n```\r\n\r\n`Mounts`:\r\n\r\n```\r\n\"Mounts\": [\r\n    {\r\n        \"Type\": \"tmpfs\",\r\n        \"Source\": \"\",\r\n        \"Destination\": \"/foo\",\r\n        \"Mode\": \"\",\r\n        \"RW\": true,\r\n        \"Propagation\": \"\"\r\n    }\r\n],\r\n```\r\n\r\n\r\nSo, it looks like there's an issue in SwarmKit, or integration of SwarmKit into docker\r\n\r\n/cc @cpuguy83 @AkihiroSuda "},{"labels":["api",null],"text":"I'm using docker in mas OS with TLS and CORS enabled. I'm connecting to the docker daemon from javascript, but I get following error in the browser:\r\nNo 'Access-Control-Allow-Origin' header is present on the requested resource\r\n\r\nI'm using following curl commands to check docker behaviour (I've previously created the container and the images):\r\n1. I create a process with exec:\r\n\r\n```\r\ncurl -v -X POST -H \"Content-Type: application/json\" --cert ..../cert.p12 --pass XXXX --key ..../key.pem --cacert ..../ca.pem https://192.168.99.100:2376/containers/ba88fb9efcce4962dbd9faaed1e7580df6d33d8778f08e1f469a57b7a4fee118/exec -d '{                 \r\n\"AttachStdin\" : false,\r\n\"AttachStdout\" : true,\r\n\"AttachStderr\" : true,\r\n\"Tty\" : false,\r\n\"Cmd\" : [\"/bin/date\"]}'\r\n\r\nNote: Unnecessary use of -X or --request, POST is already inferred.\r\n*   Trying 192.168.99.100...\r\n* Connected to 192.168.99.100 (192.168.99.100) port 2376 (#0)\r\n* WARNING: SSL: CURLOPT_SSLKEY is ignored by Secure Transport. The private key must be in the Keychain.\r\n* WARNING: SSL: Certificate type not set, assuming PKCS#12 format.\r\n* Client certificate: mmiguel.<bootstrap>\r\n* WARNING: using IP address, SNI is being disabled by the OS.\r\n* TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\r\n* Server certificate: XXXX\r\n* Server certificate: XXXX\r\n> POST /containers/ba88fb9efcce4962dbd9faaed1e7580df6d33d8778f08e1f469a57b7a4fee118/exec HTTP/1.1\r\n> Host: 192.168.99.100:2376\r\n> User-Agent: curl/7.49.1\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 108\r\n> \r\n* upload completely sent off: 108 out of 108 bytes\r\n< HTTP/1.1 201 Created\r\n< Access-Control-Allow-Headers: Origin, X-Requested-With, Content-Type, Accept, X-Registry-Auth\r\n< Access-Control-Allow-Methods: HEAD, GET, POST, DELETE, PUT, OPTIONS\r\n< Access-Control-Allow-Origin: *\r\n< Content-Type: application/json\r\n< Server: Docker/1.12.3 (linux)\r\n< Date: Fri, 02 Dec 2016 12:21:30 GMT\r\n< Content-Length: 74\r\n< \r\n{\"Id\":\"6b2f0da5b53fc60d9ab87256bc2c625fdde77ead838daa3c1902db7405885a6c\"}\r\n* Connection #0 to host 192.168.99.100 left intact\r\n```\r\n\r\nWhen I execute the create exec command I receive the Access-Control-Allow-Origin header, and the process id.\r\n\r\n2. Then I start the exec process:\r\n\r\n```\r\ncurl -v -X POST -H \"Content-Type: application/json\" --cert ..../cert.p12 --pass XXXX --key ..../key.pem --cacert .... /ca.pem https://192.168.99.100:2376/exec/6b2f0da5b53fc60d9ab87256bc2c625fdde77ead838daa3c1902db7405885a6c/start -d '{\"Detach\" : false, \"Tty\" : false}'\r\n\r\nNote: Unnecessary use of -X or --request, POST is already inferred.\r\n*   Trying 192.168.99.100...\r\n* Connected to 192.168.99.100 (192.168.99.100) port 2376 (#0)\r\n* WARNING: SSL: CURLOPT_SSLKEY is ignored by Secure Transport. The private key must be in the Keychain.\r\n* WARNING: SSL: Certificate type not set, assuming PKCS#12 format.\r\n* Client certificate: mmiguel.<bootstrap>\r\n* WARNING: using IP address, SNI is being disabled by the OS.\r\n* TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\r\n* Server certificate: xxxx\r\n* Server certificate: xxxx\r\n> POST /exec/6b2f0da5b53fc60d9ab87256bc2c625fdde77ead838daa3c1902db7405885a6c/start HTTP/1.1\r\n> Host: 192.168.99.100:2376\r\n> User-Agent: curl/7.49.1\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 33\r\n> \r\n* upload completely sent off: 33 out of 33 bytes\r\n< HTTP/1.1 200 OK\r\n< Content-Type: application/vnd.docker.raw-stream\r\n* no chunk, no close, no size. Assume close to signal end\r\n< \r\nFri Dec  2 12:25:06 UTC 2016\r\n* Closing connection 0\r\n```\r\n\r\nThis executes the command (/bin/date), I receive the output, but the header doesn't includes Access-Control-Allow-Origin header (previous execution with the same configuration included the header).\r\nBecause of that I can't get the execution result, when I execute the same thing from javascript in the client browser.\r\n\r\nDo I need to make any cors configuration for the process that we create with the exec command?\r\n(I haven't found anything about this in the rest api doc)."},{"labels":["api",null],"text":"\r\n**Environment**\r\n\r\n* CentOS 7.1.1503   kernel 3.10.0-229.el7.x86_64\r\n* docker version: 1.12.1\r\n\r\n**Problem description**:\r\n\r\nI recently encountered a problem: I have removed the container by `docker rm $containerID`, but it is not really removed. there are lots of errors in /var/log/messages, such as\r\n\r\n```shell\r\n[op@localhost ~]$ sudo tail -f /var/log/messages\r\nDec  2 15:12:10 localhost dockerd: time=\"2016-12-02T15:12:10.114497059+08:00\" level=error msg=\"Handler for GET /containers/30d8fecac0f9fcf78c56e9b1cab3939d52f5ac7cda53e5b6df46a175f8af6fbb/json returned error: No such container: 30d8fecac0f9fcf78c56e9b1cab3939d52f5ac7cda53e5b6df46a175f8af6fbb\"\r\nDec  2 15:12:10 localhost dockerd: time=\"2016-12-02T15:12:10.114806985+08:00\" level=error msg=\"Handler for GET /containers/e5a6cdf84d37efa8a8185e142cb326ff622f15a168b26ba08382c1b01f938db5/json returned error: No such container: e5a6cdf84d37efa8a8185e142cb326ff622f15a168b26ba08382c1b01f938db5\"\r\nDec  2 15:12:10 localhost dockerd: time=\"2016-12-02T15:12:10.115129370+08:00\" level=error msg=\"Handler for GET /containers/98e8c3bda8ca0adb138a7d3d6f2116453ba7543e4384c2d56b018fa6c7540018/json returned error: No such container: 98e8c3bda8ca0adb138a7d3d6f2116453ba7543e4384c2d56b018fa6c7540018\"\r\nDec  2 15:12:10 localhost dockerd: time=\"2016-12-02T15:12:10.115444802+08:00\" level=error msg=\"Handler for GET /containers/effb24af21f7f3cb7b682e4baaaf383f39fb3ca9b1cd20f1c01461c139ac02f2/json returned error: No such container: effb24af21f7f3cb7b682e4baaaf383f39fb3ca9b1cd20f1c01461c139ac02f2\"\r\nDec  2 15:12:10 localhost dockerd: time=\"2016-12-02T15:12:10.115739337+08:00\" level=error msg=\"Handler for GET /containers/f038482af075bbfdaaa4ac1844ef4ccacd0c7ba9b5f95a16229468c45913ccb1/json returned error: No such container: f038482af075bbfdaaa4ac1844ef4ccacd0c7ba9b5f95a16229468c45913ccb1\"\r\nDec  2 15:12:10 localhost dockerd: time=\"2016-12-02T15:12:10.116081434+08:00\" level=error msg=\"Handler for GET /containers/42097edcc80320f3727e7d9fe3f122ddf415af3827db40604d24aceee84c883b/json returned error: No such container: 42097edcc80320f3727e7d9fe3f122ddf415af3827db40604d24aceee84c883b\"\r\nDec  2 15:12:10 localhost dockerd: time=\"2016-12-02T15:12:10.116373021+08:00\" level=error msg=\"Handler for GET /containers/25e380857eda37c25b01b14afb51c74eba83978c358a8a489d8b59b14712ea41/json returned error: No such container: 25e380857eda37c25b01b14afb51c74eba83978c358a8a489d8b59b14712ea41\"\r\nDec  2 15:12:10 localhost dockerd: time=\"2016-12-02T15:12:10.116663990+08:00\" level=error msg=\"Handler for GET /containers/9a71ef7a2cd5ceae29e54d5827800af7acc1742b8b5cc7481071e3ec5c94a76f/json returned error: No such container: 9a71ef7a2cd5ceae29e54d5827800af7acc1742b8b5cc7481071e3ec5c94a76f\"\r\nDec  2 15:12:10 localhost dockerd: time=\"2016-12-02T15:12:10.116973822+08:00\" level=error msg=\"Handler for GET /containers/f5b24d5887ef1bcd2e021f365ae029254c6be9be1a0ec34aa540e627e076ddc8/json returned error: No such container: f5b24d5887ef1bcd2e021f365ae029254c6be9be1a0ec34aa540e627e076ddc8\"\r\n```\r\n\r\n \r\n\r\nIn the ¬†storage directory, i can find the containID.  but it can't be see in `docker ps -a` \r\n\r\n```shell\r\n[root@localhost docker]# ls\r\ncontainers  devicemapper  image  network  swarm  tmp  trust  volumes\r\n```\r\n\r\nthe removed containerID can be find in **devicemapper** directory, but can not be find in **containers** directory.\r\n\r\nhow can i do to solve the problem?\r\n\r\n"},{"labels":["api",null],"text":"since https://github.com/docker/docker/pull/28840/ got merged, the swagger generation is not working as expected.\r\n\r\n* doing a `make swagger-gen` now generated a `api/types/containers` with an `s` owned by root instead of updating the files in `api/types/container`\r\n* `rm api/types/volume/volumes_create.go && make swagger-gen` doesn't' generate the missing file.\r\n\r\nlooks like tags have a effect on the folder where the types are generated and the above PR changed them.\r\n\r\n/cc @bfirsh @dnephin \r\n\r\nit blocks https://github.com/docker/docker/pull/29002"},{"labels":["api",null,null,null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\nI am receiving the following error when on 1.13-rc2 and directing a Docker host to build a container through the mounted Docker socket.\r\n```\r\nERRO[0000] error removing container: Error response from daemon: removal of container ce0976ad22495c7cbe9487752ea32721a282164862db036b2f3377bd07461c3a is already in progress\r\n```\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n\r\nOne file \"Dockerfile-builder\" for the container which will initiate the build:\r\n```docker\r\nFROM debian:jessie\r\n\r\nRUN apt-get update && apt-get install -y \\\r\n        ca-certificates \\\r\n        curl \\\r\n    --no-install-recommends && rm -r /var/lib/apt/lists/*\r\n\r\n# Set up Docker\r\nRUN  set -x \\\r\n    && curl -fSL \"https://test.docker.com/builds/Linux/x86_64/docker-1.13.0-rc2.tgz\" -o docker.tgz \\\r\n    && tar -xzvf docker.tgz \\\r\n    && mv docker/* /usr/local/bin/ \\\r\n    && rmdir docker \\\r\n    && rm docker.tgz \\\r\n    && docker -v\r\n\r\nENTRYPOINT [ \"docker\" ]\r\n```\r\n\r\nOne file \"Dockerfile\" for a simple image being built:\r\n```docker\r\nFROM debian:jessie\r\n```\r\n\r\nBuild the builder, then use it to build the simple image along with the build context for that directory:\r\n```bash\r\ndocker build -f Dockerfile-builder -t builder .\r\ndocker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $PWD:$PWD --workdir $PWD builder build -t example .\r\n```\r\n\r\nYou may have to run the second command a couple times to encounter the error.\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\nSending build context to Docker daemon 3.072 kB\r\nStep 1/1 : FROM debian:jessie\r\n ---> 73e72bf822ca\r\nSuccessfully built 73e72bf822ca\r\nERRO[0000] error removing container: Error response from daemon: removal of container ce0976ad22495c7cbe9487752ea32721a282164862db036b2f3377bd07461c3a is already in progress\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\n```\r\nSending build context to Docker daemon 3.072 kB\r\nStep 1/1 : FROM debian:jessie\r\n ---> 73e72bf822ca\r\nSuccessfully built 73e72bf822ca\r\n```\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nRunning this on:\r\n* Docker Machine `Version: 0.9.0-rc1, build ed849a7`\r\n* Installed as part of Docker for Mac `Version: 0.9.0-rc1, build ed849a7`\r\n* macOS Sierra 10.12.1.\r\n\r\nThe virtual machine is VMWare Fusion `Version 8.5.2 (4635224)`.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0-rc2\r\n API version:  1.24\r\n Go version:   go1.7.3\r\n Git commit:   1f9b3ef\r\n Built:        Wed Nov 23 17:40:58 2016\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:             1.13.0-rc2\r\n API version:         1.25\r\n Minimum API version: 1.12\r\n Go version:          go1.7.3\r\n Git commit:          1f9b3ef\r\n Built:               Wed Nov 23 17:40:58 2016\r\n OS/Arch:             linux/amd64\r\n Experimental:        false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 511\r\nServer Version: 1.13.0-rc2\r\nStorage Driver: aufs\r\n Root Dir: /mnt/sda1/var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 706\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e\r\nrunc version: 51371867a01c467f08af739783b8beafc154c4d7\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\nKernel Version: 4.4.34-boot2docker\r\nOperating System: Boot2Docker 1.13.0-rc2 (TCL 7.2); HEAD : 51fa426 - Wed Nov 23 20:08:44 UTC 2016\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 1.955 GiB\r\nName: default\r\nID: EZ5K:RZIJ:SLYL:Q4DX:H5JL:L76H:OROI:D2BL:S34W:45FX:DGSN:L6VN\r\nDocker Root Dir: /mnt/sda1/var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 14\r\n Goroutines: 23\r\n System Time: 2016-12-01T22:07:58.068629497Z\r\n EventsListeners: 0\r\nUsername: taiidani\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\n provider=vmwarefusion\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n"},{"labels":["api",null,null,null,null],"text":"**Description**\r\n**Steps to reproduce the issue:**\r\n1. Get docker v1.13 on Docker for Mac\r\n2. `docker run -d --restart=on-failure nginx`\r\n\r\n**Describe the results you received:**\r\n```\r\ndocker: Error response from daemon: maximum restart count must be a positive integer.\r\nSee 'docker run --help'.\r\n```\r\n\r\n**Describe the results you expected:**\r\n* Container is started without a problem.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\n$ docker version\r\nClient:\r\n Version:      1.13.0-rc2\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   1f9b3ef\r\n Built:        Wed Nov 23 17:40:58 2016\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:             1.13.0-rc2\r\n API version:         1.25\r\n Minimum API version: 1.12\r\n Go version:          go1.7.3\r\n Git commit:          1f9b3ef\r\n Built:               Wed Nov 23 17:40:58 2016\r\n OS/Arch:             linux/amd64\r\n Experimental:        true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\nhttp://pastebin.com/raw/ckKsKLNh\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n* Docker for Mac\r\n* The same thing works with docker v1.12.\r\n"},{"labels":["api",null,null,null,null],"text":"This is a continuation of #27275\r\n\r\nIn 1.11 a change was introduced to validate that hostnames are RFC compliant (#20566, https://tools.ietf.org/html/rfc1123).\r\nThis change did not follow the normal deprecation policy and broke users using non-RFC compliant hostnames.\r\n\r\nAffected versions are Docker 1.11 - 1.13-rc2\r\n\r\nPing @thaJeztah \r\n@vdemeester who I believe introduced version checking at least in the API to only valid in api versions >= 1.24 (1.12+)"},{"labels":["api",null],"text":"**Description**\r\n\r\nThe Docker client API from tag v1.13.0-rc2 breaks the ImageList API when used with a Docker server below 1.25.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n1. Create a client with version 1.24: ```client := NewClient(socket, \"1.24\", nil, header))```\r\n2. Build an ImageListOptions object with a ```reference``` filter (replaces the MatchName property from previous versions of the API):\r\n```\r\n    filter := filters.NewArgs()\r\n    filter.Add(\"reference\", imageName)\r\n    options := types.ImageListOptions{All: false, Filters: filter}\r\n```\r\n3. Use the ImageList object with these options: ```list, err := client.ImageList(ctx, options)```\r\n4. Test the client against a 1.12.3 Docker engine\r\n\r\n**Describe the results you received:**\r\n\r\nThe Docker engine complains about an unknown filter:\r\nError response from daemon: Invalid filter 'reference'\r\n\r\n**Describe the results you expected:**\r\n\r\nThe API should adapt (based on the version passed to NewClient) and provide the proper parameters to the server.\r\n"},{"labels":["api",null],"text":"When using the docker stats api currently each request to the API will take up to 2 seconds. As explained in https://github.com/docker/docker/issues/23188 the docker API needs two measurement points to calculate an average. \r\n\r\nFor stats collectors like [Metricbeat](https://github.com/elastic/beats/tree/master/metricbeat) it would be useful to get the raw cpu values and either do the calculations on the collector side or directly when viewing the data on the storage system (in our case Elasticsearch).\r\n\r\nI'm proposing to add a flag/param to the docker stats API request that skips average calculations and return only raw values instead. This will speed up the API request and will potentially also reduce the load on the docker service as the request is open for a much shorter time.\r\n\r\nCollecting stats for a large number of containers has currently to be done one by one which leads to lots of open http requests and is quite slow because of the above issue. This will potentially be solved with https://github.com/docker/docker/pull/25361 by @WeiZhang555 but also as part of this bulk request it would be nice to have the flag to disable calculations."},{"labels":["api"],"text":"There is an API endpoint which exists for updating metadata for a secret (i.e., labels) but there is not yet a method on the Go client in the `github.com/docker/docker/client` package.\r\n\r\nNote: this issue is **not** requesting that we add a CLI command for updating a secret."},{"labels":["api",null],"text":"Please see https://github.com/docker/docker/pull/28299#discussion_r88733899.\r\n\r\nThe new `hosts` field just uses the format from `/etc/hosts`, since this is cross-platform capable.\r\n\r\n@thaJeztah @cpuguy83 "},{"labels":["api",null,null,null,null],"text":"I think there's a 1.13.0-rc1 (client) / 1.12.3 (server) incompatibility.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n1. `docker deploy --bundle-file .\\iv.dab iv`\r\n\r\n**Describe the results you received:**\r\n\r\nLoading bundle from .\\iv.dab\r\nCreating network iv_back-tier\r\nError response from daemon: rpc error: code = 3 desc = driver name: if driver is specified name is required\r\n\r\n**Describe the results you expected:**\r\n\r\nDAB file deployed\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nThis works with 1.12.3 client\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0-rc1\r\n API version:  1.24 (downgraded from 1.25)\r\n Go version:   go1.7.3\r\n Git commit:   75fd88b\r\n Built:        Fri Nov 11 22:32:34 2016\r\n OS/Arch:      windows/amd64\r\n\r\nServer:\r\n Version:             1.12.3\r\n API version:         1.24\r\n Minimum API version:\r\n Go version:          go1.6.3\r\n Git commit:          6b644ec\r\n Built:               Thu Oct 27 00:09:21 2016\r\n OS/Arch:             linux/amd64\r\n Experimental:        true\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nRunning Windows client and Docker for AWS.\r\n\r\nDAB file below:\r\n\r\n```\r\n{\r\n  \"services\": {\r\n    \"db\": {\r\n      \"Image\": \"postgres@sha256:f76245b04ddbcebab5bb6c28e76947f49222c99fec4aadb0bb1c24821a9e83ef\", \r\n      \"Networks\": [\r\n        \"back-tier\"\r\n      ]\r\n    }, \r\n    \"redis\": {\r\n      \"Image\": \"redis@sha256:2e75b1750a11e1bb060b3af6a80f8f5c536a2b16bc85c02e006ffc2f93ec8ba6\", \r\n      \"Networks\": [\r\n        \"back-tier\"\r\n      ], \r\n      \"Ports\": [\r\n        {\r\n          \"Port\": 6379, \r\n          \"Protocol\": \"tcp\"\r\n        }\r\n      ]\r\n    }, \r\n    \"result\": {\r\n      \"Image\": \"docker4x/demo-result@sha256:9932a45ccc04447430659acb88243ddf3ff207efc8cd28f6cda03da0c9d4a426\", \r\n      \"Networks\": [\r\n        \"front-tier\", \r\n        \"back-tier\"\r\n      ], \r\n      \"Ports\": [\r\n        {\r\n          \"Port\": 80, \r\n          \"Protocol\": \"tcp\"\r\n        }\r\n      ]\r\n    }, \r\n    \"vote\": {\r\n      \"Image\": \"docker4x/demo-vote@sha256:c961faf9a715176f09fe10104fd763b96cf8341d274031cf477b0dfd1fe2af32\", \r\n      \"Networks\": [\r\n        \"front-tier\", \r\n        \"back-tier\"\r\n      ], \r\n      \"Ports\": [\r\n        {\r\n          \"Port\": 80, \r\n          \"Protocol\": \"tcp\"\r\n        }\r\n      ]\r\n    }, \r\n    \"worker\": {\r\n      \"Image\": \"docker4x/demo-worker@sha256:df16d85fba95eef19d2d53f1ee5367c22aa4956fab0977ed9a187d69ec15dab0\", \r\n      \"Networks\": [\r\n        \"back-tier\"\r\n      ]\r\n    }\r\n  }, \r\n  \"version\": \"0.1\"\r\n}\r\n```\r\n\r\ncc @vieux @mavenugo "},{"labels":["api",null,null],"text":"# Problem statement\r\n\r\nDocker 1.12.0 and 1.13.0 introduce new syntaxes for:\r\n\r\n- Mount specifications (`docker run --mount` and `docker service create --mount`)\r\n- Port specifications (`docker service create --port`)\r\n- Secret specifications (`docker service create --secret`)\r\n\r\nThis raises several questions regarding consistency:\r\n\r\n1. What are the guidelines in terms of short syntax (\"porcelain\") versus long syntax (\"plumbing\")?\r\n2. How many flags should be exposed: one for porcelain and one for plumbing, or a single one with two possible syntaxes?\r\n3. Where those flags overlap, do they use the same naming scheme for long syntax option names?\r\n\r\n## Current state\r\n\r\n<table>\r\n  <tbody>\r\n    <tr>\r\n      <th colspan=\"2\">Area</th>\r\n      <th>Mounts</th>\r\n      <th>Ports</th>\r\n      <th>Secrets</th>\r\n    </tr>\r\n    <tr>\r\n      <th align=\"left\" rowspan=\"2\">Syntax</th>\r\n      <th align=\"left\">Short</th>\r\n      <td><a href=\"https://docs.docker.com/engine/reference/run/#/volume-shared-filesystems\"><code>/src:/dest:rw</code></a></td>\r\n      </td>\r\n      <td><a href=\"https://github.com/docker/docker/pull/27917#issuecomment-258556920\"><code>80:8080/tcp</code></a></td>\r\n      <td><code>secret_name</code></td>\r\n    </tr>\r\n<tr>\r\n      <th align=\"left\">Long</th>\r\n      <td><a href=\"https://docs.docker.com/engine/reference/run/#/volume-shared-filesystems\"><code>src=/src,dst=/dest,readonly=true</code></a></td>\r\n      <td><code>target=80,published=8080,protocol=tcp</code></td>\r\n      <td><code>source=secret_name,target=alias</code></td>\r\n</tr>\r\n    <tr>\r\n      <th align=\"left\" rowspan=\"2\">Flags</th>\r\n      <th align=\"left\">Short</th>\r\n      <td><code>-v, --volume</code></td>\r\n      <td><code>-p, --publish</code></td>\r\n      <td><code>--secret</code></td>\r\n    </tr>\r\n<tr>\r\n      <th align=\"left\">Long</th>\r\n      <td><code>--mount</code></td>\r\n      <td><code>--port</code></td>\r\n      <td><code>--secret</code></td>\r\n</tr>\r\n    <tr>\r\n      <th align=\"left\" colspan=\"2\">Named options</th>\r\n      <td>\r\n<ul>\r\n<li>type</li>\r\n<li>src, source</li>\r\n<li>dst, destination, target</li>\r\n<li>readonly, ro</li>\r\n<li>bind-propagation</li>\r\n<li>volume-driver</li>\r\n<li>volume-label</li>\r\n<li>volume-nocopy</li>\r\n<li>volume-opt</li>\r\n</ul>\r\n</td>\r\n<td>\r\n<ul>\r\n<li>target</li>\r\n<li>published</li>\r\n<li>protocol</li>\r\n<li>mode</li>\r\n</ul>\r\n</td>\r\n<td>\r\n\r\n<ul>\r\n<li>source</li>\r\n<li>target</li>\r\n<li>uid</li>\r\n<li>gid</li>\r\n<li>mode</li>\r\n</ul>\r\n</td>\r\n    </tr>\r\n</tbody>\r\n</table>\r\n\r\nWhat we can see from the table above is that:\r\n\r\n- Some areas have a same flag support the short and long syntax.\r\n- Some areas have overlapping named options, but not necessarily the same short versions.\r\n- Some areas have overlapping named options, but not necessarily the same semantic (*to be verified*).\r\n\r\n# Proposal\r\n\r\n*The proposal is to ~burn it all~ homogenize according to well defined guidelines that we can reuse in the future for every feature with the same requirement. What follows is an attempt at defining such guidelines.*\r\n\r\nAll features which require both a rich way to express complex things in a non-ambiguous manner, while preserving a nice \"porcelain\" syntax for the 80% use case should:\r\n\r\n1. Use the same flag for both the short and long syntax.\r\n2. The long syntax should be a **comma separated** list of **`arg=value`** specifications (e.g., `arg1=val1,arg2=val2`).\r\n3. The short syntax should be a separated list of values (**NOTE:** separator TBD, although `--publish` and `--volume` use `:` today), which defines positional arguments that map directly to an expanded long term equivalent. For example, given the order `arg1`, `arg2`, `arg3`, the short syntax `val1:val2` is equivalent to the long form `arg1=val1,arg2=val2`. This is inspired by the way Python function invocation syntax deals with optional and keyword-only arguments.\r\n4. Wherever possible, consistency of named arguments in the long form across different features should be enforced, including in any short term aliases that those named arguments can take.\r\n\r\n# What it means for 1.13.0\r\n\r\nIf we agree to move forward with this, then we need to review the current set of flags and act accordingly:\r\n\r\n- [x] The newly introduced `--port` flag should likely disappear in favor of `--publish`, ensuring that the short form maps cleanly to the long form. #28943\r\n- [x] We know that the `-v` syntax is likely already too overloaded to map cleanly to the long-syntax equivalent introduced by mount, and we might need to drop support for `--mount` in `run` until we can figure this out.\r\n- [ ] We need to reconcile named arguments in secrets with those in mounts (especially with regard to the aliases that `source` supports in mounts).\r\n\r\n# References\r\n\r\n- #26825 - Add `--mount` flag to `docker create` and `docker run`\r\n- #27794 - Add secret management\r\n- #27917 - Add support for host port `PublishMode` in services using the `--port` option in docker service create\r\n\r\nPing @joaofnfernandes @aluzzardi @thaJeztah @mstanleyjones @vieux @dhiltgen @ehazlett @dnephin :cactus:"},{"labels":["api"],"text":"This is a tracking issue so that we don't release 1.13 before the remaining review comments on the secrets feature are addressed; https://github.com/docker/docker/pull/27794#issuecomment-261100495\r\n\r\n/cc @ehazlett @stevvooe "},{"labels":["api",null,null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nThe output from docker info includes a section *Plugins*, within which there is *Network*. Typically this shows four items: *bridge null host overlay* (in no particular order); but on my docker installations it only shows three: *bridge null host* .\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\nPlugins:\r\n Volume: local\r\n Network: bridge null host\r\n```\r\n\r\n**Describe the results you expected:**\r\n```\r\nPlugins:\r\n Volume: local\r\n Network: bridge null host overlay\r\n```\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n```\r\nClient:\r\n Version:         1.10.3\r\n API version:     1.22\r\n Package version: docker-common-1.10.3-46.el7.centos.10.x86_64\r\n Go version:      go1.6.3\r\n Git commit:      d381c64-unsupported\r\n Built:           Thu Aug  4 13:21:17 2016\r\n OS/Arch:         linux/amd64\r\n\r\nServer:\r\n Version:         1.10.3\r\n API version:     1.22\r\n Package version: docker-common-1.10.3-46.el7.centos.10.x86_64\r\n Go version:      go1.6.3\r\n Git commit:      d381c64-unsupported\r\n Built:           Thu Aug  4 13:21:17 2016\r\n OS/Arch:         linux/amd64\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 3\r\n Running: 3\r\n Paused: 0\r\n Stopped: 0\r\nImages: 3\r\nServer Version: 1.10.3\r\nStorage Driver: devicemapper\r\n Pool Name: docker-253:2-395657-pool\r\n Pool Blocksize: 65.54 kB\r\n Base Device Size: 10.74 GB\r\n Backing Filesystem: xfs\r\n Data file: /dev/loop0\r\n Metadata file: /dev/loop1\r\n Data Space Used: 644.3 MB\r\n Data Space Total: 107.4 GB\r\n Data Space Available: 7.127 GB\r\n Metadata Space Used: 1.552 MB\r\n Metadata Space Total: 2.147 GB\r\n Metadata Space Available: 2.146 GB\r\n Udev Sync Supported: true\r\n Deferred Removal Enabled: false\r\n Deferred Deletion Enabled: false\r\n Deferred Deleted Device Count: 0\r\n Data loop file: /var/lib/docker/devicemapper/devicemapper/data\r\n WARNING: Usage of loopback devices is strongly discouraged for production use. Either use `--storage-opt dm.thinpooldev` or use `--storage-opt dm.no_warn_on_loop_devices=true` to suppress this warning.\r\n Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\r\n Library Version: 1.02.107-RHEL7 (2016-06-09)\r\nExecution Driver: native-0.2\r\nLogging Driver: json-file\r\nPlugins:\r\n Volume: local\r\n Network: bridge null host\r\nKernel Version: 3.10.0-327.28.3.el7.x86_64\r\nOperating System: CentOS Linux 7 (Core)\r\nOSType: linux\r\nArchitecture: x86_64\r\nNumber of Docker Hooks: 2\r\nCPUs: 2\r\nTotal Memory: 31.26 GiB\r\nName: webdmz8-10-250-130-124\r\nID: 2FHN:3AEV:SPGX:QHHJ:34HL:A3MW:LGR5:MCPB:D7HQ:6CPQ:A4WV:WLVX\r\nWARNING: bridge-nf-call-iptables is disabled\r\nWARNING: bridge-nf-call-ip6tables is disabled\r\nRegistries: docker.io (secure)\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nA set of virtual machines each running CentOS 7.0; the same problem is observed on all seven.\r\n\r\nNote: I understand that the [overlay driver should now be supported on kernel 3.10](https://github.com/docker/docker/releases/tag/v1.10.0) however there might be some remaining incompatibility problem?\r\n\r\n"},{"labels":["api",null,null],"text":"**Description**\r\n\r\n`docker info` yields the following error message, and doesn't display the info:\r\n```\r\nError reading remote info: json: cannot unmarshal object into Go value of type string\r\n```\r\n\r\nAlso, pulling an image yields the following warning (but the pull proceeds anyway):\r\n```\r\nWarning: failed to get default registry endpoint from daemon (Error reading remote info: json: cannot unmarshal object into Go value of type string). Using system default: https://index.docker.io/v1/\r\n```\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.12.1\r\n API version:  1.25\r\n Go version:   go1.6.3\r\n Git commit:   23cf638\r\n Built:        Thu Aug 18 05:32:35 2016\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n\r\nServer:\r\n Version:      1.13.0-rc1\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   75fd88b\r\n Built:        Fri Nov 11 19:47:07 2016\r\n OS/Arch:      linux/amd64\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nError reading remote info: json: cannot unmarshal object into Go value of type string\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nFWIW I provisioned the Engine with `docker-machine` 0.9.0-rc1 on AWS."},{"labels":["api",null],"text":"## Reasoning\r\n\r\nAs part of [my work to improve the API documentation](https://github.com/docker/docker.github.io/pull/210) I realised that \"Docker Remote API\" is a bit of a confusing name. The Docker Registry serves the [Docker Registry API](https://docs.docker.com/registry/spec/api/), Docker Cloud serves the [Docker Cloud API](https://docs.docker.com/registry/spec/api/), Docker Hub has (had?) the [Docker Hub API](https://docs.docker.com/v1.7/reference/api/docker-io_api/), Docker Trusted Registry has the [Docker Trusted Registry API](https://docs.docker.com/apidocs/overview/), but Engine is the odd one out.\r\n\r\nAs far as I can see, it's a historical artefact from when \"Docker\" was just the Engine. We've since added other APIs, and the original was never given a distinctive name.\r\n\r\nBesides consistency, here are some reasons for the change:\r\n\r\n1) \"Remote\" is redundant ‚Äì¬†all HTTP APIs are remote. \"Docker API\" would collide with other Docker APIs, hence \"Docker Engine API\".\r\n2) When you want to find the API for the Engine, it's not immediately clear that you should be looking for the \"Remote API\". (And vice versa, \"Remote API\" does not make it immediately obvious that it's the thing the Engine exposes.)\r\n3) The information architecture in the documentation is a bit weird, because \"Remote API\" doesn't comfortably sit under \"Engine\".\r\n\r\n## Implementation\r\n\r\nThe only place we reference it seems to be in the documentation and CLI docs, so looks like we can just do a big ol' search and replace.\r\n\r\nThe only breakage I can think of is if people search for \"Docker Remote API\" on Google and the documentation doesn't turn up. To counteract this, we can leave it as the \"Remote API\" in old versions of the API documentation, and add \"Remote API\" to the keywords of the latest API docs. Or, just a bit of copy like: \"In version X of Docker and below, the Engine API was called the Docker Remote API.\"\r\n\r\n/cc @dnephin @johndmulhausen @icecrime @shykes "},{"labels":["api",null,null],"text":"**Description**\r\n\r\nThe WebSocket container attach endpoint at `/containers/<container ID>/attach/ws` always sends text frames, but the data contained within those frames is just the bytestream from the container's stdout or stderr. This means that the text frames may not contain valid UTF-8 data, but the WebSocket spec requires that text frames only contain valid UTF-8:\r\n\r\nhttps://tools.ietf.org/html/rfc6455#section-8.1\r\n\r\nWeb browsers such as Chrome, for instance, will automatically close a WebSocket connection if they get invalid UTF-8 data in a text frame.\r\n\r\n**Steps to reproduce the issue:**\r\nOne can create a container that creates invalid UTF-8 data by simply doing:\r\n\r\n```\r\ndocker run -it busybox sh -c \"while true; do echo -e '\\\\xc3\\\\x28'; done\"\r\n```\r\n\r\n**Describe the results you received:**\r\nGot invalid UTF-8 bytes in a WebSocket text frame.\r\n\r\n**Describe the results you expected:**\r\nThe frames would either be marked as binary frames or their contents would be sanitized somehow.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nServer:\r\n Version:      1.12.2-cs2\r\n API version:  1.24\r\n Go version:   go1.6.3\r\n Git commit:   d5fda6e\r\n Built:        Wed Oct 12 22:55:42 2016\r\n OS/Arch:      linux/amd64\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 73\r\nServer Version: 1.12.2-cs2\r\nStorage Driver: aufs\r\n Root Dir: /mnt/sda1/var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 77\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge null host overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: seccomp\r\nKernel Version: 4.4.24-boot2docker\r\nOperating System: Boot2Docker 1.12.1 (TCL 7.2); master : 4b170dc - Fri Oct  7 22:28:40 UTC 2016\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 1.955 GiB\r\nName: default-cs\r\nID: AMY7:2Q4A:QOPC:LLOK:7C5O:OOTV:Q7OS:5RZN:QBQR:DC3B:DFXB:MPL6\r\nDocker Root Dir: /mnt/sda1/var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 31\r\n Goroutines: 125\r\n System Time: 2016-11-08T19:52:31.989430161Z\r\n EventsListeners: 0\r\nUsername: wsongdocker\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\n provider=virtualbox\r\nInsecure Registries:\r\n 127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null],"text":"#26276 introduced a backwards incompatible api change in the docker info api. If the client reports a lower API version than 1.25, we need to return a response using the old format."},{"labels":["api",null,null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- IRC - irc.freenode.net #docker channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\nThe docker engine server-side API does not respect the Source parameter provided by the API (which specifies a reader that can be used). When specifying a Source with no SourceName (they are described as mutually exclusive in the docs), it tries to process an empty string as a URL and while doing that successfully producing `http://`, yields no error except for in the response body, which makes it really fun to catch. :)\r\n\r\n**Steps to reproduce the issue:**\r\n1. use the docker api for image import with no SourceName and an open io.Reader attached to Source\r\n2. monitor err and response reader, the latter will be readable with json output stating the error. the former will be nil.\r\n3. observe it is trying to pull `http://`\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nI think the relevant code is here: look at this https://github.com/docker/docker/blob/master/api/server/router/image/image_routes.go#L109-L115\r\n\r\nI don't believe the body is considered at all without examining the post parameters first.\r\n\r\nIs this a case of wrong docs?\r\n\r\nhttps://godoc.org/github.com/docker/docker/api/types#ImageImportSource\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.12.3\r\n API version:  1.24\r\n Go version:   go1.6.3\r\n Git commit:   6b644ec\r\n Built:        Wed Oct 26 22:01:48 2016\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.12.3\r\n API version:  1.24\r\n Go version:   go1.6.3\r\n Git commit:   6b644ec\r\n Built:        Wed Oct 26 22:01:48 2016\r\n OS/Arch:      linux/amd64\r\n\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\nnot using the docker client but I'm using the 1.12.3 tag and also tried docker/engine-api before finding out it was deprecated.\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nbuilding with go 1.7.3, but i really doubt that matters"},{"labels":["api"],"text":"Related: https://github.com/docker/engine-api/issues/77, #5893, #22931\r\n\r\nWe now have a [swagger spec](https://github.com/docker/docker/blob/master/api/swagger.yaml) which we use to generate a few types. This issue is to document and track the rest of the required work.\r\n\r\n## Project\r\n\r\n* [x] (#28215) add a validate script to check that running the generation does not result in file changes (same idea as `validate-vendor`)\r\n* [x] (#28038) add validation for the swagger.yaml file (see https://github.com/bfirsh/docker-api-reference/blob/master/dobi.yaml) https://github.com/docker/docker/pull/28038\r\n* [x] (#28506) replace [api reference docs](https://docker.github.io/engine/reference/api/docker_remote_api/) with [generated docs](https://bfirsh.github.io/docker-api-reference/). See https://github.com/bfirsh/docker-api-reference for a working prototype and https://github.com/docker/docker.github.io/pull/210 for a WIP PR\r\n* [ ] document how contributors can work with the swagger spec and add new types.\r\n\r\n## Milestone 1 - Types\r\n \r\nGenerate `api/types` from the spec:\r\n\r\n**api/types/types.go**\r\n* [x] ContainerChange\r\n* [x] ImageHistory\r\n* [x] ImageDelete\r\n* [x] GraphDriverData\r\n* [ ] RootFS\r\n* [ ] ImageInspect\r\n* [ ] Container\r\n* [x] CopyConfig\r\n* [ ] ContainerPathStat\r\n* [ ] ContainerStats\r\n* [ ] ContainerProcessList\r\n* [x] Version\r\n* [ ] Info\r\n* [ ] PluginsInfo\r\n* [ ] ExecStartCheck\r\n* [ ] HealthcheckResult\r\n* [ ] Health\r\n* [ ] ContainerState\r\n* [ ] ContainerNode\r\n* [ ] ContainerJSONBase\r\n* [ ] ContainerJSON\r\n* [ ] NetworkSettings\r\n* [ ] SummaryNetworkSettings\r\n* [ ] NetworkSettingsBase\r\n* [ ] DefaultNetworkSettings\r\n* [ ] MountPoint\r\n* [ ] NetworkResource\r\n* [ ] EndpointResource\r\n* [ ] NetworkCreate\r\n* [ ] NetworkCreateRequest\r\n* [ ] NetworkCreateResponse\r\n* [ ] NetworkConnect\r\n* [ ] NetworkDisconnect\r\n* [ ] Checkpoint\r\n* [ ] Runtime\r\n* [ ] DiskUsage\r\n* [ ] ImagesPruneConfig\r\n* [ ] ContainersPruneConfig\r\n* [ ] VolumesPruneConfig\r\n* [ ] NetworksPruneConfig\r\n* [ ] ContainersPruneReport\r\n* [ ] VolumesPruneReport\r\n* [ ] ImagesPruneReport\r\n* [ ] NetworksPruneReport\r\n\r\n**api/types/swarm/**:\r\n* [ ] Version\r\n* [ ] Meta\r\n* [ ] Annotations\r\n* [ ] ContainerSpec\r\n* [ ] Endpoint\r\n* [ ] EndpointSpec\r\n* [ ] ResolutionMode\r\n* [ ] PortConfig\r\n* [ ] PortConfigProtocol\r\n* [ ] EndpointVirtualIP\r\n* [ ] Network\r\n* [ ] NetworkSpec\r\n* [ ] NetworkAttachmentConfig\r\n* [ ] NetworkAttachment\r\n* [ ] IPAMOptions\r\n* [ ] IPAMConfig\r\n* [ ] Driver\r\n* [ ] Node\r\n* [ ] NodeSpec\r\n* [ ] NodeRole\r\n* [ ] NodeAvailability\r\n* [ ] NodeDescription\r\n* [ ] Platform\r\n* [ ] EngineDescription\r\n* [ ] PluginDescription\r\n* [ ] NodeStatus\r\n* [ ] Reachability\r\n* [ ] ManagerStatus\r\n* [ ] NodeState\r\n* [ ] Service\r\n* [ ] ServiceSpec\r\n* [ ] ServiceMode\r\n* [ ] UpdateState\r\n* [ ] UpdateStatus\r\n* [ ] ReplicatedService\r\n* [ ] GlobalService\r\n* [ ] UpdateConfig\r\n* [ ] ClusterInfo\r\n* [ ] Swarm\r\n* [ ] JoinTokens\r\n* [ ] Spec\r\n* [ ] OrchestrationConfig\r\n* [ ] TaskDefaults\r\n* [ ] RaftConfig\r\n* [ ] DispatcherConfig\r\n* [ ] CAConfig\r\n* [ ] ExternalCAProtocol\r\n* [ ] ExternalCAProtocol\r\n* [ ] ExternalCA\r\n* [ ] InitRequest\r\n* [ ] JoinRequest\r\n* [ ] LocalNodeState\r\n* [ ] Info\r\n* [ ] Peer\r\n* [ ] UpdateFlags\r\n* [ ] TaskState\r\n* [ ] Task\r\n* [ ] TaskSpec\r\n* [ ] Resources\r\n* [ ] ResourceRequirements\r\n* [ ] Placement\r\n* [ ] RestartPolicy\r\n* [ ] RestartPolicyCondition\r\n* [ ] TaskStatus\r\n* [ ] ContainerStatus\r\n\r\n\r\n## Milestone 2 - Client\r\n\r\nGenerate (most of) `client/` from the spec. \r\n\r\nThis milestone can be done in parallel with Milestone 3, but requires a prototype before work can be enumerated.\r\n\r\n## Milestone 3 - Server (router)\r\n\r\nGenerate (most of) `api/server/router/` from the spec. \r\n\r\nThis milestone can be done in parallel with Milestone 2, but requires a prototype before work can be enumerated.\r\n\r\n"},{"labels":["api",null,null,null],"text":"**Description**\n\nThe Docker Remote API response to `GET /containers/(id or name)/json` changed in version 1.20 and 1.21 from prior versions, changing the location of some fields.  Docker attempts to maintain compatibility by dispatching to [a versioned function](https://github.com/docker/docker/blob/v1.12.2/daemon/inspect.go#L16-L27), which functions properly [on Linux](https://github.com/docker/docker/blob/v1.12.2/daemon/inspect_unix.go#L23) (with logic to provide the expected values of old fields).  However, on Windows, that function [just calls the current version](https://github.com/docker/docker/blob/v1.12.2/daemon/inspect_windows.go#L29-L32) instead of the requested compatibility version.\n\n**Steps to reproduce the issue:**\n1. Call the inspect API with the current API version on Linux\n2. Call the inspect API with an old (pre-1.20) version on Linux\n3. Call the inspect API with the current API version on Windows\n4. Call the inspect API with an old (pre-1.20) version on Windows\n5. Observe that a Linux daemon returns an appropriate response for the requested version while a Windows daemon returns the current API version response regardless of requested version\n\n**Describe the results you received:**\n\nA Windows daemon ignores the requested API version and just returns a response appropriate for the current version of the API.\n\n**Describe the results you expected:**\n\nExpected the Windows daemon to either return an appropriate response for the requested API version or to reject the request for an unsupported API version.\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.2-cs2-ws-beta\n API version:  1.25\n Go version:   go1.7.1\n Git commit:   050b611\n Built:        Tue Oct 11 02:35:40 2016\n OS/Arch:      windows/amd64\n\nServer:\n Version:      1.12.2-cs2-ws-beta\n API version:  1.25\n Go version:   go1.7.1\n Git commit:   050b611\n Built:        Tue Oct 11 02:35:40 2016\n OS/Arch:      windows/amd64\n```\n\n**Output of `docker info`:**\n\n```\nPS C:\\Users\\Administrator> docker info\nContainers: 0\n Running: 0\n Paused: 0\n Stopped: 0\nImages: 0\nServer Version: 1.12.2-cs2-ws-beta\nStorage Driver: windowsfilter\n Windows:\nLogging Driver: json-file\nPlugins:\n Volume: local\n Network: nat null overlay\nSwarm: inactive\nDefault Isolation: process\nKernel Version: 10.0 14393 (14393.321.amd64fre.rs1_release_inmarket.161004-2338)\nOperating System: Windows Server 2016 Datacenter\nOSType: windows\nArchitecture: x86_64\nCPUs: 8\nTotal Memory: 32 GiB\nName: EC2AMAZ-T211LER\nID: 6JSQ:WIFX:QJ25:TM5T:JBOG:CR7M:NSOW:X2AJ:QJXR:PRID:CLE2:6Q67\nDocker Root Dir: C:\\ProgramData\\docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nInsecure Registries:\n 127.0.0.0/8\nLive Restore Enabled: false\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):** On EC2, using Microsoft Windows Server 2016 Base with Containers - ami-5e6bce3e\n"},{"labels":["api",null,null],"text":"Networks don't support updates. While this makes sense for the most part (it's impossible to change a driver midway), there are some fields which would be harmless to update such as labels.\n\nThere's also some other fields which could be considered such as `attachable`.\n\n/cc @diogomonica @mrjana @mavenugo \n"},{"labels":["api",null],"text":"**Description**\nThe below is the response body for a `POST (uri)/containers/create?name=(name)` and it is malformed JSON but valid JS. This is an issue because `JSON.parse` cannot handle the response. Instead we have to resort to using `eval()` on the response.\n\nActual repsonse:\n\n``` json\n{ Id: '604e48f4b7a650340b43c0bbb139d334edf63fe3476f2e503877b3e2c8cc1a2a',\n  Warnings: null }\n```\n\nShould be:\n\n``` json\n{ \"Id\": \"604e48f4b7a650340b43c0bbb139d334edf63fe3476f2e503877b3e2c8cc1a2a\",\n  \"Warnings\": null }\n```\n\n**Steps to reproduce the issue:**\n1. Make any valid `/containers/create` request to a engine remote\n2. Run JSON.parse on the response's body\n3. Handle error `SyntaxError: Unexpected token o in JSON at position 1`\n\n**Describe the results you received:**\nI received invalid JSON on a http response that should yield valid JSON for the content-type \"application/json\"\n\n**Describe the results you expected:**\nValid json that meets RFC7159 specification  https://tools.ietf.org/html/rfc7159 \nSpecifically the part that says **\"A string begins and ends with quotation marks.\"**\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\n\n**Output of `docker version`:**\n\n```\nDocker version 1.12.1, build 23cf638\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 8\n Running: 0\n Paused: 0\n Stopped: 8\nImages: 10\nServer Version: 1.12.1\nStorage Driver: devicemapper\n Pool Name: docker-253:0-202281288-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 10.74 GB\n Backing Filesystem: xfs\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 932.2 MB\n Data Space Total: 107.4 GB\n Data Space Available: 33.4 GB\n Metadata Space Used: 2.22 MB\n Metadata Space Total: 2.147 GB\n Metadata Space Available: 2.145 GB\n Thin Pool Minimum Free Space: 10.74 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\n Data loop file: /var/lib/docker/devicemapper/devicemapper/data\n Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\n Library Version: 1.02.107-RHEL7 (2016-06-09)\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: bridge null host overlay\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 3.10.0-327.36.1.el7.x86_64\nOperating System: CentOS Linux 7 (Core)\nOSType: linux\nArchitecture: x86_64\nCPUs: 2\nTotal Memory: 3.703 GiB\nName: vm\nID: RPLT:DWEL:LJBT:54Z6:H2KO:44F5:2NQB:BL6K:L7IT:UCMJ:OYQH:UT6Z\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): true\n File Descriptors: 17\n Goroutines: 26\n System Time: 2016-10-16T09:59:17.159342406-04:00\n EventsListeners: 0\nRegistry: https://index.docker.io/v1/\nInsecure Registries:\n 127.0.0.0/8\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\nI'm running Centos 7 in VirtualBox Version 5.1.6 r110634 (Qt5.5.1)\nI can replicate this on my DigitalOcean VPS running Centos7 as well.\nI encountered this while writing a NodeJS library https://github.com/matutter/docker-as-promised/tree/dev  \n"},{"labels":["api",null],"text":"Hi,\nDoes anyone knows how to specify the network parameter (name and driver) while creating a docker service via Docker Remote API ?\nI'm doing it like this:\nPOST: http://vm-test1.sandbox.lan:2375/services/create\nBody:\n\n> {\n>     \"Name\": \"test-service\",\n>     \"TaskTemplate\": {\n>         \"ContainerSpec\": {\n>             \"Image\": \"vm-test1.sandbox.lan:5000/test-image\"\n>         },\n>         \"LogDriver\": {\n>             \"Name\": \"syslog\",\n>             \"Options\": {\n>                 \"tag\": \"test-service\"\n>             }\n>         },\n>         \"EndpointSpec\": {\n>             \"Ports\": [{\n>                 \"Protocol\": \"tcp\",\n>                 \"PublishedPort\": 10080,\n>                 \"TargetPort\": 8080\n>             }]\n>         }\n>     },\n>     \"Networks\": [{\n>         \"Name\": \"test_network\",\n>         \"Driver\": \"overlay\"\n>     }]\n> }\n\nHowever, I get a 403 Forbidden message:\n`{\"message\":\"network bridge is not eligible for docker services\"}`\n\n> docker network ls\n> NETWORK ID          NAME                DRIVER              SCOPE\n> c97a6c216498        bridge              bridge              local  \n> ew1wt4xa5olk        test_network        overlay             swarm  \n> 6ae7e1d9fe4b        docker_gwbridge     bridge              local       \n\nI believe that something is wrong inside my JSON request,  at \"Networks\" field.\n\nDocker Remote API v1.24\n\n> Create a service\n> POST /services/create\n> ...\n> Networks ‚Äì Array of network names or IDs to attach the service to.\n"},{"labels":["api",null,null,null,null],"text":"<!--\nIf you are reporting a new issue, make sure that we do not have any duplicates\nalready open. You can ensure this by searching the issue list for this\nrepository. If there is a duplicate, please close your issue and add a comment\nto the existing issue instead.\n\nIf you suspect your issue is a bug, please edit your issue description to\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\ninformation within 7 days, we cannot debug your issue and will close it. We\nwill, however, reopen it if you later provide the information.\n\nFor more information about reporting issues, see\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\n\n---------------------------------------------------\nBUG REPORT INFORMATION\n---------------------------------------------------\nUse the commands below to provide key information from your environment:\nYou do NOT have to include this information if this is a FEATURE REQUEST\n-->\n\n**Description**\nWhen I ran the \"info\" path in the Remote API v1.24 I got a lot more fields then the documentation said, these are:\n\nPlugins > Authorization\nCPUShares\nCPUSet\nBridgeNfIptables\nBridgeNfIp6tables\nExecutionDriver\nLoggingDriver\nRegistryConfig > Mirrors??? (the IndexConfigs have array of Mirrors but the RegistryConfig itself has also Mirrors, maybe a bug?)\nClusterAdvertise\nRuntimes\nDefaultRuntime\nSwarm (has lots of things in it)\nLiveRestoreEnabled\n\nI attach the raw response json I got:\n[info.txt](https://github.com/docker/docker/files/512218/info.txt)\n\n**Steps to reproduce the issue:**\n1. run \"/info\" on the remote api v1.24\n2. check the response JSON and compare to docs\n3.\n\n**Describe the results you received:**\nLots of more fields then documentation has\n\n**Describe the results you expected:**\nDocumentation of all fields\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.1\n API version:  1.24\n Go version:   go1.7\n Git commit:   23cf638\n Built:        Fri Aug 19 02:03:02 2016\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.12.1\n API version:  1.24\n Go version:   go1.7\n Git commit:   23cf638\n Built:        Fri Aug 19 02:03:02 2016\n OS/Arch:      linux/amd64\n\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 1\n Running: 0\n Paused: 0\n Stopped: 1\nImages: 6\nServer Version: 1.12.1\nStorage Driver: devicemapper\n Pool Name: docker-253:1-10223820-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 10.74 GB\n Backing Filesystem: xfs\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 664.9 MB\n Data Space Total: 107.4 GB\n Data Space Available: 106.7 GB\n Metadata Space Used: 1.389 MB\n Metadata Space Total: 2.147 GB\n Metadata Space Available: 2.146 GB\n Thin Pool Minimum Free Space: 10.74 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\n Data loop file: /var/lib/docker/devicemapper/devicemapper/data\n WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.\n Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\n Library Version: 1.02.135 (2016-09-26)\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: overlay null host bridge\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 4.7.5-1-ARCH\nOperating System: Arch Linux\nOSType: linux\nArchitecture: x86_64\nCPUs: 8\nTotal Memory: 23.49 GiB\nName: karl_rog\nID: IOCD:Y7FK:RDB6:43I7:QLCF:OBP5:LKJR:QLYD:NC6U:V7GA:ROQA:TCVE\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nInsecure Registries:\n codeslasher.se:5000\n 127.0.0.0/8\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\n"},{"labels":["api",null,null],"text":"Hello, Docker Team.\n\nDocker inspect incorrectly shows environment variable with ampersand (&).\n\n**Steps to reproduce the issue:**\n1. docker run -ti --env TEST_ENV=\"soanni&rtr\" alpine:latest sh\n2. docker inspect <container_id>\n3. Screenshot is attached\n\n**Output of `docker version`:**\n\nClient:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:\n OS/Arch:      linux/amd64\n\n**Output of `docker info`:**\n\nContainers: 1\n Running: 1\n Paused: 0\n Stopped: 0\nImages: 51\nServer Version: 1.12.0\nStorage Driver: devicemapper\n Pool Name: docker-202:2-8828904-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 10.74 GB\n Backing Filesystem: xfs\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 5.301 GB\n Data Space Total: 107.4 GB\n Data Space Available: 1.405 GB\n Metadata Space Used: 9.22 MB\n Metadata Space Total: 2.147 GB\n Metadata Space Available: 1.405 GB\n Thin Pool Minimum Free Space: 10.74 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\n Data loop file: /var/lib/docker/devicemapper/devicemapper/data\n WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.\n Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\n Library Version: 1.02.107-RHEL7 (2015-10-14)\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: bridge null host overlay\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 3.10.0-327.el7.x86_64\nOperating System: Red Hat Enterprise Linux Server 7.2 (Maipo)\nOSType: linux\nArchitecture: x86_64\nCPUs: 1\nTotal Memory: 991.7 MiB\nName: ip-172-31-25-213.us-west-2.compute.internal\nID: RZKH:EXW3:V7DY:HOFH:Y7BK:YMSK:OEML:AD3H:FZDO:WC2F:7GPC:BMCE\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nInsecure Registries:\n 127.0.0.0/8\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\nAWS AMI Linux\n\n![image](https://cloud.githubusercontent.com/assets/5715840/18952955/2c1ab79a-865d-11e6-9fa2-e2fbab8878a4.png)\n"},{"labels":["api",null,null,null],"text":"First time daemon is booted (no `docker0` bridge present, no or empty `/var/lib/docker/network/files/local-kv.db` file), IPAM.Config structure in network inspect output will not contain the Gateway field\n\n```\n$ docker network inspect bridge\n[\n    {\n        \"Name\": \"bridge\",\n        \"Id\": \"2b5cc5f97b6de6a5e0533b1e2d5bec6284d900a9a82632ce782320a19db8b9e0\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": null,\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.17.0.0/16\"\n                }\n            ]\n        },\n\n```\n\nVerified problem exists in `1.11.2`, `1.12.0` and in current master (`1.13.0`).\n\nGiven the `IPAM.Config` filed currently used to carry both configuration and operational data, the gateway address should always be there.\n\n**Note:**\nA daemon reload will fix the issue\n"},{"labels":["api",null,null],"text":"The following change that was merged yesterday broke some of our tests:\n\nhttps://github.com/docker/docker/commit/53774423ff0db50cb0934e7b1e5ce507363e8147#diff-5251fbdfab3c1500c0c76ec0d8adf746R78\n\nIt's a backwards incompatible API change and prevents older docker clients from running containers on newer daemons. I think it should be reverted unless a compatibility layer is added for older engines.\n"},{"labels":["api",null],"text":"**Description**\nThanks for the work on this project. \n\nAttempting to pull an image (by sending a request to the remote API) fails depending on the whitespace present in the unencoded auth config. Here are examples:\n\n``` shell\n# WORKS\nAUTH=`echo -n \"{ \\\"username\\\": \\\"$DOCKER_USERNAME\\\",\n     \\\"password\\\": \\\"$DOCKER_PASSWORD\\\",\n     \\\"serveraddress\\\": \\\"$DOCKER_REGISTRY\\\"\n}\" | perl -pe 's/\\r\\n|\\n|\\r/\\r\\n/g' | base64`;\ncurl -X POST -H \"X-Registry-Auth: $AUTH\" -H \"Cache-Control: no-cache\" \\\nhttps://$DOCKER_HOST_IP:2376/images/create\\?fromImage\\=$DOCKER_REGISTRY%2Fcassandra\\&tag\\=latest \\\n--cert $DOCKER_CERT_PATH/cert.p12 --pass mypass --key $DOCKER_CERT_PATH/key.pem --cacert $DOCKER_CERT_PATH/ca.pem\n\n# {\"status\":\"Pulling from cassandra\",\"id\":\"latest\"}\n# . . . \n```\n\n``` shell\n# FAILS\nAUTH=`echo -n \"{\\\"username\\\": \\\"$DOCKER_USERNAME\\\",\n     \\\"password\\\": \\\"$DOCKER_PASSWORD\\\",\n     \\\"serveraddress\\\": \\\"$DOCKER_REGISTRY\\\"\n}\" | perl -pe 's/\\r\\n|\\n|\\r/\\r\\n/g' | base64`;\ncurl -X POST -H \"X-Registry-Auth: $AUTH\" -H \"Cache-Control: no-cache\" \\\nhttps://$DOCKER_HOST_IP:2376/images/create\\?fromImage\\=$DOCKER_REGISTRY%2Fcassandra\\&tag\\=latest \\\n--cert $DOCKER_CERT_PATH/cert.p12 --pass mypass --key $DOCKER_CERT_PATH/key.pem --cacert $DOCKER_CERT_PATH/ca.pem\n\n# {\"message\":\"Get https://my-registry.com/v2/cassandra/manifests/latest: unauthorized: authentication required\"}\n```\n\nNote:\n- The only difference between the two is the space after the opening `{` of the auth json. No space breaks it.\n- I needed to use DOS line endings to get anything to work at all.\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.1\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   23cf638\n Built:        Thu Aug 18 17:52:38 2016\n OS/Arch:      darwin/amd64\n\nServer:\n Version:      1.12.1\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   23cf638\n Built:        Thu Aug 18 17:52:38 2016\n OS/Arch:      linux/amd64\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 9\n Running: 2\n Paused: 0\n Stopped: 7\nImages: 13\nServer Version: 1.12.1\nStorage Driver: aufs\n Root Dir: /mnt/sda1/var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 180\n Dirperm1 Supported: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: host bridge null overlay\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 4.4.17-boot2docker\nOperating System: Boot2Docker 1.12.1 (TCL 7.2); HEAD : ef7d0b4 - Thu Aug 18 21:18:06 UTC 2016\nOSType: linux\nArchitecture: x86_64\nCPUs: 1\nTotal Memory: 3.858 GiB\nName: default\nID: SLVU:TD74:RZM6:KB5M:7IXK:PEVM:7QWW:NDLB:MYTY:BY6D:BFGM:CKHF\nDocker Root Dir: /mnt/sda1/var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): true\n File Descriptors: 25\n Goroutines: 48\n System Time: 2016-09-15T14:16:52.261023938Z\n EventsListeners: 0\nRegistry: https://index.docker.io/v1/\nLabels:\n provider=virtualbox\nInsecure Registries:\n 127.0.0.0/8\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\nDocker Machine is running in VirtualBox Version 5.1.4 r110228 (Qt5.5.1)\n"},{"labels":["api",null,null],"text":"**Description**\n\nWhen using the remote API to create a service but in the params an invalid network ID is send, the API returns 404. A 404 error signals in REST semantics that an inexistent resource has been tryied to be accessed. However, in this case we are creating a new resource, the fact that the new resource has a property that \"links\" to an invalid resource should not be relevant in this case.\nBesides, the documentation https://docs.docker.com/engine/reference/api/docker_remote_api_v1.24/#/create-a-volume\ndoes not mention that the call can return 404:\n\n**Steps to reproduce the issue:**\nJust use the remote API to create a service with an invalid network ID\n\n**Describe the results you received:**\n404 { message: 'network xxxxxx not found' }\n\n**Describe the results you expected:**\n406 { message: 'network xxxxxx not found' }\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:        Thu Jul 28 23:54:00 2016\n OS/Arch:      darwin/amd64\n\nServer:\n Version:      1.12.1\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   23cf638\n Built:        Thu Aug 18 05:33:38 2016\n OS/Arch:      linux/amd64\n```\n"},{"labels":["api",null,null,null],"text":"**Description**\n\nWhen trying to create a network using the remote API, according to the documentation 1.24 (https://docs.docker.com/engine/reference/api/docker_remote_api_v1.24/#/create-a-network)\nthe IPAM field is an optional parameter, but if not provided, the following error is returned:\n\"rpc error: code = 3 desc = driver name: if driver is specified name is required\" which does not seem correct either.\n\n**Steps to reproduce the issue:**\nJust use the remote API to create a network, using curl or whatever you feel comfortable with.\n**Describe the results you received:**\n\"rpc error: code = 3 desc = driver name: if driver is specified name is required\"\n\n**Describe the results you expected:**\nstatus = 201\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:        Thu Jul 28 23:54:00 2016\n OS/Arch:      darwin/amd64\n\nServer:\n Version:      1.12.1\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   23cf638\n Built:        Thu Aug 18 05:33:38 2016\n OS/Arch:      linux/amd64\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 158\n Running: 8\n Paused: 0\n Stopped: 150\nImages: 258\nServer Version: 1.12.1\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 577\n Dirperm1 Supported: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: bridge overlay host null\nSwarm: active\n NodeID: cbq5d7h0cigpzulcfyqvaomlq\n Is Manager: true\n ClusterID: 070qemaxhu18hg3tvatjlh602\n Managers: 1\n Nodes: 1\n Orchestration:\n  Task History Retention Limit: 5\n Raft:\n  Snapshot interval: 10000\n  Heartbeat tick: 1\n  Election tick: 3\n Dispatcher:\n  Heartbeat period: 5 seconds\n CA configuration:\n  Expiry duration: 3 months\n Node Address: 138.201.132.20\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: apparmor seccomp\nKernel Version: 4.4.0-36-generic\nOperating System: Ubuntu 16.04.1 LTS\nOSType: linux\nArchitecture: x86_64\nCPUs: 8\nTotal Memory: 62.75 GiB\nName: caturra\nID: 46TP:5YN6:AVJS:7CAZ:JZJO:SFJY:H5R7:JVJR:OCQU:NW4Y:5WL7:UDLX\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nUsername: manast\nRegistry: https://index.docker.io/v1/\nWARNING: No swap limit support\nLabels:\n provider=generic\nInsecure Registries:\n 127.0.0.0/8\n```\n"},{"labels":["api",null,null,null],"text":"Somewhat frequently users see this error when trying to `docker rm foo`: `device or resource busy`.\nThis error is returned from the kernel when trying to remove container rw layers and/or the container config root... typically due to mounts leaked into other namespaces.\nWhen this happens the container gets flagged as `Dead` and they can re-try later... or if the user specified `-f` it'll just get removed from the container list by force even if the underlying files are still there... this may leak disk space.\n\nI propose instead of erroring out we add these paths to a deferred deletion queue where we can re-try unmounting and removing them every X amount of time.\n\nPaths in this state should be visible to the data management command proposed here: #26108\nAnd a call to `docker prune` would also cause a forced GC run of these deferred removals out-of-band from the normal run.\n\n`Dead` containers should not be seen by end users... except maybe in the aforementioned data management command.\n\nping @mlaventure \n"},{"labels":["api",null,null,null],"text":"**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.1-rc1\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   7889dc7\n Built:        Fri Aug 12 18:35:53 2016\n OS/Arch:      darwin/amd64\n Experimental: true\n\nServer:\n Version:      1.12.1-rc1\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   7889dc7\n Built:        Fri Aug 12 18:35:53 2016\n OS/Arch:      linux/amd64\n Experimental: true\n```\n\n**Steps to reproduce the issue:**\n\nIn one terminal:\n\n``` bash\ndocker events --filter event=health_status\n```\n\nIn another terminal;\n\n``` bash\ndocker run --name=test -d --health-cmd='stat /etc/passwd || exit 1' --health-interval=2s   busybox sleep 1d\n```\n\n**Describe the results you received:**\n\n``` bash\n$ docker events --filter event=health_status\n<no output>\n\n$ docker events --filter event=exec_create\n<no output>\n\n\n$ docker events --filter event=exec_start\n<no output>\n```\n\n**Describe the results you expected:**\n\n``` bash\n$ docker events --filter event=health_status\n\n2016-08-17T12:10:34.337301145Z container health_status: healthy da1bab7bc91a424cd8e0571808c1b4638a903a8508eb6612e9cdfc49f9dde555 (image=busybox, name=test)\n\n\n$ docker events --filter event=exec_create\n\n2016-08-17T12:10:34.198347963Z container exec_create: /bin/sh -c stat /etc/passwd || exit 1 da1bab7bc91a424cd8e0571808c1b4638a903a8508eb6612e9cdfc49f9dde555 (image=busybox, name=test)\n2016-08-17T12:10:36.338156681Z container exec_create: /bin/sh -c stat /etc/passwd || exit 1 da1bab7bc91a424cd8e0571808c1b4638a903a8508eb6612e9cdfc49f9dde555 (image=busybox, name=test)\n\n\n$ docker events --filter event=exec_start\n\n2016-08-17T12:10:34.198549073Z container exec_start: /bin/sh -c stat /etc/passwd || exit 1 da1bab7bc91a424cd8e0571808c1b4638a903a8508eb6612e9cdfc49f9dde555 (image=busybox, name=test)\n2016-08-17T12:10:36.338214034Z container exec_start: /bin/sh -c stat /etc/passwd || exit 1 da1bab7bc91a424cd8e0571808c1b4638a903a8508eb6612e9cdfc49f9dde555 (image=busybox, name=test)\n```\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\n\nI tried to reproduce on older versions of docker, and this seems to work on Docker 1.8, but fails on Docker 1.9\n\nI debugged this issue, and as far as I can see, the cause of this is that, unlike other events, the `event.Action` for `exec_create`, `exec_start`, and `health_status` contains additional output. This is the content of `event.Action` of events fired by the example container;\n\n```\ncreate\nconnect\nstart\nexec_create: /bin/sh -c stat /etc/passwd || exit 1\nexec_start: /bin/sh -c stat /etc/passwd || exit 1\nhealth_status: healthy\n```\n\nThe filter executes an _exact_ match on `event.Action` (`ef.filter.ExactMatch(\"event\", ev.Action)`), and fails to recognize the events due to this extra output;\n\nSee [daemon/events/filter.go#L21)](https://github.com/docker/docker/blob/297745b1cdfb79a12986465f8150e22b0018c640/daemon/events/filter.go#L21), and [vendor/src/github.com/docker/engine-api/types/filters/parse.go#L209-L219](https://github.com/docker/docker/blob/75109b32db4c23f469b57fb99300fc5d4a689dce/vendor/src/github.com/docker/engine-api/types/filters/parse.go#L209-L219)\n\nPossibly we can change the `ef.filter.ExactMatch()` with `ef.filter.FuzzyMatch()`, however that would result in `--filter event=exec` to match both `exec_start` and `exec_create` (not sure we want that).\n\nIf we want this filter to be an \"exact\" match, we could filter on;\n1. Exact match (for, e.g. `start`)\n2. A _prefix_ match for `exec_start:` (the event name provided, but with a _colon_ (`:`) after\n\nThis would prevent `exec` to match `exec_start`.\n"},{"labels":["api",null,null,null],"text":"When issuing a docker run command with the --volume option, a volume name with a label one character in length will result in a long random string being provided to the driver as the name (like: 051280b61be3b55d1d3a80899475ea7abb657da4cf9bd65a4263a6c4ceacde73).\n\nThis was found utilizing the NetApp volume plugin, but is present without the plugin involved.\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:        Thu Jul 28 22:11:10 2016\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:        Thu Jul 28 22:11:10 2016\n OS/Arch:      linux/amd64\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 4\n Running: 0\n Paused: 0\n Stopped: 4\nImages: 3\nServer Version: 1.12.0\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 21\n Dirperm1 Supported: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local netapp\n Network: host bridge overlay null\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: apparmor seccomp\nKernel Version: 4.4.0-34-generic\nOperating System: Ubuntu 16.04.1 LTS\nOSType: linux\nArchitecture: x86_64\nCPUs: 2\nTotal Memory: 3.859 GiB\nName: openstack2\nID: OMJ2:4XKE:HUKO:C3VM:KHEG:UK2D:BHDG:CEP5:ON5Y:SGWX:2W5V:CFMW\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nWARNING: No swap limit support\nInsecure Registries:\n 127.0.0.0/8\n\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\nVM running under KVM/QEMU\n\n**Steps to reproduce the issue:**\n1. Issue a docker run of the form `docker run --rm -it --volume <name>:/my_vol java bash`, where name is a single character in length.\n\n**Describe the results you received:**\nThe volume driver receives a garbage/generated value rather than the expected name.\n\n**Describe the results you expected:**\nThe name passed in through the Create request should be the same name that the user passed in.\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\nN/A\n"},{"labels":["api",null,null,null,null,null],"text":"<!--\nIf you are reporting a new issue, make sure that we do not have any duplicates\nalready open. You can ensure this by searching the issue list for this\nrepository. If there is a duplicate, please close your issue and add a comment\nto the existing issue instead.\n\nIf you suspect your issue is a bug, please edit your issue description to\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\ninformation within 7 days, we cannot debug your issue and will close it. We\nwill, however, reopen it if you later provide the information.\n\nFor more information about reporting issues, see\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\n\n---------------------------------------------------\nBUG REPORT INFORMATION\n---------------------------------------------------\nUse the commands below to provide key information from your environment:\nYou do NOT have to include this information if this is a FEATURE REQUEST\n-->\n\nI'm opening an issue here as well as on engine-api: https://github.com/docker/engine-api/issues/368\n\nThere seems to be a disagreement between engine-api and docker about whether the IPAM driver name is required in the network create api. engine-api doesn't set it by default and docker requires it by default. This breaks existing applications that use engine-api to create overlay networks.\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:        Thu Jul 28 21:04:48 2016\n OS/Arch:      linux/amd64\n Experimental: true\n\nServer:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:        Thu Jul 28 21:04:48 2016\n OS/Arch:      linux/amd64\n Experimental: true\n\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 153\n Running: 13\n Paused: 0\n Stopped: 140\nImages: 743\nServer Version: 1.12.0\nStorage Driver: overlay2\n Backing Filesystem: extfs\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: overlay host null bridge\nSwarm: active\n NodeID: 0jnlg1wjfbomj3vpagxqcjied\n Is Manager: true\n ClusterID: 7npas0qe6x670sbnzawyulo5y\n Managers: 1\n Nodes: 1\n Orchestration:\n  Task History Retention Limit: 10\n Raft:\n  Snapshot interval: 10000\n  Heartbeat tick: 1\n  Election tick: 3\n Dispatcher:\n  Heartbeat period: 5 seconds\n CA configuration:\n  Expiry duration: 3 months\n Node Address: 172.17.0.1\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 4.6.4-1-ARCH\nOperating System: Arch Linux\nOSType: linux\nArchitecture: x86_64\nCPUs: 4\nTotal Memory: 7.709 GiB\nName: compooter\nID: GKSI:YHZC:YPNI:PAGO:EYPD:AYME:K6BY:BAIH:EBKQ:SOAK:WUFP:6MJM\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): true\n File Descriptors: 1966\n Goroutines: 1943\n System Time: 2016-08-15T15:22:58.960604046-07:00\n EventsListeners: 2\nUsername: viktorstanchev\nRegistry: https://index.docker.io/v1/\nExperimental: true\nInsecure Registries:\n 172.17.0.1\n 192.168.0.106\n dtr2-2061409770.us-west-2.elb.amazonaws.com\n new-1428125395.us-west-2.elb.amazonaws.com\n 127.0.0.0/8\n\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\n\n**Steps to reproduce the issue:**\n1. See https://github.com/docker/engine-api/issues/368\n2.\n3.\n\n**Describe the results you received:**\nerror\n\n**Describe the results you expected:**\nno error\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\n"},{"labels":["api"],"text":"<!--\nIf you are reporting a new issue, make sure that we do not have any duplicates\nalready open. You can ensure this by searching the issue list for this\nrepository. If there is a duplicate, please close your issue and add a comment\nto the existing issue instead.\n\nIf you suspect your issue is a bug, please edit your issue description to\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\ninformation within 7 days, we cannot debug your issue and will close it. We\nwill, however, reopen it if you later provide the information.\n\nFor more information about reporting issues, see\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\n\n---------------------------------------------------\nBUG REPORT INFORMATION\n---------------------------------------------------\nUse the commands below to provide key information from your environment:\nYou do NOT have to include this information if this is a FEATURE REQUEST\n-->\n\n**Output of `docker version`:**\n\n```\nDocker version 1.11.1, build 5604cbe\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 7\n Running: 7\n Paused: 0\n Stopped: 0\nImages: 8\nServer Version: 1.11.1\nStorage Driver: devicemapper\n Pool Name: docker-253:1-33556103-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 10.74 GB\n Backing Filesystem: xfs\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 2.871 GB\n Data Space Total: 171.8 GB\n Data Space Available: 168.9 GB\n Metadata Space Used: 6.959 MB\n Metadata Space Total: 17.05 GB\n Metadata Space Available: 17.04 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\n Data loop file: /var/lib/docker/devicemapper/devicemapper/data\n WARNING: Usage of loopback devices is strongly discouraged for production use. Either use `--storage-opt dm.thinpooldev` or use `--storage-opt dm.no_warn_on_loop_devices=true` to suppress this warning.\n Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\n Library Version: 1.02.107-RHEL7 (2015-12-01)\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: null host bridge\nKernel Version: 3.10.0-123.4.4.el7.x86_64\nOperating System: CentOS Linux 7 (Core)\nOSType: linux\nArchitecture: x86_64\nCPUs: 8\nTotal Memory: 7.64 GiB\nName: ***\nID: ***\nDocker Root Dir: /var/lib/docker\nDebug mode (client): false\nDebug mode (server): false\nRegistry: https://index.docker.io/v1/\nWARNING: bridge-nf-call-iptables is disabled\nWARNING: bridge-nf-call-ip6tables is disabled\nCluster store: ***\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\n\n**Steps to reproduce the issue:**\n1. `docker inspect [container_id]`\n\n**Describe the results you received:**\nOne can't tell if the container inspected is in removal\n\n**Describe the results you expected:**\nI expect there's a `RemovalInProgress` in `State` from the inspect results, to indicate that the container is in removal.\n\n**We'll be happy to create a PR for this**\n"},{"labels":["api",null,null,null,null],"text":"<!--\nIf you are reporting a new issue, make sure that we do not have any duplicates\nalready open. You can ensure this by searching the issue list for this\nrepository. If there is a duplicate, please close your issue and add a comment\nto the existing issue instead.\n\nIf you suspect your issue is a bug, please edit your issue description to\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\ninformation within 7 days, we cannot debug your issue and will close it. We\nwill, however, reopen it if you later provide the information.\n\nFor more information about reporting issues, see\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\n\n---------------------------------------------------\nBUG REPORT INFORMATION\n---------------------------------------------------\nUse the commands below to provide key information from your environment:\nYou do NOT have to include this information if this is a FEATURE REQUEST\n-->\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:        Thu Jul 28 21:04:48 2016\n OS/Arch:      darwin/amd64\n Experimental: true\n\nServer:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:        Thu Jul 28 21:04:48 2016\n OS/Arch:      linux/amd64\n Experimental: true\n```\n\nand\n\n```\nClient:\n Version:      1.11.0\n API version:  1.23\n Go version:   go1.5.4\n Git commit:   4dc5990\n Built:        Wed Apr 13 18:34:23 2016\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.11.0\n API version:  1.23\n Go version:   go1.5.4\n Git commit:   4dc5990\n Built:        Wed Apr 13 18:34:23 2016\n OS/Arch:      linux/amd64\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 99\n Running: 2\n Paused: 0\n Stopped: 97\nImages: 52\nServer Version: 1.12.0\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 250\n Dirperm1 Supported: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: bridge host overlay null\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 4.4.15-moby\nOperating System: Alpine Linux v3.4\nOSType: linux\nArchitecture: x86_64\nCPUs: 2\nTotal Memory: 1.954 GiB\nName: moby\nID: A7F5:MEE2:XJ2N:ZQ6Q:HRKO:SRQJ:CTJF:RR3B:6K7F:SQPP:NBJ7:I7MM\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): true\n File Descriptors: 26\n Goroutines: 41\n System Time: 2016-08-10T18:29:32.322513876Z\n EventsListeners: 1\nNo Proxy: *.local, 169.254/16\nUsername: flavin\nRegistry: https://index.docker.io/v1/\nExperimental: true\nInsecure Registries:\n 127.0.0.0/8\n```\n\nand\n\n```\nContainers: 7\n Running: 0\n Paused: 0\n Stopped: 7\nImages: 1\nServer Version: 1.11.0\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 15\n Dirperm1 Supported: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: bridge null host\nKernel Version: 4.2.0-27-generic\nOperating System: Ubuntu 14.04.4 LTS\nOSType: linux\nArchitecture: x86_64\nCPUs: 1\nTotal Memory: 1.954 GiB\nName: xnat\nID: 3XVY:66LA:O7YA:ZRXD:5O3L:HR56:FBKD:5CG3:HAV3:JDG7:K3MX:44G7\nDocker Root Dir: /var/lib/docker\nDebug mode (client): false\nDebug mode (server): false\nRegistry: https://index.docker.io/v1/\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\nthe first machine is my local Docker for Mac installation; the second is an Ubuntu 14.04 VM in VirtualBox.\n\n**Steps to reproduce the issue:**\n1. Use the remote API to GET events, using the `since` query param.. For example, here is a simple example that asks for all events since time 0. (I have verified this behavior with other, more realistic time values.)\n\n```\ncurl --unix-socket /var/run/docker.sock http://localhost/events?since=0\n```\n\n**Describe the results you received:**\nThe events in the specified time range (in the example, from time 0 until now) are sent to me from docker, and the HTTP stream remains open.\n\n**Describe the results you expected:**\nThe events in the specified time range (in the example, from time 0 until now) are sent to me from docker, and the stream is closed. This is the documented behavior when using the `since` or `until` query params.\n"},{"labels":["api",null],"text":"For `/nodes`, it looks like the DELETE and GET methods can take either an ID, a full name or an ID prefix, but POST can only use the actual ID. This seems inconsistent (and doesn't match the docs). Let's standardize on one or the other.\n"},{"labels":["api",null,null],"text":"While working on https://github.com/docker/docker/pull/25548, I noticed some things in the plugin API that may need improvement; putting them in an issue so that I don't forget, and we can discuss.\n1. Plugins can only be referenced by _name_ on the API (not by ID). Referencing by ID may be more consistent with other API endpoints, and also keeps control over possibly \"ambiguous\" URLs (see other points below)\n2. Due to using names in the URL we may run into issues with plugins installed from third-party registries (`my-registry:5000/my/plugin:latest`). I'm not sure routing those URL's will always work; they look a bit \"scary\".\n3. Potentially ambiguous URLs (for example, inspecting a plugin called `helloworld/enable` would produce URL `/plugins/helloworld/enable`). This is not a _direct_ issue, because inspect uses `GET`, and enable `POST`, but just posting in case.\n4. Some endpoints don't return a message in the response. I didn't check if other endpoints consistently do this, but a \"success\" message may be nice (e.g. `/plugins/(plugin)/enable` only responds with `HTTP/1.1 200 OK`, but no message (e.g. `{message: \"successfully enabled plugin foo\"}`\n\n/cc @anusha-ragunathan @tiborvass @bfirsh\n"},{"labels":["api",null],"text":"The `image/load` endpoint returns either `text/plain` or `application/json`, depending on if the `?quiet` query-parameter is set to true/1 or false/0;\n\n```\ncat my-image.tar | curl --data \"@-\" --verbose -H \"Content-Type: application/x-tar\" -X POST http://127.0.0.1:2375/v1.25/images/load?quiet=0\n\n(snip)\n\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nContent-Type: application/json\nTransfer-Encoding: chunked\n\n{\"status\":\"Loading layer\",\"progressDetail\":{\"current\":32768,\"total\":1292800},\"progress\":\"[=                                                 ] 32.77 kB/1.293 MB\",\"id\":\"8ac8bfaff55a\"}\n{\"status\":\"Loading layer\",\"progressDetail\":{\"current\":65536,\"total\":1292800},\"progress\":\"[==                                                ] 65.54 kB/1.293 MB\",\"id\":\"8ac8bfaff55a\"}\n{\"status\":\"Loading layer\",\"progressDetail\":{\"current\":98304,\"total\":1292800},\"progress\":\"[===                                               ]  98.3 kB/1.293 MB\",\"id\":\"8ac8bfaff55a\"}\n{\"status\":\"Loading layer\",\"progressDetail\":{\"current\":131072,\"total\":1292800},\"progress\":\"[=====                                             ] 131.1 kB/1.293 MB\",\"id\":\"8ac8bfaff55a\"}\n...\n{\"stream\":\"Loaded image: busybox:latest\\n\"}\n```\n\n```\ncat my-image.tar | curl --data \"@-\" --verbose -H \"Content-Type: application/x-tar\" -X POST http://127.0.0.1:2375/v1.25/images/load?quiet=1\n\n(snip)\n\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nContent-Length: 29\nContent-Type: text/plain; charset=utf-8\n\nLoaded image: busybox:latest\n```\n\nThe endpoint should return JSON in both cases to be consistent\n\n/cc @bfirsh \n"},{"labels":["api",null,null,null],"text":"Sorry for being brief, but I feel the subject says it all. If you need anything else, please let me know.\n"},{"labels":["api",null,null],"text":"# Problem statement\n\nThe API/CLI version compatibility requirement is a pain for a huge number of users, and is only getting worse as we have Docker deployed on more and more heterogeneous environments. On the daemon-side, that logic is implemented in the [`VersionMiddleware`](https://github.com/docker/docker/blob/master/api/server/middleware/version.go).\n\n```\n        if versions.GreaterThan(apiVersion, v.defaultVersion) {\n            return badRequestError{fmt.Errorf(\"client is newer than server (client API version: %s, server API version: %s)\", apiVersion, v.defaultVersion)}\n        }\n        if versions.LessThan(apiVersion, v.minVersion) {\n            return badRequestError{fmt.Errorf(\"client version %s is too old. Minimum supported API version is %s, please upgrade your client to a newer version\", apiVersion, v.minVersion)}\n        }\n```\n\nToday, the only possible workaround is a horrific hack that simply overrides the version string using the [`DOCKER_API_VERSION`](https://github.com/docker/docker/blob/7c8780ea6327b1d403b13c8b144d9557b5e655e5/api/client/cli.go#L221-L223) environment variable.\n# Possible solution\n\nCreate a Go package capable of detecting the remote version and accommodating for that (up to its own capabilities, of course). Perhaps we could create a repository that packages multiple versions of the [`docker/engine-api`](https://github.com/docker/engine-api) project and would be \"version-aware\"? It would expose the latest Go interface, and could provide policies on ways to deal with unsolvable incompatibilities (e.g., the server you're interacting with doesn't implement feature X).\n\nAny idea is welcome on the best way to tackle this!\n\nCc @vdemeester @fermayo @crosbymichael.\n"},{"labels":["api",null,null],"text":"**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:        Thu Jul 28 22:00:36 2016\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:        Thu Jul 28 22:00:36 2016\n OS/Arch:      linux/amd64\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 53\n Running: 1\n Paused: 0\n Stopped: 52\nImages: 138\nServer Version: 1.12.0\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 186\n Dirperm1 Supported: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: bridge overlay null host\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: apparmor\nKernel Version: 3.19.0-33-generic\nOperating System: Ubuntu 14.04.5 LTS\nOSType: linux\nArchitecture: x86_64\nCPUs: 4\nTotal Memory: 15.67 GiB\nName: mafiosso-HSC\nID: 4IXB:YZFW:X4AW:LUMH:4K3Z:VB5V:DNAZ:DFPP:GCRY:EJJF:PB6F:HBVX\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nWARNING: No swap limit support\nInsecure Registries:\n 127.0.0.0/8\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\n\n**Steps to reproduce the issue:**\n1. Post a large image via curl on /load\n\n**Describe the results you received:**\n Remote API returns code 500 with message {\"message\":\"http: POST too large\"}.\n\n**Describe the results you expected:**\nExpected behavior shloud be code 200\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\n"},{"labels":["api",null,null],"text":"Docker version - v1.12 \nOS - Ubuntu 14.04.4-LTS\nClustering mode - Swarm\n\nCreated an overlay network:\n\n```\n$ docker -H tcp://0.0.0.0:2375 network create --driver overlay --subnet=10.0.9.0/24 my-net\n```\n\nCreating the container: `[POST] http://localhost:2375/container/create?name={id}`\n\n```\n{\n\"Env\": [\n        \"env1=val1\"\n   ],\n   \"Cmd\": [\n       \"/Run.sh\",\n       \"launch\n    ],\n   \"Image\": \"<image>\",\n   \"Volumes\": {\n       \"/tmp\" : {}\n   },\n   \"HostConfig\": {\n     \"NetworkMode\": \"my-net\"\n   }\n}\n```\n\nResponse of $ docker inspect:\n\n```\n\"HostConfig\": {\n    \"Binds\": null,\n    \"ContainerIDFile\": \"\",\n    \"LogConfig\": {\n        \"Type\": \"json-file\",\n        \"Config\": {}\n    },\n    \"NetworkMode\": \"my-net\",\n    \"PortBindings\": null,\n    \"RestartPolicy\": {\n        \"Name\": \"\",\n        \"MaximumRetryCount\": 0\n    },\n    \"AutoRemove\": false,\n    \"VolumeDriver\": \"\",\n    \"VolumesFrom\": null,\n}\n```\n\nThis creates container with networkMode as my-net. But when I run the container using the rest API `[POST] http://localhost:2375/containers/{id}/start` networkMode changes to default.\n\nResponse of $ docker inspect:\n\n```\n\"HostConfig\": {\n    \"Binds\": null,\n    \"ContainerIDFile\": \"\",\n    \"LogConfig\": {\n        \"Type\": \"json-file\",\n        \"Config\": {}\n    },\n    \"NetworkMode\": \"default\",\n    \"PortBindings\": null,\n    \"RestartPolicy\": {\n        \"Name\": \"\",\n        \"MaximumRetryCount\": 0\n    },\n    \"AutoRemove\": false,\n    \"VolumeDriver\": \"\",\n    \"VolumesFrom\": null,\n}\n```\n\nWhereas `docker run --network=my-net` command works fine with overlay network.\n"},{"labels":["api",null],"text":"## Why we should do this\n\nThere are various ways we can clean up the API to fit HTTP conventions. This will make it easier to comprehend, easier to use, and generally better organised.\n\nHere are some things that could be changed:\n1. We could remove `/json` from URLs because:\n   - They're all JSON anyway.\n   - If we want to add different formats, we can use parameters or the `Accept` header.\n   - Consistency with new `/networks` and `/volumes` endpoints.\n2. We could remove `/create` from API URLs because `POST` implies you are creating.\n3. We could remove `/update` from API URLs and use `PUT` instead.\n## Why we shouldn't do this\n\nArguably, this is a pretty big change for a minor improvement in usability and aesthetics. It wouldn't be a breaking change because we can use a new API version, but it _is_ breaking in the sense that people will be forced to update their client libraries to use this API version.\n\nAlthough this is a minor improvement on the surface, I think people who see this crufty API design will perceive Docker as poor quality, and it is a [broken window](https://en.wikipedia.org/wiki/Broken_windows_theory) that encourages more bad design.\n## How\n\nThis is non-trivial, because some other API endpoints need renaming (e.g. `/images/search` will collide with an image called `search`). See the failed attempt in [#23219](https://github.com/docker/docker/pull/23219) for full details.\n\nThe trivial ones:\n- Rename `GET /containers/json` to `GET /containers`\n- Rename `GET /containers/(id or name)/json` to `GET /containers/(id or name)`\n- Rename `POST /containers/(id or name)/update` to `PUT /containers/(id or name)`\n- Rename `GET /images/json` to `GET /images`\n- Rename `POST /images/create` to `POST /images`\n- Rename `GET /images/json` to `GET /images`\n- Rename `GET /images/(name)/json` to `GET /images/(name)`\n- Rename `POST /images/create` to `POST /images`\n- Rename `GET /exec/(id)/json` to `GET /exec/(id)`\n- Rename `POST /volumes/create` to `POST /volumes`\n- Rename `POST /networks/create` to `POST /networks`\n- Rename `POST /services/create` to `POST /services`\n- Rename `POST /services/(id or name)/update` to `PUT /services/(id or name)`\n\nThe ones that are a bit more complex: \n- Do something to `GET /images/search` because it collides with `GET /images/(name)`. We could either:\n  - Move it client side, because all it does is query Docker Hub.\n  - Give it a different name. e.g. `GET /image-search?q=...` It's a different resource to daemon images, anyway.\n- Rename `GET /images/(name)/get` to `GET /images/(name)?format=tar` (`GET .../get` is not particularly descriptive)\n- Rename `POST /images/load` to `POST /images?format=tar`\n- Rename `GET /images/get?names=(name1)&names=(name2)` to `GET /images?format=tar&name=(name1)&name=(name2)`. Alternatively, we could remove this entirely because it's probably pretty simple to concatenate the tarballs client-side.\n## See also\n- #5893\n- #23219\n\n/cc @justincormack @thaJeztah @vdemeester @cpuguy83 \n"},{"labels":["api",null,null,null],"text":"Stopping multiple containers is currently implemented in the client.\n\nAs a result, stopping multiple containers takes longer than needed, and also can result in only _some_ of the containers being stopped if the client disconnects during the process.\n\nFor example, having three containers, and stopping them all through the CLI;\n\n``` bash\ndocker run -dit --name one busybox\ndocker run -dit --name two busybox\ndocker run -dit --name three busybox\n\ndocker stop one two three\n```\n\nResults in:\n\n```\nDEBU[0683] Calling POST /v1.25/containers/one/stop\nDEBU[0683] Sending 15 to 4abc5dc9add562469a8aeda45c6955453c6615ca0a6d897ce2aff01f33acd04e\nINFO[0693] Container 4abc5dc9add562469a8aeda45c6955453c6615ca0a6d897ce2aff01f33acd04e failed to exit within 10 seconds of signal 15 - using the force\nDEBU[0693] Sending 9 to 4abc5dc9add562469a8aeda45c6955453c6615ca0a6d897ce2aff01f33acd04e\nDEBU[0693] containerd: process exited                    id=4abc5dc9add562469a8aeda45c6955453c6615ca0a6d897ce2aff01f33acd04e pid=init status=137 systemPid=734\nDEBU[0693] received containerd event: &types.Event{Type:\"exit\", Id:\"4abc5dc9add562469a8aeda45c6955453c6615ca0a6d897ce2aff01f33acd04e\", Status:0x89, Pid:\"init\", Timestamp:0x578a7d0e}\nDEBU[0693] Revoking external connectivity on endpoint one (9aad9a405dde09368cf35444ffa3b65a664856f8786ef8aecd59594f6a5caf19)\nDEBU[0693] Releasing addresses for endpoint one's interface on network bridge\nDEBU[0693] ReleaseAddress(LocalDefault/172.18.0.0/16, 172.18.0.2)\nDEBU[0693] Calling POST /v1.25/containers/two/stop\nDEBU[0693] Sending 15 to de985018aa64897c1ec5d5b985143403450559741ef05c103e74784c06397941\nINFO[0703] Container de985018aa64897c1ec5d5b985143403450559741ef05c103e74784c06397941 failed to exit within 10 seconds of signal 15 - using the force\nDEBU[0703] Sending 9 to de985018aa64897c1ec5d5b985143403450559741ef05c103e74784c06397941\nDEBU[0703] containerd: process exited                    id=de985018aa64897c1ec5d5b985143403450559741ef05c103e74784c06397941 pid=init status=137 systemPid=775\nDEBU[0703] received containerd event: &types.Event{Type:\"exit\", Id:\"de985018aa64897c1ec5d5b985143403450559741ef05c103e74784c06397941\", Status:0x89, Pid:\"init\", Timestamp:0x578a7d18}\nDEBU[0703] Revoking external connectivity on endpoint two (8453045aeb96f59a41e32cac1351835df8820e11460bac6c666e7378440f5cd6)\nDEBU[0703] Releasing addresses for endpoint two's interface on network bridge\nDEBU[0703] ReleaseAddress(LocalDefault/172.18.0.0/16, 172.18.0.3)\nDEBU[0703] Calling POST /v1.25/containers/three/stop\nDEBU[0703] Sending 15 to 744058945ea8424a1be8ba640ce5fe722edf6e0815714720bae8a3d34f41f459\nINFO[0713] Container 744058945ea8424a1be8ba640ce5fe722edf6e0815714720bae8a3d34f41f459 failed to exit within 10 seconds of signal 15 - using the force\nDEBU[0713] Sending 9 to 744058945ea8424a1be8ba640ce5fe722edf6e0815714720bae8a3d34f41f459\nDEBU[0713] containerd: process exited                    id=744058945ea8424a1be8ba640ce5fe722edf6e0815714720bae8a3d34f41f459 pid=init status=137 systemPid=817\nDEBU[0713] received containerd event: &types.Event{Type:\"exit\", Id:\"744058945ea8424a1be8ba640ce5fe722edf6e0815714720bae8a3d34f41f459\", Status:0x89, Pid:\"init\", Timestamp:0x578a7d23}\nDEBU[0713] Revoking external connectivity on endpoint three (8c14e18ecee41b2ff8aef42678ddee73a5b522e0be5442782cf0da92d189b15b)\nDEBU[0714] Releasing addresses for endpoint three's interface on network bridge\nDEBU[0714] ReleaseAddress(LocalDefault/172.18.0.0/16, 172.18.0.4)\n```\n\nThe client calls `stop` for the first container, and doesn't stop the second container\nuntil stopping the first container was completed. Stopping these containers therefore\ntakes 30 seconds.\n\nOn the other hand, stopping the _daemon_ (dockerd), will execute this in parallel, so only taking 10 seconds;\n\n```\n^CINFO[0748] Processing signal 'interrupt'\nDEBU[0748] starting clean shutdown of all containers...\nDEBU[0748] stopping de985018aa64897c1ec5d5b985143403450559741ef05c103e74784c06397941\nDEBU[0748] Sending 15 to de985018aa64897c1ec5d5b985143403450559741ef05c103e74784c06397941\nDEBU[0748] stopping 744058945ea8424a1be8ba640ce5fe722edf6e0815714720bae8a3d34f41f459\nDEBU[0748] Sending 15 to 744058945ea8424a1be8ba640ce5fe722edf6e0815714720bae8a3d34f41f459\nDEBU[0748] stopping 4abc5dc9add562469a8aeda45c6955453c6615ca0a6d897ce2aff01f33acd04e\nDEBU[0748] Sending 15 to 4abc5dc9add562469a8aeda45c6955453c6615ca0a6d897ce2aff01f33acd04e\nINFO[0758] Container 4abc5dc9add562469a8aeda45c6955453c6615ca0a6d897ce2aff01f33acd04e failed to exit within 10 seconds of signal 15 - using the force\nDEBU[0758] Sending 9 to 4abc5dc9add562469a8aeda45c6955453c6615ca0a6d897ce2aff01f33acd04e\nINFO[0758] Container 744058945ea8424a1be8ba640ce5fe722edf6e0815714720bae8a3d34f41f459 failed to exit within 10 seconds of signal 15 - using the force\nDEBU[0758] Sending 9 to 744058945ea8424a1be8ba640ce5fe722edf6e0815714720bae8a3d34f41f459\nINFO[0758] Container de985018aa64897c1ec5d5b985143403450559741ef05c103e74784c06397941 failed to exit within 10 seconds of signal 15 - using the force\nDEBU[0758] Sending 9 to de985018aa64897c1ec5d5b985143403450559741ef05c103e74784c06397941\n```\n\nWe could improve here, and have an API endpoint that allows stopping _multiple_ containers, so that\nstopping occurs in parallel.\n"},{"labels":["api",null],"text":"**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.0-rc3\n API version:  1.24\n Go version:   go1.6.2\n Git commit:   91e29e8\n Built:        Sat Jul  2 00:09:24 2016\n OS/Arch:      darwin/amd64\n Experimental: true\n\nServer:\n Version:      1.12.0-rc3\n API version:  1.24\n Go version:   go1.6.2\n Git commit:   876f3a7\n Built:        Tue Jul  5 02:20:13 2016\n OS/Arch:      linux/amd64\n Experimental: true\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 19\n Running: 1\n Paused: 0\n Stopped: 18\nImages: 9\nServer Version: 1.12.0-rc3\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 60\n Dirperm1 Supported: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: overlay bridge null host\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 4.4.14-moby\nOperating System: Alpine Linux v3.4\nOSType: linux\nArchitecture: x86_64\nCPUs: 2\nTotal Memory: 1.954 GiB\nName: moby\nID: 2DSY:BZFE:2LSD:RS2O:KQWU:HAWE:H6DW:SXZ5:ZPHJ:ZMYY:X2TY:P35F\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): true\n File Descriptors: 23\n Goroutines: 43\n System Time: 2016-07-14T01:29:33.766456833Z\n EventsListeners: 1\nRegistry: https://index.docker.io/v1/\nExperimental: true\nInsecure Registries:\n 127.0.0.0/8\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\nDocker for Mac\n\n**Steps to reproduce the issue:**\n1. Start a container. `docker run -it ubuntu /bin/bash`\n2. Use the API to get information. `curl --unix-socket /var/run/docker.sock http:/containers/json`\n3. Specify an older version of the API. `curl --unix-socket /var/run/docker.sock http:/v1.22/containers/json`\n\n**Describe the results you received:**\n1. API version 1.24\n   `[{\"Id\":\"c0cf517247df0c0b4dbc17c78e09582a017c0a15c45b5031cd7297fe459ae416\",\"Names\":[\"/hungry_heisenberg\"],\"Image\":\"ubuntu\",\"ImageID\":\"sha256:12543ced0f6f754223eff4cca67b56cbf9f384456ab9deaa824ba9ff28bcfdd6\",\"Command\":\"/bin/bash\",\"Created\":1468459844,\"Ports\":[],\"Labels\":{},\"State\":\"running\",\"Status\":\"Up 33 seconds\",\"HostConfig\":{\"NetworkMode\":\"default\"},\"NetworkSettings\":{\"Networks\":{\"bridge\":{\"IPAMConfig\":null,\"Links\":null,\"Aliases\":null,\"NetworkID\":\"dfddde6472aac68727b764d95aa8f613075db2b9dc692051c1135340d0532f7a\",\"EndpointID\":\"b89d95007c1d903d8e5ded3493b9b4160c4d084628ae1c38614f3432ab62b4d6\",\"Gateway\":\"172.17.0.1\",\"IPAddress\":\"172.17.0.2\",\"IPPrefixLen\":16,\"IPv6Gateway\":\"\",\"GlobalIPv6Address\":\"\",\"GlobalIPv6PrefixLen\":0,\"MacAddress\":\"02:42:ac:11:00:02\"}}},\"Mounts\":[]}]`\n2. API version 1.22\n   `[{\"Id\":\"c0cf517247df0c0b4dbc17c78e09582a017c0a15c45b5031cd7297fe459ae416\",\"Names\":[\"/hungry_heisenberg\"],\"Image\":\"ubuntu\",\"ImageID\":\"sha256:12543ced0f6f754223eff4cca67b56cbf9f384456ab9deaa824ba9ff28bcfdd6\",\"Command\":\"/bin/bash\",\"Created\":1468459844,\"Ports\":[],\"Labels\":{},\"State\":\"running\",\"Status\":\"Up About a minute\",\"HostConfig\":{\"NetworkMode\":\"default\"},\"NetworkSettings\":{\"Networks\":{\"bridge\":{\"IPAMConfig\":null,\"Links\":null,\"Aliases\":null,\"NetworkID\":\"dfddde6472aac68727b764d95aa8f613075db2b9dc692051c1135340d0532f7a\",\"EndpointID\":\"b89d95007c1d903d8e5ded3493b9b4160c4d084628ae1c38614f3432ab62b4d6\",\"Gateway\":\"172.17.0.1\",\"IPAddress\":\"172.17.0.2\",\"IPPrefixLen\":16,\"IPv6Gateway\":\"\",\"GlobalIPv6Address\":\"\",\"GlobalIPv6PrefixLen\":0,\"MacAddress\":\"02:42:ac:11:00:02\"}}},\"Mounts\":[]}]`\n\n**Describe the results you expected:**\n\nv1.22 and older veresions of the API should not return `\"State\":\"running\"` as this was only added in [v1.23](https://docs.docker.com/engine/reference/api/docker_remote_api/#/v1-23-api-changes)\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\n"},{"labels":["api",null,null,null],"text":"**Output of `docker version`:**\n\n```\n$ docker version\nClient:\n Version:      1.12.0-dev\n API version:  1.25\n Go version:   go1.6.2\n Git commit:   906c1dc\n Built:        Fri Jun 17 16:48:48 2016\n OS/Arch:      linux/amd64\n Experimental: true\n\nServer:\n Version:      1.12.0-dev\n API version:  1.25\n Go version:   go1.6.2\n Git commit:   906c1dc\n Built:        Fri Jun 17 16:48:48 2016\n OS/Arch:      linux/amd64\n Experimental: true\n```\n\n**Output of `docker info`:**\n\n```\n$ docker info\nContainers: 0\n Running: 0\n Paused: 0\n Stopped: 0\nImages: 0\nServer Version: 1.12.0-dev\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 0\n Dirperm1 Supported: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: host bridge overlay null\nSwarm: active\n NodeID: cjz9ffldhgrc2r5v4zj5vvmbi\n IsManager: Yes\n Managers: 1\n Nodes: 1\n CACertHash: sha256:9e85419452564689e7f8a5c72069ae4abe7a7e1ff48958a024e1451cc7c89d7a\nRuntimes: default\nDefault Runtime: default\nSecurity Options: apparmor seccomp\nKernel Version: 4.2.0-23-generic\nOperating System: Ubuntu 15.10\nOSType: linux\nArchitecture: x86_64\nCPUs: 1\nTotal Memory: 1.954 GiB\nName: manager1\nID: 7SAZ:IYHI:XB25:GMRN:OLUS:ERHX:4LAL:2S7A:KLYS:EDL6:GAZM:PQGX\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): true\n File Descriptors: 35\n Goroutines: 109\n System Time: 2016-07-13T11:34:31.825999312-07:00\n EventsListeners: 0\nUsername: mikegoelzer\nRegistry: https://index.docker.io/v1/\nWARNING: No swap limit support\nExperimental: true\nInsecure Registries:\n 127.0.0.0/8\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\n\nVirtualbox\n\n**Steps to reproduce the issue:**\n\n```\n$ curl --unix-socket /var/run/docker.sock http:/networks/ | jq .\n```\n\n**Describe the results you received:**\n\n```\n{\n  \"Name\": \"bridge\",\n  \"Id\": \"63eb8a3bd519a737a1eadaa5143dd89ee832be08c8370f94a8c9f1dc7f7affde\",\n  \"Scope\": \"local\",\n  \"Driver\": \"bridge\",\n  \"EnableIPv6\": false,\n  \"IPAM\": {\n    \"Driver\": \"default\",\n    \"Options\": null,\n    \"Config\": [\n      {\n        \"Subnet\": \"172.17.0.0/16\",\n        \"Gateway\": \"172.17.0.1\"\n      }\n    ]\n  },\n  \"Internal\": false,\n  \"Containers\": {},\n  \"Options\": {\n    \"com.docker.network.bridge.default_bridge\": \"true\",\n    \"com.docker.network.bridge.enable_icc\": \"true\",\n    \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n    \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\",\n    \"com.docker.network.bridge.name\": \"docker0\",\n    \"com.docker.network.driver.mtu\": \"1500\"\n  },\n  \"Labels\": {}\n}\n```\n\n**Describe the results you expected:**\nI would either expect an error (because I am trying to inspect a network with an empty name) or a list of all networks (if it ignores the trailing slash).\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\nSwarm mode is enabled\n"},{"labels":["api",null],"text":"<!--\nIf you are reporting a new issue, make sure that we do not have any duplicates\nalready open. You can ensure this by searching the issue list for this\nrepository. If there is a duplicate, please close your issue and add a comment\nto the existing issue instead.\n\nIf you suspect your issue is a bug, please edit your issue description to\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\ninformation within 7 days, we cannot debug your issue and will close it. We\nwill, however, reopen it if you later provide the information.\n\nFor more information about reporting issues, see\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\n\n---------------------------------------------------\nBUG REPORT INFORMATION\n---------------------------------------------------\nUse the commands below to provide key information from your environment:\nYou do NOT have to include this information if this is a FEATURE REQUEST\n-->\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.0-rc3\n API version:  1.24\n Go version:   go1.6.2\n Git commit:   91e29e8\n Built:        \n OS/Arch:      linux/amd64\n Experimental: true\n\nServer:\n Version:      1.12.0-rc3\n API version:  1.24\n Go version:   go1.6.2\n Git commit:   91e29e8\n Built:        \n OS/Arch:      linux/amd64\n Experimental: true\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 0\n Running: 0\n Paused: 0\n Stopped: 0\nImages: 7\nServer Version: 1.12.0-rc3\nStorage Driver: devicemapper\n Pool Name: docker-253:0-25774666-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 10.74 GB\n Backing Filesystem: xfs\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 760.2 MB\n Data Space Total: 107.4 GB\n Data Space Available: 4.982 GB\n Metadata Space Used: 1.606 MB\n Metadata Space Total: 2.147 GB\n Metadata Space Available: 2.146 GB\n Thin Pool Minimum Free Space: 10.74 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\n Data loop file: /var/lib/docker/devicemapper/devicemapper/data\n WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.\n Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\n Library Version: 1.02.107-RHEL7 (2016-06-09)\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: host null overlay bridge\nSwarm: active\n NodeID: 1evcplm30vhdpr9aopzh9nyr9\n IsManager: Yes\n Managers: 1\n Nodes: 1\n CACertHash: sha256:849aba16e2db83d572a454d5169152444670824fee4fb810a98cf01f92f62ce1\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 3.10.0-327.18.2.el7.x86_64\nOperating System: CentOS Linux 7 (Core)\nOSType: linux\nArchitecture: x86_64\nCPUs: 1\nTotal Memory: 3.703 GiB\nName: centos-vm1.localdomain\nID: PCUR:AM7W:CPRK:4PQY:CMEL:KKRU:AY3Y:KUIX:OONU:7HBU:K65S:ECRK\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nExperimental: true\nInsecure Registries:\n 127.0.0.0/8\n```\n\n**Steps to reproduce the issue:**\n\n```\n$ docker run -d --privileged -p 8000:8000 --name=dind dockerswarm/dind:1.12.0-rc3 docker daemon -H 0.0.0.0:8000\ndffb8c1a3ae38733c95500014b6ddd069fc70644549c285304d46fd53e40152f\n$ docker -H localhost:8000 swarm init\nSwarm initialized: current node (9c2e1w54km44r2ymo8z4i4wv7) is now a manager.\n$ curl http://localhost:8000/services\nnull\n```\n\n**Describe the results you received:**\nWhen there are no services running in the swarm, the server returns `null`\n\n**Describe the results you expected:**\nWhen there are no services running in the swarm, the server should return `[]`\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\nAlso happens with older 1.12.0 versions (e.g. RC1).\n"},{"labels":["api",null,null,null,null],"text":"Both `docker info` and `docker swarm inspect` display information regarding the swarm.\n\nThey do so in a different way.\n\nThere are also other inconsistencies in `swarm inspect` (#23689, #24122).\n\n/cc @stevvooe @aanand @dnephin @tonistiigi \n"},{"labels":["api",null,null],"text":"Swarm mode internally tracks removed nodes with a cert blacklist recording the CN of the nodes cert.  It would be useful to expose this list via an API for visibility/management purposes.\n"},{"labels":["api",null,null],"text":"Barring a resolution to https://github.com/docker/swarmkit/issues/696 there should be a programmatic way to restart the swarm mode manager after making configuration changes via the API.\n"},{"labels":["api",null],"text":"On `Docker version 1.11.2, build b9f10c9`, both `POST /v1.23/containers/<container ID>/exec` and `POST /v1.23/exec/<exec ID>/start` have the following body:\n\n``` json\n{\n  \"AttachStderr\": true,\n  \"AttachStdin\": true,\n  \"AttachStdout\": true,\n  \"Cmd\": [\n    \"true\"\n  ],\n  \"Container\": \"<container ID>\",\n  \"Detach\": false,\n  \"DetachKeys\": \"\",\n  \"Privileged\": false,\n  \"Tty\": true,\n  \"User\": \"\"\n}\n```\n\nOn `Docker version 1.12.0-rc2, build 906eacd, experimental`, both `POST /v1.24/containers/<container ID>/exec` and `POST /v1.24/exec/<exec ID>/start` have the following body:\n\n``` json\n{\n  \"AttachStderr\": true,\n  \"AttachStdin\": true,\n  \"AttachStdout\": true,\n  \"Cmd\": [\n    \"true\"\n  ],\n  \"Detach\": false,\n  \"DetachKeys\": \"\",\n  \"Privileged\": false,\n  \"Tty\": true,\n  \"User\": \"\"\n}\n```\n\nNote that the bodies are different -- the v1.23 body includes the container ID. This change doesn't appear in the Remote API documentation.\n"},{"labels":["api",null,null],"text":"In Rancher we've been following docker-compose format for naming containers \"stackName_serviceName_number\" (\"foo_bar_1\"). With docker 1.12 change for hostname validation, the containers can no longer be started due to \"Invalid hostname format\". \n\n@thaJeztah commented on https://github.com/rancher/rancher/issues/5195:\n\n> Could you open an issue in the Docker issue tracker as well, to discus this? Although validating the hostname may be a good thing, possibly it's too much of a breaking change\n"},{"labels":["api",null],"text":"See docker/engine-api#279\n\n> # 151 broke backward compat, since StorageOpt is unused most of a time, let's put an omitempty to prevent unmarshalling error.\n\nWe need to bump docker/engine-api for 1.12.0-RC2 and fix this issue.\n"},{"labels":["api",null],"text":"<!--\nIf you are reporting a new issue, make sure that we do not have any duplicates\nalready open. You can ensure this by searching the issue list for this\nrepository. If there is a duplicate, please close your issue and add a comment\nto the existing issue instead.\n\nIf you suspect your issue is a bug, please edit your issue description to\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\ninformation within 7 days, we cannot debug your issue and will close it. We\nwill, however, reopen it if you later provide the information.\n\nFor more information about reporting issues, see\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\n\n---------------------------------------------------\nBUG REPORT INFORMATION\n---------------------------------------------------\nUse the commands below to provide key information from your environment:\nYou do NOT have to include this information if this is a FEATURE REQUEST\n-->\n\nhttps://docs.docker.com/engine/reference/api/docker_remote_api_v1.23\n\nCreate a container -- status codes:\n[mistake] 404: no such container --> image\n[miss] 409: the name \"xxx\" is already in use\n[confuse] 406: impossible to attach.\nHow to trigger a 406 error in a create action?\n\nStart a container -- status codes:\n[mistake] 404: no such container --> can also be \"executable file not found in $PATH\"\n"},{"labels":["api",null,null,null],"text":"Hi, all,\n\nI use two APIs to get one volume details\n\nAs I call `192.168.0.11:2376/volumes` against docker engine :\nNo labels in results.\n\n```\n{\n  \"Volumes\": [\n    {\n      \"Name\": \"allen\",\n      \"Driver\": \"local\",\n      \"Mountpoint\": \"/var/lib/docker/volumes/allen/_data\",\n      \"Labels\": null\n    },\n    {\n      \"Name\": \"test5\",\n      \"Driver\": \"local\",\n      \"Mountpoint\": \"/var/lib/docker/volumes/test5/_data\",\n      \"Labels\": null\n    }\n  ],\n  \"Warnings\": null\n}\n```\n\nwhile calling `192.168.0.11:2376/volumes/test5` has label details:\n\n```\n{\n  \"Name\": \"test5\",\n  \"Driver\": \"local\",\n  \"Mountpoint\": \"/var/lib/docker/volumes/test5/_data\",\n  \"Labels\": {\n    \"owner\": \"ryan\"\n  }\n}\n```\n\nIt is inconsistency. Since Swarm uses /volumes to get volumes, there is no way for user to use `docker volumes inspect xxx` to get volume labels.\n\nrelated https://github.com/docker/swarm/issues/2245\n\ndocker version\n\n```\nroot@ubuntu:~# docker version\nClient:\n Version:      1.11.1\n API version:  1.23\n Go version:   go1.5.4\n Git commit:   5604cbe\n Built:        Tue Apr 26 23:30:23 2016\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.11.1\n API version:  1.23\n Go version:   go1.5.4\n Git commit:   5604cbe\n Built:        Tue Apr 26 23:30:23 2016\n OS/Arch:      linux/amd64\n```\n\ndocker info:\n\n```\nroot@ubuntu:~# docker info\nContainers: 2\n Running: 0\n Paused: 0\n Stopped: 2\nImages: 46\nServer Version: 1.11.1\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 364\n Dirperm1 Supported: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: bridge null host\nKernel Version: 3.19.0-25-generic\nOperating System: Ubuntu 14.04.3 LTS\nOSType: linux\nArchitecture: x86_64\nCPUs: 1\nTotal Memory: 1.954 GiB\nName: ubuntu\nID: HRBI:EV6M:3NAC:CXZ3:BDS7:UOKL:PD6Y:ZCK4:V3PF:V7MR:CU2Y:3LGG\nDocker Root Dir: /var/lib/docker\nDebug mode (client): false\nDebug mode (server): true\n File Descriptors: 15\n Goroutines: 33\n System Time: 2016-05-20T02:09:44.861951674+08:00\n EventsListeners: 1\nRegistry: https://index.docker.io/v1/\nWARNING: No swap limit support\n```\n\nuname -a\n\n```\nroot@ubuntu:~# uname -a\nLinux ubuntu 3.19.0-25-generic #26~14.04.1-Ubuntu SMP Fri Jul 24 21:16:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n```\n"},{"labels":["api",null],"text":"Querying a container looks like this\n\n``` JSON\n{\n    \"Id\": \"6f50c841707d1a2c9e456faecbfe9e7d9174bf5004179506b20d7d9f4c3d806a\",\n    \"Names\": [\n      \"/big_yalow\"\n    ],\n    \"Image\": \"mongo\",\n    \"ImageID\": \"sha256:ddad4160b92fbfe39698089d72ca6c8907b7d997fd0c5aeafe5a0ade825803f8\",\n    \"Command\": \"/entrypoint.sh mongod\",\n    \"Created\": 1462167207,\n    \"Ports\": [\n      {\n        \"PrivatePort\": 27017,\n        \"Type\": \"tcp\"\n      }\n    ],\n    \"Labels\": {},\n    \"Status\": \"Up 3 days\",\n    \"HostConfig\": {\n      \"NetworkMode\": \"default\"\n    },\n    \"NetworkSettings\": {\n      \"Networks\": {\n        \"bridge\": {\n          \"IPAMConfig\": null,\n          \"Links\": null,\n          \"Aliases\": null,\n          \"NetworkID\": \"\",\n          \"EndpointID\": \"46e04db264b5fd529c7a8f80f59ab1a60ccc82b85821fef66de9e202cf98d323\",\n          \"Gateway\": \"172.17.0.1\",\n          \"IPAddress\": \"172.17.0.3\",\n          \"IPPrefixLen\": 16,\n          \"IPv6Gateway\": \"\",\n          \"GlobalIPv6Address\": \"\",\n          \"GlobalIPv6PrefixLen\": 0,\n          \"MacAddress\": \"02:42:ac:11:00:03\"\n        },\n        \"isolated_nw\": {\n          \"IPAMConfig\": null,\n          \"Links\": null,\n          \"Aliases\": null,\n          \"NetworkID\": \"\",\n          \"EndpointID\": \"2dc44cc549b09e972dbc86a2a453b77af6bb6a7989e2db5ec87c7d4d61caacd9\",\n          \"Gateway\": \"172.20.10.11\",\n          \"IPAddress\": \"172.20.10.0\",\n          \"IPPrefixLen\": 16,\n          \"IPv6Gateway\": \"\",\n          \"GlobalIPv6Address\": \"\",\n          \"GlobalIPv6PrefixLen\": 0,\n          \"MacAddress\": \"02:42:ac:14:0a:00\"\n        }\n      }\n    }\n  },\n```\n\nI was hoping we could get something like this.\n\n``` JSON\n{\n    \"Id\": \"6f50c841707d1a2c9e456faecbfe9e7d9174bf5004179506b20d7d9f4c3d806a\",\n    \"Names\": [\n      \"/big_yalow\"\n    ],\n    \"Image\": \"mongo\",\n    \"ImageID\": \"sha256:ddad4160b92fbfe39698089d72ca6c8907b7d997fd0c5aeafe5a0ade825803f8\",\n    \"Command\": \"/entrypoint.sh mongod\",\n    \"Created\": 1462167207,\n    \"Ports\": [\n      {\n        \"PrivatePort\": 27017,\n        \"Type\": \"tcp\"\n      }\n    ],\n    \"Labels\": {},\n    \"Status\": \"Up 3 days\",\n    \"HostConfig\": {\n      \"NetworkMode\": \"default\"\n    },\n    \"NetworkSettings\": {\n      \"Networks\": [\n       {\n          \"Name\": \"bridge\",\n          \"IPAMConfig\": null,\n          \"Links\": null,\n          \"Aliases\": null,\n          \"NetworkID\": \"\",\n          \"EndpointID\": \"46e04db264b5fd529c7a8f80f59ab1a60ccc82b85821fef66de9e202cf98d323\",\n          \"Gateway\": \"172.17.0.1\",\n          \"IPAddress\": \"172.17.0.3\",\n          \"IPPrefixLen\": 16,\n          \"IPv6Gateway\": \"\",\n          \"GlobalIPv6Address\": \"\",\n          \"GlobalIPv6PrefixLen\": 0,\n          \"MacAddress\": \"02:42:ac:11:00:03\"\n        },\n         {\n          \"Name\": \"isolated_nw\",\n          \"IPAMConfig\": null,\n          \"Links\": null,\n          \"Aliases\": null,\n          \"NetworkID\": \"\",\n          \"EndpointID\": \"2dc44cc549b09e972dbc86a2a453b77af6bb6a7989e2db5ec87c7d4d61caacd9\",\n          \"Gateway\": \"172.20.10.11\",\n          \"IPAddress\": \"172.20.10.0\",\n          \"IPPrefixLen\": 16,\n          \"IPv6Gateway\": \"\",\n          \"GlobalIPv6Address\": \"\",\n          \"GlobalIPv6PrefixLen\": 0,\n          \"MacAddress\": \"02:42:ac:14:0a:00\"\n        }\n      ]\n    }\n  },\n```\n\nThis would making lining the api request using GraphQL much easier as then the schema would be better defined rather than having dynamic object names. I'm looking at just converting the object each time before pushing it to graphQL\n"},{"labels":["api",null,null,null],"text":"**Output of `docker version`:**\n\n```\nClient:\n Version:      1.11.0\n API version:  1.23\n Go version:   go1.5.4\n Git commit:   4dc5990\n Built:        Wed Apr 13 18:34:23 2016\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.11.0\n API version:  1.23\n Go version:   go1.5.4\n Git commit:   4dc5990\n Built:        Wed Apr 13 18:34:23 2016\n OS/Arch:      linux/amd64\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 10\n Running: 10\n Paused: 0\n Stopped: 0\nImages: 30\nServer Version: 1.11.0\nStorage Driver: aufs\n Root Dir: /mnt/docker/aufs\n Backing Filesystem: extfs\n Dirs: 342\n Dirperm1 Supported: false\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: null host bridge\nKernel Version: 3.13.0-65-generic\nOperating System: Ubuntu 14.04.4 LTS\nOSType: linux\nArchitecture: x86_64\nCPUs: 4\nTotal Memory: 29.96 GiB\nName: ip-10-153-152-120\nID: DK42:EDNQ:Y6SG:7RR3:25VN:EMGH:XDH6:RIGU:EMRV:HSCD:V53O:PNTC\nDocker Root Dir: /mnt/docker\nDebug mode (client): false\nDebug mode (server): false\nRegistry: https://index.docker.io/v1/\nWARNING: No swap limit support\n```\n\n**Describe the results you received:**\n when performing \n\n```\necho -ne \"GET /containers/cc43cecb25b0195d740ae68e81451a5d7238a6db7d2bc1366c8bc6bb8b037144/stats HTTP/1.0\\r\\n\\r\\n\" | sudo nc -q 5 -U /var/run/docker.sock\n```\n\nthe memory_stats.stats section is empty:\n\n```\n{\"read\":\"2016-04-27T21:00:33Z\",\"precpu_stats\":{\"cpu_usage\":{\"total_usage\":0,\"percpu_usage\":null,\"usage_in_kernelmode\":0,\"usage_in_usermode\":0},\"system_cpu_usage\":0,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"cpu_stats\":{\"cpu_usage\":{\"total_usage\":4341303184586,\"percpu_usage\":[1095363405711,1116566179332,1050078722879,1079294876664],\"usage_in_kernelmode\":1170440000000,\"usage_in_usermode\":2095430000000},\"system_cpu_usage\":118987410000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"memory_stats\":{\"usage\":2674970624,\"max_usage\":2747441152,\"stats\":null,\"failcnt\":0,\"limit\":32170233856},\"blkio_stats\":{\"io_service_bytes_recursive\":[{\"major\":202,\"minor\":4096,\"op\":\"Read\",\"value\":0},{\"major\":202,\"minor\":4096,\"op\":\"Write\",\"value\":73728},{\"major\":202,\"minor\":4096,\"op\":\"Sync\",\"value\":0},{\"major\":202,\"minor\":4096,\"op\":\"Async\",\"value\":73728},{\"major\":202,\"minor\":4096,\"op\":\"Total\",\"value\":73728}],\"io_serviced_recursive\":[{\"major\":202,\"minor\":4096,\"op\":\"Read\",\"value\":0},{\"major\":202,\"minor\":4096,\"op\":\"Write\",\"value\":18},{\"major\":202,\"minor\":4096,\"op\":\"Sync\",\"value\":0},{\"major\":202,\"minor\":4096,\"op\":\"Async\",\"value\":18},{\"major\":202,\"minor\":4096,\"op\":\"Total\",\"value\":18}],\"io_queue_recursive\":[],\"io_service_time_recursive\":[],\"io_wait_time_recursive\":[],\"io_merged_recursive\":[],\"io_time_recursive\":[],\"sectors_recursive\":[]},\"pids_stats\":{}}\n{\"read\":\"2016-04-27T21:00:34Z\",\"precpu_stats\":{\"cpu_usage\":{\"total_usage\":4341303184586,\"percpu_usage\":[1095363405711,1116566179332,1050078722879,1079294876664],\"usage_in_kernelmode\":1170440000000,\"usage_in_usermode\":2095430000000},\"system_cpu_usage\":118987410000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"cpu_stats\":{\"cpu_usage\":{\"total_usage\":4341472345867,\"percpu_usage\":[1095385054810,1116638571900,1050104815044,1079343904113],\"usage_in_kernelmode\":1170470000000,\"usage_in_usermode\":2095460000000},\"system_cpu_usage\":118991060000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"memory_stats\":{\"usage\":2674970624,\"max_usage\":2747441152,\"stats\":null,\"failcnt\":0,\"limit\":32170233856},\"blkio_stats\":{\"io_service_bytes_recursive\":[{\"major\":202,\"minor\":4096,\"op\":\"Read\",\"value\":0},{\"major\":202,\"minor\":4096,\"op\":\"Write\",\"value\":73728},{\"major\":202,\"minor\":4096,\"op\":\"Sync\",\"value\":0},{\"major\":202,\"minor\":4096,\"op\":\"Async\",\"value\":73728},{\"major\":202,\"minor\":4096,\"op\":\"Total\",\"value\":73728}],\"io_serviced_recursive\":[{\"major\":202,\"minor\":4096,\"op\":\"Read\",\"value\":0},{\"major\":202,\"minor\":4096,\"op\":\"Write\",\"value\":18},{\"major\":202,\"minor\":4096,\"op\":\"Sync\",\"value\":0},{\"major\":202,\"minor\":4096,\"op\":\"Async\",\"value\":18},{\"major\":202,\"minor\":4096,\"op\":\"Total\",\"value\":18}],\"io_queue_recursive\":[],\"io_service_time_recursive\":[],\"io_wait_time_recursive\":[],\"io_merged_recursive\":[],\"io_time_recursive\":[],\"sectors_recursive\":[]},\"pids_stats\":{}}\n```\n\n**Describe the results you expected:**\nrunning the same for the same container on another instacne still running docker 1.9.0\n\n```\n{\"read\":\"2016-04-27T20:25:57.848975794Z\",\"precpu_stats\":{\"cpu_usage\":{\"total_usage\":2836319781512,\"percpu_usage\":[1326177125488,527018532881,486271592733,496852530410],\"usage_in_kernelmode\":304660000000,\"usage_in_usermode\":1746480000000},\"system_cpu_usage\":21499257010000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"cpu_stats\":{\"cpu_usage\":{\"total_usage\":2836328515244,\"percpu_usage\":[1326180655922,527023151840,486272105286,496852602196],\"usage_in_kernelmode\":304660000000,\"usage_in_usermode\":1746480000000},\"system_cpu_usage\":21499260900000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"memory_stats\":{\"usage\":1300934656,\"max_usage\":1314185216,\"stats\":{\"active_anon\":1196941312,\"active_file\":35741696,\"cache\":103866368,\"hierarchical_memory_limit\":18446744073709551615,\"inactive_anon\":0,\"inactive_file\":68124672,\"mapped_file\":23048192,\"pgfault\":501671,\"pgmajfault\":437,\"pgpgin\":409404,\"pgpgout\":376962,\"rss\":1196941312,\"rss_huge\":1126170624,\"total_active_anon\":1196941312,\"total_active_file\":35741696,\"total_cache\":103866368,\"total_inactive_anon\":0,\"total_inactive_file\":68124672,\"total_mapped_file\":23048192,\"total_pgfault\":501671,\"total_pgmajfault\":437,\"total_pgpgin\":409404,\"total_pgpgout\":376962,\"total_rss\":1196941312,\"total_rss_huge\":1126170624,\"total_unevictable\":0,\"total_writeback\":0,\"unevictable\":0,\"writeback\":0},\"failcnt\":0,\"limit\":32170233856},\"blkio_stats\":{\"io_service_bytes_recursive\":[{\"major\":7,\"minor\":0,\"op\":\"Read\",\"value\":0},{\"major\":7,\"minor\":0,\"op\":\"Write\",\"value\":16384},{\"major\":7,\"minor\":0,\"op\":\"Sync\",\"value\":0},{\"major\":7,\"minor\":0,\"op\":\"Async\",\"value\":16384},{\"major\":7,\"minor\":0,\"op\":\"Total\",\"value\":16384},{\"major\":252,\"minor\":0,\"op\":\"Read\",\"value\":0},{\"major\":252,\"minor\":0,\"op\":\"Write\",\"value\":16384},{\"major\":252,\"minor\":0,\"op\":\"Sync\",\"value\":0},{\"major\":252,\"minor\":0,\"op\":\"Async\",\"value\":16384},{\"major\":252,\"minor\":0,\"op\":\"Total\",\"value\":16384},{\"major\":252,\"minor\":6,\"op\":\"Read\",\"value\":92225536},{\"major\":252,\"minor\":6,\"op\":\"Write\",\"value\":77824},{\"major\":252,\"minor\":6,\"op\":\"Sync\",\"value\":0},{\"major\":252,\"minor\":6,\"op\":\"Async\",\"value\":92303360},{\"major\":252,\"minor\":6,\"op\":\"Total\",\"value\":92303360}],\"io_serviced_recursive\":[{\"major\":7,\"minor\":0,\"op\":\"Read\",\"value\":0},{\"major\":7,\"minor\":0,\"op\":\"Write\",\"value\":4},{\"major\":7,\"minor\":0,\"op\":\"Sync\",\"value\":0},{\"major\":7,\"minor\":0,\"op\":\"Async\",\"value\":4},{\"major\":7,\"minor\":0,\"op\":\"Total\",\"value\":4},{\"major\":252,\"minor\":0,\"op\":\"Read\",\"value\":0},{\"major\":252,\"minor\":0,\"op\":\"Write\",\"value\":4},{\"major\":252,\"minor\":0,\"op\":\"Sync\",\"value\":0},{\"major\":252,\"minor\":0,\"op\":\"Async\",\"value\":4},{\"major\":252,\"minor\":0,\"op\":\"Total\",\"value\":4},{\"major\":252,\"minor\":6,\"op\":\"Read\",\"value\":5669},{\"major\":252,\"minor\":6,\"op\":\"Write\",\"value\":19},{\"major\":252,\"minor\":6,\"op\":\"Sync\",\"value\":0},{\"major\":252,\"minor\":6,\"op\":\"Async\",\"value\":5688},{\"major\":252,\"minor\":6,\"op\":\"Total\",\"value\":5688}],\"io_queue_recursive\":[],\"io_service_time_recursive\":[],\"io_wait_time_recursive\":[],\"io_merged_recursive\":[],\"io_time_recursive\":[],\"sectors_recursive\":[]}}\n```\n\nSo something has changed for memory_stats.stats to be \"null\". and I could not find it in release notes for API 1.22 or 1.23\n"},{"labels":["api",null,null],"text":"**Output of `docker version`:**\n\n```\nClient:\n Version:      1.10.2\n API version:  1.22\n Go version:   go1.5.3\n Git commit:   6f36242-unsupported\n Built:        Fri Feb 26 11:59:13 2016\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.10.2\n API version:  1.22\n Go version:   go1.5.3\n Git commit:   6f36242-unsupported\n Built:        Fri Feb 26 11:59:13 2016\n OS/Arch:      linux/amd64\n\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 3\n Running: 3\n Paused: 0\n Stopped: 0\nImages: 12\nServer Version: 1.10.2\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 132\n Dirperm1 Supported: false\nExecution Driver: native-0.2\nLogging Driver: json-file\nPlugins: \n Volume: local\n Network: null host bridge\nKernel Version: 3.13.0-65-generic\nOperating System: Ubuntu 14.04.4 LTS\nOSType: linux\nArchitecture: x86_64\nCPUs: 2\nTotal Memory: 3.861 GiB\nName: trusty\nID: MBNO:UHUZ:QX3M:SYFQ:R6C7:3NLJ:4VBG:BTW7:3MLX:OL7G:UATE:ZTRP\nWARNING: No swap limit support\n\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\nVirtualBox\n\n**Steps to reproduce the issue:**\n1. Push image to private registry\n2. print out stream log in console\n3. Sometimes it will get `current` is bigger than `total`\n\n**Describe the results you received:**\n    {u'status': u'Pushing', u'progressDetail': {u'current': 190034944, u'total': 187764542}, u'id': u'c8528dddc096', u'progress': u'[==================================================>]   190 MB'}\n\n**Describe the results you expected:**\ncurrent should not bigger than total. Right?\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\n"},{"labels":["api",null,null],"text":"I use docker go api read docker log   (docker.LogsOptions{\n        Container:    id,\n        OutputStream: outwr,\n        ErrorStream:  errwr,\n        Stdout:       true,\n        Stderr:       true,\n        Follow:       true,\n        Tail:         \"0\",\n    }), when the pressure is too large,output read have a error: buf readstring stop: read/write on closed pipe,what is wrong?\n"},{"labels":["api",null],"text":"Hello,\n\nTrying to remove a referenced image with the docker remote API return non-JSON:\n\n``` shell\nsilex@silex-laptop:~$ curl -X DELETE --unix-socket /var/run/docker.sock http:/images/7a5866c2edbf\nconflict: unable to delete 7a5866c2edbf (must be forced) - image is referenced in one or more repositories\n```\n\n```\nClient:\n Version:      1.11.0\n API version:  1.23\n Go version:   go1.5.4\n Git commit:   4dc5990\n Built:        Wed Apr 13 18:38:59 2016\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.11.0\n API version:  1.23\n Go version:   go1.5.4\n Git commit:   4dc5990\n Built:        Wed Apr 13 18:38:59 2016\n OS/Arch:      linux/amd64\n\n```\n"},{"labels":["api"],"text":"As of API 1.17, creating a container with `POST /containers/create`, you could set some cpu and memory params on the top level of the posted object. These were `Memory`, `MemorySwap`, `CpuShares`, and `CpuSet`. See the [example request](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.17.md#L126); the params' respective [description texts](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.17.md#L192) were correctly placed at the top level with the other descriptions.\n\nIn API 1.18, these CPU and memory parameters were moved into `HostConfig`. However, the description text kept the parameters at the top level, i.e. they did not move into the corresponding `HostConfig` section of the description. See the [example object](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.18.md#L168), where the params are inside `HostConfig`, and the [description text](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.18.md#L209), where they are not.\n\nThis should be a pretty easy fix, right? Just move those descriptions under the `HostConfig` section. But it gets a little funnier than that.\n\nIn API 1.19, some new CPU params‚Äî`CpuPeriod`, `CpuQuota`, `CpusetMems`‚Äîwere added that could be set in the `HostConfig` (see [example object](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.19.md#L170)). But their descriptions (brand new in this version, so they should go in the right place, right?) were added [next to the other incorrectly placed parameters](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.19.md#L216). :joy:\n\n...Ok, well, I think it's funny.\n\nThis problem just keeps growing with each API version. New parameters get added to `HostConfig`, and the container creation documentation shows them inside `HostConfig` for the example request, but not under `HostConfig` in the descriptions. I haven't made a comprehensive survey of exactly which parameters' descriptions should be moved in each version of the docs, but it will be a lot, and more in recent versions than older versions.\n\nLastly, while I'm pointing out issues with these parameter descriptions, I noticed another small problem that could be cleaned up at the same time. `Cpuset` has been deprecated since API 1.18, and yet it still gets documented in every version of the API docs as \n\n> **Cpuset** - Deprecated please don't use. Use `CpusetCpus` instead. \n\nCould this just be removed from the docs? At least the more recent versions. It has been deprecated for several versions now.\n"},{"labels":["api",null,null],"text":"Hi there,\n\nDo you guys think it could be a good idea to have in the API an endpoint which allows to get the stats of all the running containers at once?\n\nAt the moment I am using this collectd plugin (https://github.com/lebauce/docker-collectd-plugin) to get the stats out of my server. \n\nThe problem I am seeing is that when I am running 100+ container the server starts loading because I am making too many requests too often to the docker daemon (aka one call per container to the /stats endpoint every 20s).\n\nIf we could get all the stats at once that would fix this problem, for now I have implemented some rate limit on that plugin but not sure if it is the best as I do  not have a real time info anymore.\n\nCheers.\n"},{"labels":["api",null],"text":"Seen via `strace`:\n\n```\n[pid  9460] read(5, \"HTTP/1.1 200 OK\\r\\nContent-Length: 167\\r\\nContent-Type: application/json\\r\\nDate: Tue, 12 Apr 2016 10:25:27 GMT\\r\\nServer: Docker/1.11.0-rc5 (linux)\\r\\n\\r\\nThe image weaveworks/weave:latest already exists, renaming the old one with ID sha256:8a1f2f5f008334b625425659bab9ebdd2ffaea7dae6821d57bf9e0c2e9ad0c69 to empty string\\n\", 4096) = 311\n```\n\nit is claiming to send JSON, but actually sends plain text, which the client then barfs on.\n\n<!--\nIf you are reporting a new issue, make sure that we do not have any duplicates\nalready open. You can ensure this by searching the issue list for this\nrepository. If there is a duplicate, please close your issue and add a comment\nto the existing issue instead.\n\nIf you suspect your issue is a bug, please edit your issue description to\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\ninformation within 7 days, we cannot debug your issue and will close it. We\nwill, however, reopen it if you later provide the information.\n\nFor more information about reporting issues, see\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\n\n---------------------------------------------------\nBUG REPORT INFORMATION\n---------------------------------------------------\nUse the commands below to provide key information from your environment:\nYou do NOT have to include this information if this is a FEATURE REQUEST\n-->\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.11.0-rc5\n API version:  1.23\n Go version:   go1.5.3\n Git commit:   6178547\n Built:        Mon Apr 11 21:11:46 2016\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.11.0-rc5\n API version:  1.23\n Go version:   go1.5.3\n Git commit:   6178547\n Built:        Mon Apr 11 21:11:46 2016\n OS/Arch:      linux/amd64\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 3\n Running: 0\n Paused: 0\n Stopped: 3\nImages: 29\nServer Version: 1.11.0-rc5\nStorage Driver: overlay\n Backing Filesystem: extfs\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins: \n Volume: local\n Network: bridge null host\nKernel Version: 4.2.0-34-generic\nOperating System: Ubuntu 15.10\nOSType: linux\nArchitecture: x86_64\nCPUs: 1\nTotal Memory: 362.9 MiB\nName: host1\nID: WSO5:2WPX:NINR:DJJJ:U5VI:VZRJ:KBFJ:JCSE:VQGB:Y5WX:AOMI:24L6\nDocker Root Dir: /var/lib/docker\nDebug mode (client): false\nDebug mode (server): true\n File Descriptors: 14\n Goroutines: 30\n System Time: 2016-04-12T10:40:04.73189936Z\n EventsListeners: 0\nRegistry: https://index.docker.io/v1/\nWARNING: No swap limit support\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\n\nVirtualBox running Ubuntu 15.10\n\n**Steps to reproduce the issue:**\n1. build the Weave Net project https://github.com/weaveworks/weave\n2. `docker load` the output on a different machine\n3. change something and rebuild the project, so you get different checksums\n4. `docker load` the output onto the same machine as before\n\n**Describe the results you received:**\n\n```\n$ docker load -i weave.tar.gz \n2aa27ff8f322: Loading layer [==================================================>] 21.24 MB/21.24 MB\n6c02f687aa00: Loading layer [==================================================>]   277 kB/277 kB\ninvalid character 'T' looking for beginning of value\n```\n\n**Describe the results you expected:**\n\n```\nThe image weaveworks/weave:latest already exists, renaming the old one with ID sha256:8a1f2f5f008334b625425659bab9ebdd2ffaea7dae6821d57bf9e0c2e9ad0c69 to empty string\n```\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\n\nHappens every time.\n\nThe comparable http reply from 1.10.3 is:\n\n```\nHTTP/1.1 200 OK\\r\\nServer: Docker/1.10.3 (linux)\\r\\nDate: Tue, 12 Apr 2016 10:29:53 GMT\\r\\nContent-Length: 167\\r\\nContent-Type: text/plain; charset=utf-8\\r\\n\\r\\nThe image weaveworks/weave:latest already exists, renaming the old one with ID sha256:3cb08e6d141a1545e066e4e3f4873e4869bc62752a01e8c4342176ac252dcaca to empty string\\n\n```\n\nNote the content-type matches the content there.\n"},{"labels":["api",null],"text":"There are many times when the Docker version on a client can differ to that on a server.\n\nThis is typically because that end users are faster to update their clients whereas hosted Docker services or servers in production are slower to upgrade.\n\nThis issue can be much worse when attempting to RC test the new version of Docker as you need to switch Docker Client versions or set `DOCKER_API_VERSION`. The latter can have consequences e.g newer client features and flags failing against older engine versions.\n## Today\n\nAttempting to connect to older server:\n\n```\n$ docker ps\nError response from daemon: client is newer than server (client API version: 1.23, server API version: 1.22)\n```\n\nAttempting to create an IPv6 network\n\n```\n$ DOCKER_API_VERSION=1.22 docker network create --ipv6 foo\n2d6a8ce8e8303d27fbfdc19cb1d2a73328d5d278a1dea173d31ec4b9d586e8ca\n$ DOCKER_API_VERSION=1.22 docker network inspect foo\n[\n    {\n        \"Name\": \"foo\",\n        \"Id\": \"2d6a8ce8e8303d27fbfdc19cb1d2a73328d5d278a1dea173d31ec4b9d586e8ca\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": {},\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.18.0.0/16\",\n                    \"Gateway\": \"172.18.0.1/16\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Containers\": {},\n        \"Options\": {},\n        \"Labels\": null\n    }\n]\n```\n\nThe command succeeds, but IPv6 wasn't enabled as this is only available in a newer API version!\n## Tomorrow\n\nRegardless of version, commands should work:\n\n```\n$ docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n```\n\nHandling of unsupported operations\n\n```\n$ docker network create --ipv6 foo\nError: `--ipv6` is not available on your server\nClient Version: 1.23 \nServer Version: 1.22\n```\n## Suggestion\n\nIf the Docker Client were able to maintain some form of session state, it could detect and preserve the Docker API version for a session. It should also be possible to prevent newer client features from being used on servers that do not support them to avoid inconsistencies like the example noted above\n"},{"labels":["api",null],"text":"### Problem Statement\n\nFor the docker Remote API there is a sound versioning scheme in place even with [history](https://docs.docker.com/engine/reference/api/docker_remote_api/#version-history).\n\nFor the plugin API only a [single mention](https://docs.docker.com/engine/extend/plugin_api/#api-design) of versioning can be found:\n\n_The API is versioned via an Accept header, which currently is always set to `application/vnd.docker.plugins.v1+json`._\n\nAccording to [this comment](https://github.com/docker/docker/issues/21857#issuecomment-207057067) there are possible changes in how the API works and/or is used. Furthermore, in contrast to the Remote API which is only implemented once (by docker engine, and of course swarm) the plugin API is implemented by a variety of services provided by different vendors.  \n\nTherefore I see the need to introduce versioning information for this API.\n### Requirements\n1. API Client (docker daemon) should indicate which version of the API it is supporting.\n2. API Service (plugin) should inidicate which version of the API it is supporting.\n3. For every API call it should be clear, which API version it refers to.\n4. A history for the versions should be maintained.\n### Possible implementation\n\nWhen the Plugin gets activated, the payload (currently empty) specifies, which plugin types for which API version is supported.\n**Request**\n\n```\n{\n    [ \n        { \n            \"PluginType\" : string, \n            \"APIVersion\" : string\n        }\n   ]\n}\n```\n\nThe following `PluginType`s are currently defined:  `authz` - `NetworkDriver` - `VolumeDriver`.\nIf for a given `PluginType` more then one APIVersion is supported it is listed multiple times. \n\n**Response**\nThe response indicates which Docker subsystems the plugin implements.\n\n```\n{\n    \"Implements\": [ \n    {\n        \"PluginType\" : string, \n        \"APIVersion\" : string\n    }\n    ]\n}\n```\n\nAt its own discretion the plugin can return only those `APIVersion` that the daemon also supports or it can return all versions.\nDocker Daemon can pick any of the supported `APIVersion` to communicate with the plugin. The daemon should stick with the version selected at the beginning of communication, changing API version during lifetime of plugin may result in undefined behaviour.\nIf the plugin supports more then one Docker subsystem,  the plugin may support different API versions for different subsystems. The order of entries in the list indicates plugin's preferences.\nSimilarily Docker daemon may use different API version when talking to different subsystems the plugin implements.\n\n**API-Calls**\nThe Version of the API-Call is encoded similiar the Remote API. A call gets the API version prepended, e.g. `/v1/VolumeDriver.List`. A call without the version prefix means the version of the first list entry for this subsystem returned by the plugin as responss to plugin activation. \n_This is not necessary the highest version currently specified or the highest version supported by daemon!_.\n\n**History**\nChanges between different versions should be tracked either in the [plugin documentation overview](https://docs.docker.com/engine/extend/plugin_api/) or in the documentation of the various subsystems ([volume](https://docs.docker.com/engine/extend/plugins_volume/), [network](https://docs.docker.com/engine/extend/plugins_network/)).\n\nSince the API comprises alls subsystems the API version is comprises all subsystems to.. Thus it is possible, that for a given subsystem no change exists between subsequent version.\n### Notes\n\nWhile this proposal could be part of #20363 too, I feel the discussion there is to wide and partly orthogonal. Thus I present this as a separate issue.\n"},{"labels":["api"],"text":"See https://github.com/docker/engine-api/pull/186; this breaks compatibility with some programs parsing Docker requests; e.g. https://github.com/weaveworks/weave/issues/2109\n\n<!--\nIf you are reporting a new issue, make sure that we do not have any duplicates\nalready open. You can ensure this by searching the issue list for this\nrepository. If there is a duplicate, please close your issue and add a comment\nto the existing issue instead.\n\nIf you suspect your issue is a bug, please edit your issue description to\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\ninformation within 7 days, we cannot debug your issue and will close it. We\nwill, however, reopen it if you later provide the information.\n\nFor more information about reporting issues, see\nhttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues\n\n---------------------------------------------------\nBUG REPORT INFORMATION\n---------------------------------------------------\nUse the commands below to provide key information from your environment:\nYou do NOT have to include this information if this is a FEATURE REQUEST\n-->\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.11.0-rc2\n API version:  1.23\n Go version:   go1.5.3\n Git commit:   aa9f9c8-unsupported\n Built:        Fri Apr  1 16:26:27 2016\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.11.0-rc2\n API version:  1.23\n Go version:   go1.5.3\n Git commit:   aa9f9c8-unsupported\n Built:        Fri Apr  1 16:26:27 2016\n OS/Arch:      linux/amd64\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 1\n Running: 0\n Paused: 0\n Stopped: 1\nImages: 283\nServer Version: 1.11.0-rc2\nStorage Driver: aufs\n Root Dir: /home/docker/aufs\n Backing Filesystem: extfs\n Dirs: 326\n Dirperm1 Supported: false\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins: \n Volume: local\n Network: null host weavemesh bridge\nKernel Version: 3.13.0-83-generic\nOperating System: Ubuntu 14.04.4 LTS\nOSType: linux\nArchitecture: x86_64\nCPUs: 2\nTotal Memory: 3.861 GiB\nName: bbvlx1\nID: IVMU:DIYM:GNIF:DNSW:GCHY:42Z5:R573:MDYB:YWOK:W57O:P4WY:2LQS\nDocker Root Dir: /home/docker\nDebug mode (client): false\nDebug mode (server): false\nUsername: bboreham\nRegistry: https://index.docker.io/v1/\nWARNING: No swap limit support\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\n\n**Steps to reproduce the issue:**\n1. Install Weave Net https://github.com/weaveworks/weave\n2. `weave launch`\n3. `eval $(weave env)`\n4. `docker run --net=none -ti alpine /bin/sh`\n\n**Describe the results you received:**\n\n`docker: Error response from daemon: EOF.`\n\n**Describe the results you expected:**\n\nRunning shell inside Alpine container.\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\n"},{"labels":["api",null],"text":"When `docker load`ing a `tar` file with image(s), the [(current v1.22) API](https://docs.docker.com/engine/reference/api/docker_remote_api_v1.22/#load-a-tarball-with-a-set-of-images-and-tags-into-docker) should return the list of images it loaded.\n"},{"labels":["api",null,null],"text":"Wrong HTTP-Status codes in many API-Docs, needs review\n\n**Describe the results you received:**\n\n```\ngrep \"201 OK\" docs/reference/api/*\ndocs/reference/api/docker_remote_api_v1.14.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.15.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.15.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.15.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.15.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.16.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.16.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.16.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.16.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.17.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.17.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.17.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.17.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.18.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.18.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.18.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.18.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.19.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.19.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.19.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.19.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.20.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.20.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.20.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.20.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.21.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.21.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.21.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.21.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.22.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.22.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.23.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.23.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.24.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.24.md:    HTTP/1.1 201 OK\n```\n\n**Describe the results you expected:**\nExpected \"HTTP/1.1 201 Created\" as per RFC2616\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\nSometimes wrong responsetype (\"OK\" instead of \"Created\"), sometimes wrong HTTP-Status Code number \"201\" instead of \"200\" documented)\n\nThere may be other statuscode deviations in the api docs\n"},{"labels":["api",null,null],"text":"We're having issues using the PUT /containers/(id)/archive endpoint due to file ownership permissions. When a container is running as a non-root user, the ownership is always reset back to root after uploading the file.\n\n```\n  > docker version                                                                         \nClient:                                                                                    \n Version:      1.10.0                                                                      \n API version:  1.22                                                                        \n Go version:   go1.5.3                                                                     \n Git commit:   590d5108                                                                    \n Built:        Thu Feb  4 18:36:33 2016                                                    \n OS/Arch:      linux/amd64                                                                 \n\nServer:                                                                                    \n Version:      1.10.0                                                                      \n API version:  1.22                                                                        \n Go version:   go1.5.3                                                                     \n Git commit:   590d5108-unsupported                                                        \n Built:        Fri Feb  5 02:32:52 2016                                                    \n OS/Arch:      linux/amd64  \n```\n\nGiven an image with a directory owned by a different user\n\n```\nFROM ubuntu\nRUN mkdir /opt/www-data && chown www-data:www-data /opt/www-data\ndocker build -t secure .\n```\n\nAnd a tar file owned by a non-root user\n\n```\n> touch test\n> tar -zcvf test.tar.gz test\n\n> ls -lha \n-rw-r--r-- 1 non-root non-root    0 Mar 30 10:19 test  \n-rw-r--r-- 1 non-root non-root  114 Mar 30 10:19 test.tar.gz\n```\n\nWhen you launch the container as a non-root user\n\n```\ndocker run -d -u www-data --name target secure sleep 100000\n```\n\nAfter uploading the tar, the file ownership permissions will be reset to root. The ownership should match either the original file or the user the container is being run as. \n\n```\ncurl -s -XPUT  -T test.tar.gz docker:2345/containers/target/archive?path=/opt/www-data\ndocker exec -it target bash\n\n> /opt/www-data$ ls -lha\ndrwxr-xr-x 1 www-data www-data 4.0K Mar 30 10:24 .\ndrwxr-xr-x 1 root     root     4.0K Mar 30 10:22 ..\n-rw-r--r-- 1 root     root        0 Mar 30 10:19 test \n```\n"},{"labels":["api",null],"text":"Every part of the remote API that returns a collection of objects (`GET /images/json`, `GET /containers/json`, `GET /events`, etc.) returns its values as a JSON list of objects: `[{...}, {...}, ...]`. Every part, that is, except `GET /volumes`. That endpoint returns an object of one element whose value is a list: `{ \"Volumes\": [{...}, {...}, ...] }`. This is still the case in the [most recent dev Remote API Docs](https://github.com/docker/docker/blob/master/docs/reference/api/docker_remote_api_v1.24.md#list-volumes).\n\nIs there a reason `GET /volumes` is inconsistent with the rest of the API? If there is no reason, I ask that it be made to return a flat list.\n"},{"labels":["api",null],"text":"This is more a question than an issue, but I'm wondering why the `/build` Remote API call returns JSON-formatted chunks like `{\"stream\":\"...\"}` and `{\"error\":\"...\"}` instead of multiplexing `stdout` and `stderr` like other API calls.\n\nAs documented in: https://docs.docker.com/engine/reference/api/docker_remote_api_v1.22/#build-image-from-a-dockerfile\n\n**Output of `docker version`:**\n\n```\nClient version: 1.6.2\nClient API version: 1.18\nGo version (client): go1.3.3\nGit commit (client): 7c8fca2\nOS/Arch (client): linux/amd64\nServer version: 1.6.2\nServer API version: 1.18\nGo version (server): go1.3.3\nGit commit (server): 7c8fca2\nOS/Arch (server): linux/amd64\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 48\nImages: 1016\nStorage Driver: aufs\n Root Dir: /data2/docker/aufs\n Backing Filesystem: extfs\n Dirs: 1146\n Dirperm1 Supported: true\nExecution Driver: native-0.2\nKernel Version: 3.16.0-4-amd64\nOperating System: Debian GNU/Linux 8 (jessie)\nCPUs: 16\nTotal Memory: 63.11 GiB\nName: irill2\nID: GRUJ:4V5T:KSWG:L5HV:5JKV:RW5L:CYSK:ZBMG:GXSZ:W5JG:Q3CX:H2RP\nWARNING: No memory limit support\nWARNING: No swap limit support\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\n\nPhysical server running `Linux 3.16.0-4-amd64` and `Debian 8.3 jessie`.\n\n**Steps to reproduce the issue:**\n1. Send a properly formatted request with tar stream to the `/build` API endpoint.\n2. Listen for Docker's response.\n\n**Describe the results you received:**\n\nA series of JSON-formatted chunks like `{\"stream\":\"...\"}` (and `{\"error\":\"...\"}` if the build failed).\n\n**Describe the results you expected:**\n\nA stream with multiplexed `stdout` and `stderr`.\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\n\nReproduces 100%.\n"},{"labels":["api",null],"text":"Just a quick placeholder, following a discussion on Slack;\n\nCurrently we accept both `/something` (\"latest\" API version), and `/vXX.YY/something` (API version \"XX.YY\").\n\nThe \"latest\" API version can be troublesome, because software using the \"latest\" version (and not explicitly defining a version), can break after an upgrade of the daemon.\n\nInstead, we can deprecated the \"latest\" URLs, and require consumers of the API to explicitly specify the API version they're using.\n\n/cc @tiborvass @dgageot @nishanttotla \n"},{"labels":["api"],"text":"Originally reported in https://github.com/docker/docker-py/issues/978\n\nExpected result: HTTP status 400 \"Bad request\", (ideally) with explicit error message about invalid parameter.\n\nObserved result: Connection aborted - Connection reset by peer.\n"},{"labels":["api",null],"text":"Hi,\n\nOk, so I've finally worked out what I needed to do as <a href=\"http://blog.arungupta.me/enable-docker-remote-api-mac-osx-machine/\">workaround</a> for the Mac Kitematic issue so that I can access the API using curl. \n\nThis works OK: \n\n```\ncurl -s --no-buffer -XGET --insecure --cert cert.p12 --pass mypass https://127.0.0.1:52376/events\n```\n\nHowever, I now want to filter the response stream. The API 1.21 docs suggest that this should work:\n\n```\nhttps://127.0.0.1:52376/events?filter=........\n```\n\ne.g.\n\n   events?filters=%7B%22image%22%3A%5B%22injcristianrojas%2Fnginx-ssl%22%5D%7D\n\nHowever, no matter what I try here the filter gets ignored.\n\nI need to filter on the `status` and `name`fields but so far I can't get this to work. The docs aren't particularly clear as to the filter should be constructed. \n\nAre there any examples out there ? \n\nI'm trying to create a filter that only returns based on a `Type=container` and `status=start or status=die`\n"},{"labels":["api",null,null],"text":"Currently docker merges labels with some container attributes in here: https://github.com/docker/docker/blob/master/daemon/events.go#L17\n\nThe way it is right now the user can start a container with the label \"image=this-is-my-label\" and that label won't show up in the docker events.\n\nSo my my proposal is:\n- Somehow split engine-api message with labels in one map and remaining attributes in the other.\n- Use the special labels assigned to docker e.g. \"com.docker.container.image\" and \"com.docker.container.name\"\n\nThoughts?\n\nPing @calavera \n"},{"labels":["api"],"text":"Currently, the `/info` endpoint for the Swarm API uses `DriverStatus` field in the Engine API. We would like to create a new field exclusively for Swarm to use.\n\nCorresponding `docker/swarm` issue: https://github.com/docker/swarm/issues/1625\n\ncc @calavera @vieux\n"},{"labels":["api",null,null],"text":"We have a tool that interacts with the docker API directly and it started failing on master (aka 1.10, aka 723be0a3325799fd6b2a6b689af54f5a07edf992). It tries to start containers with a custom network using the `NetworkMode` parameter in the `start` API. There is a warning that this will be removed in 1.12, but it looks like it already doesn't work for `NetworkMode`.\n\nExample docker log when this fails:\n\n```\nDEBU[0061] Calling POST /v1.13/containers/create        \nDEBU[0061] POST /v1.13/containers/create?name=(redacted) \nDEBU[0061] form data: {\"AttachStderr\":false,\"AttachStdin\":false,\"AttachStdout\":false,\"Env\":[\"NO_PROXY=(redacted)\",\"HTTPS_PROXY=\",\"HTTP_PROXY=\"],\"Image\":\"(redacted):(redacted)\",\"Memory\":0,\"MemorySwap\":0,\"NetworkDisabled\":false,\"OpenStdin\":false,\"StdinOnce\":false,\"Tty\":false}\nDEBU[0061] container mounted via layerStore: /var/lib/docker/overlay/a231abd7438a8a6dc86f68fe0e7abba14a63f89a00aa8076f3b88a0f23c2bb90/merged \nDEBU[0061] Incrementing volume reference: driver local, name cc80f3f57a0a9b57e3d787c5062f37497732f0cc2da1874c031fc3290bb85e3c \nDEBU[0061] Calling GET /v1.13/containers/json           \nDEBU[0061] GET /v1.13/containers/json?all=1&limit=-1&trunc_cmd=1&size=0 \nDEBU[0061] Calling GET /v1.13/containers/json           \nDEBU[0061] GET /v1.13/containers/json?all=0&limit=-1&trunc_cmd=1&size=0 \nDEBU[0061] Calling POST /v1.13/containers/(redacted)/start \nDEBU[0061] POST /v1.13/containers/(redacted)/start \nDEBU[0061] form data: {\"Binds\":[\"/var/(redacted):/var/(redacted):rw\"],\"NetworkMode\":\"(redacted)\",\"PortBindings\":{},\"RestartPolicy\":{\"MaximumRetryCount\":0,\"Name\":\"always\"},\"SecurityOpt\":[\"label:type:(redacted)\"]} \nWARN[0061] DEPRECATED: Setting host configuration options when the container starts is deprecated and will be removed in Docker 1.12 \nDEBU[0061] Decrementing volume reference: driver local, name cc80f3f57a0a9b57e3d787c5062f37497732f0cc2da1874c031fc3290bb85e3c \nDEBU[0061] container mounted via layerStore: /var/lib/docker/overlay/a231abd7438a8a6dc86f68fe0e7abba14a63f89a00aa8076f3b88a0f23c2bb90/merged \nDEBU[0061] Assigning addresses for endpoint (redacted)'s interface on network bridge \nDEBU[0061] RequestAddress(LocalDefault/172.17.0.0/16, <nil>, map[])\n```\n\nExpected result: Container starts attached to the custom network\nActual result: Container starts on the default \"bridge\" network\n"},{"labels":["api",null],"text":"Currently the [https://docs.docker.com/engine/reference/api/docker_remote_api_v1.21/#list-containers](`GET /containers/json`) endpoint returns a human readable `Status` field, which is useful for the `docker ps` cli, but not very useful for other API clients, since it's not machine readable. For example, this is what it has returned for me (simplified to only include the Id and Status fields from the returned JSON): \n\n```\nId                                                               Status\n9080c3d4e54b1367cd659d5841953f0a0b0ed789d52805491ba752744ca7ed33 Created\nda837d8058c56c0c038d4580f5f8c2197a7c383be7de106dfbc6d17849975f2a Exited (137) 12 days ago\n624d6deaf83091659d563d2063c6fcf0275a4b945b02e5b2262557a64e6953f8 Up 8 minutes (Paused)\n2a6e659fe99f33a5f43605e313fbee17c2eb91e317567d6fd98d69c5d30504db Up 5 seconds\n```\n\nIt would be more useful if the Status field (or a new field, for backwards compatibility) returned the states from this state diagram:\n\n[![State diagram from Remote API documentation](https://docs.docker.com/engine/reference/api/images/event_state.png)](https://docs.docker.com/engine/reference/api/docker_remote_api/#docker-events)\n\nI therefore propose a new `State` field to the result of calling `GET /containers/json` which will have one of the values from that diagram, namely `created`, `running`, `paused` or `stopped` (I don't think it can ever have `deleted`, since, well, it's deleted).\n"},{"labels":["api",null,null],"text":"The current implementation of `update`(#15078), and thus the endpoint `/containers/(id)/update`, is using `HostConfig` struct although it's only updating `Resources`. \n\nThis raises few concerns :\n- We decided that `update` should only _update_ stuff that are in `Resources` struct, but it's possible to send a complete `HostConfig` struct which could lead to confusion ‚Äî like why is some fields not taken care of, etc‚Ä¶.\n- If a complete `HostConfig` struct is passed, it will completely and **silently ignore** all attributes except `Resources`. It should at least put a warning.\n\nI think we should _reduce_ what we send and change the API `/containers/(id)/update` to just take `Resoures` struct instead of `HostConfig` ‚Äî it would make it clear that only stuff _in_ this struct are supported (and it's simpler to implement than doing some diff or something and warn that something that is not in `Resources` has been wrongly set).\n\n/cc @hqhq @tiborvass @thaJeztah @runcom @duglin @unclejack @icecrime @calavera \n"},{"labels":["api",null,null,null],"text":"When Docker daemon is exiting, request to retrieve containers returns container JSON without names. This may cause tooling failure. For example, swarm decides named containers do not exist, instead of engine unreachable. I think docker daemon should reject requests during shutdown. \n\nThe problem is easy to reproduce under swarm setup. Reproduce steps: \n- start a swarm manager with 1 second refresh interval\n- start a docker engine on another machine, join the swarm \n- create a container with name thru swarm, validate container name exists\n- stop Docker engine with ^C\n- send `docker ps -a` to swarm, validate container without name\n\nActual Results thru swarm:\n\n```\ndchen@vm4:~$ docker -H 192.168.56.202:2372 ps -a \nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                            NAMES\n475f6d2008a4        busybox             \"/bin/sh -c 'echo hel\"   2 weeks ago         Host Down                                                            \n4b40a7988c1f        ubuntu              \"/bin/bash -c 'while \"   3 weeks ago         Host Down                                                            \ndd32d46a1892        nginx               \"nginx -g 'daemon off\"   3 weeks ago         Host Down           80/tcp, 443/tcp, 192.168.56.203:8080->8080/tcp   \n```\n\nExpected Results:\n\n```\ndchen@vm4:~$ docker  -H 192.168.56.202:2372 ps -a \nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                            NAMES\n475f6d2008a4        busybox             \"/bin/sh -c 'echo hel\"   2 weeks ago         Host Down                                                            vm3/test_container1\n4b40a7988c1f        ubuntu              \"/bin/bash -c 'while \"   3 weeks ago         Host Down                                                            vm3/evil_cray\ndd32d46a1892        nginx               \"nginx -g 'daemon off\"   3 weeks ago         Host Down           80/tcp, 443/tcp, 192.168.56.203:8080->8080/tcp   vm3/tiny_euclid\n\n```\n\nDocker information. \n\n```\ndchen@vm3:~/go/src/github.com/docker/swarm$ docker version\nClient:\n Version:      1.10.0-dev\n API version:  1.22\n Go version:   go1.5.1\n Git commit:   9c1006c\n Built:        Wed Nov  4 12:36:27 UTC 2015\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.10.0-dev\n API version:  1.22\n Go version:   go1.5.1\n Git commit:   9c1006c\n Built:        Wed Nov  4 12:36:27 UTC 2015\n OS/Arch:      linux/amd64\n\ndchen@vm3:~/go/src/github.com/docker/swarm$ docker info\nContainers: 3\nImages: 259\nServer Version: 1.10.0-dev\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 265\n Dirperm1 Supported: true\nExecution Driver: native-0.2\nLogging Driver: json-file\nKernel Version: 3.19.0-25-generic\nOperating System: Ubuntu 14.04.3 LTS\nCPUs: 2\nTotal Memory: 3.86 GiB\nName: vm3\nID: QCAK:VVFW:GTEN:RF4O:O5EF:4AAT:RXDM:2FIJ:FVIF:CJBL:IDUU:2DG4\nWARNING: No swap limit support\nCluster store: consul://192.168.56.204:8500/swarm\n\ndchen@vm3:~/go/src/github.com/docker/swarm$ uname -a\nLinux vm3 3.19.0-25-generic #26~14.04.1-Ubuntu SMP Fri Jul 24 21:16:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n```\n"},{"labels":["api",null,null],"text":"Description of problem:\nUsing pull API to pull an image. But sometime it response detail information with `total:-1`.\n\n`docker version`:\n\n```\nClient:\n Version:      1.9.1\n API version:  1.21\n Go version:   go1.4.1\n Git commit:   d997753\n Built:        Thu Nov 26 02:31:23 UTC 2015\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.9.1\n API version:  1.21\n Go version:   go1.4.1\n Git commit:   d997753\n Built:        Thu Nov 26 02:31:23 UTC 2015\n OS/Arch:      linux/amd64\n```\n\n`docker info`:\n\n```\nContainers: 0\nImages: 116\nServer Version: 1.9.1\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 116\n Dirperm1 Supported: false\nExecution Driver: native-0.2\nLogging Driver: json-file\nKernel Version: 3.13.0-65-generic\n```\n\n`uname -a`:\nLinux trusty-64abced 3.13.0-65-generic #106-Ubuntu SMP Fri Oct 2 22:08:27 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n\nEnvironment details: VirtualBox\n\nHow reproducible:\nJust pull images by docker-py\n\nSteps to Reproduce:\n1. Pull image by docker-py\n2. Check the stream output\n\nActual Results:\n\n```\n{u'id': u'379cc190f32e',\n u'progress': u'7.395 MB',\n u'progressDetail': {u'current': 7395421, u'total': -1},\n u'status': u'Downloading'}\n```\n\nExpected Results:\ntotal without -1\n\nAdditional info:\n"},{"labels":["api",null,null],"text":"I have a container which needs to be restarted when the machine reboots.  If the process crashes or exits with an error I would like it to stay down so it can be diagnosed.\n\nExisting restart policies:\n- `on-failure` will not achieve either requirement.\n- `always` will achieve the first requirement but not the second.\n- `unless-stopped` is slightly better than `always`, but not quite what I want.\n\nI apologise if this is a misguided request; I searched around quite a lot but didn't find an open discussion of the topic.  I found [this](https://www.pivotfreight.com/devblog/on-docker-restart-policies) which asserts that `on-failure` will restart containers on a daemon restart, but this does not match my experiments or my reading of the code.  On a hard reset of the machine, the exit code will be recorded as zero so no restart.\n\nIn #7586 it is [asserted](https://github.com/docker/docker/issues/7586#issuecomment-57061376) that `always` has a max-retry count, and a max-retry count of 1 would be good enough for my purposes, but again this does not match what I find in the code.\n"},{"labels":["api",null],"text":"Currently the networking API always report 500 on failures (except in [special cases when the error message matches certain patterns](https://github.com/docker/docker/blob/e75da4b6fffbcf9dab86cd581e962a19d3efa35a/api/server/httputils/httputils.go#L129-L151)). Should HTTP handlers in the networking API use the [errcode package](https://godoc.org/github.com/docker/distribution/registry/api/errcode)? If so, I can prepare a patch for that.\n"},{"labels":["api",null,null],"text":"I see the need for a docker run --volumes-no option that enables me to run a normal production image and start a container instance of it so that it saves the content on docker commit even in the directorys that are normal defined as volume by the source image.\n"},{"labels":["api",null],"text":"There are some information that can only be reliably retrieved using the container inspection.\n\nWhen you get normal container information (e.g. through container listing), one cannot find out in what network is a container in. Before api 1.21, one could not find the imageID of the containers without inspecting it too - sometimes it returned the image repo+tag and sometimes the id.\n\nWhen a single host has thousands of containers, getting network information for every single container is very expensive, since it demands a get request per container.\n\nI would like to suggest an API extension where all the containers' inspection information will be retrieved in a single request. Although the response may be considerable large (several jsons), it is still better than a restful request per inspection.\n"},{"labels":["api",null,null],"text":"Instead of leaving a dangling image around or potentially purging common layers to early, it would be nice if there was an option to cleanly replace an image when pulling or building and tagging so there will not be a dangling image left behind.\n"},{"labels":["api",null,null],"text":"I like how, when manipulating containers, I can type the first few non-colliding characters of the container's ID. This doesn't seem to be true for volumes. Could these also be matched in the same way that container/image IDs are? At the moment I have to cut-and-paste the entire volume ID, which is annoying.\n\nThanks.\n"},{"labels":["api",null,null],"text":"`docker inspect`  should also return:\n- subnet\n- ip-range\n- gateway\n\nThey should show with the default or empty if they have nothing.\n"},{"labels":["api",null,null],"text":"We use SNMP to monitor our infrastructur. Unfortunately there's no easy pluggable solution - at least to my knowlegde - to integrate docker into this.\n\n`AgentX` is a [standard protocol](https://www.ietf.org/rfc/rfc2741.txt) to register a sub-agent with an Master SNMP agent for some particular information - plus some more things. Rather than writing a script which uses some hacks to get information about running containers, `docker daemon` could expose this information via `AgentX` to a SNMP-master daemon running on the same node.\n\nI found this [paper](http://research.arpa2.org/library/nyczak-2015-systemd-snmp-zeroconf.pdf) which describes a solution for systemd. And [here's](http://wiki.libvirt.org/page/Libvirt-snmp) the solution for libvirt.\n\nIn general it looks like this:\n\n```\ndocker <--agentx--> snmpd <--snmp--> monitoring solution\n```\n\nDocker would expose information about the service running in it's containers to the snmpd via AgentX-protocol ([RFC](https://www.ietf.org/rfc/rfc2741.txt)).\n\nWhat do you think? Does this makes sense?\n"},{"labels":["api",null],"text":"As of docker 1.8,\nDocker uses invalid JSON format in some API functions, as they reply with header `Content-Type: application/json`. So I expect they reply valid JSON.\n- /build\n- /images/create\n- /images/(name)/push\n- /events\n\nThis make parsing the output of these functions troublesome.\n"},{"labels":["api",null,null],"text":"Description of problem:\n\nAs described in the docs for [`/containers/(id)/logs`](https://docs.docker.com/reference/api/docker_remote_api_v1.20/#get-container-logs), the response Content-Type should be `application/vnd.docker.raw-stream`. Actually, it is always `text/plain`, using the current Docker 1.8.2 release.\n\nThings become a bit more complex, though, because plain text works well as long as the container isn't running in detached mode (Config.Tty = false). Only for a detached container the logs will be a raw stream, supporting multiplexing on stdout and stderr.\n\nFor consistency with `../attach`, it would be nice to always return the raw stream (and declare it correctly via `Content-Type`), with disabled multiplexing for attached containers.\n\nIf you like, I can try to create a PR, but I was a bit lost in the different router/cli/daemon source files... any pointer or suggestions how to tackle this would help!\n\n`docker version`:\n\n```\nClient:\n Version:      1.8.2\n API version:  1.20\n Go version:   go1.4.2\n Git commit:   0a8c2e3\n Built:        Thu Sep 10 19:10:10 UTC 2015\n OS/Arch:      darwin/amd64\n\nServer:\n Version:      1.8.2\n API version:  1.20\n Go version:   go1.4.2\n Git commit:   0a8c2e3\n Built:        Thu Sep 10 19:10:10 UTC 2015\n OS/Arch:      linux/amd64\n```\n\n`docker info`:\n\n```\nContainers: 3\nImages: 97\nStorage Driver: aufs\n Root Dir: /mnt/sda1/var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 103\n Dirperm1 Supported: true\nExecution Driver: native-0.2\nLogging Driver: json-file\nKernel Version: 4.0.9-boot2docker\nOperating System: Boot2Docker 1.8.2 (TCL 6.4); master : aba6192 - Thu Sep 10 20:58:17 UTC 2015\nCPUs: 1\nTotal Memory: 1.956 GiB\nName: default\nID: BDI6:3E4G:RBCP:BURV:FYFE:GEPK:J4QI:53U4:HKG4:ZUJW:XFCL:7A72\nDebug mode (server): true\nFile Descriptors: 14\nGoroutines: 23\nSystem Time: 2015-10-09T15:50:19.097175534Z\nEventsListeners: 0\nInit SHA1: \nInit Path: /usr/local/bin/docker\nDocker Root Dir: /mnt/sda1/var/lib/docker\nUsername: gesellix\nRegistry: https://index.docker.io/v1/\nLabels:\n provider=virtualbox\n```\n\n`uname -a`:\n\n```\nDarwin foo.bar 15.0.0 Darwin Kernel Version 15.0.0: Wed Aug 26 16:57:32 PDT 2015; root:xnu-3247.1.106~1/RELEASE_X86_64 x86_64\n```\n\nEnvironment details (AWS, VirtualBox, physical, etc.):\nMac w/ Docker Toolbox\n\nHow reproducible:\nalways\n\nSteps to Reproduce:\n1. run the Docker daemon\n2. `docker run -d --name container-id busybox:latest ping 127.0.0.1`\n3. `GET https://docker.host:2376/containers/container-id/logs?follow=true&stdout=true&stderr=true&timestamps=false&since=0`\n\nActual Results:\n\n```\nHTTP/1.1 200 OK\nContent-Type: text/plain; charset=utf-8\nDate: Fri, 09 Oct 2015 15:55:53 GMT\nServer: Docker/1.8.2 (linux)\nTransfer-Encoding: chunked\n```\n\nExpected Results:\n\n```\nHTTP/1.1 101 UPGRADED\nConnection: Upgrade\nContent-Type: application/vnd.docker.raw-stream\nDate: Fri, 09 Oct 2015 15:55:53 GMT\nUpgrade: tcp\nServer: Docker/1.8.2 (linux)\n```\n\nAdditional info:\n"},{"labels":["api",null,null],"text":"In many cases, it might be required for the user to be aware of the NUMA topology of the docker host in order to specify valid 'cpuset' for the containers.Currently NUMA topology information is not available via docker APIs. It's available by using commands like numactl or lscpu or via sysfs. \nThis proposal is for considering addition of NUMA topology info to docker Info API so that the same can be used by users or swarm in future.\n\nHere is an example on how the extended info API might look like:\n\n```\nroot@ubuntu:~/docker/bundles/1.8.0/binary# echo -e \"GET /info HTTP/1.0\\r\\n\" | nc -U /var/run/docker.sock\nHTTP/1.0 200 OK\nContent-Type: application/json\nServer: Docker/1.8.0 (linux)\nDate: Mon, 05 Oct 2015 06:52:06 GMT\nContent-Length: 1136\n\n{\"ID\":\"KFL7:6UJ7:QM6U:F3JV:VHPQ:4QKX:KLAB:YRLU:N25F:PD57:PYWZ:XM32\",\"Containers\":17,\"Images\":60,\"Driver\":\"aufs\",\"DriverStatus\":[[\"Root Dir\",\"/var/lib/docker/aufs\"],[\"Backing Filesystem\",\"extfs\"],[\"Dirs\",\"94\"],[\"Dirperm1 Supported\",\"true\"]],\"MemoryLimit\":true,\"SwapLimit\":false,\"CpuCfsPeriod\":true,\"CpuCfsQuota\":true,\"IPv4Forwarding\":true,\"BridgeNfIptables\":true,\"BridgeNfIp6tables\":true,\"Debug\":false,\"NFd\":34,\"OomKillDisable\":true,\"NGoroutines\":27,\"SystemTime\":\"2015-10-05T06:52:06.053388928Z\",\"ExecutionDriver\":\"native-0.2\",\"LoggingDriver\":\"json-file\",\"NEventsListener\":0,\"KernelVersion\":\"3.19.0-25-generic\",\"OperatingSystem\":\"Ubuntu 14.04.3 LTS\",\"IndexServerAddress\":\"https://index.docker.io/v1/\",\"RegistryConfig\":{\"InsecureRegistryCIDRs\":[\"127.0.0.0/8\"],\"IndexConfigs\":{\"docker.io\":{\"Name\":\"docker.io\",\"Mirrors\":null,\"Secure\":true,\"Official\":true}},\"Mirrors\":null},\"InitSha1\":\"\",\"InitPath\":\"/root/docker/bundles/1.8.0/binary/docker\",\"NCPU\":4,\"MemTotal\":4144381952,\"DockerRootDir\":\"/var/lib/docker\",\"HttpProxy\":\"\",\"HttpsProxy\":\"\",\"NoProxy\":\"\",\"Name\":\"ubuntu\",\"Labels\":null,\"ExperimentalBuild\":false,\"NumaNodes\":1,\"NodeCpus\":\"0-3\\n\"}\n```\n\nHere is what \"numactl -H\" output looks like:\n\n```\nroot@ubuntu:~/docker/bundles/1.8.0/binary# numactl -H\navailable: 1 nodes (0)\nnode 0 cpus: 0 1 2 3\nnode 0 size: 3952 MB\nnode 0 free: 1450 MB\nnode distances:\nnode   0 \n  0:  10 \n```\n\nThe API will result in showing number of numa nodes and the cpus in each node. The following code(a rough draft) can be added to daemon/info.go in order to scan sysfs and retrieve the numa topology:\n\n```\n       nodes, _ := filepath.Glob(\"/sys/devices/system/node/\" + \"/node*\")\n        num := len(nodes)\n\n        val := \"\"\n        for i:=0; i<len(nodes); i++ {\n\n                new, _ := filepath.Glob(nodes[i] + \"/cpulist\")\n                read, _ := ioutil.ReadFile(new[0])\n                val += string(read)\n        }\n```\n\nThe info structure can be modified by adding NumaNodes and NodeCpus:\n\n```\nv := &types.Info{\n                ID:                 daemon.ID,\n                Containers:         len(daemon.List()),\n                Images:             imgcount,\n                Driver:             daemon.GraphDriver().String(),\n                DriverStatus:       daemon.GraphDriver().Status(),\n                IPv4Forwarding:     !daemon.SystemConfig().IPv4ForwardingDisabled,\n                BridgeNfIptables:   !daemon.SystemConfig().BridgeNfCallIptablesDisabled,\n                BridgeNfIp6tables:  !daemon.SystemConfig().BridgeNfCallIp6tablesDisabled,\n                Debug:              os.Getenv(\"DEBUG\") != \"\",\n                NFd:                fileutils.GetTotalUsedFds(),\n                NGoroutines:        runtime.NumGoroutine(),\n                SystemTime:         time.Now().Format(time.RFC3339Nano),\n                ExecutionDriver:    daemon.ExecutionDriver().Name(),\n                LoggingDriver:      daemon.defaultLogConfig.Type,\n                NEventsListener:    daemon.EventsService.SubscribersCount(),\n                KernelVersion:      kernelVersion,\n                OperatingSystem:    operatingSystem,\n                IndexServerAddress: registry.IndexServer,\n                RegistryConfig:     daemon.RegistryService.Config,\n                InitSha1:           dockerversion.INITSHA1,\n                InitPath:           initPath,\n                NCPU:               runtime.NumCPU(),\n                MemTotal:           meminfo.MemTotal,\n                DockerRootDir:      daemon.Config().Root,\n                Labels:             daemon.Config().Labels,\n                ExperimentalBuild:  utils.ExperimentalBuild(),\n                NumaNodes:          num,\n                NodeCpus:           val,\n        }\n```\n\nIt further can be extended to scan more options other that NUMA topology to help users make better decisions.\n"},{"labels":["api",null,null],"text":"https://github.com/docker/compose/issues/1510 is one example of where this would be used. We use labels to track containers within a project.\n\n+area/api\n+kind/enhancement\n"},{"labels":["api",null],"text":"This is a quick write up of a design to enable programmatic bootstrapping of a Docker cluster.  I will quickly submit a PR if we can decide this is generally the right direction.  The motivation of this is to allow bootstrapping a cluster in a more user friendly fashion and additionally allow scripts and other programs to setup a cluster without having to deal with distro specific configuration files to handle daemon flags.\n## API\n\n`POST /join`\n\n``` json\n{\n  \"DiscoveryBackend\": \"...\",\n  \"DiscoveryAddress\": \"...\",\n  \"KvStore\": \"...\",\n}\n```\n## CLI\n\n`docker join --backend ... --address .. --kv-store ...`\n## Design\n\nIf no options are passed as daemon flags for `--discovery-backend`, `--discovery-address`, and `--kv-store` then the `/join` API can be used.  If any of those daemon flags are set the `/join` API should fail.  When POST-ing to `/join` the three arguments will be passed to `pkg/discovery` to initialize the discovery backend.  Additionally these parameters will be saved in `/var/lib/docker/discovery/config.json` to be used if the daemon restarts.\n\nOn start of the daemon discovery info will be read first from the CLI and then if not available will look in `/var/lib/docker/cluster/config.json`\n"},{"labels":["api",null,null,null],"text":"Hi guys,\n\nWe use swarm as orchestration tools. And we add labels on docker daemon to let swarm to do some specific scheduling, such as schedule redis container to the docker daemon which has `ssd` label.\n\nBut in some case, we need to change the docker daemon labels, such as we want add MapR-ability label to some daemon in the midnight, so the map reduce container could be scheduled to this daemon. \n\nThere's no API to change the daemon labels on the fly, and we can't afford to restart daemon. So we want add API to do that, such as:\n\n```\nUsage: docker labels [COMMAND] [OPTION]\n\nManage docker daemon labels:\n\nlist - show the docker daemon labels.\nadd - add new labels to docker daemon, docker labels add --label=[k=v]\nremove - remove any exist labels from docker daemon, docker labels remove --label=[k]\n```\n"},{"labels":["api",null,null,null],"text":"I have created an image from a running container - all good so far.\n\n```\nroot@scw-ec24f6:~# docker images\nREPOSITORY               TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nkapolos/armhf-arangodb   2.7.0-devel         6515245edb56        3 minutes ago       1.564 GB\n[...skipped...]\n```\n\nI realize I forgot to clean some files, I remove them on the still running container and commit again\n\n```\nroot@scw-ec24f6:~# docker commit hopeful_bose kapolos/armhf-arangodb:2.7.0-devel\n0bbc0ce06368e8a923737b4c8505d4157d43399495a72cf6a39b606a1b24e9ed\n```\n\nAnd then...\n\n```\nroot@scw-ec24f6:~# docker images\nREPOSITORY               TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nkapolos/armhf-arangodb   2.7.0-devel         0bbc0ce06368        44 seconds ago      -1.956e+09 B\n```\n\nNegative volume is awesome but might be slightly problematic :) Pushing the image to the hub, I see the actual size is 938MB, which sounds right.\n\n```\nDocker version 1.8.1, build d12ea79-dirty\n```\n\n```\narmhf arch\n```\n"},{"labels":["api",null],"text":"It would be useful to have a list of error codes and their corresponding cause. This could be in a tabular format such as:\n\n| Error Code | Meaning |\n| --- | --- |\n| NNN | Text |\n| NNN | Text |\n"},{"labels":["api",null,null],"text":"Right now the API will send an error when someone tries to call `stop` or `kill` on a paused container.\nThis is because signals alone don't do anything to processes that have been frozen by cgroup freezer.\n\nHowever once the process is unfrozen the kernel will go ahead and send those signals.\nWe should be able to update the API to go ahead and send the requested signal to the container, then automatically unpause it.\n\nThis is better than asking the user to unpause it first as the container may be paused due to some bad behavior in the container.\n\nIntroducing this behavior would also allow us to remove the work-around added in #13304\n"},{"labels":["api",null],"text":"In [pulp](https://pulp-docker.readthedocs.org/en/latest/) you can store docker images and serve them via readonly registry API. The way v1 content is uploaded is that you `docker save` the image and upload it to pulp via pulp's API. With v2, we would like to upload blobs and manifest directly. Unfortunately there is only a single way to get those: via v2 registry API. That's pretty cumbersome.\n\nWould it possible for docker client to output manifest and blobs?\n\nI have in mind something like:\n\n```\n$ docker manifest <image>\n{\n   \"name\": \"image\",\n   \"tag\": \"latest\",\n   \"architecture\": \"amd64\",\n   \"fsLayers\": [\n      {\n         \"blobSum\": \"sha256:074533a2d610d82f28097af30284da4077614e30cb0171f0d8d859d2bd294d74\"\n      },\n...\n```\n\nand\n\n```\n$ docker export -o blob.tar.gz --blob sha256:074533a2d610d82f28097af30284da4077614e30cb0171f0d8d859d2bd294d74\n```\n\nThis is _not_ a dupe of https://github.com/docker/distribution/issues/727\n"},{"labels":["api",null,null,null],"text":"Currently the output of `docker info` looks like:\n\n```\n$ docker info\nContainers: 1362\nImages: 145\nStorage Driver: overlay\n Backing Filesystem: extfs\nExecution Driver: native-0.2\nLogging Driver: json-file\nKernel Version: 4.1.4-1-ARCH\nOperating System: Arch Linux\nCPUs: 8\nTotal Memory: 15.6 GiB\nName: archbox\nID: OUQD:OBQE:7KQO:2FQ5:YJIC:ILXS:O7SE:PWEK:3ZWT:PG7I:RUPA:2EIW\n```\n\nThis does not really help at a first glance to assess how many containers are running on a machine. Indeed on those **1362** containers, I only have **10** _running_ containers, the rest are _stopped_. I might have a few _paused_ containers too.\n\nThis would be useful in `docker info` to show more informations on the current state of containers:\n\n```\n$ docker info\nContainers: 1362\n Running: 8\n Paused: 2\n Stopped: 1352\nImages: 145\nStorage Driver: overlay\n Backing Filesystem: extfs\nExecution Driver: native-0.2\nLogging Driver: json-file\nKernel Version: 4.1.4-1-ARCH\nOperating System: Arch Linux\nCPUs: 8\nTotal Memory: 15.6 GiB\nName: archbox\nID: OUQD:OBQE:7KQO:2FQ5:YJIC:ILXS:O7SE:PWEK:3ZWT:PG7I:RUPA:2EIW\n```\n\nThis also means adding this to the remote API on `/info`. This way we can also use it in Swarm as a quick way to assess the load on machines (see related issue on the Swarm side docker/swarm#1140)\n\nI agree that this information is provided somehow by `docker ps` but this could be an added convenience to have this on `info` :smiley:\n"},{"labels":["api",null,null],"text":"Hi All,\n\nNow that volume plugins were added to Docker experimental channel, I would like to suggest adding server-side plugins for handling Docker commands. This will allow Docker users to achieve similar capabilities as supplied by [PowerStrip](https://github.com/ClusterHQ/powerstrip).\n\nThe server side command handler plugins are pre/post extension to Docker command handling, allowing to modify input commands before processed by Docker engine, and output data after processed by Docker Engine (but before sent to client). It will allow adding new capabilities into Docker engine, implemented as out-of-process plugins.\n\nI've implemented a similar mechanism for a project I am working on. I'll be glad to get your feedback on the design and contribute the code if it makes sense.\n## Plugin Mechanics\n\nThe Command Handler plugins are similar to [Volume Plugins](https://github.com/docker/docker/blob/master/experimental/plugin_api.md): \n- Processes running on same host as Docker Engine. \n- Registered by placing a file in `/usr/share/docker/plugins/srv/cmd`. \n- There can be two type of plugin files:\n  - `.sock` files are UNIX domain sockets.\n  - `.spec` files are text files containing a URL, such as unix:///other.sock.\n- The name of the file (excluding the extension) determines the plugin name.\n- Plugins should be started before Docker, and stopped after Docker.\n- The Plugin API is RPC-style JSON over HTTP. Requests flow from the Docker daemon to the plugin.\n## Plugin Initialization\n\nUnlike volume plugins, the command handler plugins should be initialized upon Docker Engine startup. \nDocker Engine sends a /Plugin.Activate request and receives list of commands and type of handling (input or output) that plugin is interested in.\n### /Plugin.Activate\n\n**Request:** empty body\n\n**Response:**\n\n```\n{\n    \"Implements\": [\n        {\"cmd\":\"run\", \"type\":\"input\"}, \n        {\"cmd\":\"stop\", \"type\":\"input\"}, \n        {\"cmd\":\"inspect\", \"type\":\"output\"}\n    ]\n}\n```\n## Plugin Invocation\n\nOnce a plugin is registered for set of commands, Docker Engine calls the plugin before processing the command (\"input\" command handler) and before sending the output to client (\"output\" command handler). \n\nPlugin invocation is done by calling /Plugin.Execute request, while passing type of processing (input or output) and the associated payload (complete input command or output message).\n### /Plugin.Execute\n\n**Request:** \n\n```\n{\n    \"Command\": \"run\",\n    \"Type\": \"input\" or \"output\"\n    \"Payload\": { COMMAND PAYLOAD }\n}\n```\n\n**Response:**\n\n```\n{\n    \"Action\": \"continue\" or \"stop\"\n    \"Payload\": {UPDATED PAYLOAD}\n    \"Return_Code\": 0\n    \"Error_Msg\": {OPTIONAL ERROR MESSAGE}        \n}\n```\n\nDocker Engine should block until plugin responds back (timeouts?). It will continue processing the command in case the plugin responded with \"continue\" response action. It should stop processing the command (and returning return code and message) in case the response action is \"stop\".\n\nIn case of \"continue\" action, Docker Engine should use the Payload returned from the plugin response instead of the original command payload.\nThis allows plugins to modify command input parameters or output data.\n\nNote that multiple command handler plugins can be registered for the same command. Docker Engine will continue calling plugins for the same command as long as it did not get \"stop\" action from one of the handlers. After processing all plugins registered for a command, Docker Engine should continue handling the modified command (as returned from the last plugin).\n## Example Plugins\n\nExample for capabilities we would be able to implement using command handler plugins:\n- Run additional commands before/after container is started/stopped. E.g. when containerA is started/stopped, automatically start/stop containerB.\n- Add missing parameters to command line. E.g. add security parameters (cap-add, cap-drop) even if not specified in command line.\n- Prevent running command with certain parameters.\n- Modify Docker output to include additional data. E.g. modifying 'docker inspect' output to include container start time (or anything else which is useful). Note that this one is tricky as the CLI might be expecting certain outputs.\n"},{"labels":["api",null,null],"text":"Currently the filter for `ps`, `images`, and `events` only work with `key=value`. I was very surprised to learn that there is no `key!=value` expression for exclusion unlike affinity/constraint filters you can set for Docker Swarm. My suggestion is for filter should have the ability to include as well as exclude. Thoughts?\n"},{"labels":["api",null],"text":"**Description of problem**:\nHas the spec for this endpoint been changed in docker 1.7? Using the latest version of https://github.com/fsouza/go-dockerclient against https://master.dockerproject.com/ results in `Unrecognized input header` being returned when calling `client.Stats()`. Works correctly in 1.6. I can dig deeper if this isn't already a known issue.\n\n``` console\n$ docker version\nClient version: 1.6.0\nClient API version: 1.18\nGo version (client): go1.4.2\nGit commit (client): 4749651\nOS/Arch (client): darwin/amd64\nServer version: 1.7.0-dev\nServer API version: 1.19\nGo version (server): go1.4.2\nGit commit (server): 4bcfa47\nOS/Arch (server): linux/amd64\n```\n\n``` console\n$ docker info\nContainers: 5\nImages: 12\nStorage Driver: aufs\n Root Dir: /mnt/sda/var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 22\n Dirperm1 Supported: true\nExecution Driver: native-0.2\nKernel Version: 3.16.1-tinycore64\nOperating System: Boot2Docker 1.2.0 (TCL 5.3); 3.16.1-config-file : e75396e - Fri Aug 22 06:45:30 UTC 2014\nCPUs: 1\nTotal Memory: 495.1 MiB\nName: boot2docker\nID: 4MLS:BGLV:7FJH:UIG7:EOH5:FEME:W6LK:535D:JGRT:JXQI:JZUH:ROXH\nDebug mode (server): true\nDebug mode (client): false\nFds: 81\nGoroutines: 89\nSystem Time: Sat May 23 05:10:21 UTC 2015\nEventsListeners: 13\nInit Path: /usr/local/bin/docker\nDocker Root Dir: /mnt/sda/var/lib/docker\nHttp Proxy:\nHttps Proxy:\nNo Proxy:\nUsername: ejholmes\nRegistry: [https://index.docker.io/v1/]\n```\n\n``` console\n$ uname -a\nLinux boot2docker 3.16.1-tinycore64 #1 SMP Fri Aug 22 06:40:10 UTC 2014 x86_64 GNU/Linux\n```\n\n**Environment details (AWS, VirtualBox, physical, etc.)**:\nAble to reproduce in boot2docker and also on AWS EC2 instances.\n\n**How reproducible**:\n100%\n\n**Steps to Reproduce**:\n1. Run docker 1.7 daemon\n2. Run a container: `docker run -d alpine:3.1 /bin/sh -c \"while true; do echo hello; sleep 1; done\"`\n3. Issue a request to stream the stats for the container with telnet:\n\n``` console\n$ telnet <docker host> <port>\nTrying ::1...\ntelnet: connect to address ::1: Connection refused\nTrying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\nGET /containers/4cda41c21e8d0e41e6da635b12f9e8e13b61f4dc62f7b65a05ff9d60d5393fdb/stats HTTP/1.1\n```\n\n**Actual Results**:\n\nOne stat message is streamed, then a 0 is sent and no more stats are sent after that:\n\n``` console\nHTTP/1.1 200 OK\nDate: Sat, 23 May 2015 05:06:25 GMT\nContent-Type: text/plain; charset=utf-8\nTransfer-Encoding: chunked\n\n560\n{\"read\":\"2015-05-23T05:06:24.831430951Z\",\"network\":{\"rx_bytes\":0,\"rx_packets\":0,\"rx_errors\":0,\"rx_dropped\":0,\"tx_bytes\":0,\"tx_packets\":0,\"tx_errors\":0,\"tx_dropped\":0},\"cpu_stats\":{\"cpu_usage\":{\"total_usage\":847371027,\"percpu_usage\":[847371027],\"usage_in_kernelmode\":50000000,\"usage_in_usermode\":170000000},\"system_cpu_usage\":1878570000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"memory_stats\":{\"usage\":163840,\"max_usage\":1179648,\"stats\":{\"active_anon\":65536,\"active_file\":0,\"cache\":4096,\"hierarchical_memory_limit\":18446744073709551615,\"hierarchical_memsw_limit\":18446744073709551615,\"inactive_anon\":0,\"inactive_file\":0,\"mapped_file\":0,\"pgfault\":58722,\"pgmajfault\":0,\"pgpgin\":19824,\"pgpgout\":19800,\"rss\":94208,\"rss_huge\":0,\"swap\":0,\"total_active_anon\":65536,\"total_active_file\":0,\"total_cache\":4096,\"total_inactive_anon\":0,\"total_inactive_file\":0,\"total_mapped_file\":0,\"total_pgfault\":58722,\"total_pgmajfault\":0,\"total_pgpgin\":19824,\"total_pgpgout\":19800,\"total_rss\":94208,\"total_rss_huge\":0,\"total_swap\":0,\"total_unevictable\":0,\"total_writeback\":0,\"unevictable\":0,\"writeback\":0},\"failcnt\":0,\"limit\":519147520},\"blkio_stats\":{\"io_service_bytes_recursive\":[],\"io_serviced_recursive\":[],\"io_queue_recursive\":[],\"io_service_time_recursive\":[],\"io_wait_time_recursive\":[],\"io_merged_recursive\":[],\"io_time_recursive\":[],\"sectors_recursive\":[]}}\n\n0\n```\n\n**Expected Results**:\n\nI expect a continuous stream of stats to be sent, like below, which was captured against docker 1.6.\n\n``` console\nHTTP/1.1 200 OK\nContent-Type: application/json\nDate: Sat, 23 May 2015 05:03:14 GMT\nTransfer-Encoding: chunked\n\n582\n{\"read\":\"2015-05-23T05:03:14.412287818Z\",\"network\":{\"rx_bytes\":648,\"rx_packets\":8,\"rx_errors\":0,\"rx_dropped\":0,\"tx_bytes\":648,\"tx_packets\":8,\"tx_errors\":0,\"tx_dropped\":0},\"cpu_stats\":{\"cpu_usage\":{\"total_usage\":327891630,\"percpu_usage\":[61105665,115203059,53758803,97824103],\"usage_in_kernelmode\":130000000,\"usage_in_usermode\":20000000},\"system_cpu_usage\":75857340000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"memory_stats\":{\"usage\":454656,\"max_usage\":655360,\"stats\":{\"active_anon\":61440,\"active_file\":4096,\"cache\":8192,\"hierarchical_memory_limit\":18446744073709551615,\"hierarchical_memsw_limit\":18446744073709551615,\"inactive_anon\":0,\"inactive_file\":0,\"mapped_file\":0,\"pgfault\":6277,\"pgmajfault\":0,\"pgpgin\":2199,\"pgpgout\":2161,\"rss\":147456,\"rss_huge\":0,\"swap\":0,\"total_active_anon\":61440,\"total_active_file\":4096,\"total_cache\":8192,\"total_inactive_anon\":0,\"total_inactive_file\":0,\"total_mapped_file\":0,\"total_pgfault\":6277,\"total_pgmajfault\":0,\"total_pgpgin\":2199,\"total_pgpgout\":2161,\"total_rss\":147456,\"total_rss_huge\":0,\"total_swap\":0,\"total_unevictable\":0,\"total_writeback\":0,\"unevictable\":0,\"writeback\":0},\"failcnt\":0,\"limit\":2105860096},\"blkio_stats\":{\"io_service_bytes_recursive\":[],\"io_serviced_recursive\":[],\"io_queue_recursive\":[],\"io_service_time_recursive\":[],\"io_wait_time_recursive\":[],\"io_merged_recursive\":[],\"io_time_recursive\":[],\"sectors_recursive\":[]}}\n\n582\n{\"read\":\"2015-05-23T05:03:15.412531749Z\",\"network\":{\"rx_bytes\":648,\"rx_packets\":8,\"rx_errors\":0,\"rx_dropped\":0,\"tx_bytes\":648,\"tx_packets\":8,\"tx_errors\":0,\"tx_dropped\":0},\"cpu_stats\":{\"cpu_usage\":{\"total_usage\":329912723,\"percpu_usage\":[61402741,116102576,53758803,98648603],\"usage_in_kernelmode\":130000000,\"usage_in_usermode\":20000000},\"system_cpu_usage\":75861300000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"memory_stats\":{\"usage\":401408,\"max_usage\":655360,\"stats\":{\"active_anon\":53248,\"active_file\":4096,\"cache\":8192,\"hierarchical_memory_limit\":18446744073709551615,\"hierarchical_memsw_limit\":18446744073709551615,\"inactive_anon\":0,\"inactive_file\":0,\"mapped_file\":0,\"pgfault\":6326,\"pgmajfault\":0,\"pgpgin\":2216,\"pgpgout\":2174,\"rss\":163840,\"rss_huge\":0,\"swap\":0,\"total_active_anon\":53248,\"total_active_file\":4096,\"total_cache\":8192,\"total_inactive_anon\":0,\"total_inactive_file\":0,\"total_mapped_file\":0,\"total_pgfault\":6326,\"total_pgmajfault\":0,\"total_pgpgin\":2216,\"total_pgpgout\":2174,\"total_rss\":163840,\"total_rss_huge\":0,\"total_swap\":0,\"total_unevictable\":0,\"total_writeback\":0,\"unevictable\":0,\"writeback\":0},\"failcnt\":0,\"limit\":2105860096},\"blkio_stats\":{\"io_service_bytes_recursive\":[],\"io_serviced_recursive\":[],\"io_queue_recursive\":[],\"io_service_time_recursive\":[],\"io_wait_time_recursive\":[],\"io_merged_recursive\":[],\"io_time_recursive\":[],\"sectors_recursive\":[]}}\n```\n\n**Additional info**:\n"},{"labels":["api",null,null],"text":"For day-to-day use and simple scripting purposes It'd be great if the --filter function was extended with filters on more columns.\n\nSpecifically:\n\n```\n$ docker ps --filter image=myname/test \n```\n\nWould be great so we can kill all our tests in one go like so:\n\n```\n$ docker ps --filter image=myname/test -q | xargs docker rm -f\n```\n\nThis is helpful specifically in this combination because I want only image id's to be returned, and |grep thus doesn't work.\n\nOther filters that would make sense to me:\n\n_For images_\n- Repository (with tag)\n- Age? (--filter agemore=4h --filter ageless=2w)\n\n_For containers_\n- Image (with tag)\n- Name (this is implemented by the way https://github.com/docker/docker/issues/10897, but undocumented)\n- Age? (as above)\n- Status (running, exited, etc)\n\n**references**\nI found this ticket: https://github.com/docker/docker/pull/11904 which describes something that sounds similar but (I think) is actually for the bash completion (only).\n"},{"labels":["api",null,null],"text":"As a frequent exporter of docker filesystems, I want an option to tell `docker cp` to copy symlinks as literals, so that my filesystem archives receive the symlinks that my containers contain.\n\nMaybe `docker cp -a`?\n"},{"labels":["api"],"text":"This kind of defeats the purpose of having an API in the first place and is completely unnecessary since the client and the server are typically the same binary.\n"},{"labels":["api",null],"text":"With #10874 I wanted to make sure that the client sent an explicit `no` when you use `--restart=no`, unfortunately in \"fixing\" this issue the \"fix\" on that issue also changed the default value from `--restart=\"\"` to `--restart=\"no\"` which undoes all the advantage of having `--restart=no` pass through `RestartPolicy: \"no\"`. It means that we're once again in a situation where:\n\n```\ndocker run -it ubuntu\n```\n\nand:\n\n```\ndocker run --restart=no -it ubuntu\n```\n\ncannot be distinguished at the server. Previously they could not be distinguished because they would both show up to the API as `RestartPolicy: \"\"`. I filed #10874 with the intention that the first case continue to result in `RestartPolicy: \"\"` and the second case result in `RestartPolicy: \"no\"` so that they could be distinguished.\n\nUnfortunately the change that was actually pushed instead means that in both cases the API will see `RestartPolicy: \"no\"` and they're still indistinguishable.\n"},{"labels":["api",null,null],"text":"**Problem**\n\nThe docker api logs are lacking and can be verbose and not useful.\n\n**Solution**\n\nReview the logging calls in https://github.com/docker/docker/tree/master/api/server and use our standard log package `github.com/Sirupsen/logrus` to make meaningful log messages.\n\nIt could be helpful to remove all existing log calls and then go through and log meaning requests, warnings, errors, and debug messages for the API.\n"},{"labels":["api",null,null],"text":"According to the wikipedia example, DELETE on a resource with no parameters should delete all instances of that resource. Currently, it throws an error saying the null id could not be found:\n\n```\ncloudscaling@mngmt2:~> curl -X DELETE http://localhost:2375/images/\nNo such image:\ncloudscaling@mngmt2:~> curl -X DELETE http://localhost:2375/containers/\nNo such container:\n```\n\n[Wiki](http://en.wikipedia.org/wiki/Representational_state_transfer#Example)\n"},{"labels":["api",null,null],"text":"It is bizarre to me that there is a containers/resize endpoint, but that those parameters are not available to be set on container creation or start. In addition, _calling resize doesn't even work_ - you need to restart the container as well, making the whole flow for creating a TTY of a certain size nigh impossible in the usual Docker flow.\n"},{"labels":["api",null,null],"text":"Generally, a docker command instantiation makes several http requests to a running registry. Processing these requests in the registry server to sessionize the request flow is a non-trivial problem. While we have a proposed `Docker-Command` header in https://github.com/dmcgowan/docker/pull/18, it would be smart to include a unique token for each command execution that is added in a header to support trivial sessionization.\n\nUse cases of these session identifiers include producing usable metrics for private registries or added to outgoing webhooks (docker/distribution#42) for later processing.\n\nThe header would consist of the command that was run (not the entire cli, ie \"push\" or \"pull\") and a session id generated at the start of each instantiation of the docker client process. An example of such a header might be as follows:\n\n```\nDocker-Command: push 3eed4669-d1e8-4753-9420-998e530386b1\n```\n\nThe header could be added to all requests, from the client to the engine and beyond. If taken that far, such a header could support distributed debugging or begin to enable [dapper](http://research.google.com/pubs/pub36356.html)-like analysis.\n"},{"labels":["api",null,null,null],"text":"I use the Docker API, and when I run this request, the tags doesn't return.\n\n```\nGET /images/{id}/json\n```\n\nThis information is given when I list all images.\n\nWhat's the best practices to get image's tags information ?\n"},{"labels":["api",null,null],"text":"Sometimes you have really important containers, like data only containers, that you don't want accidentally deleted.  `docker rm -f $(docker ps -qa)` is just too easy to type sometimes and then, \"oh !@#!\", it's all gone.  (Well not really because you can find your data in `/var/lib/docker/vfs`).  Anyhow, I propose we add the following:\n\n`docker run/create --lock=true ...`\n`docker lock CID`\n`docker unlock CID`\n\nIf one was to do `docker rm CID` and CID was locked it wouldn't delete and exit with an error code.  Start/stop/restart should still work.  This flag is the equivalent of EC2's `DisableApiTermination` flag.  In order to delete a locked container you must first run `docker unlock CID`.\n"},{"labels":["api",null,null,null,null],"text":"The `docker export` command and corresponding API endpoint allow the client to get an archive of the container's root filesystem. This is useful for squashing an entire set of image layers into one, but there's currently no way to get just the file system diff for a container.\n\nThis could be achieved by adding an optional parameter to the container export API endpoint and an optional flag to the `docker export` command: `diff=1` This would instruct the runtime to only return the layer diff for the container rather than the entire filesystem.\n## Why is this useful?\n\nIt would allow for additional functionality in tools which are used to build images like the `docker build` command. Layer archives could be collected by the client, checksums computed for each layer archive, and for images to be built using a new content-addressable format.\n"},{"labels":["api",null],"text":"Currently the `docker cp` command supports copying a file/directory from inside container to the client. I propose that we create a complementary command, perhaps `docker add` or overloading of the `docker cp` command, which does the opposite: copy from `HOSTPATH` to `CONTAINER:PATH`\n## Why is this useful?\n1. It would clear the way for the `docker build` subsystem to be completely removed from the\n   Docker daemon.\n   \n   Most of the functionality of `docker build` is already possible with the API, as every line of a\n   Dockerfile simply creates a container with the current build config, modifies the filesystem of the\n   container in some way (either by ADD/COPY of some resource or by executing a command), then\n   commits the changes as a new Image. All of this is possible with the current Docker Remote API\n   except for ADDing resources to the container.\n   \n   In a brave new world, builds of new images could be orchestrated remotely over the API and\n   ultimately give more power to users who want/need extra functionality in their builds.\n2. Allows for updating containers with miscellaneous data.\n   \n   Such functionality would make it possible for files to be dynamically loaded into a newly created\n   or running container. Things like TLS certificates, keys, or other configuration files could be added\n   to a container before it starts or while it is running, adding all sorts of new possibilities to\n   configuration management tools and scripts.\n"},{"labels":["api",null],"text":"Currently we can only inspect a single image or container. It would be great as part of the listing of all images or containers to be able to specify a parameter, something like '/images/json?inspect=true' which will return all images/containers in their 'inspected format' instead of the summary we get now. Thoughts?\n"},{"labels":["api",null,null],"text":"It would be nice if \"docker images -f\" could also filter by images that were not pushed to the repository after its creation whether by commit, build or import / load.\n\n``` sh\ndocker images -f 'not-pushed=true'\n```\n"},{"labels":["api",null,null,null],"text":"Currently there is no way to attach to an existing exec. If I run `docker exec -di my_container bash`, there is no way to attach to this process, using the command line or the API.\n\nWhat are the steps needed to have such a feature implemented (maybe `docker exec attach :exec_id`)?\n"},{"labels":["api"],"text":"When one calls `/containers/(id)/start` with a command that does not exist (provided to `/containers/create`), the server replies with `HTTP/1.1 500 Internal Server Error` with a payload that explains the failure.\n\nIn contrast, when one calls  `/exec/(id)/start` with a non-existing command (provided to\n`/containers/(id)/exec`), the server answers `HTTP/1.1 200 OK` but embeds in the _docker.raw-stream_ the error `2014/11/30 19:37:16 docker-exec: failed to exec: exec: \"`_‚ü®command‚ü©_`\": executable file not found in $PATH`.  I think it would be better for `/exec/(id)/start` to return a status of 500 as well.\n"},{"labels":["api",null,null],"text":"Docker Remote API already provides a WebSocket endpoint to attach to a container's tty with a WebSocket connection (`/containers/(id)/attach/ws` ‚Äî although not documented).\n\nIt would be great to have this functionality for execs as well. It would let people attach to exec ttys with standard WebSocket libraries and totally avoid HTTP hijacking.\n"},{"labels":["api",null,null],"text":"I came across this when working on the Ruby docker-api gem. If you attempt to start a random Exec instance the response will be a 200. Shouldn't this be a 404?\n\nhttps://gist.github.com/tduffield/21a64cd272962b4345fe\n"},{"labels":["api",null],"text":"It is too complex to set up authenticated https binding. Using ssh subsystem functionality would mean no additional authentication is needed. You can get std in and out and tunnel it to existing http calls, but both client and server have to understand this.\n"},{"labels":["api",null,null],"text":"Currently there is no unique event for when a container is automatically restarted by the daemon.  Such an event _can_ be determined from the sequence of events for a container:\n- restart - die, start, restart\n- stop - die, stop\n- start - start\n- abend - die, start\n\nTrick is to simply track \"die, start\" sequences and check for at some later time the absence or presence of a restart event for the container in question (ugly).  A unique event would be nice, eg:\n- abend - die, start, _autorestarted_ or whatever\n\nUse case is that docker does a nice job of hiding containers that abend by just restarting them.  It would be nice to trap that event to get an idea that it is happening.\n\nDiscussed here on forum:\n\nhttps://forums.docker.com/t/docker-events-when-container-automatically-restarted/356\n"},{"labels":["api"],"text":"I'm trying to mount volumes from other containers. The example format in the [ v1.15 docs](https://docs.docker.com/reference/api/docker_remote_api_v1.15/#start-a-container) doesn't seem to work:\n\n```\nPOST /containers/(id)/start\n{\n    \"VolumesFrom\": [\"data\"],\n    ...\n}\n```\n\nHowever, following the same pattern as `/containers/create` does work:\n\n```\nPOST /containers/(id)/start\n{\n    \"HostConfig\": {\n        \"VolumesFrom\": [\"data\"]\n    }\n    ...\n}\n```\n\nLet me know if I'm missing something obvious here, thanks.\nOther info:\n\n```\n$ uname -a\nDarwin CRP10795M 13.4.0 Darwin Kernel Version 13.4.0: Sun Aug 17 19:50:11 PDT 2014; root:xnu-2422.115.4~1/RELEASE_X86_64 x86_64\n```\n\n```\n$ docker version\nClient version: 1.3.1\nClient API version: 1.15\nGo version (client): go1.3.3\nGit commit (client): 4e9bbfa\nOS/Arch (client): darwin/amd64\nServer version: 1.3.1\nServer API version: 1.15\nGo version (server): go1.3.3\nGit commit (server): 4e9bbfa\n```\n\n```\n$ docker -D info\nContainers: 4\nImages: 116\nStorage Driver: aufs\n Root Dir: /mnt/sda1/var/lib/docker/aufs\n Dirs: 124\nExecution Driver: native-0.2\nKernel Version: 3.16.4-tinycore64\nOperating System: Boot2Docker 1.3.1 (TCL 5.4); master : 9a31a68 - Fri Oct 31 03:14:34 UTC 2014\nDebug mode (server): true\nDebug mode (client): true\nFds: 21\nGoroutines: 18\nEventsListeners: 0\nInit Path: /usr/local/bin/docker\n```\n"},{"labels":["api"],"text":"The API to pull an image is a bit inconsistent.\nIE POST /images/create?fromImage=xxx.xx/asd/qwe\nWhen the pull fails it still returns http status 200, and the response body seems like some sort of pseudo-json like\n{\"status\":\"Pulling repository aaa.com/ns/name\"}\n{\"errorDetail\":{\"message\":\"Error: image ns/name not found\"},\"error\":\"Error: image ns/name not found\"}\n\nwhere it should probably be like \n{\"status\":\"Pulling repository aaa.com/ns/name\",\n\"errorDetail\":{\"message\":\"Error: image ns/name not found\"},\"error\":\"Error: image ns/name not found\"}\n\nand the response status probalby a 422\n\n\"The 422 (Unprocessable Entity) status code means the server understands the content type of the request entity (hence a 415(Unsupported Media Type) status code is inappropriate), and the syntax of the request entity is correct (thus a 400 (Bad Request) status code is inappropriate) but was unable to process the contained instructions.\"\n"},{"labels":["api",null],"text":"After reading through everyone's feedback on https://github.com/docker/docker/issues/8664, I propose adding to docker the metadata equivalent of a \"time last-modified\" metadata common on filesystems. This wouldn't require additional logging or filtering.\n\nThe current state metadata is like this:\n\n```\n\"State\": {\n    \"ExitCode\": 0,\n    \"FinishedAt\": \"0001-01-01T00:00:00Z\",\n    \"Paused\": false,\n    \"Pid\": 19967,\n    \"Restarting\": false,\n    \"Running\": true,\n    \"StartedAt\": \"2014-10-20T10:53:50.649532096Z\"\n},\n```\n\nSo with my proposal here, we could have a new state datapoint for \"ModifiedAt\":\n\n```\n\"State\": {\n    \"ExitCode\": 0,\n    \"FinishedAt\": \"0001-01-01T00:00:00Z\",\n    \"Paused\": false,\n    \"Pid\": 19967,\n    \"Restarting\": false,\n    \"Running\": true,\n    \"StartedAt\": \"2014-10-20T10:53:50.649532096Z\",\n    \"ModifiedAt\": \"2014-10-20T10:55:50.649532096Z\"\n},\n```\n\nOn container start, ModifiedAt would be set to the same at StartedAt. And docker exec calls on a running container would update the ModifiedAt field.\n\nthoughts? @jpetazzo @crosbymichael smells ok? :-)\n"},{"labels":["api"],"text":"With docker 1.11, a POST to /containers/$id/start with {\"PublishAllPorts\": true} would start the container and bind exposed ports as expected.\n\nAfter upgrading to 1.12, the container no longer binds any ports.\n\nAPI docs show no changes in this area - did something change, or is this a regression?\n"},{"labels":["api",null,null],"text":"Right now the remote API does not allow running clients with a newer API version than the daemon.\n\n```\n$ docker ps\n2014/08/26 14:21:03 Error response from daemon: client and server don't have same version (client : 1.13, server: 1.12)\n```\n\nThis message is misleading/incorrect. The code in question is [daemon.go:1057](https://github.com/docker/docker/blob/c4a190db0c7020ee39672421d1bbca3678f86683/api/server/server.go#L1057), which is checking to see that the client API is **newer** than the server API, not different. That code would happily allow running a client which is older than the server.\n\nThis brings me to the next point, why does it allow running an older client, but not a newer one?\nThis is extremely irritating to work with as I have to keep a separate client which is older than all the remote servers I end up working with.\nThe remote API changes between versions are usually so trivial, that in my opinion, this restriction is not warranted.\n\nCan we either:\n1. Fix the message to indicate that the client API is newer than the server API.\n2. Remove the restriction altogether and just display a warning.\n\nI would much prefer # 2.\n"},{"labels":["api",null,null],"text":"Make `docker cp` work more like `scp`\n\n`Usage: docker cp CONTAINER:PATH HOSTPATH`\n## Proposed\n\n1 Allow the `PATH` to contain standard filesystem wildcards, and then expand them on the container side.\n2 Allow the `HOSTPATH` to be the resulting filename _if_ the daemon sends it a single file. \n## right now\n\n`HOSTPATH` is a dir, which will even be created for you - rather than the name of the resulting file, and wildcards are not expanded.\n\n```\ntmp $ mkdir sven\ntmp $ docker cp sven:/etc/* sven\n2014/08/25 14:22:37 Error response from daemon: Could not find the file /etc/* in container sven\ntmp $ docker cp sven:/etc/passwd sven/banana\ntmp $ ls sven/\nbanana  passwd\ntmp $ more sven/*\n\n*** sven/banana: directory ***\n\ntmp $ cd sven\nsven $ docker cp sven:/etc/* .\n2014/08/25 14:22:23 Error response from daemon: Could not find the file /etc/* in container sven\n```\n"},{"labels":["api",null,null],"text":"Here are some calls and their endpoints:\n- List images: `/images/json`\n- Get image: `/images/{{image}}/json`\n- Get image history `/images/{{image}}/history`\n\nFirst of all having `json` in the URL does not make sense. Either get that json/xml information from `Accept-Type` header or a query string like `?output=json` (or even worse, use `.json` extension at the end of the URI).\n\nBy having URLs like I listed above you just made `history` a same-level or same-type of  thing as `json`, which is not correct. (and \"get image history\" does not end with `.../json` either.)\n\nIf this would be my API I would go for:\n- List images: `/images`\n- Get image: `/images/{{image}}`\n- Get image history `/images/{{image}}/history`\n\nI just looked at these 3 calls in the entire API and found that problem, I will be updating this issue as I go.\n\nFixing this would be a breaking API change, just leaving this here for future reference.\n"},{"labels":["api"],"text":"`/image/json` call responds `Created` field with UNIX epoch:\n\n``` json\n[{\"Created\":1405979233,\"Id\":\"ba5877dc9beca5a0af9521846e79419e98575a11cbfe1ff2ad2e95302cff26bf\",\"ParentId\":\"2318d26665eff33e9f91c4c99036751afb40eb58f944a585372bec1407828ad3\",\"RepoTags\":[\"ubuntu:latest\"],\"Size\":0,\"VirtualSize\":192735895}\n```\n\n`/image/{{name}}/json` call responds `Created` field with ISO 8601 String.\n\n``` json\n{...\n  \"Created\": \"2014-07-21T21:47:13.032415435Z\",\n...}\n```\n\nThis doesn't make sense. I am having really hard time writing an API client due to different deserialization of DateTime formats because you have more than one DateTime format in the API.\n\n(I'm using API v1.13)\n"},{"labels":["api"],"text":"I am using the [Dockerode](https://github.com/apocas/dockerode) npm module to interface with the Docker API on a local machine.\n\nIf I specify an integer PortBindings value when calling the API to start an existing container (i.e. POST /containers/(id)/start), it fails to take effect. For instance, if my passed config is:\n\n``` javascript\n{ \"Binds\":[\"/var/lib/mongo/data:/data/db\"],\"PortBindings\":{\"27017/tcp\":[{\"HostPort\":27017}]} }\n```\n\nthen it fails, but if it is:\n\n``` javascript\n{ \"Binds\":[\"/var/lib/mongo/data:/data/db\"],\"PortBindings\":{\"27017/tcp\":[{\"HostPort\":\"27017\"}]} }\n```\n\nthen it works (notice the 27017 is a string in the second version). This was confusing because I expected that the port number, being a native integer, would be valid and correct. \n\nI had to cast my Integer to a String in order to have it take effect (but not before spending a large amount of time narrowing down the issue).\n"},{"labels":["api",null],"text":"In addition to work in #5893 and related issues. \n# Refactoring Docker Remote API Client\n## What's wrong\n\nThe docker remote api isn't easy to use because:\n- There's no official client to the API\n- Much of the validation the CLI provides is in the CLI code, not the\n  API layer\n- The documentation doesn't always show a proper mapping of CLI commands\n  to API calls (e.g. `docker run` involves multiple steps)\n- The CLI code is cluttered with many concerns and makes understanding\n  how to use the API properly by example difficult\n- Marshaling/Unmarshaling in Go should use the same structures as the\n  internal code for easier code sharing (i.e. dont require consumers to\n  implement a `type Containers struct` for unmarshalling the output of\n  `docker ps`)\n## How to fix\n\nPropose:\n- Creating an official API client for use in the CLI tool\n- Exposing proper validation from the API layer or in the API client\n- Simplifying the CLI code and breaking commands down into smaller files\n  so they're easier to understand.\n- Leverage pre-existing types when (un)serializing calls from the API\n## Proposed implementation\n\nSee https://gist.github.com/mcculloughsean/5c1dd3cc674e6fd583f5#file-proposal-go for example code. \n### Creating an official client\n\nComposes ['Call'](https://github.com/docker/docker/blob/403df1765abfd3ac62b7f6b8bd709fb0d691d8c8/api/client/utils.go#L42-L42) with commands to create a fetcher per endpoint in the API with proper unmarshalling.\n### Reimplement CLI in terms of API client\n\nUse existing types for marshaling/unmarshaling JSON data for use in Go\ncode.\n\nMove formatting to methods for CLI stringification.\n\nCreate helper methods to generate valid query strings.\n### Push validations down to API as much as possible\n\nRemove all checks from the CLI level that can easily live in the API\nlayer.\n\nCreate a common pattern for passing validation errors back up through\nthe API pipeline (maybe by switching unmarshaling strategy based on http\nstatus code)\n\nEnsure that validation failure messages are verbose. e.g.:\n\n``` bash\n$curl -v -H \"Content-Type: application/json\" -d \"{\\\"Hostname\\\":\\\"\\\",\\\"User\\\":\\\"\\\",\\\"Memory\\\":0,\\\"MemorySwap\\\":0,\\\"AttachStdin\\\":false,\\\"AttachStdout\\\":true,\\\"AttachStderr\\\":true,\\\"PortSpecs\\\":null,\\\"Tty\\\":false,\\\"OpenStdin\\\":false,\\\"StdinOnce\\\":false,\\\"Env\\\":null,\\\"Cmd\\\":[\\\"date\\\"],\\\"Image\\\":\\\"repository.snc1/candyland/echo-fedora\\\",\\\"Volumes\\\":{\\\"/tmp\\\":{}},\\\"WorkingDir\\\":\\\"\\\",\\\"DisableNetwork\\\":false,\\\"ExposedPorts\\\":{\\\"22/tcp\\\":{}}}\" http://localhost:12345/containers/create?name=foo\n* About to connect() to localhost port 12345 (#0)\n*   Trying ::1... Connection refused\n*   Trying 127.0.0.1... connected\n* Connected to localhost (127.0.0.1) port 12345 (#0)\n> POST /containers/create?name=foo HTTP/1.1\n> User-Agent: curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.15.3 zlib/1.2.3 libidn/1.18 libssh2/1.4.2\n> Host: localhost:12345\n> Accept: */*\n> Content-Type: application/json\n> Content-Length: 340\n>\n< HTTP/1.1 201 Created\n< Content-Type: application/json\n< Date: Thu, 31 Jul 2014 21:54:33 GMT\n< Content-Length: 90\n<\n{\"Id\":\"2d3a1faaa6d83680ddb4164dc39755ef18fab37b4bf66e88f62bd00168547faa\",\"Warnings\":null}\n* Connection #0 to host localhost left intact\n* Closing connection #0\n\n$curl -v -H \"Content-Type: application/json\" -d \"{\\\"Hostname\\\":\\\"\\\",\\\"User\\\":\\\"\\\",\\\"Memory\\\":0,\\\"MemorySwap\\\":0,\\\"AttachStdin\\\":false,\\\"AttachStdout\\\":true,\\\"AttachStderr\\\":true,\\\"PortSpecs\\\":null,\\\"Tty\\\":false,\\\"OpenStdin\\\":false,\\\"StdinOnce\\\":false,\\\"Env\\\":null,\\\"Cmd\\\":[\\\"date\\\"],\\\"Image\\\":\\\"repository.snc1/candyland/echo-fedora\\\",\\\"Volumes\\\":{\\\"/tmp\\\":{}},\\\"WorkingDir\\\":\\\"\\\",\\\"DisableNetwork\\\":false,\\\"ExposedPorts\\\":{\\\"22/tcp\\\":{}}}\" http://localhost:12345/containers/create?name=foo\n* About to connect() to localhost port 12345 (#0)\n*   Trying ::1... Connection refused\n*   Trying 127.0.0.1... connected\n* Connected to localhost (127.0.0.1) port 12345 (#0)\n> POST /containers/create?name=foo HTTP/1.1\n> User-Agent: curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.15.3 zlib/1.2.3 libidn/1.18 libssh2/1.4.2\n> Host: localhost:12345\n> Accept: */*\n> Content-Type: application/json\n> Content-Length: 340\n>\n< HTTP/1.1 500 Internal Server Error\n< Content-Type: text/plain; charset=utf-8\n< Date: Thu, 31 Jul 2014 21:54:35 GMT\n< Content-Length: 53\n<\nAbort due to constraint violation: constraint failed\n```\n\nThe second error message isn't useful. The dockerd logs themselves\naren't useful either:\n\n```\n[debug] server.go:999 Calling POST /containers/create\n2014/07/31 21:54:33 POST /containers/create?name=foo\n[ead17ee3] +job create(foo)\n[error] mount.go:11 [warning]: couldn't run auplink before unmount:\nexec: \"auplink\": executable file not found in $PATH\n[ead17ee3] -job create(foo) = OK (0)\n[debug] server.go:999 Calling POST /containers/create\n2014/07/31 21:54:35 POST /containers/create?name=foo\n[ead17ee3] +job create(foo)\nAbort due to constraint violation: constraint failed\n[ead17ee3] -job create(foo) = ERR (1)\n[error] server.go:1025 Error: Abort due to constraint violation:\nconstraint failed\n[error] server.go:90 HTTP Error: statusCode=500 Abort due to constraint\nviolation: constraint failed\n```\n"},{"labels":["api"],"text":"It would be super helpful if the documentation for this endpoint explained or listed a small note about what each of the parameters actually do and what the possible values for properties who's values are objects.\n\nI am aware that this is the same object gleamed from `docker inspect` however to my knowledge this structure isn't precisely described in any part of the documentation. \n\nFor example, the documentation has the following text:\n\n```\n {\n         \"Hostname\":\"\",\n         \"User\":\"\",\n         \"Memory\":0,\n         \"MemorySwap\":0,\n         \"AttachStdin\":false,\n         \"AttachStdout\":true,\n         \"AttachStderr\":true,\n         \"PortSpecs\":null,\n         \"Tty\":false,\n         \"OpenStdin\":false,\n         \"StdinOnce\":false,\n         \"Env\":null,\n         \"Cmd\":[\n                 \"date\"\n         ],\n         \"Image\":\"base\",\n         \"Volumes\":{\n                 \"/tmp\": {}\n         },\n         \"WorkingDir\":\"\",\n         \"DisableNetwork\": false,\n         \"ExposedPorts\":{\n                 \"22/tcp\": {}\n         }\n    }\n```\n\nI think we should denote what the possible values of the properties such as `ExposedPorts`, `Volumes`, and `Cmd` in the section for this endpoint, or describe the configuration structure elsewhere and link to it from here, and similiar endpoints that utilize it like the inspection endpoint (/containers/(id)/json)\n"},{"labels":["api"],"text":"\"docker inspect mycontainer\" does not show container's IPv6 address:\n\n```\n\"NetworkSettings\": {\n    \"Bridge\": \"docker0\",\n    \"Gateway\": \"172.17.42.1\",\n    \"IPAddress\": \"172.17.0.8\",\n    \"IPPrefixLen\": 16,\n    \"PortMapping\": null,\n    \"Ports\": {}\n},\n```\n\nthe ifconfig output inside the container:\n\n```\nroot@5f54af0a7db0:/# ifconfig\neth0  Link encap:Ethernet  HWaddr 96:79:64:33:6f:17\n      inet addr:172.17.0.9  Bcast:0.0.0.0  Mask:255.255.0.0\n      inet6 addr: 2a11:4f8:140:2425:9479:64ff:fe33:6f17/64 Scope:Global\n      inet6 addr: fe80::9479:64ff:fe33:6f17/64 Scope:Link\n      UP BROADCAST RUNNING  MTU:1500  Metric:1\n      RX packets:13 errors:0 dropped:4 overruns:0 frame:0\n      TX packets:7 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:1000\n      RX bytes:1490 (1.4 KB)  TX bytes:586 (586.0 B)\n```\n\nIt would be nice to have a key \"IPv6Address\" under \"NetworkSettings\".\n"},{"labels":["api",null,null],"text":"Would it be possible to \"pin\" a container so that it needs to have an extra flag passed to it (something like `--purge`) in order for the container to actually be deleted via `docker rm` or similar commands?\n"},{"labels":["api",null],"text":"There are a few issues that ask for specific hooks, but none of them have apparently been fully addressed. The ones that are closed were promised a \"generic\" hooks mechanism for all commands/events.\n\nA few usecases from reading the issues:\n- shutdown hook (EXITPOINT ?) for gracefulness (#2100)\n- start hook (#252 is a bit old, and #3317)\n\nFrom https://github.com/GoogleCloudPlatform/kubernetes/issues/140#issuecomment-48602271:\n\n> [...] we felt there were two cases we wanted to handle:\n> - hooks that either need the container context (and as such executing outside the process namespace would be pointless), or if interrupted by container shutdown would not be internally inconsistent. Pre-termination is a good example\n> - hooks that should be outside of a container, because they need to continue to run even if a container fails. Deploy across multiple containers is a good example, or post-termination.\n\nPlease feel free to comment with more.\n\nIt makes sense to offer hooks for greater customization, however, this might affect the current way of doing things (see the `exec` discussion in https://github.com/dotcloud/docker/issues/3317#issuecomment-31273101)\n\nFor solutions, there was a mention of \"predefined paths\" for executables.\n\nSome hooks (start and shutdown) would be more useful if they were executed synchronously (unlike how `docker events` fires currently).\n\nWe need to define what hooks should be implemented in docker and what should be done externally via docker events.\n"},{"labels":["api"],"text":"When a build fails, the http request returns a 200 response.  A failure response would be more appropriate.  An example http response from a failure:\n\n``` clj\n{:status 200,\n :body \"{\\\"stream\\\":\\\"Step 0 : FROM java\\\\n\\\"}\n        {\\\"status\\\":\\\"Pulling repository java\\\"}\n        {\\\"errorDetail\\\":{\\\"message\\\":\\\"HTTP code: 404\\\"},\\\"error\\\":\\\"HTTP code: 404\\\"}\"}\n```\n"},{"labels":["api"],"text":"When calling the `build` endpoint (in 1.12), the returned string is a sequence of json objects rather than a json array.  This causes problems when using some generic http libraries, which detect the content type (sent as \"application/json\") and parse the response body automatically, causing them to return only the first json object or to report an error.\n\nExample response:\n\n``` json\n{\"stream\":\"Step 1...\"}\n{\"stream\":\"...\"}\n{\"error\":\"Error...\", \"errorDetail\":{\"code\": 123, \"message\": \"Error...\"}}\n```\n\nValid json would be:\n\n``` json\n[{\"stream\":\"Step 1...\"},\n {\"stream\":\"...\"},\n {\"error\":\"Error...\", \"errorDetail\":{\"code\": 123, \"message\": \"Error...\"}}]\n```\n"},{"labels":["api",null],"text":"Using gradle-docker I have the option of using either the REST API to build an image or the `docker` command line tool.  When I choose the REST API option I am able to create images tagged with capital letters.  However, when I attempt the same operation using the client I see:\n\n```\nCommand line [docker build -t tc.you.pds/dropwizardBase /home/ubuntu/github.com/pds-deployment/common/build/docker/dropwizardBase] returned:\n  2014/07/10 23:58:25 Invalid repository name (dropwizardBase), only [a-z0-9-_.] are allowed\n```\n\nWhile I'm not sure I completely understand why capital letters are forbidden, at the very least it seems that the behavior should be consistent.\n"},{"labels":["api"],"text":"This is an edge case, but it should be more consistent on the returns of an out-of-sync client and server.  `docker build` seems to run regardless of version difference.  `docker run` just silently fails because it tries to fetch from the index.  `docker images` finally gives an error that should have been encountered on the first interaction with the docker server.\n\nOutput of the three commands (when docker client was 1.13 and server was 1.12):\n\n``` console\n$ docker build -t infosiftr/jbilling .\nSending build context to Docker daemon 328.6 MB\nSending build context to Docker daemon \nStep 0 : FROM java\n ---> f14d9b4cde6f\nStep 1 : ADD jbilling-community-3.1.0/ /usr/local/jbilling/\n ---> Using cache\n ---> 1520b79e1eb8\nStep 2 : WORKDIR /usr/local/jbilling/bin\n ---> Running in 0036197d8bfc\n ---> 9085b16f76c5\nRemoving intermediate container 0036197d8bfc\nStep 3 : RUN chmod +x *.sh\n ---> Running in 81604d05b1a5\n ---> 9f7f442c623c\nRemoving intermediate container 81604d05b1a5\nStep 4 : CMD [\"./startup.sh\"]\n ---> Running in ef39f2dc039e\n ---> 85cf958acdf1\nRemoving intermediate container ef39f2dc039e\nSuccessfully built 85cf958acdf1\n$ docker run -it --rm --name jbill infosiftr/jbilling\nUnable to find image 'infosiftr/jbilling' locally\nPulling repository infosiftr/jbilling\n2014/07/07 15:49:41 HTTP code: 404\n$ docker images\n2014/07/07 15:49:56 Error response from daemon: client and server don't have same version (client : 1.13, server: 1.12)\n```\n\nRelevant version stuffs (after restarting docker server):\n\n``` console\n$ docker version\nClient version: 1.1.0\nClient API version: 1.13\nGo version (client): go1.3\nGit commit (client): 79812e3\nServer version: 1.1.0\nServer API version: 1.13\nGo version (server): go1.3\nGit commit (server): 79812000\n$ docker -D info\nContainers: 2\nImages: 188\nStorage Driver: btrfs\nExecution Driver: native-0.2\nKernel Version: 3.12.21-gentoo-r1\nDebug mode (server): false\nDebug mode (client): true\nFds: 10\nGoroutines: 10\nEventsListeners: 0\nInit SHA1: 51b8dd8c22b5c2bbfdc550b0a6bb1cb2df838169\nInit Path: /usr/libexec/docker/dockerinit\nSockets: [unix:///var/run/docker.sock]\n$ uname -a\nLinux minas-morgul 3.12.21-gentoo-r1 #1 SMP Fri Jun 6 15:17:15 MDT 2014 x86_64 AMD Phenom(tm) II X6 1090T Processor AuthenticAMD GNU/Linux\n```\n"},{"labels":["api"],"text":"Sent a POST /container/create with an empty body.. Its sending HTTP 500 (server error) back, which isn't correct imho.\n\nShould send something like bad request.\n\nI'd like to help. Where can this be fixed?\n"},{"labels":["api",null,null],"text":"As an initial use-case, this would allow `docker images --help` to show the user supported parameters for the --filter flag. Though this API could allow for other similar use-cases.\n\nSee some conversation on https://github.com/dotcloud/docker/pull/6162\n"},{"labels":["api"],"text":"Hi,\n\nthe Docker cli supports image names like `<registry>:<port>/<image>:<tag>`. This established a common pattern to specify images like that.\nSince Docker only parse the registry when providing ImageSrc parameter but requires the tag as additional parameter, pretty much all docker clients need to implement the parsing. I was about to add this to kubernetes.\nThis is not only bad because the duplicated work but even pushes out the interpretation of that string to clients which might cause lots of confusing in case this will ever change.\n"},{"labels":["api"],"text":"The docs don't make it very clear that this endpoint does two things which require two different set of parameters:\n- Pull from registry: fromImage, tag\n- Create from local file: fromSrc, repo\n\nAnd it's unclear/undefined what happens if fromImage or repo includes a tag.\n\nBeside that, fromImage and repo are both image names ('fully qualified' if you want). Calling them 'image' here but 'repo' there is confusing.\nGuess it's up for discussion if the api should be changed, but at least this should get documented.\n\nAnother thing are the responses: What happens if another client is already pulling an image? Which response code will it return?\n"},{"labels":["api"],"text":"When the command is parseable as JSON, the resulting JSON type is returned by inspect and API.\n\nExample: `true` converted to boolean\n\n```\n$ docker run busybox true; docker inspect `docker ps -l -q` | grep \\\"Path\\\"\n    \"Path\": true,\n```\n\nExample: `99` converted to a number\n\n```\n$ docker run busybox 99; docker inspect `docker ps -l -q` | grep \\\"Path\\\"\n    \"Path\": 99,\n```\n\nExample: `{\"a\": \"map\"}` converted to a Hash (for fun)\n\n```\n$docker run busybox '{\"a\": \"map\"}'; docker inspect `docker ps -l -q` | grep -A 2 \\\"Path\\\"\n    \"Path\": {\n        \"a\": \"map\"\n    },\n```\n"},{"labels":["api"],"text":"While trying to automatically digest the api with ActiveRecord I ran into an issue with the number first hash keys. rails/activeresource#138\n\n```\n\"Ports\":{\n  \"4500/tcp\":[\n    {\n      \"HostIp\":\"0.0.0.0\",\n      \"HostPort\":\"4500\"\n    }\n  ]\n}\n```\n\nIt seems to me that ActiveRecord is/will not be the only thing thats going to have this issue. While this will not effect everything, I do think its of some importance to have an API layer that is easily digestible and programmatically object mappable. \n\nSomething kinda like this?\n\n```\n\"Ports\":{\n  \"tcp\":[\n    {\n      \"SourcePort\":\"4500\",\n      \"HostIp\":\"0.0.0.0\",\n      \"HostPort\":\"4500\"\n    }\n  ]\n}\n```\n"},{"labels":["api",null,null,null],"text":"Systemd does a lot of stuff.  Docker does a lot of stuff.  That stuff may or may not overlap.  I don't really care.  I just need to solve one very specific problem.  I just need a sane way to launch Docker containers in a systemd environment as a system service.  As it stands today, the only way I know how is to do `docker start -a` or `docker run ...` without `-d`.  Then dockerd launches the container in the background and systemd essentially monitors the docker client.  Two problems with this.  First, whether or not the docker client is running says very little about whether the actual container is running.  Second, I'm left with a rather large `docker run` process in memory that's not providing much value except to stream stdout/stderr to journald.\n\nSo I hacked up the below script to make things better, or really just to see if it was possible to make things better since the script is just a dirty hack.  You don't really need to read the script, just skip down and I'll explain what it does.\n\n``` bash\n#!/bin/bash\nset -e\n\nID=$(/usr/bin/docker \"$@\")\nPID=$(docker inspect -f '{{.State.Pid}}' $ID)\n\ndeclare -A SRC DEST\n\nfor line in $(grep slice /proc/$PID/cgroup); do\n        IFS=: read _ NAME LOC <<< \"$line\"\n        SRC[${NAME##name=}]=$LOC\ndone \n\nfor line in $(grep slice /proc/$$/cgroup); do\n        IFS=: read _ NAME LOC <<< \"$line\"\n        DEST[${NAME##name=}]=$LOC\ndone\n\nfor type in ${!SRC[@]}; do\n        from=/sys/fs/cgroup/${type}${SRC[$type]}\n        to=/sys/fs/cgroup/$type/\"${DEST[$type]}\"/$(basename \"${SRC[$type]}\")\n\n        echo $from \"=>\" $to\n        mkdir -p $to\n        for p in $(<$from/cgroup.procs); do\n                echo $p > $to/cgroup.procs\n        done\ndone\n\necho $PID > /var/run/test.pid\n```\n\nThen I wrote the following unit file\n\n```\n[Unit]\nDescription=My Service\nAfter=docker.service\nRequires=docker.service\n\n[Service]\nExecStart=/opt/bin/docker-wrapper.sh run -d busybox /bin/sh -c \"while true; do echo Hello World; sleep 1; done\"\nType=forking\nPIDFile=/var/run/test.pid\n\n[Install]\nWantedBy=multi-user.target\n```\n\nSo what this does (and I know it's a hack, but I wanted to see if my proposal has any chance of working) is that after the container is launched, I look up the PID of the container and all of its cgroups.  I then create child cgroups of the systemd cgroups and then move the PIDs from the original cgroups to the systemd child cgroups.  After that is done I then write the PID of the container to a file.  I end up with systemd cgroups being the parent, then a child cgroup under that.  Looking something like below\n\n```\n  ‚îú‚îÄtest.service\n  ‚îÇ ‚îî‚îÄdocker-8a0ff7503e0fca4f44d48f76a24cbcae82079818e3ad4d0d707ccf5765698184.scope\n  ‚îÇ   ‚îú‚îÄ19103 /bin/sh -c while true; do echo Hello World; sleep 1; done\n  ‚îÇ   ‚îî‚îÄ19169 sleep 1\n```\n\nAlso, since I told systemd to use a PIDFile, systemd is monitoring the PID 1 of the container because I wrote it to a file.   So now if I do either `docker stop` or `systemctl stop` things just work (at least they seem to do) and I don't have a useless docker client hanging around in memory  Now if you look at the script, you'll notice I'm just moving the PIDs, not the settings, so yeah, total hack that defeats the purpose of the original cgroup, but that's not the point right now.\n\nHere's what I propose to make systemd and docker integration a tad bit better.  When you want to run docker in a systemd unit you run `docker run/start --yo-dawg-use-my-cgroups-as-your-parent ...` which will read the current `/proc/$$/cgroup` of the client and pass it to dockerd.  Dockerd now just creates its cgroups as a child of the cgroups passed in, if the subsystem exists.  I think this means we can remove the systemd cgroup code and just use the cgroup fs based code (but docker will still have to write to the name=systemd fs).  So now systemd can setup the parent cgroups however it wishes and Docker can setup the child cgroups how ever it wishes.\n\nIs this the best solution?  Probably not.  But it seems a lot better than what we have today and it solves a current pain point.\n\nIs this just plain stupid or already been thought of and shot down?\n"},{"labels":["api",null],"text":"The current Remote API has a number issues (#5722, #5278, #2786, #3037, #1011, #3622, #2949, etc) that make it award to use. I propose that the following issues be addressed in a new version of the API. This new API will breaking but I believe going forward the benefit of these changes will outweigh the cost IMHO. \n1. Change POST request that don't have payload to GET requests.\n2. Utilize Server-Side-Events for blocking operations and use JSON data for event data.\n3. Standardize error response and return a JSON object that encapsulates error messages.\n4. Avoid using \"/json\" in request URL and instead rely on \"Accept\" header.\n5. Return appropriate Content-Type header information.\n6. Use \"camelCase\" or \"PascalCase\" for JSON property names but not both.\n7. For PascalCase, two letter property names should not be capitalized (Change \"ID\" to \"Id\", and \"OS\" to \"Os\"). Doing so would make the JSON easier to process.\n8. Stream content type should be specific. If returning octet-stream that's a gzip file then use \"application/gzip) ([RFC 6713](http://www.rfc-editor.org/rfc/rfc6713.txt))\n9. Break the Remote API documentation page into smaller pages.\n10. Add JSON schema definitions for JSON objects.\n11. Add HATEOAS support?\n\nI have started a new repository [wiki page](https://github.com/saden1/docker-api/wiki) to track this proposal. I have also done a first take on revamping the List Containers request and would love feedback. \n\nhttps://github.com/saden1/docker-api/wiki/List-Containers\n\nIs this something the docker team is interested in doing?\n"},{"labels":["api",null,null],"text":"1. The \"/images/create\" request is a POST request but nothing is actually being posted. Either change the query parameters into JSON post payload for or change the request type to a GET request.\n2. The first chunk of the response contains a status JSON data that ends with \"\\r\\n\" but subsequent chunks don't end with a new line character therefore making difficult to parse the response. Bellow is the raw response I am seeing:\n   \n   ``` json\n   {\"status\":\"Pulling repository base\"}\\r\\n\n   {\"status\":\"Pulling image (ubuntu-quantl) from base\",\"progressDetail\":{},\"id\":\"b750fe79269d\"}{\"status\":\"Pulling image (ubuntu-quantl) from base, endpoint: https://cdn-registry-1.docker.io/v1/\",\"progressDetail\":{},\"id\":\"b750fe79269d\"}{\"status\":\"Pulling dependent layers\",\"progressDetail\":{},\"id\":\"b750fe79269d\"}{\"status\":\"Download complete\",\"progressDetail\":{},\"id\":\"27cf78414709\"}{\"status\":\"Download complete\",\"progressDetail\":{},\"id\":\"b750fe79269d\"}{\"status\":\"Download complete\",\"progressDetail\":{},\"id\":\"b750fe79269d\"}\n   ```\n3. The \"/images/create\" response property names don't conform to the general pascal casing used by Docker Remote API. Change response to conform to this casing:\n   \n   ``` json\n   {\"Status\":\"Pulling blah\", \"Error\": \"blah\", \"ProgressDetail\": \"blah\" }\n   ```\n4. The \"/images/create\" is a blocking operation that could take some time. Instead of blocking you should utilize command/query pattern for the request. The create image request should return a token/id for the request and allow the user to query the status of the request. Break the API down to:\n   \n   ```\n   Request:  \"/images/create\"\n   Response: \"{\"Status\": \"Creating Image ....\", \"Id\": \"abc\", \"Error\": [true|false]}\"\n   ```\n   \n   ```\n   Request: \"/images/create/status?Id=abc\n   Response: \"[\n     {\"Status\": \"Creating Image ....\", \"Id\": \"abc\", \"Error\": [true|false]}\n   ]\"\n   ```\n"},{"labels":["api",null],"text":"http://docs.docker.io/en/latest/reference/api/docker_remote_api_v1.10/#tag-an-image-into-a-repository\n\nDoesn't describe how to set the tag on the image...just allows you to provide the image repo.\n"},{"labels":["api",null],"text":"When retrieving the logs for a container that had output a long line with no breaks the `docker logs` command will either crash or hang. \n\nThe `echo $(printf '=%.0s' {1..1000})` command was run to output a string of characters of varying lengths. The threshold seems to be around the size of a 16-bit signed integer. Running the following commands work as expected:\n\n``` no-highlight\n$ docker run -d ubuntu echo $(printf '=%.0s' {1..32768})\n$ docker logs <container_id>\n============================================....<32768 times>\n```\n\nIncreasing the number of characters by one results in the following error:\n\n``` no-highlight\n$ docker run -d ubuntu echo $(printf '=%.0s' {1..32769})\n$ docker logs <container_id>\n\npanic: runtime error: makeslice: len out of range\n\ngoroutine 6 [running]:\nruntime.panic(0x9e5da0, 0x12e9800)\n        /usr/local/go/src/pkg/runtime/panic.c:266 +0xb6\ngithub.com/dotcloud/docker/utils.StdCopy(0x7f9eb72d4168, 0xc210000008, 0x7f9eb72d4168, 0xc210000010, 0x7f9eb72d5cd8, ...)\n        /go/src/github.com/dotcloud/docker/utils/stdcopy.go:116 +0x348\ngithub.com/dotcloud/docker/api.func¬∑015(0x0, 0x0)\n        /go/src/github.com/dotcloud/docker/api/client.go:2250 +0x1da\ngithub.com/dotcloud/docker/utils.func¬∑002()\n        /go/src/github.com/dotcloud/docker/utils/utils.go:38 +0x2e\ncreated by github.com/dotcloud/docker/utils.Go\n        /go/src/github.com/dotcloud/docker/utils/utils.go:39 +0xa7\n\ngoroutine 1 [chan receive]:\ngithub.com/dotcloud/docker/api.(*DockerCli).hijack(0xc2100468c0, 0xa759a0, 0x4, 0xc210046070, 0x6c, ...)\n        /go/src/github.com/dotcloud/docker/api/client.go:2276 +0x98a\ngithub.com/dotcloud/docker/api.(*DockerCli).CmdLogs(0xc2100468c0, 0xc21000a020, 0x1, 0x1, 0x0, ...)\n        /go/src/github.com/dotcloud/docker/api/client.go:1565 +0x934\nreflect.callMethod(0xc2100b92a0, 0x7f9eb7134ab8)\n        /usr/local/go/src/pkg/reflect/value.go:676 +0x17b\nreflect.methodValueCall(0xc21000a020, 0x1, 0x1, 0xc2100b92a0, 0x7f9eb72d4101)\n        /usr/local/go/src/pkg/reflect/asm_amd64.s:26 +0x24\ngithub.com/dotcloud/docker/api.ParseCommands(0xc2100bb120, 0x4, 0xc2100bb127, 0x14, 0xc21000a010, ...)\n        /go/src/github.com/dotcloud/docker/api/client.go:69 +0x31f\nmain.main()\n        /go/src/github.com/dotcloud/docker/docker/docker.go:151 +0x1f5f\n\ngoroutine 3 [syscall]:\nos/signal.loop()\n        /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e\ncreated by os/signal.init¬∑1\n        /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x31\n```\n\nIncreasing the number of characters by more than a few causes the command to hang:\n\n``` no-highlight\n$ docker run -d ubuntu echo $(printf '=%.0s' {1..33000})\n$ docker logs <container_id>\n...does not return\n```\n### Additional details\n\n``` no-highlight\nOperating System: Ubuntu 12.04\n\n$ uname -a \nLinux macbuntu 3.11.0-18-generic #32~precise1-Ubuntu SMP Thu Feb 20 17:52:10 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\n\n$ docker version\nClient version: 0.9.0\nGo version (client): go1.2.1\nGit commit (client): 2b3fdf2\nServer version: 0.9.0\nGit commit (server): 2b3fdf2\nGo version (server): go1.2.1\nLast stable version: 0.9.0\n\n$ docker info\nContainers: 138\nImages: 58\nDriver: aufs\n Root Dir: /var/lib/docker/aufs\n Dirs: 334\nUsername: asheehan\nRegistry: [https://index.docker.io/v1/]\nWARNING: No swap limit support\n```\n"},{"labels":["api"],"text":"Running 0.9 on ubuntu precise:\n\nIf I link a container to another, the env gets set properly (and connectivity works) but the `Links` attribute is `null`:\n\n```\n$ docker run -d -p 1234 --name backend ubuntu sleep 3600\nc08bd8d09cb44b202910b21aeb0d6c9d2450ed441481e57c7cfa8a78c529a4c0\n\n$ docker run -d --link backend:be --name frontend ubuntu /bin/sh -c 'env; sleep 3600'\nfb14354e907d2054c0878d5bbca3bab0b72a61a3b4af47f9172d14e60ac8f47b\n\n$ docker inspect backend|grep Links\n        \"Links\": null,\n\n$ docker inspect frontend|grep Links\n        \"Links\": null,\n\n$ docker logs frontend\nBE_PORT_1234_TCP_PORT=1234\nBE_PORT_1234_TCP_PROTO=tcp\nHOSTNAME=fb14354e907d\nHOME=/\nBE_PORT_1234_TCP=tcp://172.17.0.2:1234\nBE_PORT=tcp://172.17.0.2:1234\nBE_NAME=/frontend/be\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nPWD=/\nBE_PORT_1234_TCP_ADDR=172.17.0.2\n```\n\nDuring my tests, I could restarting the container as well as docker and the env still get restored as expected. Even after stopping the 'frontend', restarting docker, starting it again everything seemed fine from a user perspective. BUT I found this issues because I'm still investigating why some containers have lost their links by just restarting them. So this might be related but I'm still looking.\n"},{"labels":["api"],"text":"I have a docker host running 0.8.1 with devicemapper backend on 3.8 ubuntu precise and get this on the containers/json endpoint:\n\n```\n{\n  \"Status\": \"Exit 0\",\n  \"Ports\": [],\n  \"Names\": [\n    \"/sharp_brattain\"\n  ],\n  \"Image\": -9223372036854776000,\n  \"Id\": \"09906a9649d279dc7991dd1e58dbdcc372f9f9e14304549628fbcef21c398785\",\n  \"Created\": 1392262739,\n  \"Command\": \"/bin/sh -c #(nop) CMD [sh -c /docker-registry/test/dockertest.sh]\"\n},\n```\n\nImage is \"-9223372036854776000\" (hex: -0x80000000000000c0L), but `docker inspect` (or`curl /containers/09906a9649d279dc7991dd1e58dbdcc372f9f9e14304549628fbcef21c398785/json`) shows the correct image hash:\n\n```\n...\n\"Image\": \"228745108e70710d07397eb1ba7fded83e144bf2190edfad3296efe955b56f10\",\n...\n```\n"},{"labels":["api"],"text":"When a client using version X of the protocol invokes the remote API, the server returns elements defined in versions greater than X.   Some clients may break due to unexpected elements in the response.\n\nFor example, the HostConfig element of the 'inspect' response is new to 1.8.  Yet a request for 1.7 unexpectedly returns the HostConfig element.  e.g. the below will contain HostConfig:\ncurl http://127.0.0.1:4243/v1.7/containers/CONTAINERID/json\n\nThis is the only example of the issue that I've noticed.   I filed the bug to raise the design question - i.e. is docker open- or closed-schema by design?\n"},{"labels":["api"],"text":"If you have containers with cmd \"true\" and get a list of all containers from the API, the string \"true\" gets converted to true:\n\n```\n$ curl http://192.168.100.64:4243/containers/json?all=1|grep -i true\n[{\"Command\":true,\"Created\":1394217266,\"Id\":\"2f6343c95930e4e9b6ef065478a03112b11a6ab1ddea58cecfc022fa8702218f\",\"Image\":\"busybox:latest\",\"Names\":[\"/high_euclid7\"],\"Ports\":[],\"Status\":\"Exit 0\"},\n....\n```\n\nIt seems like the same error doesn't happen with the /containers/<id>/json endpoint, this one correctly keeps it as a string.\n\nUbuntu running docker 0.8.1 both server and client.\n"},{"labels":["api",null,null],"text":"Since I can't seem to figure out how to add this support, here's the idea:\n\nIt would be great if the /info endpoint would include any data related to the following:\n- BridgeIface\n- BridgeIP\n- BridgeNetwork\n- BridgeNetmask\n\nGiven the fact that both BridgeIface and BridgeIP are represented in config.go, I figure this is doable. From there, I'd assume the remaining attributes could be determined and published.\n"},{"labels":["api"],"text":"You can reproduce by listening on the events api\n`docker run busybox sh`\nexit out of the container\nno event is sent for the stop, kill, die or whatever\n"},{"labels":["api",null],"text":"Right now the docker push command has lots of great output when using the CLI, but sometimes you don't need that much information, like when you are scripting something, or you are using the API. When this happens it would be nice if there was a  less verbose output that you could use. Docker build already has a similar command, so maybe we can use something similar.\n\n/cc @vieux \n"},{"labels":["api"],"text":"As far as I know there's no way to do this; it would be nice to be able to say something like:\n\n```\n$ docker commit /home/me/foo/\n```\n\nto commit only the changes under that directory.\n"},{"labels":["api"],"text":"docker run & pull seem to get random auth errors, see the following :\n\n<pre>\nlsoave@basenode:~$ docker run -i -t ubuntu bash\nUnable to find image 'ubuntu' (tag: latest) locally\nPulling repository ubuntu\n2014/01/03 23:06:59 Authentication is required.\n\nlsoave@basenode:~$ docker pull  ubuntu \nPulling repository ubuntu\nPlease login prior to push:\nLogin against server at https://index.docker.io/v1/\nUsername (lgsd):          \n2014/01/03 23:10:57 Error: Wrong login/password, please try again\n\nlsoave@basenode:~$ docker pull  ubuntu \nPulling repository ubuntu\n8dbd9e392a96: Download complete \nb750fe79269d: Download complete \n27cf78414709: Download complete \n\nlsoave@basenode:~$ docker images\nREPOSITORY             TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nubuntu                 12.04               8dbd9e392a96        8 months ago        128 MB\nubuntu                 latest              8dbd9e392a96        8 months ago        128 MB\nubuntu                 precise             8dbd9e392a96        8 months ago        128 MB\nubuntu                 12.10               b750fe79269d        9 months ago        175.3 MB\nubuntu                 quantal             b750fe79269d        9 months ago        175.3 MB\n\nlsoave@basenode:~$ docker version\nClient version: 0.7.2\nGo version (client): go1.2\nGit commit (client): 28b162e\nServer version: 0.7.2\nGit commit (server): 28b162e\nGo version (server): go1.2\nLast stable version: 0.7.2\n\n</pre>\n\n\nPlease note that on the second `docker pull  ubuntu` it didn't ask me for any password, just get the images silently.\n"},{"labels":["api",null],"text":"I'm trying to use the docker remote API to build images/containers, referring to the document:  http://docs.docker.io/en/latest/api/docker_remote_api_v1.7/\n\nI was unable to find information on  \"ExposedPorts\" for creating a container and \"PortBindings\" for starting a container.\n\nThere is no such parameter \"ExposedPorts\" for the creating a container and\nthere is no parameter \"PortBindings\" for starting a container.\n"},{"labels":["api"],"text":"Hi,\n\nRunning docker 0.6.7 on Ubuntu 13.04.\n\nI built a container whose CMD executes a uwsgi process (also tried with other executables). I run without detaching, and sigproxy is True.\n\nHitting Ctrl-C seems to have no effect over the running container and the only way to leave it or kill it is with `docker kill` and `docker stop`...\n\nIs this a known issue?\n"},{"labels":["api"],"text":"I'm using Ruby gem  'docker-api' with a Docker daemon running on a remote server.\n\nI ran into timeout issue when I want to get output from running a command inside the container.  \n# create an image\n\nimage = Docker::Image.create('fromImage'=>'base')\n# insert a local file into the image\n\nimage.insert_local('localPath'=>['/root/docker_scripts/install_prereqs.sh', '/root/docker_scripts/weaver_script.sh'], 'outputPath'=>'/tmp/')   \n# get the image id from the response\n\nimage_data = eval(\"image.json\")\nputs image.json\nimage_id = image_data[\"id\"]\ninputs = Hash.new\ninputs[\"Image\"] = image_id\ninputs[\"Cmd\"] = ['ls -al']\n# create a container with the image id and the command 'ls -al'\n\nmyContainer = Docker::Container.create(inputs)\n# start the container and stream the output\n\nmyContainer.tap(&:start).attach {|stream,chunk| puts \"#{stream}: #{chunk}\"}\n\nRESPONSE: \nread time out reached\n.docker_9f738e00-3424-0131-e558-525400c6ff8e [Status: failed]\n"},{"labels":["api"],"text":"I'm scripting Docker, but basically you can reproduce this by programmatically `fork/exec`ing `docker attach` with a stdin you write to once immediately after starting the process then closing it.\n\nThe strace when you write to stdin right away:\n\n```\nProcess 6134 attached\nread(0,\n```\n\nJust hangs reading stdin, forever.\n\nThe strace when you **add a 5 second sleep before writing**:\n\n![lol](https://dl.dropbox.com/s/67xmmvpfd5tca7l/1._vagrantpackervmware__ssh_20131108_235501.png)\n\nAs you can see, it worked.\n\nCrazy, but I think you have a race condition in reading the stdin somewhere.\n"},{"labels":["api"],"text":"Picture shows it. I did this manually here but in practice I'm actually doing this as fast as it'll go programmatically. It runs into a lot of problems of just randomly NOT executing my command.\n\nThe container was run with: `docker run -d -i -t -v '/tmp:/host' ubuntu /bin/bash`\n\n![lol](https://dl.dropbox.com/s/i5plrv7n3094mqh/1._vagrantpackervmware__bash_20131108_224427.png)\n"},{"labels":["api"],"text":"Going by the [remote API docs](http://docs.docker.io/en/latest/api/docker_remote_api_v1.6/), containers should respond with an `Id` key in their objects. In 0.6.4, the case of `Id` seems to be inconsistent amongst calls (e.g. create returns `Id`, inspect returns `ID`).\n\nFrom a cursory glance of master, it seems to fix this inconsistency so `ID` is always returned (though I haven't tested this) but the docs still seem to be out of date. Is `ID` the preferred case?\n"},{"labels":["api"],"text":"I use the API/1.5 to handle docker issues.And i need to start many different dockers with port direction(localhost:hostPort==>dockerInnerIP:GuestPort),every second time the operation will must be fail, the Error description in my application reports that the connection to localhost:hostPort is reset by peer,it seems that the port direction doesn't works well?\n"},{"labels":["api",null,null,null,null],"text":"Use case: mount a volume from host to container for use by apache as www user.\nThe problem is currently all mounts are mounted as root inside the container.\nFor example, this command\n docker run -v /tmp:/var/www ubuntu stat -c \"%U %G\" /var/www\nwill print \"root root\"\n\nI need to mount it as user www inside the container.\n"},{"labels":["api"],"text":"When requesting a listing of filesystem changes (/containers/(container id)/changes) from a container that has no current changes, the response is `null`. This violates [RFC 4627](http://www.ietf.org/rfc/rfc4627.txt), which requires the root of a JSON document to be either an object or an array.\n"},{"labels":["api"],"text":"currently, docker only support 'run' command; \nbut sometimes, we need a 'create' command to create a container only, and we can use 'start' command to start it later.\n\nI'm not sure wheather this is reasonable?\n"},{"labels":["api",null],"text":"During Docker Hack Day we discussed options around Docker having the ability to automatically attach to all containers and provide their output to a single stream that can then be sent to an external service such as syslog.\n\nA couple of scenarios came about:\n- leave it up to a client application to attach to the streams; but this needs to be done with care in order to not lose any output between starting the container and attaching to the log stream\n- implement the logic within docker; but how to provide it in a general enough way so it can be used for miscellaneous use-cases\n\nAdditionally, Docker has two facilities for getting information: `events` and `attach`.  The `events` command output appears to be for logging docker actions and `attach` appears to be for output generated by the containerized application.  Is extending attach the right place for this feature?\n\nFinally, attaching to `stdin` doesn't seem to apply here, should \"attach all\" explicitly exclude stdin?\n\nPlease share your thoughts.\n\nThanks!\n"},{"labels":["api"],"text":"This is using \"Docker version 0.6.1, build 5105263\". A machine I was running Docker on ran out of disk space (due to an application suddenly starting to write tons of data to STDOUT, which filled up docker's logs). Afterwards, the Docker service showed all containers in \"Ghost\" state, but querying one of the containers for gives a different containers' data: Slightly anonymized data:\n\n```\n# docker -H 127.0.0.1:4243 inspect c93c9275ee208469539ada5490e5d2aac22a12176e2e054b5dd86381f6e506b4\n[{\n    \"ID\": \"c93c9275ee208469539ada5490e5d2aac22a12176e2e054b5dd86381f6e506b4\",\n    \"Created\": \"2013-09-26T01:55:12.659262553Z\",\n    \"Path\": \"ipython\",\n    \"Args\": [\n        \"notebook\",\n        \"--ip='*'\",\n        \"--profile=julia\"\n    ],\n    \"Config\": {\n        \"Hostname\": \"c93c9275ee20\",\n        \"User\": \"\",\n        \"Memory\": 0,\n        \"MemorySwap\": 0,\n        \"CpuShares\": 0,\n        \"AttachStdin\": true,\n        \"AttachStdout\": true,\n        \"AttachStderr\": true,\n        \"PortSpecs\": [\n            \"8998\"\n        ],\n        \"Tty\": true,\n        \"OpenStdin\": true,\n        \"StdinOnce\": false,\n        \"Env\": [\n            \"HOME=/\",\n            \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n        ],\n        \"Cmd\": [\n            \"ipython\",\n            \"notebook\",\n            \"--ip='*'\",\n            \"--profile=julia\"\n        ],\n        \"Dns\": null,\n        \"Image\": \"julia-container\",\n        \"Volumes\": {\n            \"/files\": {}\n        },\n        \"VolumesFrom\": \"\",\n        \"WorkingDir\": \"/files\",\n        \"Entrypoint\": null,\n        \"NetworkDisabled\": false,\n        \"Privileged\": false\n    },\n    \"State\": {\n        \"Running\": true,\n        \"Pid\": 7353,\n        \"ExitCode\": 0,\n        \"StartedAt\": \"2013-09-26T01:55:12.670801169Z\",\n        \"Ghost\": true\n    },\n    \"Image\": \"25c106e096be4c09540fabd2a7b41ae65aa8c4ff4c56881089bde7e38e689008\",\n    \"NetworkSettings\": {\n        \"IPAddress\": \"172.17.0.30\",\n        \"IPPrefixLen\": 16,\n        \"Gateway\": \"172.17.42.1\",\n        \"Bridge\": \"docker0\",\n        \"PortMapping\": {\n            \"Tcp\": {\n                \"8998\": \"49182\"\n            },\n            \"Udp\": {}\n        }\n    },\n    \"SysInitPath\": \"/usr/bin/docker\",\n    \"ResolvConfPath\": \"/etc/resolv.conf\",\n    \"Volumes\": {\n        \"/files\": \"/home/ubuntu/files/XXX\"\n    },\n    \"VolumesRW\": {\n        \"/files\": true\n    }\n```\n\nHowever, looking at the config.json file:\n\n```\n cat /var/lib/docker/containers/c93c92ee208469539ada5490e5d2aac22a12176e2e054b5dd86381f6e506b4/config.json\n{\"ID\":\"c93c9275ee208469539ada5490e5d2aac22a12176e2e054b5dd86381f6e506b4\",\"Created\":\"2013-09-26T01:55:12.659262553Z\",\"Path\":\"ipython\",\"Args\":[\"notebook\",\"--ip='*'\",\"--profile=julia\"],\"Config\":{\"Hostname\":\"c93c9275ee20\",\"User\":\"\",\"Memory\":0,\"MemorySwap\":0,\"CpuShares\":0,\"AttachStdin\":true,\"AttachStdout\":true,\"AttachStderr\":true,\"PortSpecs\":[\"8998\"],\"Tty\":true,\"OpenStdin\":true,\"StdinOnce\":false,\"Env\":[\"HOME=/\",\"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"],\"Cmd\":[\"ipython\",\"notebook\",\"--ip='*'\",\"--profile=julia\"],\"Dns\":null,\"Image\":\"julia-container\",\"Volumes\":{\"/files\":{}},\"VolumesFrom\":\"\",\"WorkingDir\":\"/files\",\"Entrypoint\":null,\"NetworkDisabled\":false,\"Privileged\":false},\"State\":{\"Running\":true,\"Pid\":7353,\"ExitCode\":0,\"StartedAt\":\"2013-09-26T01:55:12.670801169Z\",\"Ghost\":false},\"Image\":\"25c106e096be4c09540fabd2a7b41ae65aa8c4ff4c56881089bde7e38e689008\",\"NetworkSettings\":{\"IPAddress\":\"172.17.0.18\",\"IPPrefixLen\":16,\"Gateway\":\"172.17.42.1\",\"Bridge\":\"docker0\",\"PortMapping\":{\"Tcp\":{\"8998\":\"49170\"},\"Udp\":{}}},\"SysInitPath\":\"/usr/bin/docker\",\"ResolvConfPath\":\"/etc/resolv.conf\",\"Volumes\":{\"/files\":\"/home/ubuntu/files/XXX\"},\"VolumesRW\":{\"/files\":true}}\n```\n\nNote that while some of the data is correct (e.g. volume information), the host/port mapping is wrong. In fact that host/port combination belongs to a different container:\n\n```\n# /var/lib/docker/containers/239f51c779b701500cc699585c64c78850f079c89f41de3c5c8583ebb1467a31/config.json\n{\"ID\":\"239f51c779b701500cc699585c64c78850f079c89f41de3c5c8583ebb1467a31\",\"Created\":\"2013-09-26T16:38:07.26415542Z\",\"Path\":\"ipython\",\"Args\":[\"notebook\",\"--ip='*'\",\"--profile=julia\"],\"Config\":{\"Hostname\":\"239f51c779b7\",\"User\":\"\",\"Memory\":0,\"MemorySwap\":0,\"CpuShares\":0,\"AttachStdin\":true,\"AttachStdout\":true,\"AttachStderr\":true,\"PortSpecs\":[\"8998\"],\"Tty\":true,\"OpenStdin\":true,\"StdinOnce\":false,\"Env\":[\"HOME=/\",\"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"],\"Cmd\":[\"ipython\",\"notebook\",\"--ip='*'\",\"--profile=julia\"],\"Dns\":null,\"Image\":\"julia-container\",\"Volumes\":{\"/files\":{}},\"VolumesFrom\":\"\",\"WorkingDir\":\"/files\",\"Entrypoint\":null,\"NetworkDisabled\":false,\"Privileged\":false},\"State\":{\"Running\":true,\"Pid\":13248,\"ExitCode\":0,\"StartedAt\":\"2013-09-26T16:38:07.27774869Z\",\"Ghost\":false},\"Image\":\"25c106e096be4c09540fabd2a7b41ae65aa8c4ff4c56881089bde7e38e689008\",\"NetworkSettings\":{\"IPAddress\":\"172.17.0.30\",\"IPPrefixLen\":16,\"Gateway\":\"172.17.42.1\",\"Bridge\":\"docker0\",\"PortMapping\":{\"Tcp\":{\"8998\":\"49182\"},\"Udp\":{}}},\"SysInitPath\":\"/usr/bin/docker\",\"ResolvConfPath\":\"/etc/resolv.conf\",\"Volumes\":{\"/files\":\"/home/ubuntu/files/YYY\"},\"VolumesRW\":{\"/files\":true}}\n```\n\nIn my tests it seems that the `config.json` file is accurate while the information returned by the docker daemon is not.\n"},{"labels":["api",null],"text":"Due to the implementation of api.go [which reads only](https://github.com/dotcloud/docker/blob/master/api.go#L1106-L1120) `/etc/group`, it is impossible to rely on other auth mechanisms (e.g. LDAP, NIS).\n\n``` go\ngroups, err := ioutil.ReadFile(\"/etc/group\")\nif err != nil {\n        return err\n}\nre := regexp.MustCompile(\"(^|\\n)docker:.*?:([0-9]+)\")\nif gidMatch := re.FindStringSubmatch(string(groups)); gidMatch != nil {\n        gid, err := strconv.Atoi(gidMatch[2])\n        if err != nil {\n                return err\n        }\n        utils.Debugf(\"docker group found. gid: %d\", gid)\n        if err := os.Chown(addr, 0, gid); err != nil {\n                return err\n        }\n}\n```\n\nInstead, the [`getgrnam`](http://man7.org/linux/man-pages/man3/getgrnam.3.html) syscall should be used to determine, whether a `docker` group exists or not.\n\nThe implemenation of [`lookup_unix.go`](http://golang.org/src/pkg/os/user/lookup_unix.go) in the [`user`](http://golang.org/pkg/os/user/) Go package might serve as inspiration on how to do this.\n"},{"labels":["api"],"text":"The project should include a go client lib for the remote api as a first class entity.\n\nIf no one else is working on this, I'd like to tackle this.  I have a branch with some progress on this.\n"},{"labels":["api"],"text":"It'd be sweet to be able to run different commands on the same container. \n\nI think ideally, `docker run IMAGE`, could optionally take a container ID instead. \n\nSometimes the container are built up over time, so one time I'd like to run a server on it, another time, execute a script.\n"},{"labels":["api",null],"text":"Currently when doing a commit on a container to update an image, the configuration the image had is not kept.\n\nI think there should be an option to drop the previous config and a default to keep it.\n"},{"labels":["api"],"text":"GET /containers/json returns objects with an \"Id\" key, but GET /containers/{id}/json returns objects with an \"ID\" key. Should standardize on one way of capitalizing.\n"}]